{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0140, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DDPM(nn.Module):\n",
    "    def __init__(self, num_timesteps):\n",
    "        super(DDPM, self).__init__()\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, 3, padding=1)\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        return self.model(x)\n",
    "\n",
    "    def compute_loss(self, x, t):\n",
    "        noise = torch.randn_like(x)\n",
    "        t = t.view(-1, 1, 1, 1)  # t의 크기를 (batch_size, 1, 1, 1)로 맞춤\n",
    "        noisy_x = x + noise * torch.sqrt(t / self.num_timesteps)\n",
    "        predicted_noise = self.forward(noisy_x, t)\n",
    "        return F.mse_loss(predicted_noise, noise)\n",
    "\n",
    "# 사용 예시\n",
    "model = DDPM(num_timesteps=1000)\n",
    "x = torch.randn(8, 3, 32, 32)  # 8개의 32x32 RGB 이미지\n",
    "t = torch.randint(0, 1000, (8,))  # 각 이미지에 대한 랜덤 타임스텝\n",
    "loss = model.compute_loss(x, t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.89 ms ± 314 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10 -r 10\n",
    "batch_size = 8\n",
    "x = torch.randn(batch_size, 3, 32, 32)  # 8개의 32x32 RGB 이미지\n",
    "t = torch.randint(0, 1000, (batch_size,))  # 각 이미지에 대한 랜덤 타임스텝\n",
    "loss = model.compute_loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0251, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DDIM(nn.Module):\n",
    "    def __init__(self, num_timesteps):\n",
    "        super(DDIM, self).__init__()\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, 3, padding=1)\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        return self.model(x)\n",
    "\n",
    "    def compute_loss(self, x, t):\n",
    "        noise = torch.randn_like(x)\n",
    "        t = t.view(-1, 1, 1, 1)  # t의 크기를 (batch_size, 1, 1, 1)로 맞춤\n",
    "        noisy_x = x + noise * torch.sqrt(t / self.num_timesteps)\n",
    "        predicted_noise = self.forward(noisy_x, t)\n",
    "        return F.mse_loss(predicted_noise, noise)\n",
    "\n",
    "# 사용 예시\n",
    "model = DDIM(num_timesteps=50)\n",
    "x = torch.randn(8, 3, 32, 32)  # 8개의 32x32 RGB 이미지\n",
    "t = torch.randint(0, 50, (8,))  # 각 이미지에 대한 랜덤 타임스텝\n",
    "loss = model.compute_loss(x, t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.57 ms ± 228 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10 -r 10\n",
    "batch_size = 8\n",
    "x = torch.randn(batch_size, 3, 32, 32)  # 8개의 32x32 RGB 이미지\n",
    "t = torch.randint(0, 50, (batch_size,))  # 각 이미지에 대한 랜덤 타임스텝\n",
    "loss = model.compute_loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDPM Sampling Time: 2.9006 seconds\n",
      "torch.Size([8, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "class DDPM(nn.Module):\n",
    "    def __init__(self, num_timesteps):\n",
    "        super(DDPM, self).__init__()\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, 3, padding=1)\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        return self.model(x)\n",
    "\n",
    "    def compute_loss(self, x, t):\n",
    "        noise = torch.randn_like(x)\n",
    "        t = t.view(-1, 1, 1, 1).float()\n",
    "        noisy_x = x + noise * torch.sqrt(t / self.num_timesteps)\n",
    "        predicted_noise = self.forward(noisy_x, t)\n",
    "        return F.mse_loss(predicted_noise, noise)\n",
    "\n",
    "    def ddpm_sampling(self, x_T):\n",
    "        x = x_T\n",
    "        for t in reversed(range(1, self.num_timesteps)):\n",
    "            t_tensor = torch.tensor([t], device=x.device).view(-1, 1, 1, 1).float()\n",
    "            epsilon = self.forward(x, t_tensor)\n",
    "            alpha_t = 1 - t / self.num_timesteps\n",
    "            alpha_t = torch.tensor(alpha_t, device=x.device).view(-1, 1, 1, 1)\n",
    "            x = (x - epsilon * torch.sqrt(1 - alpha_t) / torch.sqrt(alpha_t)) + torch.randn_like(x) * torch.sqrt(1 - alpha_t)\n",
    "        return x\n",
    "\n",
    "# 사용 예시\n",
    "model_ddpm = DDPM(num_timesteps=1000)\n",
    "x_T_ddpm = torch.randn(8, 3, 32, 32)  # 8개의 32x32 RGB 이미지로 시작\n",
    "start_time = time.time()\n",
    "sampled_images_ddpm = model_ddpm.ddpm_sampling(x_T_ddpm)\n",
    "ddpm_time = time.time() - start_time\n",
    "print(f\"DDPM Sampling Time: {ddpm_time:.4f} seconds\")\n",
    "print(sampled_images_ddpm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDIM Sampling Time: 0.1289 seconds\n",
      "torch.Size([8, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "class DDIM(nn.Module):\n",
    "    def __init__(self, num_timesteps, eta=0.):\n",
    "        super(DDIM, self).__init__()\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.eta = eta\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, 3, padding=1)\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        return self.model(x)\n",
    "\n",
    "    def compute_loss(self, x, t):\n",
    "        noise = torch.randn_like(x)\n",
    "        t = t.view(-1, 1, 1, 1).float()\n",
    "        noisy_x = x + noise * torch.sqrt(t / self.num_timesteps)\n",
    "        predicted_noise = self.forward(noisy_x, t)\n",
    "        return F.mse_loss(predicted_noise, noise)\n",
    "\n",
    "    def ddim_sampling(self, x_T):\n",
    "        x = x_T\n",
    "        for t in reversed(range(1, self.num_timesteps)):\n",
    "            t_tensor = torch.tensor([t], device=x.device).view(-1, 1, 1, 1).float()\n",
    "            epsilon = self.forward(x, t_tensor)\n",
    "            alpha_t = 1 - t / self.num_timesteps\n",
    "            alpha_t_1 = 1 - (t - 1) / self.num_timesteps\n",
    "            alpha_t = torch.tensor(alpha_t, device=x.device)\n",
    "            alpha_t_1 = torch.tensor(alpha_t_1, device=x.device)\n",
    "            x = (x - torch.sqrt(1 - alpha_t) * epsilon) / torch.sqrt(alpha_t) * torch.sqrt(alpha_t_1) + torch.sqrt(1 - alpha_t_1 - self.eta) * epsilon\n",
    "        return x\n",
    "\n",
    "# 사용 예시\n",
    "model_ddim = DDIM(num_timesteps=50)\n",
    "x_T_ddim = torch.randn(8, 3, 32, 32)  # 8개의 32x32 RGB 이미지로 시작\n",
    "start_time = time.time()\n",
    "sampled_images_ddim = model_ddim.ddim_sampling(x_T_ddim)\n",
    "ddim_time = time.time() - start_time\n",
    "print(f\"DDIM Sampling Time: {ddim_time:.4f} seconds\")\n",
    "print(sampled_images_ddim.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDPM Sampling Time: 3.4525 seconds\n",
      "torch.Size([8, 3, 32, 32])\n",
      "DDIM Sampling Time: 0.0916 seconds\n",
      "torch.Size([8, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# DDPM 샘플링\n",
    "x_T_ddpm = torch.randn(8, 3, 32, 32)  # 8개의 32x32 RGB 이미지로 시작\n",
    "start_time = time.time()\n",
    "sampled_images_ddpm = model_ddpm.ddpm_sampling(x_T_ddpm)\n",
    "ddpm_time = time.time() - start_time\n",
    "print(f\"DDPM Sampling Time: {ddpm_time:.4f} seconds\")\n",
    "\n",
    "# DDIM 샘플링\n",
    "x_T_ddim = torch.randn(8, 3, 32, 32)  # 8개의 32x32 RGB 이미지로 시작\n",
    "start_time = time.time()\n",
    "sampled_images_ddim = model_ddim.ddim_sampling(x_T_ddim)\n",
    "ddim_time = time.time() - start_time\n",
    "print(f\"DDIM Sampling Time: {ddim_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDPM Sampling Time: 15.5073 seconds\n",
      "DDIM Sampling Time: 0.4360 seconds\n",
      "================================================================================\n",
      "DDIM이 DDPM보다 35.57배 빠릅니다\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# DDPM 샘플링\n",
    "x_T_ddpm = torch.randn(100, 3, 32, 32)  # 100개의 32x32 RGB 이미지로 시작\n",
    "start_time = time.time()\n",
    "sampled_images_ddpm = model_ddpm.ddpm_sampling(x_T_ddpm)\n",
    "ddpm_time = time.time() - start_time\n",
    "print(f\"DDPM Sampling Time: {ddpm_time:.4f} seconds\")\n",
    "\n",
    "# DDIM 샘플링\n",
    "x_T_ddim = torch.randn(100, 3, 32, 32)  # 100개의 32x32 RGB 이미지로 시작\n",
    "start_time = time.time()\n",
    "sampled_images_ddim = model_ddim.ddim_sampling(x_T_ddim)\n",
    "ddim_time = time.time() - start_time\n",
    "print(f\"DDIM Sampling Time: {ddim_time:.4f} seconds\")\n",
    "\n",
    "print('='*80)\n",
    "print(f'DDIM이 DDPM보다 {ddpm_time / ddim_time:.2f}배 빠릅니다')\n",
    "print('='*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
