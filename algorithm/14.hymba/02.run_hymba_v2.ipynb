{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4033c2a",
   "metadata": {},
   "source": [
    "# Hymba v2 — Flash/Efficient SDPA, SWA(global+local), KV-share, Meta tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b23d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>attn</th>\n",
       "      <th>kv_owner</th>\n",
       "      <th>kv_share_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LOCAL(SWA)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LOCAL(SWA)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>LOCAL(SWA)</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>LOCAL(SWA)</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>LOCAL(SWA)</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>LOCAL(SWA)</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>LOCAL(SWA)</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>LOCAL(SWA)</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>LOCAL(SWA)</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    layer        attn  kv_owner  kv_share_group\n",
       "0       0      GLOBAL         0               0\n",
       "1       1  LOCAL(SWA)         1               1\n",
       "2       2  LOCAL(SWA)         1               1\n",
       "3       3  LOCAL(SWA)         3               2\n",
       "4       4  LOCAL(SWA)         3               2\n",
       "5       5  LOCAL(SWA)         5               3\n",
       "6       6      GLOBAL         6               4\n",
       "7       7  LOCAL(SWA)         7               5\n",
       "8       8  LOCAL(SWA)         7               5\n",
       "9       9  LOCAL(SWA)         9               6\n",
       "10     10  LOCAL(SWA)         9               6\n",
       "11     11      GLOBAL        11               7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est_cache_mb@512: 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.\n",
      "2025-10-02 00:59:35.219791: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-02 00:59:35.995169: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] loss=8.774 lr=3.00e-06\n",
      "[   50] loss=6.388 lr=1.50e-04\n",
      "[  100] loss=5.127 lr=3.00e-04\n",
      "[  150] loss=3.062 lr=4.50e-04\n"
     ]
    }
   ],
   "source": [
    "# 0) 준비\n",
    "import torch, math, time, pandas as pd\n",
    "from backbone.hymba_v2 import HymbaV2, ModelCfg, TrainCfg, build_everything, train_loop\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "steps = 2000\n",
    "batch_size = 128\n",
    "\n",
    "model, tok, train_dl, val_dl = build_everything(seq_len=512, bs=batch_size, vocab_size=6000)\n",
    "display(model.layer_table())\n",
    "print(\"est_cache_mb@512:\", model.estimate_kv_cache_mb(512))\n",
    "\n",
    "# 1) 짧게 학습(원하면 건너뛰어도 됨)\n",
    "\n",
    "tcfg = TrainCfg(seq_len=512, batch_size=batch_size, steps=steps, lr=6e-4, warmup=int(steps*0.1), amp=True, grad_clip=1.0)\n",
    "stats = train_loop(model, train_dl, val_dl, tcfg, device=device)\n",
    "stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9111f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) 평가/벤치 유틸\n",
    "from contextlib import nullcontext\n",
    "\n",
    "def peak_gpu_mem_mb():\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "        m = torch.cuda.max_memory_allocated()/(1024**2)\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        return round(m,2)\n",
    "    return 0.0\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_ppl(model, val_dl, amp=True):\n",
    "    model.eval()\n",
    "    nll=0.0; tok=0\n",
    "    ctx = (torch.amp.autocast(\"cuda\") if (amp and device==\"cuda\") else nullcontext())\n",
    "    with ctx:\n",
    "        for xb,yb in val_dl:\n",
    "            xb,yb = xb.to(device), yb.to(device)\n",
    "            out = model(xb, targets=yb)\n",
    "            nll += out[\"loss\"].item()*xb.numel()\n",
    "            tok += xb.numel()\n",
    "    return math.exp(nll/max(1,tok))\n",
    "@torch.no_grad()\n",
    "def bench_generate(model, prompt_len=512, gen_len=256, use_kv_cache=True, kv_share=True, warmup=1, repeat=2):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    vocab = model.cfg.vocab_size\n",
    "    torch.manual_seed(0)\n",
    "    prompt = torch.randint(0, vocab, (1, prompt_len), device=device)\n",
    "\n",
    "    # warmup\n",
    "    for _ in range(warmup):\n",
    "        _ = model.generate(prompt, max_new_tokens=16, use_kv_cache=use_kv_cache, kv_share=kv_share)\n",
    "\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    import time\n",
    "    times = []\n",
    "    for _ in range(repeat):\n",
    "        if device.type == \"cuda\": torch.cuda.synchronize()\n",
    "        t0 = time.time()\n",
    "        _ = model.generate(prompt, max_new_tokens=gen_len, use_kv_cache=use_kv_cache, kv_share=kv_share)\n",
    "        if device.type == \"cuda\": torch.cuda.synchronize()\n",
    "        times.append(time.time() - t0)\n",
    "\n",
    "    sec = sum(times) / len(times)\n",
    "    tps = int((prompt_len + gen_len) / sec)\n",
    "    mem = 0.0\n",
    "    if device.type == \"cuda\":\n",
    "        mem = torch.cuda.max_memory_allocated() / (1024**2)\n",
    "\n",
    "    # <<< 표준화된 키명 >>>\n",
    "    return {\n",
    "        \"gen_latency_s\": round(sec, 3),\n",
    "        \"gen_tps\": tps,\n",
    "        \"gen_peak_mb\": round(mem, 2),\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31b91c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ppl</th>\n",
       "      <th>gen_latency_s</th>\n",
       "      <th>gen_tps</th>\n",
       "      <th>gen_peak_mb</th>\n",
       "      <th>est_cache_mb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Cache (recompute)</td>\n",
       "      <td>1.81</td>\n",
       "      <td>3.944</td>\n",
       "      <td>194</td>\n",
       "      <td>181.38</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KV Cache (no share)</td>\n",
       "      <td>1.81</td>\n",
       "      <td>3.858</td>\n",
       "      <td>199</td>\n",
       "      <td>160.99</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KV Cache + SWA Share</td>\n",
       "      <td>1.81</td>\n",
       "      <td>3.473</td>\n",
       "      <td>221</td>\n",
       "      <td>158.99</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title   ppl  gen_latency_s  gen_tps  gen_peak_mb  \\\n",
       "0  No Cache (recompute)  1.81          3.944      194       181.38   \n",
       "1   KV Cache (no share)  1.81          3.858      199       160.99   \n",
       "2  KV Cache + SWA Share  1.81          3.473      221       158.99   \n",
       "\n",
       "  est_cache_mb  \n",
       "0            -  \n",
       "1          2.0  \n",
       "2          2.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) KV-cache 비교 표 (NoCache / KV / KV+Share)\n",
    "rows=[]\n",
    "\n",
    "b1 = bench_generate(model, prompt_len=512, gen_len=256, use_kv_cache=False, kv_share=False)\n",
    "p1 = evaluate_ppl(model, val_dl, amp=True)\n",
    "rows.append({\"title\":\"No Cache (recompute)\", \"ppl\":round(p1,3), **b1, \"est_cache_mb\":\"-\"})\n",
    "\n",
    "b2 = bench_generate(model, prompt_len=512, gen_len=256, use_kv_cache=True, kv_share=False)\n",
    "p2 = evaluate_ppl(model, val_dl, amp=True)\n",
    "rows.append({\"title\":\"KV Cache (no share)\", \"ppl\":round(p2,3), **b2, \"est_cache_mb\": model.estimate_kv_cache_mb(512)})\n",
    "\n",
    "b3 = bench_generate(model, prompt_len=512, gen_len=256, use_kv_cache=True, kv_share=True)\n",
    "p3 = evaluate_ppl(model, val_dl, amp=True)\n",
    "rows.append({\"title\":\"KV Cache + SWA Share\", \"ppl\":round(p3,3), **b3, \"est_cache_mb\": model.estimate_kv_cache_mb(512)})\n",
    "\n",
    "pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c9bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (C) 편의: 새 모델 만들기(변이)\n",
    "def new_model_from(base_cfg:ModelCfg, **kw) -> HymbaV2:\n",
    "    cfg = ModelCfg(**{**base_cfg.__dict__, **kw})\n",
    "    m = HymbaV2(cfg).to(device)\n",
    "    return m\n",
    "\n",
    "# 동일 학습 레시피(짧게 돌려 비교)\n",
    "train_recipe = TrainCfg(seq_len=512, batch_size=batch_size, steps=steps, lr=6e-4, warmup=int(steps*0.1), amp=True, grad_clip=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e447eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (D) bench_train: 단계별로 컴포넌트를 하나씩 추가하며 학습/측정\n",
    "def bench_train(tok, train_dl, val_dl, base_cfg:ModelCfg, recipe:TrainCfg):\n",
    "    rows = []\n",
    "\n",
    "    stages = [\n",
    "        # title, cfg overrides, gen flags (nocache/kv/kv+share 측정)\n",
    "        (\"0) Global-only (no SWA, no Meta)\",  {\"swa_layers\": (), \"num_meta_tokens\": 0},  {\"kv_share\": False}),\n",
    "        (\"1) + SWA (local windows)\",          {\"swa_layers\": base_cfg.swa_layers, \"num_meta_tokens\": 0}, {\"kv_share\": False}),\n",
    "        (\"2) + KV-Share (SWA cross-layer)\",   {\"swa_layers\": base_cfg.swa_layers, \"num_meta_tokens\": 0}, {\"kv_share\": True}),\n",
    "        (\"3) + MetaTokens (learnable M=4)\",   {\"swa_layers\": base_cfg.swa_layers, \"num_meta_tokens\": 4}, {\"kv_share\": True}),\n",
    "    ]\n",
    "\n",
    "    for title, cfg_over, gen_flags in stages:\n",
    "        model = new_model_from(base_cfg, **cfg_over)\n",
    "        print(f\"\\n=== {title} ===\")\n",
    "        display(model.layer_table())\n",
    "\n",
    "        stats = train_loop(model, train_dl, val_dl, recipe, device=device)\n",
    "        ppl = evaluate_ppl(model, val_dl, amp=True)\n",
    "\n",
    "        # 생성 속도/메모리 비교: NoCache vs KV(no-share) vs KV(share or not)\n",
    "        b_nc = bench_generate(model, prompt_len=512, gen_len=256, use_kv_cache=False, kv_share=False)\n",
    "        b_kv = bench_generate(model, prompt_len=512, gen_len=256, use_kv_cache=True,  kv_share=False)\n",
    "        b_sh = bench_generate(model, prompt_len=512, gen_len=256, use_kv_cache=True,  kv_share=gen_flags[\"kv_share\"])\n",
    "\n",
    "        rows.append({\n",
    "            \"title\": title,\n",
    "            \"train_loss\": round(stats[\"train_loss\"],4),\n",
    "            \"val_loss\": round(stats[\"val_loss\"],4),\n",
    "            \"ppl\": round(ppl,3),\n",
    "            # gen benches\n",
    "            \"gen_tps_nocache\": b_nc[\"gen_tps\"],\n",
    "            \"gen_tps_kv\": b_kv[\"gen_tps\"],\n",
    "            \"gen_tps_share\": b_sh[\"gen_tps\"],\n",
    "            \"gen_mb_nocache\": b_nc[\"gen_peak_mb\"],\n",
    "            \"gen_mb_kv\": b_kv[\"gen_peak_mb\"],\n",
    "            \"gen_mb_share\": b_sh[\"gen_peak_mb\"],\n",
    "            # 추정 캐시 사용량(owners 기준)\n",
    "            \"est_cache_mb@512\": model.estimate_kv_cache_mb(512),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d52225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 0) Global-only (no SWA, no Meta) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>attn</th>\n",
       "      <th>kv_owner</th>\n",
       "      <th>kv_share_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    layer    attn  kv_owner  kv_share_group\n",
       "0       0  GLOBAL         0               0\n",
       "1       1  GLOBAL         1               1\n",
       "2       2  GLOBAL         2               2\n",
       "3       3  GLOBAL         3               3\n",
       "4       4  GLOBAL         4               4\n",
       "5       5  GLOBAL         5               5\n",
       "6       6  GLOBAL         6               6\n",
       "7       7  GLOBAL         7               7\n",
       "8       8  GLOBAL         8               8\n",
       "9       9  GLOBAL         9               9\n",
       "10     10  GLOBAL        10              10\n",
       "11     11  GLOBAL        11              11\n",
       "12     12  GLOBAL        12              12\n",
       "13     13  GLOBAL        13              13\n",
       "14     14  GLOBAL        14              14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] loss=8.805 lr=1.20e-06\n",
      "[   50] loss=7.193 lr=6.00e-05\n",
      "[  100] loss=5.798 lr=1.20e-04\n",
      "[  150] loss=5.273 lr=1.80e-04\n",
      "[  200] loss=4.894 lr=2.40e-04\n",
      "[  250] loss=4.317 lr=3.00e-04\n",
      "[  300] loss=3.546 lr=3.60e-04\n",
      "[  350] loss=2.240 lr=4.20e-04\n",
      "[  400] loss=1.088 lr=4.80e-04\n",
      "[  450] loss=0.206 lr=5.40e-04\n",
      "[  500] loss=0.066 lr=6.00e-04\n",
      "[  550] loss=0.009 lr=6.00e-04\n",
      "[  600] loss=0.024 lr=5.99e-04\n",
      "[  650] loss=0.005 lr=5.98e-04\n",
      "[  700] loss=0.023 lr=5.97e-04\n",
      "[  750] loss=0.006 lr=5.95e-04\n",
      "[  800] loss=0.016 lr=5.93e-04\n",
      "[  850] loss=0.009 lr=5.91e-04\n",
      "[  900] loss=0.007 lr=5.88e-04\n",
      "[  950] loss=0.022 lr=5.85e-04\n",
      "[ 1000] loss=0.006 lr=5.82e-04\n",
      "[ 1050] loss=0.012 lr=5.78e-04\n",
      "[ 1100] loss=0.007 lr=5.74e-04\n",
      "[ 1150] loss=0.006 lr=5.70e-04\n",
      "[ 1200] loss=0.016 lr=5.65e-04\n",
      "[ 1250] loss=0.004 lr=5.60e-04\n",
      "[ 1300] loss=0.007 lr=5.54e-04\n",
      "[ 1350] loss=0.011 lr=5.49e-04\n",
      "[ 1400] loss=0.006 lr=5.43e-04\n",
      "[ 1450] loss=0.008 lr=5.36e-04\n",
      "[ 1500] loss=0.008 lr=5.30e-04\n",
      "[ 1550] loss=0.005 lr=5.23e-04\n",
      "[ 1600] loss=0.006 lr=5.16e-04\n",
      "[ 1650] loss=0.009 lr=5.08e-04\n",
      "[ 1700] loss=0.004 lr=5.01e-04\n",
      "[ 1750] loss=0.006 lr=4.93e-04\n",
      "[ 1800] loss=0.010 lr=4.85e-04\n",
      "[ 1850] loss=0.004 lr=4.76e-04\n",
      "[ 1900] loss=0.005 lr=4.68e-04\n",
      "[ 1950] loss=0.012 lr=4.59e-04\n",
      "[ 2000] loss=0.004 lr=4.50e-04\n",
      "[ 2050] loss=0.005 lr=4.41e-04\n",
      "[ 2100] loss=0.007 lr=4.32e-04\n",
      "[ 2150] loss=0.004 lr=4.22e-04\n",
      "[ 2200] loss=0.005 lr=4.12e-04\n",
      "[ 2250] loss=0.004 lr=4.03e-04\n",
      "[ 2300] loss=0.005 lr=3.93e-04\n",
      "[ 2350] loss=0.005 lr=3.83e-04\n",
      "[ 2400] loss=0.004 lr=3.73e-04\n",
      "[ 2450] loss=0.004 lr=3.62e-04\n",
      "[ 2500] loss=0.004 lr=3.52e-04\n",
      "[ 2550] loss=0.004 lr=3.42e-04\n",
      "[ 2600] loss=0.004 lr=3.31e-04\n",
      "[ 2650] loss=0.003 lr=3.21e-04\n",
      "[ 2700] loss=0.004 lr=3.10e-04\n",
      "[ 2750] loss=0.004 lr=3.00e-04\n",
      "[ 2800] loss=0.004 lr=2.90e-04\n",
      "[ 2850] loss=0.004 lr=2.79e-04\n",
      "[ 2900] loss=0.004 lr=2.69e-04\n",
      "[ 2950] loss=0.003 lr=2.58e-04\n",
      "[ 3000] loss=0.003 lr=2.48e-04\n",
      "[ 3050] loss=0.003 lr=2.38e-04\n",
      "[ 3100] loss=0.003 lr=2.27e-04\n",
      "[ 3150] loss=0.003 lr=2.17e-04\n",
      "[ 3200] loss=0.004 lr=2.07e-04\n",
      "[ 3250] loss=0.003 lr=1.97e-04\n",
      "[ 3300] loss=0.003 lr=1.88e-04\n",
      "[ 3350] loss=0.003 lr=1.78e-04\n",
      "[ 3400] loss=0.003 lr=1.68e-04\n",
      "[ 3450] loss=0.003 lr=1.59e-04\n",
      "[ 3500] loss=0.003 lr=1.50e-04\n",
      "[ 3550] loss=0.003 lr=1.41e-04\n",
      "[ 3600] loss=0.003 lr=1.32e-04\n",
      "[ 3650] loss=0.003 lr=1.24e-04\n",
      "[ 3700] loss=0.003 lr=1.15e-04\n",
      "[ 3750] loss=0.003 lr=1.07e-04\n",
      "[ 3800] loss=0.003 lr=9.93e-05\n",
      "[ 3850] loss=0.003 lr=9.16e-05\n",
      "[ 3900] loss=0.003 lr=8.42e-05\n",
      "[ 3950] loss=0.003 lr=7.71e-05\n",
      "[ 4000] loss=0.003 lr=7.02e-05\n",
      "[ 4050] loss=0.003 lr=6.36e-05\n",
      "[ 4100] loss=0.003 lr=5.73e-05\n",
      "[ 4150] loss=0.003 lr=5.13e-05\n",
      "[ 4200] loss=0.003 lr=4.56e-05\n",
      "[ 4250] loss=0.003 lr=4.02e-05\n",
      "[ 4300] loss=0.003 lr=3.51e-05\n",
      "[ 4350] loss=0.003 lr=3.04e-05\n",
      "[ 4400] loss=0.003 lr=2.59e-05\n",
      "[ 4450] loss=0.003 lr=2.18e-05\n",
      "[ 4500] loss=0.003 lr=1.81e-05\n",
      "[ 4550] loss=0.003 lr=1.47e-05\n",
      "[ 4600] loss=0.003 lr=1.16e-05\n",
      "[ 4650] loss=0.003 lr=8.91e-06\n",
      "[ 4700] loss=0.003 lr=6.56e-06\n",
      "[ 4750] loss=0.003 lr=4.56e-06\n",
      "[ 4800] loss=0.003 lr=2.92e-06\n",
      "[ 4850] loss=0.003 lr=1.64e-06\n",
      "[ 4900] loss=0.003 lr=7.31e-07\n",
      "[ 4950] loss=0.003 lr=1.83e-07\n",
      "[ 5000] loss=0.003 lr=0.00e+00\n",
      "\n",
      "=== 1) + SWA (local windows) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>attn</th>\n",
       "      <th>kv_owner</th>\n",
       "      <th>kv_share_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LOCAL(SWA)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LOCAL(SWA)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>LOCAL(SWA)</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>LOCAL(SWA)</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>LOCAL(SWA)</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>LOCAL(SWA)</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>LOCAL(SWA)</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>LOCAL(SWA)</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>LOCAL(SWA)</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    layer        attn  kv_owner  kv_share_group\n",
       "0       0      GLOBAL         0               0\n",
       "1       1  LOCAL(SWA)         1               1\n",
       "2       2  LOCAL(SWA)         1               1\n",
       "3       3  LOCAL(SWA)         3               2\n",
       "4       4  LOCAL(SWA)         3               2\n",
       "5       5  LOCAL(SWA)         5               3\n",
       "6       6      GLOBAL         6               4\n",
       "7       7  LOCAL(SWA)         7               5\n",
       "8       8  LOCAL(SWA)         7               5\n",
       "9       9  LOCAL(SWA)         9               6\n",
       "10     10  LOCAL(SWA)         9               6\n",
       "11     11      GLOBAL        11               7\n",
       "12     12      GLOBAL        12               8\n",
       "13     13      GLOBAL        13               9\n",
       "14     14      GLOBAL        14              10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] loss=8.803 lr=1.20e-06\n",
      "[   50] loss=7.194 lr=6.00e-05\n",
      "[  100] loss=5.786 lr=1.20e-04\n"
     ]
    }
   ],
   "source": [
    "# (E) 실행\n",
    "base_cfg = model.cfg\n",
    "base_cfg.n_layers = 15\n",
    "df = bench_train(tok, train_dl, val_dl, base_cfg, train_recipe)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
