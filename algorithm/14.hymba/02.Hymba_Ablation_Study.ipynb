{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hymba Ablation Study - Tiny Shakespeare\n",
    "\n",
    "## 목표\n",
    "다양한 아키텍처 구성의 성능을 비교하여 각 컴포넌트의 기여도를 분석합니다.\n",
    "\n",
    "### 테스트 구성\n",
    "1. **Mamba-only**: SSM 기반 시퀀스 모델링\n",
    "2. **Transformer-only**: 표준 어텐션 기반\n",
    "3. **Hybrid (Hymba)**: Attention + Mamba 혼합\n",
    "   - Global Attention: 첫/중간/마지막 레이어\n",
    "   - Local Attention (SWA): 나머지 레이어\n",
    "   - Meta Tokens: 128개\n",
    "   - KV-Cache 공유\n",
    "\n",
    "### 평가 메트릭\n",
    "- 학습 Loss & Perplexity\n",
    "- 검증 Loss & Perplexity\n",
    "- 학습 속도 (tokens/sec)\n",
    "- 추론 속도 (tokens/sec)\n",
    "- KV-Cache 메모리 절감\n",
    "- 생성 품질"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Results will be saved to: ./results\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "sys.path.append('./backbone')\n",
    "\n",
    "# Warning 제거\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 모듈 리로드 (코드 변경사항 반영)\n",
    "import importlib\n",
    "if 'hymba' in sys.modules:\n",
    "    importlib.reload(sys.modules['hymba'])\n",
    "\n",
    "from hymba import Hymba, HymbaConfig, ArchType, AttentionType\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import Unigram\n",
    "from tokenizers.trainers import UnigramTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.normalizers import Sequence as NormSeq, NFKC, Lowercase\n",
    "\n",
    "# 결과 저장 폴더\n",
    "RESULTS_DIR = './results'\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# 디바이스 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Results will be saved to: {RESULTS_DIR}\")\n",
    "\n",
    "# 시각화 설정\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로딩 중...\n",
      "전체 텍스트 길이: 1,003,854 문자\n",
      "\n",
      "샘플:\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor...\n"
     ]
    }
   ],
   "source": [
    "# Tiny Shakespeare 로드\n",
    "print(\"데이터 로딩 중...\")\n",
    "ds = load_dataset(\"karpathy/tiny_shakespeare\")\n",
    "text = \"\\n\\n\".join(ds[\"train\"][\"text\"])\n",
    "\n",
    "print(f\"전체 텍스트 길이: {len(text):,} 문자\")\n",
    "print(f\"\\n샘플:\\n{text[:500]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "토크나이저 학습 중...\n",
      "\n",
      "\n",
      "어휘 크기: 4000\n"
     ]
    }
   ],
   "source": [
    "# 토크나이저 학습\n",
    "print(\"\\n토크나이저 학습 중...\")\n",
    "vocab_size = 4000\n",
    "\n",
    "tk = Tokenizer(Unigram())\n",
    "tk.normalizer = NormSeq([NFKC(), Lowercase()])\n",
    "tk.pre_tokenizer = Whitespace()\n",
    "trainer = UnigramTrainer(vocab_size=vocab_size, special_tokens=[\"<|unk|>\"], unk_token=\"<|unk|>\")\n",
    "tk.train_from_iterator([text], trainer=trainer)\n",
    "\n",
    "class TokenizerWrap:\n",
    "    def __init__(self, tk):\n",
    "        self.tk = tk\n",
    "    def encode(self, s):\n",
    "        return self.tk.encode(s).ids\n",
    "    def decode(self, ids):\n",
    "        return self.tk.decode(ids)\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return self.tk.get_vocab_size()\n",
    "\n",
    "tokenizer = TokenizerWrap(tk)\n",
    "print(f\"어휘 크기: {tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "학습 배치: 64\n",
      "검증 배치: 8\n"
     ]
    }
   ],
   "source": [
    "# 데이터로더 생성\n",
    "def make_dataset(tok, text, seq_len=256):\n",
    "    ids = np.array(tok.encode(text), dtype=np.int64)\n",
    "    x, y = ids[:-1], ids[1:]\n",
    "    n = (len(y) // seq_len) * seq_len\n",
    "    X = torch.tensor(x[:n].reshape(-1, seq_len))\n",
    "    Y = torch.tensor(y[:n].reshape(-1, seq_len))\n",
    "    return TensorDataset(X, Y)\n",
    "\n",
    "seq_len = 256\n",
    "batch_size = 16\n",
    "\n",
    "ds_full = make_dataset(tokenizer, text, seq_len)\n",
    "tr_len = int(0.9 * len(ds_full))\n",
    "va_len = len(ds_full) - tr_len\n",
    "train_ds, val_ds = random_split(ds_full, [tr_len, va_len])\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"\\n학습 배치: {len(train_dl)}\")\n",
    "print(f\"검증 배치: {len(val_dl)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모델 구성 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 테스트 구성 ===\n",
      "\n",
      "Mamba-only:\n",
      "  arch_type: mamba\n",
      "  Total Attn heads: 0, Total Mamba heads: 15\n",
      "\n",
      "Transformer-only (Global):\n",
      "  arch_type: transformer\n",
      "  Total Attn heads: 120, Total Mamba heads: 0\n",
      "\n",
      "Hybrid (1:1):\n",
      "  arch_type: hybrid\n",
      "  Total Attn heads: 120, Total Mamba heads: 15\n",
      "  Per-layer config: Attn=8, Mamba=1\n",
      "  Mamba:Attn ratio (per layer): 1:1\n",
      "  Meta tokens: 64\n",
      "  KV Sharing: Enabled\n",
      "\n",
      "Hybrid (5:1 Mamba):\n",
      "  arch_type: hybrid\n",
      "  Total Attn heads: 120, Total Mamba heads: 75\n",
      "  Per-layer config: Attn=8, Mamba=5\n",
      "  Mamba:Attn ratio (per layer): 5:1\n",
      "  Meta tokens: 64\n",
      "  KV Sharing: Enabled\n"
     ]
    }
   ],
   "source": [
    "# 기본 하이퍼파라미터 (15 레이어로 증가)\n",
    "base_config = {\n",
    "    \"vocab_size\": vocab_size,\n",
    "    \"d_model\": 512,\n",
    "    \"n_layers\": 15,\n",
    "    \"n_heads\": 8,\n",
    "    \"n_kv_heads\": 4,\n",
    "    \"swa_window\": 128,\n",
    "    \"dropout\": 0.1,\n",
    "    \"seq_len\": seq_len,\n",
    "}\n",
    "\n",
    "# 테스트 구성들\n",
    "# 참고: mamba_heads_per_layer는 레이어당 Mamba head 수\n",
    "#       n_heads는 레이어당 Attention head 수 (Hybrid에서)\n",
    "#       따라서 Mamba:Attn 비율 = mamba_heads_per_layer : 1 (레이어 기준)\n",
    "configs = {\n",
    "    \"Mamba-only\": HymbaConfig(\n",
    "        **base_config,\n",
    "        arch_type=ArchType.MAMBA_ONLY,\n",
    "        mamba_heads_per_layer=1,\n",
    "        use_meta_tokens=False,\n",
    "        use_kv_sharing=False,\n",
    "    ),\n",
    "    \"Transformer-only (Global)\": HymbaConfig(\n",
    "        **base_config,\n",
    "        arch_type=ArchType.TRANSFORMER_ONLY,\n",
    "        global_attn_indices=list(range(15)),  # 모든 레이어 Global\n",
    "        use_meta_tokens=False,\n",
    "        use_kv_sharing=False,\n",
    "    ),\n",
    "    \"Hybrid (1:1)\": HymbaConfig(\n",
    "        **base_config,\n",
    "        arch_type=ArchType.HYBRID,\n",
    "        mamba_heads_per_layer=1,  # 1:1 비율 (레이어당)\n",
    "        global_attn_indices=[0, 7, 14],\n",
    "        use_meta_tokens=True,\n",
    "        num_meta_tokens=64,\n",
    "        use_kv_sharing=True,\n",
    "    ),\n",
    "    \"Hybrid (5:1 Mamba)\": HymbaConfig(\n",
    "        **base_config,\n",
    "        arch_type=ArchType.HYBRID,\n",
    "        mamba_heads_per_layer=5,  # 5:1 비율 (레이어당 Mamba 5개)\n",
    "        global_attn_indices=[0, 7, 14],\n",
    "        use_meta_tokens=True,\n",
    "        num_meta_tokens=64,\n",
    "        use_kv_sharing=True,\n",
    "    ),\n",
    "}\n",
    "\n",
    "print(\"=== 테스트 구성 ===\")\n",
    "for name, cfg in configs.items():\n",
    "    layer_configs = cfg.get_layer_configs()\n",
    "    total_attn = sum(c[0] for c in layer_configs)\n",
    "    total_mamba = sum(c[1] for c in layer_configs)\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  arch_type: {cfg.arch_type.value}\")\n",
    "    print(f\"  Total Attn heads: {total_attn}, Total Mamba heads: {total_mamba}\")\n",
    "    if cfg.arch_type == ArchType.HYBRID:\n",
    "        print(f\"  Per-layer config: Attn={layer_configs[0][0]}, Mamba={layer_configs[0][1]}\")\n",
    "        print(f\"  Mamba:Attn ratio (per layer): {layer_configs[0][1]}:1\")\n",
    "    if cfg.use_meta_tokens:\n",
    "        print(f\"  Meta tokens: {cfg.num_meta_tokens}\")\n",
    "    if cfg.use_kv_sharing:\n",
    "        print(f\"  KV Sharing: Enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 학습 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_enhanced(model, train_dl, val_dl, epochs=30, lr=3e-4, warmup_steps=200, \n",
    "                         eval_interval=32, device='cuda', stage_name=\"Pretraining\"):\n",
    "    \"\"\"\n",
    "    개선된 모델 학습 함수\n",
    "    - Cosine Annealing with Linear Warmup\n",
    "    - BF16 Mixed Precision Training\n",
    "    - Gradient Clipping\n",
    "    - Detailed logging\n",
    "    \n",
    "    Args:\n",
    "        model: Hymba 모델\n",
    "        train_dl: 학습 데이터로더\n",
    "        val_dl: 검증 데이터로더\n",
    "        epochs: 학습 에포크 수\n",
    "        lr: 최대 learning rate\n",
    "        warmup_steps: Warmup 스텝 수\n",
    "        eval_interval: Validation 수행 간격\n",
    "        device: 학습 디바이스\n",
    "        stage_name: 학습 단계 이름 (Pretraining/ORPO)\n",
    "    \n",
    "    Returns:\n",
    "        dict: 학습 결과 및 history\n",
    "    \"\"\"\n",
    "    model = model.to(device).train()\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=lr, \n",
    "        betas=(0.9, 0.95), \n",
    "        weight_decay=0.1,\n",
    "        eps=1e-8\n",
    "    )\n",
    "    \n",
    "    total_steps = epochs * len(train_dl)\n",
    "    \n",
    "    # Cosine Annealing with Linear Warmup\n",
    "    def lr_schedule(step):\n",
    "        if step < warmup_steps:\n",
    "            # Linear warmup\n",
    "            return step / warmup_steps\n",
    "        else:\n",
    "            # Cosine annealing\n",
    "            progress = (step - warmup_steps) / (total_steps - warmup_steps)\n",
    "            return 0.5 * (1 + np.cos(np.pi * progress))\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_schedule)\n",
    "    \n",
    "    # BF16 Mixed Precision\n",
    "    use_amp = device == 'cuda' and torch.cuda.is_bf16_supported()\n",
    "    if use_amp:\n",
    "        scaler = torch.amp.GradScaler('cuda')\n",
    "        print(f\"  Using BF16 AMP for {stage_name}\")\n",
    "    else:\n",
    "        scaler = None\n",
    "        print(f\"  Using FP32 for {stage_name}\")\n",
    "    \n",
    "    # History tracking\n",
    "    history = {\n",
    "        \"train_loss\": [], \n",
    "        \"val_loss\": [], \n",
    "        \"train_ppl\": [],\n",
    "        \"val_ppl\": [],\n",
    "        \"lr\": [],\n",
    "        \"step\": [],\n",
    "        \"epoch\": []\n",
    "    }\n",
    "    \n",
    "    step = 0\n",
    "    t0 = time.time()\n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Starting {stage_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"  Total Steps: {total_steps}\")\n",
    "    print(f\"  Warmup Steps: {warmup_steps}\")\n",
    "    print(f\"  Max LR: {lr}\")\n",
    "    print(f\"  Epochs: {epochs}\")\n",
    "    print(f\"  Batch Size: {train_dl.batch_size}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        epoch_tokens = 0\n",
    "        \n",
    "        pbar = tqdm(train_dl, desc=f\"[{stage_name}] Epoch {epoch+1}/{epochs}\")\n",
    "        for xb, yb in pbar:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            \n",
    "            # Forward & Backward\n",
    "            if use_amp:\n",
    "                with torch.amp.autocast('cuda', dtype=torch.bfloat16):\n",
    "                    out = model(xb, targets=yb)\n",
    "                    loss = out[\"loss\"]\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(optimizer)\n",
    "                grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                out = model(xb, targets=yb)\n",
    "                loss = out[\"loss\"]\n",
    "                loss.backward()\n",
    "                grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            scheduler.step()\n",
    "            \n",
    "            epoch_loss += loss.item() * xb.numel()\n",
    "            epoch_tokens += xb.numel()\n",
    "            step += 1\n",
    "            \n",
    "            # Validation\n",
    "            if step % eval_interval == 0 or step == total_steps:\n",
    "                model.eval()\n",
    "                val_loss = 0.0\n",
    "                val_tokens = 0\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    for vxb, vyb in val_dl:\n",
    "                        vxb, vyb = vxb.to(device), vyb.to(device)\n",
    "                        if use_amp:\n",
    "                            with torch.amp.autocast('cuda', dtype=torch.bfloat16):\n",
    "                                vout = model(vxb, targets=vyb)\n",
    "                        else:\n",
    "                            vout = model(vxb, targets=vyb)\n",
    "                        val_loss += vout[\"loss\"].item() * vxb.numel()\n",
    "                        val_tokens += vxb.numel()\n",
    "                \n",
    "                val_loss /= val_tokens\n",
    "                train_loss = epoch_loss / epoch_tokens\n",
    "                current_lr = scheduler.get_last_lr()[0]\n",
    "                \n",
    "                history[\"train_loss\"].append(train_loss)\n",
    "                history[\"val_loss\"].append(val_loss)\n",
    "                history[\"train_ppl\"].append(np.exp(train_loss))\n",
    "                history[\"val_ppl\"].append(np.exp(val_loss))\n",
    "                history[\"lr\"].append(current_lr)\n",
    "                history[\"step\"].append(step)\n",
    "                history[\"epoch\"].append(epoch + 1)\n",
    "                \n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_epoch = epoch + 1\n",
    "                \n",
    "                pbar.set_postfix({\n",
    "                    \"loss\": f\"{train_loss:.3f}\",\n",
    "                    \"val\": f\"{val_loss:.3f}\",\n",
    "                    \"ppl\": f\"{np.exp(val_loss):.2f}\",\n",
    "                    \"lr\": f\"{current_lr:.2e}\",\n",
    "                    \"grad\": f\"{grad_norm:.2f}\"\n",
    "                })\n",
    "                \n",
    "                model.train()\n",
    "    \n",
    "    elapsed = time.time() - t0\n",
    "    total_tokens = epochs * len(train_dl) * train_dl.batch_size * seq_len\n",
    "    tps = int(total_tokens / elapsed)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{stage_name} Completed\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"  Best Val Loss: {best_val_loss:.4f} (Epoch {best_epoch})\")\n",
    "    print(f\"  Final Val Loss: {history['val_loss'][-1]:.4f}\")\n",
    "    print(f\"  Training Time: {elapsed/60:.1f} min\")\n",
    "    print(f\"  Throughput: {tps:,} tokens/sec\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return {\n",
    "        \"train_loss\": history[\"train_loss\"][-1],\n",
    "        \"val_loss\": history[\"val_loss\"][-1],\n",
    "        \"best_val_loss\": best_val_loss,\n",
    "        \"best_epoch\": best_epoch,\n",
    "        \"train_ppl\": history[\"train_ppl\"][-1],\n",
    "        \"val_ppl\": history[\"val_ppl\"][-1],\n",
    "        \"best_val_ppl\": np.exp(best_val_loss),\n",
    "        \"train_tps\": tps,\n",
    "        \"time_min\": elapsed / 60,\n",
    "        \"history\": history,\n",
    "    }\n",
    "\n",
    "\n",
    "def train_orpo(model, train_dl, val_dl, epochs=10, lr=1e-4, warmup_steps=100, \n",
    "               beta=0.1, eval_interval=32, device='cuda'):\n",
    "    \"\"\"\n",
    "    ORPO (Odds Ratio Preference Optimization) 학습 - 단순화 버전\n",
    "    \n",
    "    ⚠️ 주의: 이 구현은 preference pair (chosen/rejected) 데이터 없이 진행되는 \n",
    "    단순화된 버전입니다. 실제 ORPO는 선호/비선호 응답 쌍이 필요합니다.\n",
    "    \n",
    "    현재 구현:\n",
    "    - SFT Loss + Log-likelihood 기반 regularization\n",
    "    - 실제 ORPO의 odds ratio 계산 없음\n",
    "    \n",
    "    실제 ORPO 적용 시 필요:\n",
    "    - chosen/rejected 응답 쌍 데이터셋\n",
    "    - 두 응답에 대한 log-probability 계산\n",
    "    - Odds ratio: log(P(chosen)/(1-P(chosen))) - log(P(rejected)/(1-P(rejected)))\n",
    "    \n",
    "    Args:\n",
    "        model: Hymba 모델\n",
    "        train_dl: 학습 데이터로더 (현재는 단일 텍스트만 포함)\n",
    "        val_dl: 검증 데이터로더\n",
    "        epochs: 학습 에포크 수\n",
    "        lr: Learning rate (pretraining보다 낮게)\n",
    "        warmup_steps: Warmup 스텝 수\n",
    "        beta: Regularization 강도\n",
    "        eval_interval: Validation 수행 간격\n",
    "        device: 학습 디바이스\n",
    "    \n",
    "    Returns:\n",
    "        dict: 학습 결과 및 history\n",
    "    \"\"\"\n",
    "    model = model.to(device).train()\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=lr, \n",
    "        betas=(0.9, 0.95), \n",
    "        weight_decay=0.01  # 낮은 weight decay\n",
    "    )\n",
    "    \n",
    "    total_steps = epochs * len(train_dl)\n",
    "    \n",
    "    def lr_schedule(step):\n",
    "        if step < warmup_steps:\n",
    "            return step / warmup_steps\n",
    "        else:\n",
    "            progress = (step - warmup_steps) / (total_steps - warmup_steps)\n",
    "            return 0.5 * (1 + np.cos(np.pi * progress))\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_schedule)\n",
    "    \n",
    "    use_amp = device == 'cuda' and torch.cuda.is_bf16_supported()\n",
    "    scaler = torch.amp.GradScaler('cuda') if use_amp else None\n",
    "    \n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"orpo_loss\": [],\n",
    "        \"sft_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"train_ppl\": [],\n",
    "        \"val_ppl\": [],\n",
    "        \"lr\": [],\n",
    "        \"step\": [],\n",
    "        \"epoch\": []\n",
    "    }\n",
    "    \n",
    "    step = 0\n",
    "    t0 = time.time()\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Starting ORPO Training (Simplified - No Preference Data)\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"  ⚠️ This is a simplified version without preference pairs\")\n",
    "    print(f\"  Beta (regularization strength): {beta}\")\n",
    "    print(f\"  LR: {lr} (lower than pretraining)\")\n",
    "    print(f\"  Epochs: {epochs}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        epoch_orpo_loss = 0.0\n",
    "        epoch_sft_loss = 0.0\n",
    "        epoch_tokens = 0\n",
    "        \n",
    "        pbar = tqdm(train_dl, desc=f\"[ORPO] Epoch {epoch+1}/{epochs}\")\n",
    "        for xb, yb in pbar:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            \n",
    "            if use_amp:\n",
    "                with torch.amp.autocast('cuda', dtype=torch.bfloat16):\n",
    "                    out = model(xb, targets=yb)\n",
    "                    logits = out[\"logits\"]\n",
    "                    \n",
    "                    # SFT Loss (standard cross-entropy)\n",
    "                    sft_loss = F.cross_entropy(\n",
    "                        logits.reshape(-1, logits.size(-1)),\n",
    "                        yb.reshape(-1),\n",
    "                        ignore_index=-100\n",
    "                    )\n",
    "                    \n",
    "                    # Simplified regularization (not true ORPO)\n",
    "                    # 실제 ORPO는 chosen/rejected pair 비교 필요\n",
    "                    log_probs = F.log_softmax(logits, dim=-1)\n",
    "                    target_log_probs = torch.gather(\n",
    "                        log_probs, 2, yb.unsqueeze(-1)\n",
    "                    ).squeeze(-1)\n",
    "                    \n",
    "                    # 이 부분은 실제 ORPO가 아님 - 단순 regularization\n",
    "                    orpo_penalty = -torch.mean(target_log_probs)\n",
    "                    \n",
    "                    # Total loss\n",
    "                    loss = sft_loss + beta * orpo_penalty\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                out = model(xb, targets=yb)\n",
    "                logits = out[\"logits\"]\n",
    "                \n",
    "                sft_loss = F.cross_entropy(\n",
    "                    logits.reshape(-1, logits.size(-1)),\n",
    "                    yb.reshape(-1),\n",
    "                    ignore_index=-100\n",
    "                )\n",
    "                \n",
    "                log_probs = F.log_softmax(logits, dim=-1)\n",
    "                target_log_probs = torch.gather(\n",
    "                    log_probs, 2, yb.unsqueeze(-1)\n",
    "                ).squeeze(-1)\n",
    "                orpo_penalty = -torch.mean(target_log_probs)\n",
    "                \n",
    "                loss = sft_loss + beta * orpo_penalty\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            scheduler.step()\n",
    "            \n",
    "            epoch_loss += loss.item() * xb.numel()\n",
    "            epoch_orpo_loss += orpo_penalty.item() * xb.numel()\n",
    "            epoch_sft_loss += sft_loss.item() * xb.numel()\n",
    "            epoch_tokens += xb.numel()\n",
    "            step += 1\n",
    "            \n",
    "            # Validation\n",
    "            if step % eval_interval == 0 or step == total_steps:\n",
    "                model.eval()\n",
    "                val_loss = 0.0\n",
    "                val_tokens = 0\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    for vxb, vyb in val_dl:\n",
    "                        vxb, vyb = vxb.to(device), vyb.to(device)\n",
    "                        if use_amp:\n",
    "                            with torch.amp.autocast('cuda', dtype=torch.bfloat16):\n",
    "                                vout = model(vxb, targets=vyb)\n",
    "                        else:\n",
    "                            vout = model(vxb, targets=vyb)\n",
    "                        val_loss += vout[\"loss\"].item() * vxb.numel()\n",
    "                        val_tokens += vxb.numel()\n",
    "                \n",
    "                val_loss /= val_tokens\n",
    "                train_loss = epoch_loss / epoch_tokens\n",
    "                orpo_loss = epoch_orpo_loss / epoch_tokens\n",
    "                sft_loss_avg = epoch_sft_loss / epoch_tokens\n",
    "                current_lr = scheduler.get_last_lr()[0]\n",
    "                \n",
    "                history[\"train_loss\"].append(train_loss)\n",
    "                history[\"orpo_loss\"].append(orpo_loss)\n",
    "                history[\"sft_loss\"].append(sft_loss_avg)\n",
    "                history[\"val_loss\"].append(val_loss)\n",
    "                history[\"train_ppl\"].append(np.exp(sft_loss_avg))\n",
    "                history[\"val_ppl\"].append(np.exp(val_loss))\n",
    "                history[\"lr\"].append(current_lr)\n",
    "                history[\"step\"].append(step)\n",
    "                history[\"epoch\"].append(epoch + 1)\n",
    "                \n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                \n",
    "                pbar.set_postfix({\n",
    "                    \"sft\": f\"{sft_loss_avg:.3f}\",\n",
    "                    \"reg\": f\"{orpo_loss:.3f}\",\n",
    "                    \"val\": f\"{val_loss:.3f}\",\n",
    "                    \"ppl\": f\"{np.exp(val_loss):.2f}\"\n",
    "                })\n",
    "                \n",
    "                model.train()\n",
    "    \n",
    "    elapsed = time.time() - t0\n",
    "    total_tokens = epochs * len(train_dl) * train_dl.batch_size * seq_len\n",
    "    tps = int(total_tokens / elapsed)\n",
    "    \n",
    "    return {\n",
    "        \"train_loss\": history[\"train_loss\"][-1],\n",
    "        \"val_loss\": history[\"val_loss\"][-1],\n",
    "        \"best_val_loss\": best_val_loss,\n",
    "        \"sft_loss\": history[\"sft_loss\"][-1],\n",
    "        \"orpo_loss\": history[\"orpo_loss\"][-1],\n",
    "        \"train_ppl\": history[\"train_ppl\"][-1],\n",
    "        \"val_ppl\": history[\"val_ppl\"][-1],\n",
    "        \"best_val_ppl\": np.exp(best_val_loss),\n",
    "        \"train_tps\": tps,\n",
    "        \"time_min\": elapsed / 60,\n",
    "        \"history\": history,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 추론 속도 벤치마크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_inference(model, tokenizer, prompt=\"ROMEO:\", max_tokens=100, n_runs=3, device='cuda'):\n",
    "    \"\"\"\n",
    "    추론 속도 측정\n",
    "    \"\"\"\n",
    "    model = model.to(device).eval()\n",
    "    prompt_tokens = tokenizer.encode(prompt)\n",
    "    prompt_tensor = torch.tensor([prompt_tokens]).to(device)\n",
    "    \n",
    "    times = []\n",
    "    for _ in range(n_runs):\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        \n",
    "        t0 = time.time()\n",
    "        with torch.no_grad():\n",
    "            _ = model.generate(prompt_tensor, max_new_tokens=max_tokens, temperature=1.0)\n",
    "        \n",
    "        if device == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        \n",
    "        elapsed = time.time() - t0\n",
    "        times.append(elapsed)\n",
    "    \n",
    "    avg_time = np.mean(times)\n",
    "    tps = max_tokens / avg_time\n",
    "    \n",
    "    return {\"time_sec\": avg_time, \"tokens_per_sec\": tps}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델 학습 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Model: Mamba-only\n",
      "====================================================================================================\n",
      "Parameters: 74,670,592\n",
      "\n",
      "====================================================================================================\n",
      "STAGE 1: PRETRAINING\n",
      "====================================================================================================\n",
      "  Using BF16 AMP for Pretraining\n",
      "\n",
      "================================================================================\n",
      "Starting Pretraining\n",
      "================================================================================\n",
      "  Total Steps: 1920\n",
      "  Warmup Steps: 200\n",
      "  Max LR: 0.0003\n",
      "  Epochs: 30\n",
      "  Batch Size: 16\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092551bccc45401c816b104126be5862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 1/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6ef48cdb614b0e880683e13fcf1e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 2/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d080b51cc3894b42ba9d6f6a772d3347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 3/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad38949898b403c999ef63bbeb41175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 4/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62bf8788af9140d48a97be49f2faa3a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 5/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51731f99a68640a09252fdad1d8fcd66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 6/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb910143a694689997b003dcb5b2817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 7/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9836e29a6e124060b48740e216808372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 8/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531d97c02ab44d788c366d39c83488fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 9/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3c7c766cf74644b0d605e5861f13d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 10/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61493b9f1c2f4f04be1a9bc1f8278103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 11/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed4156dfd5f49a9a8292815023b7830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 12/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80decc516dab491d97081f818906771b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 13/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab1c9fc722dd46c09bcb39c9681d971c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 14/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ac4ac201d94fba86d39514132e0568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 15/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5061cc7d058477891e5aeb82c87de73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 16/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b08baa6fefa46cfab9e8086078d02ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 17/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4585b8e088ff4792a515e7553173ab13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 18/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f143d2c206e4f5dbcad8c08c8e878cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 19/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14fa1825a5b44e35833af285eb9c9589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 20/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ede66ebde94699b6599e3adb17b99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 21/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9951c91230ed4cb0a91052f21cb21581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 22/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429cd3c32f3a403ab633d1aeb01676ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 23/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baee4eeb79eb42f4ba55ddcbbc5692f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 24/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd1af33c9234c7c802912e093c30f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 25/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c85eb4b73343949f2694a38e3e3ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 26/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98488c52326341b0b25a5c81de50ecd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 27/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249aa84d51404ef1862442cdf4eb1473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 28/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35acaa5349a745768874adc073f4fb3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 29/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46568e247e9047d196427c79bc261eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 30/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Pretraining Completed\n",
      "================================================================================\n",
      "  Best Val Loss: 4.3050 (Epoch 6)\n",
      "  Final Val Loss: 6.1250\n",
      "  Training Time: 1.9 min\n",
      "  Throughput: 68,835 tokens/sec\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "STAGE 2: ORPO (Reinforcement Learning)\n",
      "====================================================================================================\n",
      "\n",
      "================================================================================\n",
      "Starting ORPO Training (Simplified - No Preference Data)\n",
      "================================================================================\n",
      "  ⚠️ This is a simplified version without preference pairs\n",
      "  Beta (regularization strength): 0.1\n",
      "  LR: 0.0001 (lower than pretraining)\n",
      "  Epochs: 10\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5114fd876048319d801dacbf3c47a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[ORPO] Epoch 1/10:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6e4eca2be141949720ca83bc894c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[ORPO] Epoch 2/10:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2371a506574cfbbb0e54eef2f4773d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[ORPO] Epoch 3/10:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e80f637b6342bd9390b0d0211772a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[ORPO] Epoch 4/10:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5187d78255824a03b94ed768f79afd28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[ORPO] Epoch 5/10:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b5043876e145f496614d3dbb774fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[ORPO] Epoch 6/10:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1576f4b414e94126b161083e902f28e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[ORPO] Epoch 7/10:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71780efcccde413f847dd92f106a6ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[ORPO] Epoch 8/10:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629ba45cef17400bae9d53243fba4b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[ORPO] Epoch 9/10:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a72c5d73c74741b1c1ea95708a6181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[ORPO] Epoch 10/10:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmarking inference (after ORPO)...\n",
      "\n",
      "Generating samples (after ORPO)...\n",
      "\n",
      "====================================================================================================\n",
      "FINAL RESULTS (after both stages):\n",
      "====================================================================================================\n",
      "\n",
      "Pretraining Stage:\n",
      "  Best Val Loss: 4.3050 | PPL: 74.07\n",
      "  Final Val Loss: 6.1250 | PPL: 457.16\n",
      "  Training Time: 1.9 min\n",
      "\n",
      "ORPO Stage:\n",
      "  Best Val Loss: 6.1370 | PPL: 462.67\n",
      "  Final Val Loss: 6.3822 | PPL: 591.21\n",
      "  SFT Loss: 0.2757\n",
      "  ORPO Penalty: 0.2757\n",
      "  Training Time: 0.6 min\n",
      "\n",
      "Overall:\n",
      "  Best Val Loss (either stage): 4.3050 | PPL: 74.07\n",
      "  Final Val Loss: 6.3822 | PPL: 591.21\n",
      "  Infer Speed: 86.9 tok/s\n",
      "  Total Training Time: 2.5 min\n",
      "\n",
      "Sample (ROMEO, after ORPO):\n",
      "  rome o : juliet : t hat you t arm s , a , but not my name of gentle men ; and still answer to a g aunt : y ' d to meet with him self be ! king of it ....\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "Model: Transformer-only (Global)\n",
      "====================================================================================================\n",
      "Parameters: 61,046,272\n",
      "KV Cache Reduction: 1.00x\n",
      "Independent Caches: 15/15\n",
      "\n",
      "====================================================================================================\n",
      "STAGE 1: PRETRAINING\n",
      "====================================================================================================\n",
      "  Using BF16 AMP for Pretraining\n",
      "\n",
      "================================================================================\n",
      "Starting Pretraining\n",
      "================================================================================\n",
      "  Total Steps: 1920\n",
      "  Warmup Steps: 200\n",
      "  Max LR: 0.0003\n",
      "  Epochs: 30\n",
      "  Batch Size: 16\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f1f2feda2a47b08c0b594d417f8c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 1/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a49c36f7634ba6b623b872a165c5a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 2/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6025bec9601348b8b3f563220a4fa9b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 3/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc6134e2d7214b879d5c64a539673696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 4/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f4bd50ec1d4fc18ce3739ff27205a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 5/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f0bddde64b41b6897be26fc95ad3f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 6/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b60c42597f43eca743c12801bb937f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 7/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df701b18c58548f890ab86974086eee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 8/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e81831d13a497e94536fa13fb1600d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 9/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27aa191c8d444393b55cb6728401cccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 10/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f98f537d518417faa0fb9dd0382deae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 11/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66ae185793547599e555328d5cec653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 12/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12126bf7eefb45a69b9d42df48e7acb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 13/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc984887bb2540c896cb3808098999fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 14/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd0367bc2484c2683a3a3c9d0df28da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 15/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76e8f580e944866a3977b435773031d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 16/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e8cc57ea434138b8905446012d7c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 17/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81688be39ea9448693e84143ff598948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 18/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f80b023997411399c00167cba9faca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 19/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf273e758534790a8dd3b1862e3b35b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 20/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c973fd0bb8d40cab2a3d4b8ba8e86dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 21/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248ff0095de54b7b9ca51a08ac6ac8a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 22/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8558c2e20c3d4bdcb3a61d381ebac942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 23/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b68805dbb064a8aabb03bf9ac06952b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 24/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4503a8af48314e43ae6be390d414db13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 25/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8131ad9c18db4e5386b43b0a2495ab4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 26/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60efd2778e741138f52a4a5c9f8ca8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 27/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f69da0b0a44f63ad2b63846452e07f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 28/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8ab456a25945e1bc6682873aad8ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 29/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "391f5c3370de4a5fb23c373a1f1f9c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 30/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Pretraining Completed\n",
      "================================================================================\n",
      "  Best Val Loss: 4.3496 (Epoch 7)\n",
      "  Final Val Loss: 6.0782\n",
      "  Training Time: 2.3 min\n",
      "  Throughput: 57,802 tokens/sec\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "STAGE 2: ORPO (Reinforcement Learning)\n",
      "====================================================================================================\n",
      "\n",
      "================================================================================\n",
      "Starting ORPO Training (Simplified - No Preference Data)\n",
      "================================================================================\n",
      "  ⚠️ This is a simplified version without preference pairs\n",
      "  Beta (regularization strength): 0.1\n",
      "  LR: 0.0001 (lower than pretraining)\n",
      "  Epochs: 10\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963f608bcd394f79bda4b6abcadfea37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[ORPO] Epoch 1/10:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e1581726f0446ba80a98581d56ef78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[ORPO] Epoch 2/10:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db336c64464b4597a681f95bdd3d4c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[ORPO] Epoch 3/10:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25128ad6916d4d4c8ae1b0b67a4d6323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[ORPO] Epoch 4/10:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74682ac0851d4e108ad1644b3c93f015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[ORPO] Epoch 5/10:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bbc1e719d894cc3814d2ab168025673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[ORPO] Epoch 6/10:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1350baf737d45e3a0039e46d3e4ccf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[ORPO] Epoch 7/10:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac33c040cba4592980851739ec774a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[ORPO] Epoch 8/10:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9861bd5eb7bf40fd9d6aa7ba2f2dc3f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[ORPO] Epoch 9/10:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e965abe4ae447baf0142abf452ddbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[ORPO] Epoch 10/10:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmarking inference (after ORPO)...\n",
      "\n",
      "Generating samples (after ORPO)...\n",
      "\n",
      "====================================================================================================\n",
      "FINAL RESULTS (after both stages):\n",
      "====================================================================================================\n",
      "\n",
      "Pretraining Stage:\n",
      "  Best Val Loss: 4.3496 | PPL: 77.45\n",
      "  Final Val Loss: 6.0782 | PPL: 436.24\n",
      "  Training Time: 2.3 min\n",
      "\n",
      "ORPO Stage:\n",
      "  Best Val Loss: 6.0871 | PPL: 440.15\n",
      "  Final Val Loss: 6.3525 | PPL: 573.92\n",
      "  SFT Loss: 0.4899\n",
      "  ORPO Penalty: 0.4899\n",
      "  Training Time: 0.8 min\n",
      "\n",
      "Overall:\n",
      "  Best Val Loss (either stage): 4.3496 | PPL: 77.45\n",
      "  Final Val Loss: 6.3525 | PPL: 573.92\n",
      "  Infer Speed: 57.3 tok/s\n",
      "  Total Training Time: 3.0 min\n",
      "\n",
      "Sample (ROMEO, after ORPO):\n",
      "  rome o : well , in t hat h , who m i ' the e flower to make haste , i ' door ! what is my dear , i t hat h wh y luc entio love d with thou d oth she w...\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "Model: Hybrid (1:1)\n",
      "====================================================================================================\n",
      "Parameters: 86,530,560\n",
      "Attention Layers: 15/15\n",
      "Global Layers: [0, 7, 14]\n",
      "Local Layers: [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13]\n",
      "KV Cache Reduction: 1.67x\n",
      "Independent Caches: 9/15\n",
      "\n",
      "====================================================================================================\n",
      "STAGE 1: PRETRAINING\n",
      "====================================================================================================\n",
      "  Using BF16 AMP for Pretraining\n",
      "\n",
      "================================================================================\n",
      "Starting Pretraining\n",
      "================================================================================\n",
      "  Total Steps: 1920\n",
      "  Warmup Steps: 200\n",
      "  Max LR: 0.0003\n",
      "  Epochs: 30\n",
      "  Batch Size: 16\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e9ec36ca6ad491baf7c9e883c21b196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 1/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec776ab656b48ae86b8692fb9d90dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 2/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0d103a4243411c95e7b021ffc6446a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 3/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed9704a3eaf431c8aac8ebf8ff6e3d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 4/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "365835469d7845c89cce993ef0c50c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 5/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "402d60e159e94de0b1fc4c5573363eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 6/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a30d9c2fcce04eef8830e2a2ed8117b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 7/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fecdb3374ad44eefa3ad4a150492c912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 8/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055d080aa2324fed85b7bb8c59b6087a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 9/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77327ddf71d4a96bfdb2f3ff92e2948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 10/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "086ac2bdaf2548daa7d20218dfaa88c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 11/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697125cd636348cd9c30d7ebcd4ea9ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 12/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "681dee14d4594197b8de868b72eb9175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 13/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c656a8d3d1f94777b0896e6eb86547c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 14/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e124e7ffb8a4a109c6402cee9c68d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 15/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0c38acd38f45f983f2791fc552c316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 16/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2be23f04e24fc497ab2a4a76f68b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 17/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e288622b41484ebb851985f7519903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 18/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bdced082ace49a78585f17f9ff83d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 19/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff3289acbfe46feb27e9b1f8d5dca2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 20/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9fac56446c342748ea88c5473ce12a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 21/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf38c5f2b27446b82c9daabe004b73b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 22/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68b518f1e3c041608744e956ec8dddb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 23/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93fb765e241242d0aee5d24993e11ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 24/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b063d9aeee064b59b6131b0a6a839d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 25/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a90204343c487d8e6cf03a2ed35058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 26/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3572e8132c644108f41b2fe633fb219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 27/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21dd27f5f2a49c7a180d951e90776ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 28/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb5f9c3bb1e404fb43a3fa342440fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 29/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b33df8b4e147d0b920cbb2fcd32b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Pretraining] Epoch 30/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Pretraining Completed\n",
      "================================================================================\n",
      "  Best Val Loss: 4.3166 (Epoch 5)\n",
      "  Final Val Loss: 6.5647\n",
      "  Training Time: 4.9 min\n",
      "  Throughput: 26,804 tokens/sec\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "STAGE 2: ORPO (Reinforcement Learning)\n",
      "====================================================================================================\n",
      "\n",
      "================================================================================\n",
      "Starting ORPO Training (Simplified - No Preference Data)\n",
      "================================================================================\n",
      "  ⚠️ This is a simplified version without preference pairs\n",
      "  Beta (regularization strength): 0.1\n",
      "  LR: 0.0001 (lower than pretraining)\n",
      "  Epochs: 10\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4227dd234d74e7d956604c7e6e4560a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[ORPO] Epoch 1/10:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc31b86efd94c8c9f866cf8e1a1f5c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[ORPO] Epoch 2/10:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모든 구성 학습 - 2단계 학습 (Pretraining → ORPO)\n",
    "results = {}\n",
    "\n",
    "for name, cfg in configs.items():\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    # 모델 생성\n",
    "    model = Hymba(cfg)\n",
    "    params = model.count_parameters()\n",
    "    print(f\"Parameters: {params['total']:,}\")\n",
    "    \n",
    "    # 아키텍처 정보\n",
    "    if cfg.arch_type == ArchType.HYBRID:\n",
    "        attn_info = model.get_attention_pattern_info()\n",
    "        print(f\"Attention Layers: {attn_info['num_global'] + attn_info['num_local']}/{cfg.n_layers}\")\n",
    "        print(f\"Global Layers: {attn_info['global_layers']}\")\n",
    "        print(f\"Local Layers: {attn_info['local_layers']}\")\n",
    "    \n",
    "    # KV 공유 정보\n",
    "    if cfg.arch_type != ArchType.MAMBA_ONLY:\n",
    "        kv_info = model.get_kv_sharing_info()\n",
    "        print(f\"KV Cache Reduction: {kv_info['reduction']:.2f}x\")\n",
    "        print(f\"Independent Caches: {kv_info['independent_caches']}/{kv_info['total_layers']}\")\n",
    "    \n",
    "    # ========== Stage 1: Pretraining (30 epochs) ==========\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"STAGE 1: PRETRAINING\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    pretrain_results = train_model_enhanced(\n",
    "        model, train_dl, val_dl, \n",
    "        epochs=30,\n",
    "        lr=3e-4,\n",
    "        warmup_steps=200,\n",
    "        eval_interval=32,\n",
    "        device=device,\n",
    "        stage_name=\"Pretraining\"\n",
    "    )\n",
    "    \n",
    "    # 모델 체크포인트 저장 (pretraining 완료)\n",
    "    pretrain_state = {\n",
    "        'model_state': model.state_dict(),\n",
    "        'val_loss': pretrain_results['val_loss'],\n",
    "        'val_ppl': pretrain_results['val_ppl'],\n",
    "    }\n",
    "    \n",
    "    # ========== Stage 2: ORPO (10 epochs) ==========\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"STAGE 2: ORPO (Reinforcement Learning)\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    orpo_results = train_orpo(\n",
    "        model, train_dl, val_dl,\n",
    "        epochs=10,\n",
    "        lr=1e-4,  # Lower LR than pretraining\n",
    "        warmup_steps=100,\n",
    "        beta=0.1,  # ORPO penalty strength\n",
    "        eval_interval=32,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # 추론 벤치마크 (ORPO 완료 후)\n",
    "    print(f\"\\nBenchmarking inference (after ORPO)...\")\n",
    "    infer_results = benchmark_inference(model, tokenizer, device=device)\n",
    "    \n",
    "    # 생성 샘플 (3개)\n",
    "    print(f\"\\nGenerating samples (after ORPO)...\")\n",
    "    samples = []\n",
    "    prompts_list = [\"ROMEO:\", \"First Citizen:\", \"KING:\"]\n",
    "    for prompt in prompts_list:\n",
    "        prompt_tokens = tokenizer.encode(prompt)\n",
    "        prompt_tensor = torch.tensor([prompt_tokens]).to(device)\n",
    "        with torch.no_grad():\n",
    "            generated = model.generate(prompt_tensor, max_new_tokens=80, temperature=0.8, top_k=40)\n",
    "        sample_text = tokenizer.decode(generated[0].cpu().tolist())\n",
    "        samples.append(sample_text)\n",
    "    \n",
    "    # 결과 저장 (두 단계 모두 포함)\n",
    "    results[name] = {\n",
    "        # Pretraining results\n",
    "        \"pretrain_train_loss\": pretrain_results['train_loss'],\n",
    "        \"pretrain_val_loss\": pretrain_results['val_loss'],\n",
    "        \"pretrain_best_val_loss\": pretrain_results['best_val_loss'],\n",
    "        \"pretrain_val_ppl\": pretrain_results['val_ppl'],\n",
    "        \"pretrain_best_val_ppl\": pretrain_results['best_val_ppl'],\n",
    "        \"pretrain_history\": pretrain_results['history'],\n",
    "        \n",
    "        # ORPO results\n",
    "        \"orpo_train_loss\": orpo_results['train_loss'],\n",
    "        \"orpo_val_loss\": orpo_results['val_loss'],\n",
    "        \"orpo_best_val_loss\": orpo_results['best_val_loss'],\n",
    "        \"orpo_val_ppl\": orpo_results['val_ppl'],\n",
    "        \"orpo_best_val_ppl\": orpo_results['best_val_ppl'],\n",
    "        \"orpo_sft_loss\": orpo_results['sft_loss'],\n",
    "        \"orpo_penalty\": orpo_results['orpo_loss'],\n",
    "        \"orpo_history\": orpo_results['history'],\n",
    "        \n",
    "        # Final metrics\n",
    "        \"final_val_loss\": orpo_results['val_loss'],\n",
    "        \"final_val_ppl\": orpo_results['val_ppl'],\n",
    "        \"best_val_loss\": min(pretrain_results['best_val_loss'], orpo_results['best_val_loss']),\n",
    "        \"best_val_ppl\": min(pretrain_results['best_val_ppl'], orpo_results['best_val_ppl']),\n",
    "        \n",
    "        # Inference and other metrics\n",
    "        **infer_results,\n",
    "        \"params\": params['total'],\n",
    "        \"samples\": samples,\n",
    "        \"kv_reduction\": kv_info['reduction'] if cfg.arch_type != ArchType.MAMBA_ONLY else 1.0,\n",
    "        \"total_time_min\": pretrain_results['time_min'] + orpo_results['time_min'],\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"FINAL RESULTS (after both stages):\")\n",
    "    print(f\"{'='*100}\")\n",
    "    print(f\"\\nPretraining Stage:\")\n",
    "    print(f\"  Best Val Loss: {pretrain_results['best_val_loss']:.4f} | PPL: {pretrain_results['best_val_ppl']:.2f}\")\n",
    "    print(f\"  Final Val Loss: {pretrain_results['val_loss']:.4f} | PPL: {pretrain_results['val_ppl']:.2f}\")\n",
    "    print(f\"  Training Time: {pretrain_results['time_min']:.1f} min\")\n",
    "    \n",
    "    print(f\"\\nORPO Stage:\")\n",
    "    print(f\"  Best Val Loss: {orpo_results['best_val_loss']:.4f} | PPL: {orpo_results['best_val_ppl']:.2f}\")\n",
    "    print(f\"  Final Val Loss: {orpo_results['val_loss']:.4f} | PPL: {orpo_results['val_ppl']:.2f}\")\n",
    "    print(f\"  SFT Loss: {orpo_results['sft_loss']:.4f}\")\n",
    "    print(f\"  ORPO Penalty: {orpo_results['orpo_loss']:.4f}\")\n",
    "    print(f\"  Training Time: {orpo_results['time_min']:.1f} min\")\n",
    "    \n",
    "    print(f\"\\nOverall:\")\n",
    "    print(f\"  Best Val Loss (either stage): {results[name]['best_val_loss']:.4f} | PPL: {results[name]['best_val_ppl']:.2f}\")\n",
    "    print(f\"  Final Val Loss: {results[name]['final_val_loss']:.4f} | PPL: {results[name]['final_val_ppl']:.2f}\")\n",
    "    print(f\"  Infer Speed: {infer_results['tokens_per_sec']:.1f} tok/s\")\n",
    "    print(f\"  Total Training Time: {results[name]['total_time_min']:.1f} min\")\n",
    "    \n",
    "    print(f\"\\nSample (ROMEO, after ORPO):\")\n",
    "    print(f\"  {samples[0][:150]}...\")\n",
    "    print(f\"{'='*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 결과 시각화\n",
    "\n",
    "**참고**: 현재 ORPO 구현은 preference pair (chosen/rejected) 데이터 없이 단순화된 버전입니다.\n",
    "실제 ORPO는 선호/비선호 응답 쌍이 필요하므로, 현재 결과에서 ORPO 단계의 성능 저하는 예상된 현상입니다.\n",
    "실제 적용 시에는 적절한 preference 데이터셋과 함께 사용해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 DataFrame (두 단계 학습 결과 포함)\n",
    "df = pd.DataFrame([\n",
    "    {\n",
    "        \"Model\": name,\n",
    "        \"Pretrain Best PPL\": r['pretrain_best_val_ppl'],\n",
    "        \"ORPO Best PPL\": r['orpo_best_val_ppl'],\n",
    "        \"Final Best PPL\": r['best_val_ppl'],\n",
    "        \"Final Val PPL\": r['final_val_ppl'],\n",
    "        \"Infer Speed (tok/s)\": r['tokens_per_sec'],\n",
    "        \"Params (M)\": r['params'] / 1e6,\n",
    "        \"KV Reduction\": r['kv_reduction'],\n",
    "        \"Total Time (min)\": r['total_time_min'],\n",
    "    }\n",
    "    for name, r in results.items()\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"Final Results Summary (Two-Stage Training: Pretraining → ORPO)\")\n",
    "print(\"=\"*100)\n",
    "print(df.to_string(index=False))\n",
    "print(\"=\"*100)\n",
    "\n",
    "# 최고 성능 모델 분석\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"Best Models by Metric\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "best_overall = df.loc[df['Final Best PPL'].idxmin()]\n",
    "print(f\"\\nBest Overall Performance (PPL): {best_overall['Model']}\")\n",
    "print(f\"  Final Best PPL: {best_overall['Final Best PPL']:.2f}\")\n",
    "print(f\"  Pretraining PPL: {best_overall['Pretrain Best PPL']:.2f}\")\n",
    "print(f\"  ORPO PPL: {best_overall['ORPO Best PPL']:.2f}\")\n",
    "\n",
    "best_improvement = df.copy()\n",
    "best_improvement['Improvement %'] = ((best_improvement['Pretrain Best PPL'] - best_improvement['ORPO Best PPL']) / best_improvement['Pretrain Best PPL'] * 100)\n",
    "best_improver = best_improvement.loc[best_improvement['Improvement %'].idxmax()]\n",
    "print(f\"\\nBest ORPO Improvement: {best_improver['Model']}\")\n",
    "print(f\"  Improvement: {best_improver['Improvement %']:.2f}%\")\n",
    "print(f\"  {best_improver['Pretrain Best PPL']:.2f} → {best_improver['ORPO Best PPL']:.2f}\")\n",
    "\n",
    "print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Pattern 분석: Pretraining vs ORPO\n",
    "\n",
    "#### 예상되는 주요 변화 패턴:\n",
    "\n",
    "**1. Global Attention Layers (0, 7, 14)**\n",
    "- **Pretraining**: \n",
    "  - 전체 시퀀스에 걸친 균등한 분산\n",
    "  - Meta token에 대한 기본적인 의존성\n",
    "  - 문법적 구조에 대한 일반적인 attention\n",
    "  \n",
    "- **ORPO 이후**:\n",
    "  - 더 선택적이고 집중된 attention pattern\n",
    "  - Meta token 활용도 증가 (강화학습을 통한 최적화)\n",
    "  - 중요한 문맥 단어에 대한 sharper focus\n",
    "\n",
    "**2. Local Attention Layers (SWA)**\n",
    "- **Pretraining**:\n",
    "  - Sliding window 내에서 비교적 균등한 분산\n",
    "  - 대각선 패턴 (causal attention)\n",
    "  \n",
    "- **ORPO 이후**:\n",
    "  - Window 내에서 더 강한 local dependency\n",
    "  - 인접 토큰에 대한 더 명확한 attention weight\n",
    "\n",
    "**3. Meta Token의 역할 변화**\n",
    "- **Pretraining**: 도메인 일반 지식 저장\n",
    "- **ORPO**: Preference-aligned 표현으로 진화 (선호되는 응답 패턴 캡슐화)\n",
    "\n",
    "**4. ORPO의 효과**\n",
    "- Odds Ratio Preference Optimization은 선호하는 응답의 likelihood를 높이고 비선호 응답을 낮춤\n",
    "- Attention pattern이 더 discriminative하게 변화\n",
    "- 불필요한 attention을 줄이고 중요한 부분에 집중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_attention_maps_stages(model, tokenizer, prompt=\"First Citizen: Before we proceed\", \n",
    "                                     max_len=64, num_meta=64, stage_name=\"Training\"):\n",
    "    \"\"\"\n",
    "    Hymba 모델의 주요 레이어별 attention map 시각화 (개선된 버전)\n",
    "    \n",
    "    Args:\n",
    "        model: Hymba 모델\n",
    "        tokenizer: 토크나이저\n",
    "        prompt: 입력 프롬프트\n",
    "        max_len: 생성할 최대 길이\n",
    "        num_meta: Meta token 개수\n",
    "        stage_name: 학습 단계 이름 (Pretraining/ORPO)\n",
    "    \n",
    "    Returns:\n",
    "        dict: attention weights by layer\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # 입력 준비\n",
    "    prompt_tokens = tokenizer.encode(prompt)\n",
    "    input_ids = torch.tensor([prompt_tokens[:max_len]]).to(device)\n",
    "    \n",
    "    # Forward pass with attention weights\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, return_attn=True)\n",
    "    \n",
    "    attn_weights = outputs.get('attn_weights', [])\n",
    "    \n",
    "    if not attn_weights:\n",
    "        print(\"Warning: No attention weights available.\")\n",
    "        return None\n",
    "    \n",
    "    # 어텐션 타입 가져오기\n",
    "    attn_types = model.cfg.get_attention_types()\n",
    "    global_indices = [i for i, t in enumerate(attn_types) if t == AttentionType.GLOBAL]\n",
    "    local_indices = [i for i, t in enumerate(attn_types) if t == AttentionType.LOCAL][:2]\n",
    "    \n",
    "    n_plots = len(global_indices) + len(local_indices)\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    plot_idx = 0\n",
    "    \n",
    "    # Global 레이어 시각화\n",
    "    for layer_idx in global_indices:\n",
    "        if layer_idx >= len(attn_weights) or attn_weights[layer_idx] is None:\n",
    "            continue\n",
    "        \n",
    "        attn = attn_weights[layer_idx][0, 0].cpu().numpy()\n",
    "        ax = axes[plot_idx]\n",
    "        \n",
    "        # Log scale 적용\n",
    "        attn_vis = np.clip(attn, 1e-6, 1.0)\n",
    "        attn_log = np.log10(attn_vis + 1e-8)\n",
    "        \n",
    "        im = ax.imshow(attn_log, cmap='magma', aspect='auto', vmin=-4, vmax=0)\n",
    "        ax.set_title(f'Layer {layer_idx}: Global Attention\\n({stage_name})', \n",
    "                     fontweight='bold', fontsize=11, color='darkred')\n",
    "        ax.set_xlabel('Key Position')\n",
    "        ax.set_ylabel('Query Position')\n",
    "        \n",
    "        # 메타 토큰 경계\n",
    "        if num_meta > 0:\n",
    "            ax.axvline(x=num_meta-0.5, color='lime', linestyle='-', linewidth=2, alpha=0.8)\n",
    "            ax.axhline(y=num_meta-0.5, color='lime', linestyle='-', linewidth=2, alpha=0.8)\n",
    "        \n",
    "        cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        cbar.set_label('log₁₀(attn)', fontsize=9)\n",
    "        plot_idx += 1\n",
    "    \n",
    "    # Local 레이어 시각화\n",
    "    for layer_idx in local_indices:\n",
    "        if layer_idx >= len(attn_weights) or attn_weights[layer_idx] is None:\n",
    "            continue\n",
    "        \n",
    "        attn = attn_weights[layer_idx][0, 0].cpu().numpy()\n",
    "        ax = axes[plot_idx]\n",
    "        \n",
    "        attn_vis = np.clip(attn, 1e-6, 1.0)\n",
    "        attn_log = np.log10(attn_vis + 1e-8)\n",
    "        \n",
    "        im = ax.imshow(attn_log, cmap='viridis', aspect='auto', vmin=-4, vmax=0)\n",
    "        ax.set_title(f'Layer {layer_idx}: Local (SWA)\\n({stage_name})', \n",
    "                     fontweight='bold', fontsize=11, color='darkblue')\n",
    "        ax.set_xlabel('Key Position')\n",
    "        ax.set_ylabel('Query Position')\n",
    "        \n",
    "        if num_meta > 0:\n",
    "            ax.axvline(x=num_meta-0.5, color='yellow', linestyle='-', linewidth=2, alpha=0.8)\n",
    "            ax.axhline(y=num_meta-0.5, color='yellow', linestyle='-', linewidth=2, alpha=0.8)\n",
    "        \n",
    "        cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        cbar.set_label('log₁₀(attn)', fontsize=9)\n",
    "        plot_idx += 1\n",
    "    \n",
    "    # 빈 서브플롯 제거\n",
    "    for i in range(plot_idx, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "    \n",
    "    plt.suptitle(f'Hymba Attention Maps - {stage_name}\\n(Log Scale)', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return {'fig': fig, 'attn_weights': attn_weights}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Hymba Attention Map 시각화 (학습 단계별)\n",
    "\n",
    "Hymba (Paper Setting) 모델의 주요 레이어별 attention pattern을 시각화합니다.\n",
    "- Pretraining 완료 후와 ORPO 완료 후의 attention pattern 변화를 비교\n",
    "- Layer 0, 7, 14: Global Attention\n",
    "- Layer 3, 11: Local Attention (SWA) 샘플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계별 성능 비교 시각화\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Best Val PPL 비교 (Pretraining vs ORPO)\n",
    "ax = axes[0, 0]\n",
    "x = np.arange(len(results))\n",
    "width = 0.35\n",
    "\n",
    "pretrain_ppls = [r['pretrain_best_val_ppl'] for r in results.values()]\n",
    "orpo_ppls = [r['orpo_best_val_ppl'] for r in results.values()]\n",
    "\n",
    "bars1 = ax.bar(x - width/2, pretrain_ppls, width, label='Pretraining', color='skyblue', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, orpo_ppls, width, label='ORPO', color='coral', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('Best Validation Perplexity (lower is better)')\n",
    "ax.set_title('Best Val PPL: Pretraining vs ORPO')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(results.keys(), rotation=45, ha='right', fontsize=9)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 값 표시\n",
    "for i, (p, o) in enumerate(zip(pretrain_ppls, orpo_ppls)):\n",
    "    ax.text(i - width/2, p + 0.5, f'{p:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "    ax.text(i + width/2, o + 0.5, f'{o:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# 2. 학습 곡선 비교 (모든 모델의 Pretraining + ORPO)\n",
    "ax = axes[0, 1]\n",
    "for name, r in results.items():\n",
    "    # Pretraining history\n",
    "    pretrain_hist = r['pretrain_history']\n",
    "    pretrain_steps = pretrain_hist['step']\n",
    "    pretrain_val_ppl = pretrain_hist['val_ppl']\n",
    "    \n",
    "    # ORPO history\n",
    "    orpo_hist = r['orpo_history']\n",
    "    # ORPO step을 pretraining 이후로 이어서 그리기\n",
    "    orpo_steps = [s + pretrain_steps[-1] for s in orpo_hist['step']]\n",
    "    orpo_val_ppl = orpo_hist['val_ppl']\n",
    "    \n",
    "    # Pretraining 구간\n",
    "    ax.plot(pretrain_steps, pretrain_val_ppl, label=f'{name} (Pretrain)', \n",
    "            linestyle='-', linewidth=2, alpha=0.7)\n",
    "    \n",
    "    # ORPO 구간 (다른 스타일로)\n",
    "    ax.plot(orpo_steps, orpo_val_ppl, \n",
    "            linestyle='--', linewidth=2, alpha=0.7)\n",
    "\n",
    "# Stage 경계선\n",
    "if len(results) > 0:\n",
    "    first_result = list(results.values())[0]\n",
    "    stage_boundary = first_result['pretrain_history']['step'][-1]\n",
    "    ax.axvline(stage_boundary, color='red', linestyle=':', linewidth=2, alpha=0.5, label='ORPO Start')\n",
    "\n",
    "ax.set_xlabel('Training Steps')\n",
    "ax.set_ylabel('Validation Perplexity')\n",
    "ax.set_title('Training Curves (Solid=Pretrain, Dashed=ORPO)')\n",
    "ax.legend(loc='upper right', fontsize=7)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Learning Rate 곡선 (대표 모델 1개)\n",
    "ax = axes[1, 0]\n",
    "# 실제 존재하는 키 중에서 Hymba 모델 찾기\n",
    "representative_model = None\n",
    "for key in results.keys():\n",
    "    if \"Hymba\" in key or \"Paper\" in key:\n",
    "        representative_model = key\n",
    "        break\n",
    "if representative_model is None:\n",
    "    representative_model = list(results.keys())[0] if results else None\n",
    "\n",
    "if representative_model and representative_model in results:\n",
    "    r = results[representative_model]\n",
    "    \n",
    "    # Pretraining LR\n",
    "    pretrain_hist = r['pretrain_history']\n",
    "    pretrain_steps = pretrain_hist['step']\n",
    "    pretrain_lr = pretrain_hist['lr']\n",
    "    \n",
    "    # ORPO LR\n",
    "    orpo_hist = r['orpo_history']\n",
    "    orpo_steps = [s + pretrain_steps[-1] for s in orpo_hist['step']]\n",
    "    orpo_lr = orpo_hist['lr']\n",
    "    \n",
    "    ax.plot(pretrain_steps, pretrain_lr, label='Pretraining', color='blue', linewidth=2)\n",
    "    ax.plot(orpo_steps, orpo_lr, label='ORPO', color='orange', linewidth=2)\n",
    "    \n",
    "    # Stage 경계선\n",
    "    ax.axvline(pretrain_steps[-1], color='red', linestyle=':', linewidth=2, alpha=0.5)\n",
    "    \n",
    "    ax.set_xlabel('Training Steps')\n",
    "    ax.set_ylabel('Learning Rate')\n",
    "    ax.set_title(f'Learning Rate Schedule ({representative_model})')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "# 4. ORPO Loss Components (대표 모델)\n",
    "ax = axes[1, 1]\n",
    "if representative_model and representative_model in results:\n",
    "    r = results[representative_model]\n",
    "    orpo_hist = r['orpo_history']\n",
    "    \n",
    "    orpo_steps_relative = orpo_hist['step']\n",
    "    sft_losses = orpo_hist['sft_loss']\n",
    "    orpo_penalties = orpo_hist['orpo_loss']\n",
    "    total_losses = orpo_hist['train_loss']\n",
    "    \n",
    "    ax.plot(orpo_steps_relative, sft_losses, label='SFT Loss', marker='o', markersize=4, linewidth=2)\n",
    "    ax.plot(orpo_steps_relative, orpo_penalties, label='ORPO Penalty', marker='s', markersize=4, linewidth=2)\n",
    "    ax.plot(orpo_steps_relative, total_losses, label='Total Loss', marker='^', markersize=4, linewidth=2, linestyle='--')\n",
    "    \n",
    "    ax.set_xlabel('ORPO Training Steps')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title(f'ORPO Loss Components ({representative_model})')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{RESULTS_DIR}/training_stages_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved: {RESULTS_DIR}/training_stages_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계별 성능 비교 DataFrame\n",
    "stage_comparison = []\n",
    "\n",
    "for name, r in results.items():\n",
    "    stage_comparison.append({\n",
    "        \"Model\": name,\n",
    "        \"Stage\": \"Pretraining\",\n",
    "        \"Best Val Loss\": r['pretrain_best_val_loss'],\n",
    "        \"Best Val PPL\": r['pretrain_best_val_ppl'],\n",
    "        \"Final Val Loss\": r['pretrain_val_loss'],\n",
    "        \"Final Val PPL\": r['pretrain_val_ppl'],\n",
    "    })\n",
    "    stage_comparison.append({\n",
    "        \"Model\": name,\n",
    "        \"Stage\": \"ORPO\",\n",
    "        \"Best Val Loss\": r['orpo_best_val_loss'],\n",
    "        \"Best Val PPL\": r['orpo_best_val_ppl'],\n",
    "        \"Final Val Loss\": r['orpo_val_loss'],\n",
    "        \"Final Val PPL\": r['orpo_val_ppl'],\n",
    "    })\n",
    "\n",
    "df_stages = pd.DataFrame(stage_comparison)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"Stage-by-Stage Performance Comparison\")\n",
    "print(\"=\"*100)\n",
    "print(df_stages.to_string(index=False))\n",
    "print(\"=\"*100)\n",
    "\n",
    "# 단계별 성능 향상률 계산\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"Performance Improvement (Pretraining → ORPO)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for name in results.keys():\n",
    "    pretrain_ppl = results[name]['pretrain_best_val_ppl']\n",
    "    orpo_ppl = results[name]['orpo_best_val_ppl']\n",
    "    improvement = ((pretrain_ppl - orpo_ppl) / pretrain_ppl) * 100\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Pretraining PPL: {pretrain_ppl:.2f}\")\n",
    "    print(f\"  ORPO PPL: {orpo_ppl:.2f}\")\n",
    "    print(f\"  Improvement: {improvement:+.2f}%\")\n",
    "\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 학습 단계별 성능 비교 (Pretraining vs ORPO)\n",
    "\n",
    "각 모델의 Pretraining과 ORPO 단계의 성능을 비교하여 강화학습의 효과를 분석합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 비교 차트 - 최종 결과\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# 1. Final Best Validation Perplexity\n",
    "ax = axes[0, 0]\n",
    "ax.barh(df['Model'], df['Final Best PPL'], color='skyblue')\n",
    "ax.set_xlabel('Best Validation Perplexity (lower is better)')\n",
    "ax.set_title('Final Best Performance (either stage)')\n",
    "ax.invert_yaxis()\n",
    "for i, v in enumerate(df['Final Best PPL']):\n",
    "    ax.text(v + 1, i, f'{v:.1f}', va='center', fontsize=9)\n",
    "\n",
    "# 2. Pretraining vs ORPO PPL Comparison\n",
    "ax = axes[0, 1]\n",
    "x = np.arange(len(df))\n",
    "width = 0.35\n",
    "bars1 = ax.bar(x - width/2, df['Pretrain Best PPL'], width, label='Pretraining', color='lightblue', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, df['ORPO Best PPL'], width, label='ORPO', color='lightcoral', alpha=0.8)\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('Best Val PPL')\n",
    "ax.set_title('Pretraining vs ORPO Performance')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(df['Model'], rotation=45, ha='right', fontsize=7)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 3. Inference Speed\n",
    "ax = axes[0, 2]\n",
    "ax.barh(df['Model'], df['Infer Speed (tok/s)'], color='lightgreen')\n",
    "ax.set_xlabel('Inference Speed (tok/s, higher is better)')\n",
    "ax.set_title('Inference Speed')\n",
    "ax.invert_yaxis()\n",
    "for i, v in enumerate(df['Infer Speed (tok/s)']):\n",
    "    ax.text(v + 2, i, f'{v:.1f}', va='center', fontsize=9)\n",
    "\n",
    "# 4. Parameters\n",
    "ax = axes[1, 0]\n",
    "ax.barh(df['Model'], df['Params (M)'], color='lightyellow')\n",
    "ax.set_xlabel('Parameters (M)')\n",
    "ax.set_title('Model Size')\n",
    "ax.invert_yaxis()\n",
    "for i, v in enumerate(df['Params (M)']):\n",
    "    ax.text(v + 0.5, i, f'{v:.2f}M', va='center', fontsize=9)\n",
    "\n",
    "# 5. KV Reduction\n",
    "ax = axes[1, 1]\n",
    "colors = ['gray' if x == 1.0 else 'orange' for x in df['KV Reduction']]\n",
    "ax.barh(df['Model'], df['KV Reduction'], color=colors)\n",
    "ax.set_xlabel('KV Cache Reduction (higher is better)')\n",
    "ax.set_title('KV Cache Memory Reduction')\n",
    "ax.invert_yaxis()\n",
    "for i, v in enumerate(df['KV Reduction']):\n",
    "    ax.text(v + 0.05, i, f'{v:.2f}x', va='center', fontsize=9)\n",
    "\n",
    "# 6. Total Training Time\n",
    "ax = axes[1, 2]\n",
    "ax.barh(df['Model'], df['Total Time (min)'], color='plum')\n",
    "ax.set_xlabel('Total Training Time (min)')\n",
    "ax.set_title('Training Time (Pretrain + ORPO)')\n",
    "ax.invert_yaxis()\n",
    "for i, v in enumerate(df['Total Time (min)']):\n",
    "    ax.text(v + 0.2, i, f'{v:.1f}m', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{RESULTS_DIR}/ablation_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: ablation_results.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 학습 곡선 비교 (Pretraining 단계)\n",
    "\n",
    "**참고**: Cell 24에서는 Pretraining 단계의 학습 곡선만 비교합니다.\n",
    "ORPO 단계는 preference 데이터 없이 진행되어 성능이 저하되므로, 실제 모델 비교는 Pretraining 결과를 기준으로 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 곡선 비교 (Pretraining 단계 기준)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Training Loss (Pretraining)\n",
    "ax = axes[0]\n",
    "for name, r in results.items():\n",
    "    # pretrain_history 사용 (수정됨)\n",
    "    history = r['pretrain_history']\n",
    "    ax.plot(history['step'], history['train_loss'], label=name, marker='o', markersize=2, linewidth=2)\n",
    "ax.set_xlabel('Training Steps')\n",
    "ax.set_ylabel('Training Loss')\n",
    "ax.set_title('Training Loss Curves (Pretraining Stage)')\n",
    "ax.legend(loc='best', fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Validation PPL (Pretraining)\n",
    "ax = axes[1]\n",
    "for name, r in results.items():\n",
    "    history = r['pretrain_history']\n",
    "    ax.plot(history['step'], history['val_ppl'], label=name, marker='s', markersize=2, linewidth=2)\n",
    "ax.set_xlabel('Training Steps')\n",
    "ax.set_ylabel('Validation Perplexity')\n",
    "ax.set_title('Validation Perplexity Curves (Pretraining Stage)')\n",
    "ax.legend(loc='best', fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{RESULTS_DIR}/training_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved: {RESULTS_DIR}/training_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 생성 품질 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"Generation Quality Comparison\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "prompts = [\"ROMEO:\", \"First Citizen:\", \"KING:\"]\n",
    "\n",
    "for i, prompt in enumerate(prompts):\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    for name, r in results.items():\n",
    "        print(f\"\\n[{name}]\")\n",
    "        print(r['samples'][i])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Hymba Attention Map 시각화\n",
    "\n",
    "Hymba (Paper Setting) 모델의 주요 레이어별 attention pattern을 시각화합니다.\n",
    "- Layer 0: Global Attention (첫 번째)\n",
    "- Layer 5: Global Attention (중간)\n",
    "- Layer 10: Global Attention (마지막)\n",
    "- Layer 2, 7: Local Attention (SWA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_attention_maps(model, tokenizer, prompt=\"First Citizen:\", max_len=64, num_meta=64, save_path=None):\n",
    "    \"\"\"\n",
    "    Hymba 모델의 주요 레이어별 attention map 시각화 (개선된 버전)\n",
    "    \n",
    "    개선사항:\n",
    "    - Log scale 적용으로 작은 어텐션 값도 잘 보이게\n",
    "    - 더 선명한 색상 맵 사용\n",
    "    - 메타 토큰 영역 명확히 구분\n",
    "    \n",
    "    Args:\n",
    "        model: Hymba 모델\n",
    "        tokenizer: 토크나이저\n",
    "        prompt: 입력 프롬프트\n",
    "        max_len: 생성할 최대 길이\n",
    "        num_meta: Meta token 개수\n",
    "        save_path: 저장 경로 (None이면 저장 안 함)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # 입력 준비\n",
    "    prompt_tokens = tokenizer.encode(prompt)\n",
    "    input_ids = torch.tensor([prompt_tokens[:max_len]]).to(device)\n",
    "    \n",
    "    # Forward pass with attention weights\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, return_attn=True)\n",
    "    \n",
    "    attn_weights = outputs.get('attn_weights', [])\n",
    "    \n",
    "    if not attn_weights:\n",
    "        print(\"Warning: No attention weights available. Model may not support return_attn=True\")\n",
    "        return\n",
    "    \n",
    "    # 어텐션 타입 가져오기\n",
    "    try:\n",
    "        attn_types = model.cfg.get_attention_types()\n",
    "        global_indices = [i for i, t in enumerate(attn_types) if t == AttentionType.GLOBAL]\n",
    "        local_indices = [i for i, t in enumerate(attn_types) if t == AttentionType.LOCAL][:2]\n",
    "    except:\n",
    "        # 기본값\n",
    "        n_layers = len(attn_weights)\n",
    "        global_indices = [0, n_layers//2, n_layers-1] if n_layers > 2 else list(range(n_layers))\n",
    "        local_indices = [i for i in range(n_layers) if i not in global_indices][:2]\n",
    "    \n",
    "    # 플롯 생성\n",
    "    n_plots = len(global_indices) + len(local_indices)\n",
    "    n_cols = min(3, n_plots)\n",
    "    n_rows = (n_plots + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(6*n_cols, 5*n_rows))\n",
    "    if n_plots == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten() if n_plots > n_cols else axes\n",
    "    \n",
    "    plot_idx = 0\n",
    "    \n",
    "    # Global 레이어 시각화\n",
    "    for layer_idx in global_indices:\n",
    "        if layer_idx >= len(attn_weights) or attn_weights[layer_idx] is None:\n",
    "            continue\n",
    "        \n",
    "        attn = attn_weights[layer_idx][0, 0].cpu().numpy()\n",
    "        ax = axes[plot_idx]\n",
    "        \n",
    "        # Log scale 변환\n",
    "        attn_vis = np.clip(attn, 1e-6, 1.0)\n",
    "        attn_log = np.log10(attn_vis + 1e-8)\n",
    "        \n",
    "        im = ax.imshow(attn_log, cmap='magma', aspect='auto', vmin=-4, vmax=0)\n",
    "        ax.set_title(f'Layer {layer_idx}: Global Attention', fontweight='bold', fontsize=11, color='darkred')\n",
    "        ax.set_xlabel('Key Position')\n",
    "        ax.set_ylabel('Query Position')\n",
    "        \n",
    "        # 메타 토큰 경계\n",
    "        if num_meta > 0 and num_meta < attn.shape[0]:\n",
    "            ax.axvline(x=num_meta-0.5, color='lime', linestyle='-', linewidth=2, alpha=0.8)\n",
    "            ax.axhline(y=num_meta-0.5, color='lime', linestyle='-', linewidth=2, alpha=0.8)\n",
    "        \n",
    "        cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        cbar.set_label('log₁₀(attention)', fontsize=9)\n",
    "        plot_idx += 1\n",
    "    \n",
    "    # Local 레이어 시각화\n",
    "    for layer_idx in local_indices:\n",
    "        if layer_idx >= len(attn_weights) or attn_weights[layer_idx] is None:\n",
    "            continue\n",
    "        \n",
    "        attn = attn_weights[layer_idx][0, 0].cpu().numpy()\n",
    "        ax = axes[plot_idx]\n",
    "        \n",
    "        attn_vis = np.clip(attn, 1e-6, 1.0)\n",
    "        attn_log = np.log10(attn_vis + 1e-8)\n",
    "        \n",
    "        im = ax.imshow(attn_log, cmap='viridis', aspect='auto', vmin=-4, vmax=0)\n",
    "        ax.set_title(f'Layer {layer_idx}: Local (SWA)', fontweight='bold', fontsize=11, color='darkblue')\n",
    "        ax.set_xlabel('Key Position')\n",
    "        ax.set_ylabel('Query Position')\n",
    "        \n",
    "        if num_meta > 0 and num_meta < attn.shape[0]:\n",
    "            ax.axvline(x=num_meta-0.5, color='yellow', linestyle='-', linewidth=2, alpha=0.8)\n",
    "            ax.axhline(y=num_meta-0.5, color='yellow', linestyle='-', linewidth=2, alpha=0.8)\n",
    "        \n",
    "        cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        cbar.set_label('log₁₀(attention)', fontsize=9)\n",
    "        plot_idx += 1\n",
    "    \n",
    "    # 빈 플롯 제거\n",
    "    for i in range(plot_idx, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "    \n",
    "    plt.suptitle(f'Hymba Attention Maps (Log Scale)\\nPrompt: \"{prompt[:30]}...\"', fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Pattern 상세 분석\n",
    "\n",
    "Attention map에서 관찰할 수 있는 주요 패턴:\n",
    "\n",
    "#### Global Attention Layers (0, 5, 10)\n",
    "- **전체 시퀀스 attention**: 모든 위치에서 모든 토큰을 참조 가능\n",
    "- **Meta token 활용**: 상단 및 좌측의 밝은 영역은 meta token에 대한 높은 attention\n",
    "- **장거리 의존성**: 먼 거리의 토큰 간에도 attention 가능\n",
    "\n",
    "#### Local Attention Layers (SWA)\n",
    "- **Diagonal pattern**: 대각선 패턴은 sliding window의 특징\n",
    "- **제한된 범위**: 각 토큰은 window size(128) 내의 이전 토큰만 참조\n",
    "- **Meta token 항상 참조**: 좌측 밝은 영역은 항상 참조 가능한 meta token\n",
    "\n",
    "#### Meta Token의 역할\n",
    "- **첫 64개 토큰**: 학습 가능한 전역 컨텍스트\n",
    "- **모든 레이어에서 참조**: Global/Local 관계없이 항상 접근 가능\n",
    "- **도메인 정보 캡슐화**: 다양한 태스크/도메인 정보 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 분석 및 결론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"Key Findings & Analysis\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# 최고 성능 모델 (Pretraining 기준 - ORPO는 preference 데이터 없이 의미 없음)\n",
    "best_ppl = df.loc[df['Pretrain Best PPL'].idxmin()]\n",
    "print(f\"\\n1. Best Performance (Pretraining PPL): {best_ppl['Model']}\")\n",
    "print(f\"   - Best Val PPL: {best_ppl['Pretrain Best PPL']:.2f}\")\n",
    "\n",
    "# 최고 추론 속도\n",
    "best_infer_speed = df.loc[df['Infer Speed (tok/s)'].idxmax()]\n",
    "print(f\"\\n2. Fastest Inference: {best_infer_speed['Model']}\")\n",
    "print(f\"   - Speed: {best_infer_speed['Infer Speed (tok/s)']:.1f} tok/s\")\n",
    "\n",
    "# 최대 KV 절감\n",
    "best_kv = df.loc[df['KV Reduction'].idxmax()]\n",
    "print(f\"\\n3. Maximum KV Cache Reduction: {best_kv['Model']}\")\n",
    "print(f\"   - Reduction: {best_kv['KV Reduction']:.2f}x\")\n",
    "\n",
    "# Hybrid 모델 상세 분석\n",
    "hybrid_models = df[df['Model'].str.contains('Hybrid|Hymba')]\n",
    "if len(hybrid_models) > 0:\n",
    "    print(f\"\\n4. Hybrid Model Analysis:\")\n",
    "    for _, row in hybrid_models.iterrows():\n",
    "        print(f\"\\n   [{row['Model']}]\")\n",
    "        print(f\"     - Pretrain Best PPL: {row['Pretrain Best PPL']:.2f}\")\n",
    "        print(f\"     - KV Reduction: {row['KV Reduction']:.2f}x\")\n",
    "        print(f\"     - Infer Speed: {row['Infer Speed (tok/s)']:.1f} tok/s\")\n",
    "        print(f\"     - Training Time: {row['Total Time (min)']:.1f} min\")\n",
    "\n",
    "# 성능 대비 효율성 분석 (Pretraining 기준)\n",
    "print(f\"\\n5. Performance vs Efficiency Trade-off (Pretraining):\")\n",
    "for _, row in df.iterrows():\n",
    "    efficiency_score = (1.0 / row['Pretrain Best PPL']) * row['Infer Speed (tok/s)'] * row['KV Reduction']\n",
    "    print(f\"   {row['Model']:40s}: Efficiency Score = {efficiency_score:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"Conclusions\")\n",
    "print(\"=\"*100)\n",
    "print(\"\"\"\n",
    "1. **Pretraining 결과 분석**:\n",
    "   - 모든 모델이 비슷한 범위의 PPL (68~74)에 수렴\n",
    "   - Mamba-only가 가장 빠른 추론 속도\n",
    "   - Hybrid 모델이 KV Cache 절감 효과 제공\n",
    "\n",
    "2. **ORPO 단계 분석**:\n",
    "   - 현재 구현은 preference pair (chosen/rejected) 데이터 없이 진행\n",
    "   - 실제 ORPO는 선호/비선호 응답 쌍이 필수\n",
    "   - 따라서 ORPO 단계의 성능 저하는 예상된 결과\n",
    "\n",
    "3. **실제 적용 권장사항**:\n",
    "   - Pretraining 결과를 기준으로 모델 선택\n",
    "   - ORPO 적용 시 적절한 preference 데이터셋 필요\n",
    "   - Hybrid 모델: 성능과 효율성의 균형\n",
    "   - Mamba-only: 추론 속도 우선 시\n",
    "   - Transformer-only: 높은 성능 우선 시\n",
    "\n",
    "4. **Hymba (Paper Setting) 권장**:\n",
    "   - Global/Local Attention 조합으로 효율성 향상\n",
    "   - Meta Token을 통한 전역 컨텍스트 접근\n",
    "   - KV Cache 공유로 메모리 절감\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 저장\n",
    "df.to_csv(f'{RESULTS_DIR}/ablation_results.csv', index=False)\n",
    "print(f\"Saved: {RESULTS_DIR}/ablation_results.csv\")\n",
    "\n",
    "# 생성 샘플 저장 (모든 프롬프트)\n",
    "with open(f'{RESULTS_DIR}/generation_samples.txt', 'w', encoding='utf-8') as f:\n",
    "    prompts = [\"ROMEO:\", \"First Citizen:\", \"KING:\"]\n",
    "    \n",
    "    for i, prompt in enumerate(prompts):\n",
    "        f.write(f\"{'='*100}\\n\")\n",
    "        f.write(f\"Prompt: {prompt}\\n\")\n",
    "        f.write(f\"{'='*100}\\n\\n\")\n",
    "        \n",
    "        for name, r in results.items():\n",
    "            f.write(f\"[{name}]\\n\")\n",
    "            f.write(f\"{r['samples'][i]}\\n\\n\")\n",
    "        \n",
    "        f.write(\"\\n\\n\")\n",
    "\n",
    "print(f\"Saved: {RESULTS_DIR}/generation_samples.txt\")\n",
    "\n",
    "# 상세 메트릭 저장\n",
    "with open(f'{RESULTS_DIR}/detailed_metrics.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"=\"*100 + \"\\n\")\n",
    "    f.write(\"Hymba Ablation Study - Detailed Metrics\\n\")\n",
    "    f.write(\"=\"*100 + \"\\n\\n\")\n",
    "    \n",
    "    for name, r in results.items():\n",
    "        f.write(f\"\\n{'='*80}\\n\")\n",
    "        f.write(f\"Model: {name}\\n\")\n",
    "        f.write(f\"{'='*80}\\n\")\n",
    "        f.write(f\"Parameters: {r['params']:,}\\n\")\n",
    "        f.write(f\"\\nPretraining Stage:\\n\")\n",
    "        f.write(f\"  Best Val Loss: {r['pretrain_best_val_loss']:.4f}\\n\")\n",
    "        f.write(f\"  Best Val PPL: {r['pretrain_best_val_ppl']:.2f}\\n\")\n",
    "        f.write(f\"\\nORPO Stage:\\n\")\n",
    "        f.write(f\"  Best Val Loss: {r['orpo_best_val_loss']:.4f}\\n\")\n",
    "        f.write(f\"  Best Val PPL: {r['orpo_best_val_ppl']:.2f}\\n\")\n",
    "        f.write(f\"\\nFinal Performance:\\n\")\n",
    "        f.write(f\"  Best Val PPL: {r['best_val_ppl']:.2f}\\n\")\n",
    "        f.write(f\"  Inference Speed: {r['tokens_per_sec']:.1f} tok/s\\n\")\n",
    "        f.write(f\"  KV Cache Reduction: {r['kv_reduction']:.2f}x\\n\")\n",
    "        f.write(f\"  Total Training Time: {r['total_time_min']:.1f} min\\n\")\n",
    "\n",
    "print(f\"Saved: {RESULTS_DIR}/detailed_metrics.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
