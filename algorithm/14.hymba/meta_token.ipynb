{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37ccd29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. 입력 단계 ---\n",
      "입력 토큰 Shape: torch.Size([2, 512])\n",
      "입력 임베딩 Shape: torch.Size([2, 512, 256])\n",
      "복제된 메타 토큰 Shape: torch.Size([2, 4, 256])\n",
      "▶ 메타 토큰 결합 후 확장된 시퀀스 Shape: torch.Size([2, 516, 256])\n",
      "\n",
      "--- 2. 내부 처리 단계 ---\n",
      "내부 레이어 통과 후 Shape: torch.Size([2, 516, 256])\n",
      "\n",
      "--- 3. 출력 슬라이싱 단계 ---\n",
      "▶ 메타 토큰 슬라이싱 후 원래 시퀀스 Shape: torch.Size([2, 512, 256])\n",
      "최종 로짓 Shape: torch.Size([2, 512, 32000])\n",
      "\n",
      "========================================\n",
      "최종 요약:\n",
      "입력 시퀀스 길이: 512\n",
      "내부 처리 시퀀스 길이: 516\n",
      "최종 출력 시퀀스 길이: 512\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleHymbaWithMetaTokens(nn.Module):\n",
    "    \"\"\"\n",
    "    메타 토큰 처리 흐름을 명확히 보여주기 위한 간소화된 모델\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.d_model = config['d_model']\n",
    "        self.n_meta_tokens = config['n_meta_tokens']\n",
    "\n",
    "        # 학습 가능한 메타 토큰 파라미터 생성\n",
    "        # Shape: (1, n_meta_tokens, d_model)\n",
    "        self.meta_tokens = nn.Parameter(torch.randn(1, self.n_meta_tokens, self.d_model))\n",
    "        \n",
    "        # 일반 토큰을 위한 임베딩 레이어\n",
    "        self.token_embeddings = nn.Embedding(config['vocab_size'], self.d_model)\n",
    "        \n",
    "        # 모델의 내부 레이어들을 단순화한 예시\n",
    "        self.internal_layers = nn.Sequential(\n",
    "            nn.Linear(self.d_model, self.d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.d_model, self.d_model)\n",
    "        )\n",
    "\n",
    "        # 최종 출력을 위한 언어 모델 헤드\n",
    "        self.lm_head = nn.Linear(self.d_model, config['vocab_size'])\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor):\n",
    "        batch_size, seq_len = tokens.shape\n",
    "        print(f\"--- 1. 입력 단계 ---\")\n",
    "        print(f\"입력 토큰 Shape: {tokens.shape}\")\n",
    "\n",
    "        # 토큰을 임베딩으로 변환\n",
    "        input_embeds = self.token_embeddings(tokens)\n",
    "        print(f\"입력 임베딩 Shape: {input_embeds.shape}\")\n",
    "\n",
    "        # 메타 토큰을 배치 사이즈만큼 복제\n",
    "        meta_embeds = self.meta_tokens.expand(batch_size, -1, -1)\n",
    "        print(f\"복제된 메타 토큰 Shape: {meta_embeds.shape}\")\n",
    "\n",
    "        # ===> 시퀀스 확장 <===\n",
    "        combined_embeds = torch.cat([meta_embeds, input_embeds], dim=1)\n",
    "        print(f\"▶ 메타 토큰 결합 후 확장된 시퀀스 Shape: {combined_embeds.shape}\\n\")\n",
    "        \n",
    "        print(f\"--- 2. 내부 처리 단계 ---\")\n",
    "        # 모델의 내부 레이어 통과 (확장된 시퀀스로 처리)\n",
    "        processed_output = self.internal_layers(combined_embeds)\n",
    "        print(f\"내부 레이어 통과 후 Shape: {processed_output.shape}\\n\")\n",
    "\n",
    "        print(f\"--- 3. 출력 슬라이싱 단계 ---\")\n",
    "        # ===> 시퀀스 슬라이싱 <===\n",
    "        # 최종 로짓 계산을 위해 메타 토큰에 해당하는 부분을 잘라냄\n",
    "        # Shape: (batch_size, seq_len, d_model)\n",
    "        output_for_lm_head = processed_output[:, self.n_meta_tokens:, :]\n",
    "        print(f\"▶ 메타 토큰 슬라이싱 후 원래 시퀀스 Shape: {output_for_lm_head.shape}\")\n",
    "\n",
    "        # 최종 로짓 계산\n",
    "        final_logits = self.lm_head(output_for_lm_head)\n",
    "        print(f\"최종 로짓 Shape: {final_logits.shape}\")\n",
    "\n",
    "        return final_logits\n",
    "\n",
    "# --- 테스트 실행 ---\n",
    "if __name__ == '__main__':\n",
    "    # 모델 설정\n",
    "    config = {\n",
    "        'vocab_size': 32000,\n",
    "        'd_model': 256,\n",
    "        'n_meta_tokens': 4,\n",
    "    }\n",
    "\n",
    "    # 모델 초기화\n",
    "    model = SimpleHymbaWithMetaTokens(config)\n",
    "    \n",
    "    # 더미 입력 데이터 생성\n",
    "    dummy_input = torch.randint(0, config['vocab_size'], (2, 512)) # (batch_size=2, seq_len=512)\n",
    "    \n",
    "    # 모델 실행\n",
    "    with torch.no_grad():\n",
    "        output = model(dummy_input)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"최종 요약:\")\n",
    "    print(f\"입력 시퀀스 길이: {dummy_input.shape[1]}\")\n",
    "    print(f\"내부 처리 시퀀스 길이: {dummy_input.shape[1] + config['n_meta_tokens']}\")\n",
    "    print(f\"최종 출력 시퀀스 길이: {output.shape[1]}\")\n",
    "    print(\"=\"*40)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
