{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from timm.data import Mixup\n",
    "import transformers\n",
    "\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "from timm.models.layers import DropPath, trunc_normal_, to_2tuple\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01.Convolutional Token Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvEmbed(nn.Module):\n",
    "    '''\n",
    "    img/token map to Conv Embedding\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,\n",
    "                 patch_size=7, # [7, 3, 3]\n",
    "                 in_chans=3,   # [3, dim of stage1, dim of stage2]\n",
    "                 embed_dim=64, # [64, 192, 384]\n",
    "                 stride=4,     # [4, 2, 2]\n",
    "                 padding=2,    # [2, 1, 1]\n",
    "                 norm_layer=None):\n",
    "        super().__init__()\n",
    "        self.patch_size = to_2tuple(patch_size)\n",
    "        \n",
    "        self.proj = nn.Conv2d(\n",
    "            in_channels=in_chans,\n",
    "            out_channels=embed_dim,\n",
    "            kernel_size=patch_size,\n",
    "            stride=stride,\n",
    "            padding=padding\n",
    "        )\n",
    "        \n",
    "        self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)\n",
    "        \n",
    "        _, _, H, W = x.shape\n",
    "        x = rearrange(x, 'b c h w -> b (h w) c')\n",
    "        x = self.norm(x)\n",
    "        x = rearrange(x, 'b (h w) c -> b c h w', h=H, w=W)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionConv(nn.Module):\n",
    "    def __init__(self,\n",
    "                 dim=64,        # [64,192,384]\n",
    "                 num_heads=4,   # paper: [1,3,6], me: [4,8,16]\n",
    "                 qkv_bias=False,\n",
    "                 attn_drop=0.,\n",
    "                 proj_drop=0.,\n",
    "                 kernel_size=3,\n",
    "                 padding_q=1,\n",
    "                 padding_kv=1,\n",
    "                 stride_q=1,\n",
    "                 stride_kv=2,\n",
    "                 **kwargs\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.stride_q = stride_q\n",
    "        self.stride_kv = stride_kv\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads        \n",
    "        self.scale = dim ** -0.5\n",
    "        \n",
    "        self.conv_proj_q = self._build_projection(dim,\n",
    "                                                  kernel_size,\n",
    "                                                  padding_q,\n",
    "                                                  stride_q,\n",
    "                                                  )\n",
    "        self.conv_proj_k = self._build_projection(dim,\n",
    "                                                  kernel_size,\n",
    "                                                  padding_kv,\n",
    "                                                  stride_kv,\n",
    "                                                  )\n",
    "        \n",
    "        self.conv_proj_v = self._build_projection(dim,\n",
    "                                                  kernel_size,\n",
    "                                                  padding_kv,\n",
    "                                                  stride_kv,\n",
    "                                                  )\n",
    "        \n",
    "        self.linear_proj_q = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        self.linear_proj_k = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        self.linear_proj_v = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        \n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.linear_proj_last = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)        \n",
    "        \n",
    "    def _build_projection(self,\n",
    "                          dim,\n",
    "                          kernel_size,\n",
    "                          padding,\n",
    "                          stride,\n",
    "                          ):\n",
    "        \n",
    "        proj = nn.Sequential(OrderedDict([\n",
    "            ('depthwise', nn.Conv2d(\n",
    "                dim,\n",
    "                dim,\n",
    "                kernel_size=kernel_size,\n",
    "                padding=padding,\n",
    "                stride=stride,\n",
    "                bias=False,\n",
    "                groups=dim)),\n",
    "            ('bn', nn.BatchNorm2d(dim)),\n",
    "            ('rearrange', Rearrange('b c h w -> b (h w) c'))\n",
    "        ]))\n",
    "        \n",
    "        return proj\n",
    "    \n",
    "    def forward(self, x, h, w):\n",
    "        x = rearrange(x, 'b (h w) c -> b c h w', h=h, w=w)\n",
    "        \n",
    "        q = F.normalize(self.conv_proj_q(x), dim=-1)\n",
    "        k = F.normalize(self.conv_proj_k(x), dim=-1)\n",
    "        v = self.conv_proj_v(x)\n",
    "        \n",
    "        q = rearrange(self.linear_proj_q(q), 'b t (h d) -> b h t d', h=self.num_heads)\n",
    "        k = rearrange(self.linear_proj_k(k), 'b t (h d) -> b h t d', h=self.num_heads)\n",
    "        v = rearrange(self.linear_proj_v(v), 'b t (h d) -> b h t d', h=self.num_heads)\n",
    "        \n",
    "        attn_score = torch.einsum('bhlk,bhtk->bhlt', [q, k]) * self.scale\n",
    "        attn = self.attn_drop(F.softmax(attn_score, dim=-1))\n",
    "        \n",
    "        x = torch.matmul(attn, v)\n",
    "        batch_size, num_heads, seq_length, depth = x.size()\n",
    "        x = x.view(batch_size, seq_length, num_heads * depth)\n",
    "        \n",
    "        x = self.proj_drop(self.linear_proj_last(x))\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer block에 작은 스케일 인자 곱하기\n",
    "class LayerScale(nn.Module):\n",
    "    def __init__(self, dim, init_values=1e-5):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(init_values * torch.ones((dim)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gamma * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 dim,\n",
    "                 num_heads,\n",
    "                 mlp_ratio=4.,\n",
    "                 qkv_bias=False,\n",
    "                 drop=0.,\n",
    "                 attn_drop=0.,\n",
    "                 drop_path=0.,\n",
    "                 act_layer=nn.GELU,\n",
    "                 norm_layer=nn.LayerNorm,\n",
    "                 **kwargs\n",
    "                ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.ls1 = LayerScale(dim)\n",
    "        self.attn = AttentionConv(dim=dim,\n",
    "                                  num_heads=num_heads,\n",
    "                                  qkv_bias=qkv_bias,\n",
    "                                  attn_drop=attn_drop,\n",
    "                                  proj_drop=drop,\n",
    "                                  **kwargs)        \n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        self.ls2 = LayerScale(dim)\n",
    "        mlp_hidden_dim = int(dim*mlp_ratio)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, mlp_hidden_dim),\n",
    "            act_layer(),\n",
    "            nn.LayerNorm(mlp_hidden_dim),\n",
    "            nn.Linear(mlp_hidden_dim, dim),\n",
    "            nn.Dropout(drop),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, h, w):\n",
    "        res = x\n",
    "        x = self.norm1(x)\n",
    "        attn = self.attn(x, h, w)\n",
    "        x = res + self.drop_path(self.ls1(attn))\n",
    "        x = x + self.drop_path(self.ls2(self.mlp(self.norm2(x))))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = torch.Tensor(np.zeros((2,3,224,224))) # B, C, H, W\n",
    "\n",
    "block = Block(dim=64,\n",
    "              num_heads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage 1 | img shape: torch.Size([2, 3, 224, 224]) → Conv Embed Shape: torch.Size([2, 64, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "# Stage 1 \n",
    "\n",
    "## Patch Embedding\n",
    "convembed = ConvEmbed(patch_size=7, stride=4, padding=2)\n",
    "stage1_img = convembed(test_img)\n",
    "\n",
    "## Attention with Convolution\n",
    "b, c, h, w = stage1_img.shape\n",
    "stage1_img = rearrange(stage1_img, 'b c h w -> b (h w) c')\n",
    "stage1_img = block(stage1_img, h=h, w=w)\n",
    "stage1_img = rearrange(stage1_img, 'b (h w) c -> b c h w', h=h, w=w)\n",
    "\n",
    "## Check Result\n",
    "print(f'stage 1 | img shape: {test_img.shape} → Conv Embed Shape: {stage1_img.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage 2 | img shape: torch.Size([2, 64, 56, 56]) → Conv Embed Shape: torch.Size([2, 64, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Stage 2 \n",
    "\n",
    "## Patch Embedding\n",
    "convembed = ConvEmbed(patch_size=3, in_chans=64, stride=2, padding=1)\n",
    "stage2_img = convembed(stage1_img)\n",
    "\n",
    "## Attention with Convolution\n",
    "b, c, h, w = stage2_img.shape\n",
    "stage2_img = rearrange(stage2_img, 'b c h w -> b (h w) c')\n",
    "stage2_img = block(stage2_img, h=h, w=w)\n",
    "stage2_img = rearrange(stage2_img, 'b (h w) c -> b c h w', h=h, w=w)\n",
    "\n",
    "## Check Result\n",
    "print(f'stage 2 | img shape: {stage1_img.shape} → Conv Embed Shape: {stage2_img.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage 3 | img shape: torch.Size([2, 64, 28, 28]) → Conv Embed Shape: torch.Size([2, 64, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "# Stage 3 \n",
    "\n",
    "## Patch Embedding\n",
    "convembed = ConvEmbed(patch_size=3, in_chans=64, stride=2, padding=1)\n",
    "stage3_img = convembed(stage2_img)\n",
    "\n",
    "## Attention with Convolution\n",
    "b, c, h, w = stage3_img.shape\n",
    "stage3_img = rearrange(stage3_img, 'b c h w -> b (h w) c')\n",
    "stage3_img = block(stage3_img, h=h, w=w)\n",
    "stage3_img = rearrange(stage3_img, 'b (h w) c -> b c h w', h=h, w=w)\n",
    "\n",
    "## Check Result\n",
    "print(f'stage 3 | img shape: {stage2_img.shape} → Conv Embed Shape: {stage3_img.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 patch_size=16,\n",
    "                 patch_stride=16,\n",
    "                 patch_padding=0,\n",
    "                 in_chans=3,\n",
    "                 embed_dim=768,\n",
    "                 depth=12,\n",
    "                 num_heads=12,\n",
    "                 mlp_ratio=4.,\n",
    "                 qkv_bias=False,\n",
    "                 drop_rate=0.,\n",
    "                 attn_drop_rate=0.,\n",
    "                 drop_path_rate=0.,\n",
    "                 act_layer=nn.GELU,\n",
    "                 norm_layer=nn.LayerNorm,\n",
    "                 init='trunc_norm',\n",
    "                 **kwargs\n",
    "                 ):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.patch_embed = ConvEmbed(\n",
    "            patch_size=patch_size,\n",
    "            in_chans=in_chans,\n",
    "            stride=patch_stride,\n",
    "            padding=patch_padding,\n",
    "            embed_dim=embed_dim,\n",
    "            norm_layer=norm_layer\n",
    "        )\n",
    "\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Block(\n",
    "                dim=embed_dim,\n",
    "                num_heads=num_heads,\n",
    "                mlp_ratio=mlp_ratio,\n",
    "                qkv_bias=qkv_bias,\n",
    "                drop=drop_rate,\n",
    "                attn_drop=attn_drop_rate,\n",
    "                drop_path=drop_path_rate,\n",
    "                act_layer=act_layer,\n",
    "                norm_layer=norm_layer,\n",
    "                **kwargs\n",
    "            ) for _ in range(depth)\n",
    "        ])\n",
    "\n",
    "        if init == 'xavier':\n",
    "            self.apply(self._init_weights_xavier)\n",
    "        else:\n",
    "            self.apply(self._init_weights_trunc_normal)\n",
    "\n",
    "    def _init_weights_trunc_normal(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=0.02)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, (nn.LayerNorm, nn.BatchNorm2d)):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    def _init_weights_xavier(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, (nn.LayerNorm, nn.BatchNorm2d)):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        _, _, H, W = x.size()\n",
    "\n",
    "        x = rearrange(x, 'b c h w -> b (h w) c')\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        for _, blk in enumerate(self.blocks):\n",
    "            x = blk(x, H, W)\n",
    "        x = rearrange(x, 'b (h w) c -> b c h w', h=H, w=W)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalVisionTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_chans=3,\n",
    "                 num_classes=100,\n",
    "                 act_layer=nn.GELU,\n",
    "                 norm_layer=nn.LayerNorm,\n",
    "                 init='trunc_norm',\n",
    "                 spec=None):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.num_stages = spec['NUM_STAGES']\n",
    "        self.stages = nn.ModuleList()\n",
    "        for i in range(self.num_stages):\n",
    "            kwargs = {\n",
    "                'patch_size': spec['PATCH_SIZE'][i],\n",
    "                'patch_stride': spec['PATCH_STRIDE'][i],\n",
    "                'patch_padding': spec['PATCH_PADDING'][i],\n",
    "                'embed_dim': spec['DIM_EMBED'][i],\n",
    "                'depth': spec['DEPTH'][i],\n",
    "                'num_heads': spec['NUM_HEADS'][i],\n",
    "                'mlp_ratio': spec['MLP_RATIO'][i],\n",
    "                'qkv_bias': spec['QKV_BIAS'][i],\n",
    "                'drop_rate': spec['DROP_RATE'][i],\n",
    "                'attn_drop_rate': spec['ATTN_DROP_RATE'][i],\n",
    "                'drop_path_rate': spec['DROP_PATH_RATE'][i],\n",
    "                'kernel_size': spec['KERNEL_QKV'][i],\n",
    "                'padding_q': spec['PADDING_Q'][i],\n",
    "                'padding_kv': spec['PADDING_KV'][i],\n",
    "                'stride_q': spec['STRIDE_Q'][i],\n",
    "                'stride_kv': spec['STRIDE_KV'][i],\n",
    "            }\n",
    "\n",
    "            stage = VisionTransformer(\n",
    "                in_chans=in_chans,\n",
    "                init=init,\n",
    "                act_layer=act_layer,\n",
    "                norm_layer=norm_layer,\n",
    "                **kwargs\n",
    "            )\n",
    "            \n",
    "            self.stages.append(stage)\n",
    "\n",
    "            in_chans = spec['DIM_EMBED'][i]\n",
    "\n",
    "        dim_embed = spec['DIM_EMBED'][-1]\n",
    "        self.norm = norm_layer(dim_embed)\n",
    "        self.pooler = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        # Classifier head\n",
    "        self.head = nn.Linear(dim_embed, num_classes) if num_classes > 0 else nn.Identity()\n",
    "        trunc_normal_(self.head.weight, std=0.02)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        for stage in self.stages:\n",
    "            x = stage(x)\n",
    "\n",
    "        x = rearrange(x, 'b c h w -> b (h w) c') # (B, L, C)\n",
    "        x = self.norm(x)                         # (B, L, C)\n",
    "        x = self.pooler(x.transpose(1,2))        # (B, C, 1)\n",
    "        x = torch.flatten(x, 1)                  # (B, C)\n",
    "        # x = torch.mean(x, dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.head(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuickGELU(nn.Module):\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return x * torch.sigmoid(1.702 * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NUM_STAGES': 3,\n",
       " 'PATCH_SIZE': [7, 3, 3],\n",
       " 'PATCH_STRIDE': [4, 2, 2],\n",
       " 'PATCH_PADDING': [2, 1, 1],\n",
       " 'DIM_EMBED': [64, 192, 384],\n",
       " 'DEPTH': [1, 2, 10],\n",
       " 'NUM_HEADS': [4, 8, 12],\n",
       " 'MLP_RATIO': [4.0, 4.0, 4.0],\n",
       " 'QKV_BIAS': [True, True, True],\n",
       " 'DROP_RATE': [0.0, 0.0, 0.1],\n",
       " 'ATTN_DROP_RATE': [0.0, 0.0, 0.1],\n",
       " 'DROP_PATH_RATE': [0.1, 0.1, 0.1],\n",
       " 'KERNEL_QKV': [3, 3, 3],\n",
       " 'PADDING_Q': [1, 1, 1],\n",
       " 'PADDING_KV': [1, 1, 1],\n",
       " 'STRIDE_Q': [1, 1, 1],\n",
       " 'STRIDE_KV': [2, 2, 2]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec = {\n",
    "    'NUM_STAGES': 3,\n",
    "    'PATCH_SIZE': [7,3,3],\n",
    "    'PATCH_STRIDE': [4,2,2],\n",
    "    'PATCH_PADDING': [2,1,1],\n",
    "    'DIM_EMBED': [64,192,384],\n",
    "    'DEPTH': [1,2,10],\n",
    "    'NUM_HEADS': [4,8,12],   # original : [1,3,6]\n",
    "    'MLP_RATIO': [4.,4.,4.],\n",
    "    'QKV_BIAS': [True, True, True],\n",
    "    'DROP_RATE': [0.,0.,0.1],\n",
    "    'ATTN_DROP_RATE': [0.,0.,0.1],\n",
    "    'DROP_PATH_RATE': [0.1,0.1,0.1],\n",
    "    'KERNEL_QKV': [3,3,3],\n",
    "    'PADDING_Q': [1,1,1],\n",
    "    'PADDING_KV': [1,1,1],\n",
    "    'STRIDE_Q': [1,1,1],\n",
    "    'STRIDE_KV': [2,2,2],\n",
    "}\n",
    "\n",
    "spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 224, 224]),\n",
       " torch.Size([2, 100]),\n",
       " tensor([[ 0.1219, -0.0815, -0.3613,  0.1879,  0.9660, -1.0567, -0.5857,  0.0221,\n",
       "           0.0416,  0.3608,  0.0656,  0.1816,  0.0712,  0.6466, -0.1743, -0.7479,\n",
       "          -0.2648, -0.0308,  0.4186,  0.5663,  0.2949, -0.0193, -0.4290, -0.7449,\n",
       "          -0.2640,  0.0207,  0.2048,  0.0193, -0.4646,  0.4863, -0.0148,  0.0247,\n",
       "          -0.1814,  0.8372,  0.1173, -0.1608,  0.2268, -0.1958, -0.3416,  0.1195,\n",
       "           0.1928,  0.1635,  0.5514, -0.0765, -0.5758,  0.3416, -0.3915, -0.0176,\n",
       "           0.1030, -0.1409,  0.1987,  0.6768, -0.2885, -0.9015,  0.5447, -0.4804,\n",
       "           0.3498,  0.3018,  0.0196,  0.0716,  0.1800,  0.4379,  0.3129, -0.0226,\n",
       "           0.6586, -0.4514, -0.2141, -0.2445, -0.3230,  0.1894, -0.0988, -0.3749,\n",
       "           0.5958, -0.0098,  0.1248, -0.0773, -0.1809, -0.2225, -0.1625, -0.0527,\n",
       "          -0.3042,  0.6189, -0.1758, -0.6687, -0.0124,  0.5241,  0.3694,  0.1141,\n",
       "          -0.1199,  0.3000, -0.1274, -0.1706, -0.0379, -0.2792,  0.0058,  0.0186,\n",
       "           0.1680,  0.3937, -0.5447, -0.2029],\n",
       "         [ 0.1146, -0.0979, -0.3393,  0.1990,  0.9510, -1.0326, -0.5840,  0.0209,\n",
       "           0.0565,  0.3570,  0.0655,  0.2091,  0.0683,  0.6338, -0.1620, -0.7598,\n",
       "          -0.2493, -0.0599,  0.4177,  0.5804,  0.2766, -0.0178, -0.4263, -0.7390,\n",
       "          -0.2707,  0.0261,  0.1963,  0.0250, -0.4662,  0.4773, -0.0323,  0.0064,\n",
       "          -0.1967,  0.8286,  0.1179, -0.1554,  0.2385, -0.2076, -0.3414,  0.0972,\n",
       "           0.1815,  0.1631,  0.5755, -0.0877, -0.5642,  0.3372, -0.3894, -0.0170,\n",
       "           0.1067, -0.1395,  0.1905,  0.6677, -0.2511, -0.9394,  0.5409, -0.4779,\n",
       "           0.3327,  0.3085,  0.0114,  0.0825,  0.1843,  0.4301,  0.2956, -0.0256,\n",
       "           0.6390, -0.4430, -0.2152, -0.2393, -0.3272,  0.1773, -0.0880, -0.3757,\n",
       "           0.6009, -0.0378,  0.1120, -0.0830, -0.1825, -0.2245, -0.1683, -0.0554,\n",
       "          -0.3014,  0.6318, -0.1386, -0.6591, -0.0097,  0.5302,  0.3761,  0.1107,\n",
       "          -0.1118,  0.2947, -0.1380, -0.1704, -0.0456, -0.2839,  0.0098,  0.0086,\n",
       "           0.1654,  0.3917, -0.5487, -0.2211]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvolutionalVisionTransformer(act_layer=QuickGELU, spec=spec)\n",
    "\n",
    "test_result = model(test_img)\n",
    "test_img.shape, test_result.shape, test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 56, 56]           9,472\n",
      "         LayerNorm-2             [-1, 3136, 64]             128\n",
      "         ConvEmbed-3           [-1, 64, 56, 56]               0\n",
      "           Dropout-4             [-1, 3136, 64]               0\n",
      "         LayerNorm-5             [-1, 3136, 64]             128\n",
      "            Conv2d-6           [-1, 64, 56, 56]             576\n",
      "       BatchNorm2d-7           [-1, 64, 56, 56]             128\n",
      "         Rearrange-8             [-1, 3136, 64]               0\n",
      "            Conv2d-9           [-1, 64, 28, 28]             576\n",
      "      BatchNorm2d-10           [-1, 64, 28, 28]             128\n",
      "        Rearrange-11              [-1, 784, 64]               0\n",
      "           Conv2d-12           [-1, 64, 28, 28]             576\n",
      "      BatchNorm2d-13           [-1, 64, 28, 28]             128\n",
      "        Rearrange-14              [-1, 784, 64]               0\n",
      "           Linear-15             [-1, 3136, 64]           4,160\n",
      "           Linear-16              [-1, 784, 64]           4,160\n",
      "           Linear-17              [-1, 784, 64]           4,160\n",
      "          Dropout-18         [-1, 4, 3136, 784]               0\n",
      "           Linear-19             [-1, 3136, 64]           4,160\n",
      "          Dropout-20             [-1, 3136, 64]               0\n",
      "    AttentionConv-21             [-1, 3136, 64]               0\n",
      "       LayerScale-22             [-1, 3136, 64]               0\n",
      "         DropPath-23             [-1, 3136, 64]               0\n",
      "        LayerNorm-24             [-1, 3136, 64]             128\n",
      "           Linear-25            [-1, 3136, 256]          16,640\n",
      "        QuickGELU-26            [-1, 3136, 256]               0\n",
      "        LayerNorm-27            [-1, 3136, 256]             512\n",
      "           Linear-28             [-1, 3136, 64]          16,448\n",
      "          Dropout-29             [-1, 3136, 64]               0\n",
      "       LayerScale-30             [-1, 3136, 64]               0\n",
      "         DropPath-31             [-1, 3136, 64]               0\n",
      "            Block-32             [-1, 3136, 64]               0\n",
      "VisionTransformer-33           [-1, 64, 56, 56]               0\n",
      "           Conv2d-34          [-1, 192, 28, 28]         110,784\n",
      "        LayerNorm-35             [-1, 784, 192]             384\n",
      "        ConvEmbed-36          [-1, 192, 28, 28]               0\n",
      "          Dropout-37             [-1, 784, 192]               0\n",
      "        LayerNorm-38             [-1, 784, 192]             384\n",
      "           Conv2d-39          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-40          [-1, 192, 28, 28]             384\n",
      "        Rearrange-41             [-1, 784, 192]               0\n",
      "           Conv2d-42          [-1, 192, 14, 14]           1,728\n",
      "      BatchNorm2d-43          [-1, 192, 14, 14]             384\n",
      "        Rearrange-44             [-1, 196, 192]               0\n",
      "           Conv2d-45          [-1, 192, 14, 14]           1,728\n",
      "      BatchNorm2d-46          [-1, 192, 14, 14]             384\n",
      "        Rearrange-47             [-1, 196, 192]               0\n",
      "           Linear-48             [-1, 784, 192]          37,056\n",
      "           Linear-49             [-1, 196, 192]          37,056\n",
      "           Linear-50             [-1, 196, 192]          37,056\n",
      "          Dropout-51          [-1, 8, 784, 196]               0\n",
      "           Linear-52             [-1, 784, 192]          37,056\n",
      "          Dropout-53             [-1, 784, 192]               0\n",
      "    AttentionConv-54             [-1, 784, 192]               0\n",
      "       LayerScale-55             [-1, 784, 192]               0\n",
      "         DropPath-56             [-1, 784, 192]               0\n",
      "        LayerNorm-57             [-1, 784, 192]             384\n",
      "           Linear-58             [-1, 784, 768]         148,224\n",
      "        QuickGELU-59             [-1, 784, 768]               0\n",
      "        LayerNorm-60             [-1, 784, 768]           1,536\n",
      "           Linear-61             [-1, 784, 192]         147,648\n",
      "          Dropout-62             [-1, 784, 192]               0\n",
      "       LayerScale-63             [-1, 784, 192]               0\n",
      "         DropPath-64             [-1, 784, 192]               0\n",
      "            Block-65             [-1, 784, 192]               0\n",
      "        LayerNorm-66             [-1, 784, 192]             384\n",
      "           Conv2d-67          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-68          [-1, 192, 28, 28]             384\n",
      "        Rearrange-69             [-1, 784, 192]               0\n",
      "           Conv2d-70          [-1, 192, 14, 14]           1,728\n",
      "      BatchNorm2d-71          [-1, 192, 14, 14]             384\n",
      "        Rearrange-72             [-1, 196, 192]               0\n",
      "           Conv2d-73          [-1, 192, 14, 14]           1,728\n",
      "      BatchNorm2d-74          [-1, 192, 14, 14]             384\n",
      "        Rearrange-75             [-1, 196, 192]               0\n",
      "           Linear-76             [-1, 784, 192]          37,056\n",
      "           Linear-77             [-1, 196, 192]          37,056\n",
      "           Linear-78             [-1, 196, 192]          37,056\n",
      "          Dropout-79          [-1, 8, 784, 196]               0\n",
      "           Linear-80             [-1, 784, 192]          37,056\n",
      "          Dropout-81             [-1, 784, 192]               0\n",
      "    AttentionConv-82             [-1, 784, 192]               0\n",
      "       LayerScale-83             [-1, 784, 192]               0\n",
      "         DropPath-84             [-1, 784, 192]               0\n",
      "        LayerNorm-85             [-1, 784, 192]             384\n",
      "           Linear-86             [-1, 784, 768]         148,224\n",
      "        QuickGELU-87             [-1, 784, 768]               0\n",
      "        LayerNorm-88             [-1, 784, 768]           1,536\n",
      "           Linear-89             [-1, 784, 192]         147,648\n",
      "          Dropout-90             [-1, 784, 192]               0\n",
      "       LayerScale-91             [-1, 784, 192]               0\n",
      "         DropPath-92             [-1, 784, 192]               0\n",
      "            Block-93             [-1, 784, 192]               0\n",
      "VisionTransformer-94          [-1, 192, 28, 28]               0\n",
      "           Conv2d-95          [-1, 384, 14, 14]         663,936\n",
      "        LayerNorm-96             [-1, 196, 384]             768\n",
      "        ConvEmbed-97          [-1, 384, 14, 14]               0\n",
      "          Dropout-98             [-1, 196, 384]               0\n",
      "        LayerNorm-99             [-1, 196, 384]             768\n",
      "          Conv2d-100          [-1, 384, 14, 14]           3,456\n",
      "     BatchNorm2d-101          [-1, 384, 14, 14]             768\n",
      "       Rearrange-102             [-1, 196, 384]               0\n",
      "          Conv2d-103            [-1, 384, 7, 7]           3,456\n",
      "     BatchNorm2d-104            [-1, 384, 7, 7]             768\n",
      "       Rearrange-105              [-1, 49, 384]               0\n",
      "          Conv2d-106            [-1, 384, 7, 7]           3,456\n",
      "     BatchNorm2d-107            [-1, 384, 7, 7]             768\n",
      "       Rearrange-108              [-1, 49, 384]               0\n",
      "          Linear-109             [-1, 196, 384]         147,840\n",
      "          Linear-110              [-1, 49, 384]         147,840\n",
      "          Linear-111              [-1, 49, 384]         147,840\n",
      "         Dropout-112          [-1, 12, 196, 49]               0\n",
      "          Linear-113             [-1, 196, 384]         147,840\n",
      "         Dropout-114             [-1, 196, 384]               0\n",
      "   AttentionConv-115             [-1, 196, 384]               0\n",
      "      LayerScale-116             [-1, 196, 384]               0\n",
      "        DropPath-117             [-1, 196, 384]               0\n",
      "       LayerNorm-118             [-1, 196, 384]             768\n",
      "          Linear-119            [-1, 196, 1536]         591,360\n",
      "       QuickGELU-120            [-1, 196, 1536]               0\n",
      "       LayerNorm-121            [-1, 196, 1536]           3,072\n",
      "          Linear-122             [-1, 196, 384]         590,208\n",
      "         Dropout-123             [-1, 196, 384]               0\n",
      "      LayerScale-124             [-1, 196, 384]               0\n",
      "        DropPath-125             [-1, 196, 384]               0\n",
      "           Block-126             [-1, 196, 384]               0\n",
      "       LayerNorm-127             [-1, 196, 384]             768\n",
      "          Conv2d-128          [-1, 384, 14, 14]           3,456\n",
      "     BatchNorm2d-129          [-1, 384, 14, 14]             768\n",
      "       Rearrange-130             [-1, 196, 384]               0\n",
      "          Conv2d-131            [-1, 384, 7, 7]           3,456\n",
      "     BatchNorm2d-132            [-1, 384, 7, 7]             768\n",
      "       Rearrange-133              [-1, 49, 384]               0\n",
      "          Conv2d-134            [-1, 384, 7, 7]           3,456\n",
      "     BatchNorm2d-135            [-1, 384, 7, 7]             768\n",
      "       Rearrange-136              [-1, 49, 384]               0\n",
      "          Linear-137             [-1, 196, 384]         147,840\n",
      "          Linear-138              [-1, 49, 384]         147,840\n",
      "          Linear-139              [-1, 49, 384]         147,840\n",
      "         Dropout-140          [-1, 12, 196, 49]               0\n",
      "          Linear-141             [-1, 196, 384]         147,840\n",
      "         Dropout-142             [-1, 196, 384]               0\n",
      "   AttentionConv-143             [-1, 196, 384]               0\n",
      "      LayerScale-144             [-1, 196, 384]               0\n",
      "        DropPath-145             [-1, 196, 384]               0\n",
      "       LayerNorm-146             [-1, 196, 384]             768\n",
      "          Linear-147            [-1, 196, 1536]         591,360\n",
      "       QuickGELU-148            [-1, 196, 1536]               0\n",
      "       LayerNorm-149            [-1, 196, 1536]           3,072\n",
      "          Linear-150             [-1, 196, 384]         590,208\n",
      "         Dropout-151             [-1, 196, 384]               0\n",
      "      LayerScale-152             [-1, 196, 384]               0\n",
      "        DropPath-153             [-1, 196, 384]               0\n",
      "           Block-154             [-1, 196, 384]               0\n",
      "       LayerNorm-155             [-1, 196, 384]             768\n",
      "          Conv2d-156          [-1, 384, 14, 14]           3,456\n",
      "     BatchNorm2d-157          [-1, 384, 14, 14]             768\n",
      "       Rearrange-158             [-1, 196, 384]               0\n",
      "          Conv2d-159            [-1, 384, 7, 7]           3,456\n",
      "     BatchNorm2d-160            [-1, 384, 7, 7]             768\n",
      "       Rearrange-161              [-1, 49, 384]               0\n",
      "          Conv2d-162            [-1, 384, 7, 7]           3,456\n",
      "     BatchNorm2d-163            [-1, 384, 7, 7]             768\n",
      "       Rearrange-164              [-1, 49, 384]               0\n",
      "          Linear-165             [-1, 196, 384]         147,840\n",
      "          Linear-166              [-1, 49, 384]         147,840\n",
      "          Linear-167              [-1, 49, 384]         147,840\n",
      "         Dropout-168          [-1, 12, 196, 49]               0\n",
      "          Linear-169             [-1, 196, 384]         147,840\n",
      "         Dropout-170             [-1, 196, 384]               0\n",
      "   AttentionConv-171             [-1, 196, 384]               0\n",
      "      LayerScale-172             [-1, 196, 384]               0\n",
      "        DropPath-173             [-1, 196, 384]               0\n",
      "       LayerNorm-174             [-1, 196, 384]             768\n",
      "          Linear-175            [-1, 196, 1536]         591,360\n",
      "       QuickGELU-176            [-1, 196, 1536]               0\n",
      "       LayerNorm-177            [-1, 196, 1536]           3,072\n",
      "          Linear-178             [-1, 196, 384]         590,208\n",
      "         Dropout-179             [-1, 196, 384]               0\n",
      "      LayerScale-180             [-1, 196, 384]               0\n",
      "        DropPath-181             [-1, 196, 384]               0\n",
      "           Block-182             [-1, 196, 384]               0\n",
      "       LayerNorm-183             [-1, 196, 384]             768\n",
      "          Conv2d-184          [-1, 384, 14, 14]           3,456\n",
      "     BatchNorm2d-185          [-1, 384, 14, 14]             768\n",
      "       Rearrange-186             [-1, 196, 384]               0\n",
      "          Conv2d-187            [-1, 384, 7, 7]           3,456\n",
      "     BatchNorm2d-188            [-1, 384, 7, 7]             768\n",
      "       Rearrange-189              [-1, 49, 384]               0\n",
      "          Conv2d-190            [-1, 384, 7, 7]           3,456\n",
      "     BatchNorm2d-191            [-1, 384, 7, 7]             768\n",
      "       Rearrange-192              [-1, 49, 384]               0\n",
      "          Linear-193             [-1, 196, 384]         147,840\n",
      "          Linear-194              [-1, 49, 384]         147,840\n",
      "          Linear-195              [-1, 49, 384]         147,840\n",
      "         Dropout-196          [-1, 12, 196, 49]               0\n",
      "          Linear-197             [-1, 196, 384]         147,840\n",
      "         Dropout-198             [-1, 196, 384]               0\n",
      "   AttentionConv-199             [-1, 196, 384]               0\n",
      "      LayerScale-200             [-1, 196, 384]               0\n",
      "        DropPath-201             [-1, 196, 384]               0\n",
      "       LayerNorm-202             [-1, 196, 384]             768\n",
      "          Linear-203            [-1, 196, 1536]         591,360\n",
      "       QuickGELU-204            [-1, 196, 1536]               0\n",
      "       LayerNorm-205            [-1, 196, 1536]           3,072\n",
      "          Linear-206             [-1, 196, 384]         590,208\n",
      "         Dropout-207             [-1, 196, 384]               0\n",
      "      LayerScale-208             [-1, 196, 384]               0\n",
      "        DropPath-209             [-1, 196, 384]               0\n",
      "           Block-210             [-1, 196, 384]               0\n",
      "       LayerNorm-211             [-1, 196, 384]             768\n",
      "          Conv2d-212          [-1, 384, 14, 14]           3,456\n",
      "     BatchNorm2d-213          [-1, 384, 14, 14]             768\n",
      "       Rearrange-214             [-1, 196, 384]               0\n",
      "          Conv2d-215            [-1, 384, 7, 7]           3,456\n",
      "     BatchNorm2d-216            [-1, 384, 7, 7]             768\n",
      "       Rearrange-217              [-1, 49, 384]               0\n",
      "          Conv2d-218            [-1, 384, 7, 7]           3,456\n",
      "     BatchNorm2d-219            [-1, 384, 7, 7]             768\n",
      "       Rearrange-220              [-1, 49, 384]               0\n",
      "          Linear-221             [-1, 196, 384]         147,840\n",
      "          Linear-222              [-1, 49, 384]         147,840\n",
      "          Linear-223              [-1, 49, 384]         147,840\n",
      "         Dropout-224          [-1, 12, 196, 49]               0\n",
      "          Linear-225             [-1, 196, 384]         147,840\n",
      "         Dropout-226             [-1, 196, 384]               0\n",
      "   AttentionConv-227             [-1, 196, 384]               0\n",
      "      LayerScale-228             [-1, 196, 384]               0\n",
      "        DropPath-229             [-1, 196, 384]               0\n",
      "       LayerNorm-230             [-1, 196, 384]             768\n",
      "          Linear-231            [-1, 196, 1536]         591,360\n",
      "       QuickGELU-232            [-1, 196, 1536]               0\n",
      "       LayerNorm-233            [-1, 196, 1536]           3,072\n",
      "          Linear-234             [-1, 196, 384]         590,208\n",
      "         Dropout-235             [-1, 196, 384]               0\n",
      "      LayerScale-236             [-1, 196, 384]               0\n",
      "        DropPath-237             [-1, 196, 384]               0\n",
      "           Block-238             [-1, 196, 384]               0\n",
      "       LayerNorm-239             [-1, 196, 384]             768\n",
      "          Conv2d-240          [-1, 384, 14, 14]           3,456\n",
      "     BatchNorm2d-241          [-1, 384, 14, 14]             768\n",
      "       Rearrange-242             [-1, 196, 384]               0\n",
      "          Conv2d-243            [-1, 384, 7, 7]           3,456\n",
      "     BatchNorm2d-244            [-1, 384, 7, 7]             768\n",
      "       Rearrange-245              [-1, 49, 384]               0\n",
      "          Conv2d-246            [-1, 384, 7, 7]           3,456\n",
      "     BatchNorm2d-247            [-1, 384, 7, 7]             768\n",
      "       Rearrange-248              [-1, 49, 384]               0\n",
      "          Linear-249             [-1, 196, 384]         147,840\n",
      "          Linear-250              [-1, 49, 384]         147,840\n",
      "          Linear-251              [-1, 49, 384]         147,840\n",
      "         Dropout-252          [-1, 12, 196, 49]               0\n",
      "          Linear-253             [-1, 196, 384]         147,840\n",
      "         Dropout-254             [-1, 196, 384]               0\n",
      "   AttentionConv-255             [-1, 196, 384]               0\n",
      "      LayerScale-256             [-1, 196, 384]               0\n",
      "        DropPath-257             [-1, 196, 384]               0\n",
      "       LayerNorm-258             [-1, 196, 384]             768\n",
      "          Linear-259            [-1, 196, 1536]         591,360\n",
      "       QuickGELU-260            [-1, 196, 1536]               0\n",
      "       LayerNorm-261            [-1, 196, 1536]           3,072\n",
      "          Linear-262             [-1, 196, 384]         590,208\n",
      "         Dropout-263             [-1, 196, 384]               0\n",
      "      LayerScale-264             [-1, 196, 384]               0\n",
      "        DropPath-265             [-1, 196, 384]               0\n",
      "           Block-266             [-1, 196, 384]               0\n",
      "       LayerNorm-267             [-1, 196, 384]             768\n",
      "          Conv2d-268          [-1, 384, 14, 14]           3,456\n",
      "     BatchNorm2d-269          [-1, 384, 14, 14]             768\n",
      "       Rearrange-270             [-1, 196, 384]               0\n",
      "          Conv2d-271            [-1, 384, 7, 7]           3,456\n",
      "     BatchNorm2d-272            [-1, 384, 7, 7]             768\n",
      "       Rearrange-273              [-1, 49, 384]               0\n",
      "          Conv2d-274            [-1, 384, 7, 7]           3,456\n",
      "     BatchNorm2d-275            [-1, 384, 7, 7]             768\n",
      "       Rearrange-276              [-1, 49, 384]               0\n",
      "          Linear-277             [-1, 196, 384]         147,840\n",
      "          Linear-278              [-1, 49, 384]         147,840\n",
      "          Linear-279              [-1, 49, 384]         147,840\n",
      "         Dropout-280          [-1, 12, 196, 49]               0\n",
      "          Linear-281             [-1, 196, 384]         147,840\n",
      "         Dropout-282             [-1, 196, 384]               0\n",
      "   AttentionConv-283             [-1, 196, 384]               0\n",
      "      LayerScale-284             [-1, 196, 384]               0\n",
      "        DropPath-285             [-1, 196, 384]               0\n",
      "       LayerNorm-286             [-1, 196, 384]             768\n",
      "          Linear-287            [-1, 196, 1536]         591,360\n",
      "       QuickGELU-288            [-1, 196, 1536]               0\n",
      "       LayerNorm-289            [-1, 196, 1536]           3,072\n",
      "          Linear-290             [-1, 196, 384]         590,208\n",
      "         Dropout-291             [-1, 196, 384]               0\n",
      "      LayerScale-292             [-1, 196, 384]               0\n",
      "        DropPath-293             [-1, 196, 384]               0\n",
      "           Block-294             [-1, 196, 384]               0\n",
      "       LayerNorm-295             [-1, 196, 384]             768\n",
      "          Conv2d-296          [-1, 384, 14, 14]           3,456\n",
      "     BatchNorm2d-297          [-1, 384, 14, 14]             768\n",
      "       Rearrange-298             [-1, 196, 384]               0\n",
      "          Conv2d-299            [-1, 384, 7, 7]           3,456\n",
      "     BatchNorm2d-300            [-1, 384, 7, 7]             768\n",
      "       Rearrange-301              [-1, 49, 384]               0\n",
      "          Conv2d-302            [-1, 384, 7, 7]           3,456\n",
      "     BatchNorm2d-303            [-1, 384, 7, 7]             768\n",
      "       Rearrange-304              [-1, 49, 384]               0\n",
      "          Linear-305             [-1, 196, 384]         147,840\n",
      "          Linear-306              [-1, 49, 384]         147,840\n",
      "          Linear-307              [-1, 49, 384]         147,840\n",
      "         Dropout-308          [-1, 12, 196, 49]               0\n",
      "          Linear-309             [-1, 196, 384]         147,840\n",
      "         Dropout-310             [-1, 196, 384]               0\n",
      "   AttentionConv-311             [-1, 196, 384]               0\n",
      "      LayerScale-312             [-1, 196, 384]               0\n",
      "        DropPath-313             [-1, 196, 384]               0\n",
      "       LayerNorm-314             [-1, 196, 384]             768\n",
      "          Linear-315            [-1, 196, 1536]         591,360\n",
      "       QuickGELU-316            [-1, 196, 1536]               0\n",
      "       LayerNorm-317            [-1, 196, 1536]           3,072\n",
      "          Linear-318             [-1, 196, 384]         590,208\n",
      "         Dropout-319             [-1, 196, 384]               0\n",
      "      LayerScale-320             [-1, 196, 384]               0\n",
      "        DropPath-321             [-1, 196, 384]               0\n",
      "           Block-322             [-1, 196, 384]               0\n",
      "       LayerNorm-323             [-1, 196, 384]             768\n",
      "          Conv2d-324          [-1, 384, 14, 14]           3,456\n",
      "     BatchNorm2d-325          [-1, 384, 14, 14]             768\n",
      "       Rearrange-326             [-1, 196, 384]               0\n",
      "          Conv2d-327            [-1, 384, 7, 7]           3,456\n",
      "     BatchNorm2d-328            [-1, 384, 7, 7]             768\n",
      "       Rearrange-329              [-1, 49, 384]               0\n",
      "          Conv2d-330            [-1, 384, 7, 7]           3,456\n",
      "     BatchNorm2d-331            [-1, 384, 7, 7]             768\n",
      "       Rearrange-332              [-1, 49, 384]               0\n",
      "          Linear-333             [-1, 196, 384]         147,840\n",
      "          Linear-334              [-1, 49, 384]         147,840\n",
      "          Linear-335              [-1, 49, 384]         147,840\n",
      "         Dropout-336          [-1, 12, 196, 49]               0\n",
      "          Linear-337             [-1, 196, 384]         147,840\n",
      "         Dropout-338             [-1, 196, 384]               0\n",
      "   AttentionConv-339             [-1, 196, 384]               0\n",
      "      LayerScale-340             [-1, 196, 384]               0\n",
      "        DropPath-341             [-1, 196, 384]               0\n",
      "       LayerNorm-342             [-1, 196, 384]             768\n",
      "          Linear-343            [-1, 196, 1536]         591,360\n",
      "       QuickGELU-344            [-1, 196, 1536]               0\n",
      "       LayerNorm-345            [-1, 196, 1536]           3,072\n",
      "          Linear-346             [-1, 196, 384]         590,208\n",
      "         Dropout-347             [-1, 196, 384]               0\n",
      "      LayerScale-348             [-1, 196, 384]               0\n",
      "        DropPath-349             [-1, 196, 384]               0\n",
      "           Block-350             [-1, 196, 384]               0\n",
      "       LayerNorm-351             [-1, 196, 384]             768\n",
      "          Conv2d-352          [-1, 384, 14, 14]           3,456\n",
      "     BatchNorm2d-353          [-1, 384, 14, 14]             768\n",
      "       Rearrange-354             [-1, 196, 384]               0\n",
      "          Conv2d-355            [-1, 384, 7, 7]           3,456\n",
      "     BatchNorm2d-356            [-1, 384, 7, 7]             768\n",
      "       Rearrange-357              [-1, 49, 384]               0\n",
      "          Conv2d-358            [-1, 384, 7, 7]           3,456\n",
      "     BatchNorm2d-359            [-1, 384, 7, 7]             768\n",
      "       Rearrange-360              [-1, 49, 384]               0\n",
      "          Linear-361             [-1, 196, 384]         147,840\n",
      "          Linear-362              [-1, 49, 384]         147,840\n",
      "          Linear-363              [-1, 49, 384]         147,840\n",
      "         Dropout-364          [-1, 12, 196, 49]               0\n",
      "          Linear-365             [-1, 196, 384]         147,840\n",
      "         Dropout-366             [-1, 196, 384]               0\n",
      "   AttentionConv-367             [-1, 196, 384]               0\n",
      "      LayerScale-368             [-1, 196, 384]               0\n",
      "        DropPath-369             [-1, 196, 384]               0\n",
      "       LayerNorm-370             [-1, 196, 384]             768\n",
      "          Linear-371            [-1, 196, 1536]         591,360\n",
      "       QuickGELU-372            [-1, 196, 1536]               0\n",
      "       LayerNorm-373            [-1, 196, 1536]           3,072\n",
      "          Linear-374             [-1, 196, 384]         590,208\n",
      "         Dropout-375             [-1, 196, 384]               0\n",
      "      LayerScale-376             [-1, 196, 384]               0\n",
      "        DropPath-377             [-1, 196, 384]               0\n",
      "           Block-378             [-1, 196, 384]               0\n",
      "VisionTransformer-379          [-1, 384, 14, 14]               0\n",
      "       LayerNorm-380             [-1, 196, 384]             768\n",
      "AdaptiveAvgPool1d-381               [-1, 384, 1]               0\n",
      "          Linear-382                  [-1, 100]          38,500\n",
      "================================================================\n",
      "Total params: 19,684,900\n",
      "Trainable params: 19,684,900\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 406.54\n",
      "Params size (MB): 75.09\n",
      "Estimated Total Size (MB): 482.20\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model.cuda(), (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms 정의하기\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8,1), interpolation=transforms.InterpolationMode.LANCZOS),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.9, scale=(0.02, 0.33)),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "data_dir = '../data/sports'\n",
    "batch_size = 256\n",
    "\n",
    "train_path = data_dir+'/train'\n",
    "valid_path = data_dir+'/valid'\n",
    "test_path = data_dir+'/test'\n",
    "\n",
    "# dataset load\n",
    "train_data = ImageFolder(train_path, transform=train_transform)\n",
    "valid_data = ImageFolder(valid_path, transform=test_transform)\n",
    "test_data = ImageFolder(test_path, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:2'\n",
    "max_norm = 5.0 # paper : 100 with G variants\n",
    "\n",
    "model.to(device)\n",
    "model_path = '../models/cvt/model.pth'\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixup_fn = Mixup(mixup_alpha=.8, \n",
    "                cutmix_alpha=1., \n",
    "                prob=1., \n",
    "                switch_prob=0.5, \n",
    "                mode='batch',\n",
    "                label_smoothing=.1,\n",
    "                num_classes=100)\n",
    "\n",
    "epochs = 500\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-24 09:56:00.660167: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-24 09:56:00.660255: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-24 09:56:00.661270: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-24 09:56:00.667576: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-24 09:56:01.608208: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(model.parameters())\n",
    "warmup_steps = int(len(train_loader)*(epochs)*0.1)\n",
    "train_steps = len(train_loader)*(epochs)\n",
    "scheduler = transformers.get_cosine_schedule_with_warmup(optimizer, \n",
    "                                                        num_warmup_steps=warmup_steps, \n",
    "                                                        num_training_steps=train_steps,\n",
    "                                                        num_cycles=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 53/53 [01:01<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.586150187366414, Val Loss: 4.456934690475464, LR: 2e-05, Duration: 64.13 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.478289325282259, Val Loss: 4.291108131408691, LR: 4e-05, Duration: 57.71 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.41224841351779, Val Loss: 4.174118995666504, LR: 6e-05, Duration: 57.64 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.361892628219892, Val Loss: 4.071082353591919, LR: 8e-05, Duration: 57.43 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.3405843860698194, Val Loss: 4.020055532455444, LR: 0.0001, Duration: 57.58 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.303667176444575, Val Loss: 3.9813153743743896, LR: 0.00012, Duration: 57.63 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.307095311722666, Val Loss: 3.935864567756653, LR: 0.00014000000000000001, Duration: 57.64 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.244100903565029, Val Loss: 3.879255175590515, LR: 0.00016, Duration: 57.60 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.244663377977767, Val Loss: 3.832309126853943, LR: 0.00017999999999999998, Duration: 57.44 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.181018842841095, Val Loss: 3.77045214176178, LR: 0.0002, Duration: 57.65 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.18771885026176, Val Loss: 3.7876540422439575, LR: 0.00022, Duration: 57.79 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.133169669025349, Val Loss: 3.582990884780884, LR: 0.00024, Duration: 57.75 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.0751436701360735, Val Loss: 3.6107715368270874, LR: 0.00026000000000000003, Duration: 57.52 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.061728594438085, Val Loss: 3.448943614959717, LR: 0.00028000000000000003, Duration: 57.71 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.008008016730255, Val Loss: 3.3388776779174805, LR: 0.0003, Duration: 57.70 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.968221421511668, Val Loss: 3.3056617975234985, LR: 0.00032, Duration: 57.55 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.9699253631087967, Val Loss: 3.2163439989089966, LR: 0.00034, Duration: 57.69 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.8993133284010977, Val Loss: 3.15942645072937, LR: 0.00035999999999999997, Duration: 57.63 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.8858844154285936, Val Loss: 3.1059203147888184, LR: 0.00038, Duration: 57.46 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.904530223810448, Val Loss: 3.086260437965393, LR: 0.0004, Duration: 57.74 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7858618745264017, Val Loss: 2.901177406311035, LR: 0.00042, Duration: 57.71 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.8211378871269948, Val Loss: 2.862451195716858, LR: 0.00044, Duration: 57.57 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6718026107212283, Val Loss: 2.7395291328430176, LR: 0.00046, Duration: 57.70 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6999134882441105, Val Loss: 2.7774643898010254, LR: 0.00048, Duration: 57.45 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6571077715675786, Val Loss: 2.6717528104782104, LR: 0.0005, Duration: 57.62 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6001497709526205, Val Loss: 2.627289891242981, LR: 0.0005200000000000001, Duration: 57.63 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.640766350728161, Val Loss: 2.577074646949768, LR: 0.00054, Duration: 57.97 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.579383872589975, Val Loss: 2.4967554807662964, LR: 0.0005600000000000001, Duration: 57.98 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.520751264860045, Val Loss: 2.2963701486587524, LR: 0.00058, Duration: 57.63 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5125680104741512, Val Loss: 2.2917768955230713, LR: 0.0006, Duration: 57.61 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.454609794436761, Val Loss: 2.18526029586792, LR: 0.00062, Duration: 57.73 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.407726769177419, Val Loss: 2.085400938987732, LR: 0.00064, Duration: 57.60 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.3114882730088144, Val Loss: 1.9571937322616577, LR: 0.00066, Duration: 57.76 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.308893469144713, Val Loss: 1.876143455505371, LR: 0.00068, Duration: 57.92 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2733499149106584, Val Loss: 1.9462332725524902, LR: 0.0007, Duration: 57.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2869756356725155, Val Loss: 1.9122273921966553, LR: 0.0007199999999999999, Duration: 57.39 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1878899718230627, Val Loss: 1.6702244877815247, LR: 0.00074, Duration: 57.56 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.216327482799314, Val Loss: 1.697659194469452, LR: 0.00076, Duration: 57.44 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1875325913699166, Val Loss: 1.6305457949638367, LR: 0.0007800000000000001, Duration: 57.64 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.037924532620412, Val Loss: 1.482218086719513, LR: 0.0008, Duration: 57.61 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9804371887782835, Val Loss: 1.4523564577102661, LR: 0.00082, Duration: 57.56 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.200635316236964, Val Loss: 1.498509407043457, LR: 0.00084, Duration: 57.53 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.141541004180908, Val Loss: 1.3832771182060242, LR: 0.00086, Duration: 57.49 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 53/53 [00:57<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.899900398164425, Val Loss: 1.33341383934021, LR: 0.00088, Duration: 59.26 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 53/53 [00:57<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.940928189259655, Val Loss: 1.368495225906372, LR: 0.0009000000000000001, Duration: 58.07 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9873370404513375, Val Loss: 1.374603509902954, LR: 0.00092, Duration: 57.55 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1499115386099183, Val Loss: 1.337074339389801, LR: 0.00094, Duration: 57.46 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9193929726222776, Val Loss: 1.2731344103813171, LR: 0.00096, Duration: 57.55 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.97403669582223, Val Loss: 1.350655734539032, LR: 0.00098, Duration: 57.69 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 53/53 [00:57<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.872064100121552, Val Loss: 1.1906688809394836, LR: 0.001, Duration: 58.32 sec - model saved!\n",
      "Epoch 당 평균 소요시간 : 5.78초\n"
     ]
    }
   ],
   "source": [
    "training_time = 0\n",
    "losses = []\n",
    "val_losses = []\n",
    "lrs = []\n",
    "best_loss = float('inf')\n",
    "\n",
    "# GradScaler 초기화\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "text = f\"Epoch 당 평균 소요시간 : {training_time / epochs:.2f}초\"      \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.718000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.772056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.718000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.708246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.718000\n",
       "1  Precision  0.772056\n",
       "2     Recall  0.718000\n",
       "3   F1 Score  0.708246"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7665068226040535, Val Loss: 1.1513952612876892, LR: 0.0009999878153526974, Duration: 57.68 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7652107342234196, Val Loss: 1.189491868019104, LR: 0.0009999512620046521, Duration: 57.53 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7876503310113585, Val Loss: 1.1603840589523315, LR: 0.0009998903417374227, Duration: 57.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7293983225552543, Val Loss: 1.146160066127777, LR: 0.000999805057520177, Duration: 57.62 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7556404572612836, Val Loss: 1.1340115070343018, LR: 0.0009996954135095479, Duration: 57.57 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.735298770778584, Val Loss: 1.053985357284546, LR: 0.0009995614150494292, Duration: 57.59 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.647065173904851, Val Loss: 1.0217735171318054, LR: 0.0009994030686707172, Duration: 57.42 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6868075064893038, Val Loss: 1.094339370727539, LR: 0.0009992203820909905, Duration: 57.35 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.754642943166337, Val Loss: 0.9836225509643555, LR: 0.0009990133642141358, Duration: 57.38 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.520385393556559, Val Loss: 1.0066285729408264, LR: 0.0009987820251299122, Duration: 57.33 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6710894107818604, Val Loss: 0.9390007257461548, LR: 0.0009985263761134603, Duration: 57.42 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.620892988061005, Val Loss: 1.024465262889862, LR: 0.0009982464296247522, Duration: 57.25 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6349995226230263, Val Loss: 0.9267323911190033, LR: 0.0009979421993079852, Duration: 57.50 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5265902258315176, Val Loss: 0.9409182369709015, LR: 0.0009976136999909156, Duration: 57.17 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.596006874768239, Val Loss: 0.9655740559101105, LR: 0.0009972609476841367, Duration: 57.20 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5510032379402303, Val Loss: 0.9082270860671997, LR: 0.0009968839595802983, Duration: 57.46 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6762790904854827, Val Loss: 0.8568335473537445, LR: 0.0009964827540532685, Duration: 57.48 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4703521233684613, Val Loss: 0.9917267560958862, LR: 0.000996057350657239, Duration: 57.32 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5581674013497695, Val Loss: 0.9810657799243927, LR: 0.0009956077701257708, Duration: 57.42 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4895956426296593, Val Loss: 0.8693333566188812, LR: 0.0009951340343707852, Duration: 57.20 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2984805219578295, Val Loss: 0.8589175343513489, LR: 0.0009946361664814943, Duration: 57.24 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4878765254650475, Val Loss: 0.8901630640029907, LR: 0.0009941141907232765, Duration: 57.27 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4232643235404536, Val Loss: 0.8339859843254089, LR: 0.000993568132536494, Duration: 57.34 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.492827791088032, Val Loss: 0.8259621262550354, LR: 0.0009929980185352525, Duration: 57.43 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4314578749098867, Val Loss: 0.7984817028045654, LR: 0.000992403876506104, Duration: 57.71 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3017859346461744, Val Loss: 0.7667959928512573, LR: 0.000991785735406693, Duration: 57.45 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.348900574558186, Val Loss: 0.863225132226944, LR: 0.0009911436253643444, Duration: 57.26 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.375192939110522, Val Loss: 0.8945190608501434, LR: 0.0009904775776745957, Duration: 57.31 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3655606890624425, Val Loss: 0.796538770198822, LR: 0.000989787624799672, Duration: 57.35 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.384475141201379, Val Loss: 0.8058009445667267, LR: 0.0009890738003669028, Duration: 57.37 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.361142691576256, Val Loss: 0.7908467054367065, LR: 0.000988336139167084, Duration: 57.35 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3633987251317725, Val Loss: 0.7779646813869476, LR: 0.0009875746771527815, Duration: 57.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.405437021885278, Val Loss: 0.8767770528793335, LR: 0.0009867894514365802, Duration: 57.31 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.296632375357286, Val Loss: 0.8130852580070496, LR: 0.0009859805002892731, Duration: 57.38 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2524191860882743, Val Loss: 0.8305707573890686, LR: 0.0009851478631379982, Duration: 57.31 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1908118072545752, Val Loss: 0.787274569272995, LR: 0.0009842915805643156, Duration: 57.46 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.396979975250532, Val Loss: 0.8138859868049622, LR: 0.0009834116943022299, Duration: 57.34 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.381452497446312, Val Loss: 0.742680698633194, LR: 0.0009825082472361558, Duration: 57.54 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.164947509765625, Val Loss: 0.7804007530212402, LR: 0.0009815812833988292, Duration: 57.29 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.228540078648981, Val Loss: 0.7850973606109619, LR: 0.0009806308479691594, Duration: 57.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.23381939699065, Val Loss: 0.8030985295772552, LR: 0.0009796569872700287, Duration: 57.34 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3610893105560877, Val Loss: 0.7701332271099091, LR: 0.0009786597487660335, Duration: 57.24 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2706473840857453, Val Loss: 0.7348388731479645, LR: 0.0009776391810611717, Duration: 57.42 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1260643185309642, Val Loss: 0.7865238189697266, LR: 0.0009765953338964734, Duration: 57.20 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.235013763859587, Val Loss: 0.8033565878868103, LR: 0.0009755282581475768, Duration: 57.23 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1184254209950284, Val Loss: 0.7333329319953918, LR: 0.0009744380058222483, Duration: 57.32 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2796859426318474, Val Loss: 0.8996785879135132, LR: 0.0009733246300578483, Duration: 57.33 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1136001888311133, Val Loss: 0.7579029500484467, LR: 0.0009721881851187406, Duration: 57.26 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3288611938368597, Val Loss: 0.8034792244434357, LR: 0.0009710287263936483, Duration: 57.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1135655079247817, Val Loss: 0.780707597732544, LR: 0.0009698463103929542, Duration: 57.27 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.868143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.837439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.850000\n",
       "1  Precision  0.868143\n",
       "2     Recall  0.850000\n",
       "3   F1 Score  0.837439"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_time = 0\n",
    "losses = []\n",
    "val_losses = []\n",
    "lrs = []\n",
    "best_loss = float('inf')\n",
    "\n",
    "# GradScaler 초기화\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2447368401401446, Val Loss: 0.789492130279541, LR: 0.0009686409947459458, Duration: 57.47 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2561860759303256, Val Loss: 0.77885901927948, LR: 0.0009674128381980072, Duration: 57.40 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1651837106020944, Val Loss: 0.798984706401825, LR: 0.0009661619006077561, Duration: 57.36 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.237081669411569, Val Loss: 0.7555150389671326, LR: 0.0009648882429441257, Duration: 57.68 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.331378199019522, Val Loss: 0.7795320749282837, LR: 0.0009635919272833937, Duration: 57.46 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1574697134629734, Val Loss: 0.8480467796325684, LR: 0.0009622730168061567, Duration: 57.42 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.090698093738196, Val Loss: 0.7688798904418945, LR: 0.0009609315757942503, Duration: 57.63 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.167536677054639, Val Loss: 0.7970060110092163, LR: 0.0009595676696276172, Duration: 57.50 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.035414974644499, Val Loss: 0.7589446008205414, LR: 0.0009581813647811198, Duration: 57.41 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.034520113243247, Val Loss: 0.7750673592090607, LR: 0.0009567727288213005, Duration: 57.46 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.013751844190202, Val Loss: 0.8036313354969025, LR: 0.0009553418304030885, Duration: 57.46 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.091280648168528, Val Loss: 0.7601830065250397, LR: 0.0009538887392664543, Duration: 57.43 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.079949010093257, Val Loss: 0.7426605224609375, LR: 0.0009524135262330098, Duration: 57.62 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0403007021490134, Val Loss: 0.8107430636882782, LR: 0.000950916263202557, Duration: 57.36 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0164068487455262, Val Loss: 0.8320716321468353, LR: 0.0009493970231495835, Duration: 57.33 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.030673037160118, Val Loss: 0.7929392457008362, LR: 0.0009478558801197064, Duration: 57.61 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.076251467443862, Val Loss: 0.8212406635284424, LR: 0.0009462929092260628, Duration: 57.42 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.080373116259305, Val Loss: 0.8081710338592529, LR: 0.0009447081866456489, Duration: 57.51 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.197812749529785, Val Loss: 0.7785863280296326, LR: 0.0009431017896156073, Duration: 57.58 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1285982671773658, Val Loss: 0.7644692361354828, LR: 0.0009414737964294635, Duration: 57.48 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1722849922360115, Val Loss: 0.8767917454242706, LR: 0.0009398242864333083, Duration: 57.60 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.100978028099492, Val Loss: 0.8175743222236633, LR: 0.0009381533400219318, Duration: 57.48 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0437112394368873, Val Loss: 0.8697881996631622, LR: 0.0009364610386349048, Duration: 57.65 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9453573181944073, Val Loss: 0.7733601331710815, LR: 0.0009347474647526095, Duration: 57.57 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0432563412864253, Val Loss: 0.8488913178443909, LR: 0.0009330127018922195, Duration: 57.46 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0538592720931432, Val Loss: 0.7882393002510071, LR: 0.0009312568346036287, Duration: 57.50 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0200062315419034, Val Loss: 0.7746059894561768, LR: 0.0009294799484653322, Duration: 57.42 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1133402282336973, Val Loss: 0.7778400778770447, LR: 0.0009276821300802534, Duration: 57.43 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9850806312740974, Val Loss: 0.8394316136837006, LR: 0.0009258634670715238, Duration: 57.34 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0784138621024364, Val Loss: 0.8031216561794281, LR: 0.0009240240480782129, Duration: 57.44 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.000716659257997, Val Loss: 0.8297117948532104, LR: 0.0009221639627510075, Duration: 57.38 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9680488098342463, Val Loss: 0.8218267858028412, LR: 0.0009202833017478421, Duration: 57.41 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0726230268208488, Val Loss: 0.7991952300071716, LR: 0.0009183821567294809, Duration: 57.37 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9051389761690825, Val Loss: 0.7611626088619232, LR: 0.0009164606203550497, Duration: 57.42 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.790781965795553, Val Loss: 0.8029864728450775, LR: 0.0009145187862775209, Duration: 57.27 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.929679106991246, Val Loss: 0.7211359441280365, LR: 0.0009125567491391475, Duration: 57.63 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0369873766629203, Val Loss: 0.8558749854564667, LR: 0.000910574604566852, Duration: 57.24 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8648204353620421, Val Loss: 0.7799547016620636, LR: 0.0009085724491675642, Duration: 57.35 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9446939893488615, Val Loss: 0.740919291973114, LR: 0.0009065503805235138, Duration: 57.28 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0593911364393414, Val Loss: 0.7661505341529846, LR: 0.0009045084971874737, Duration: 57.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.844159445672665, Val Loss: 0.7693415880203247, LR: 0.000902446898677957, Duration: 57.38 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9365468430069257, Val Loss: 0.8029922842979431, LR: 0.0009003656854743667, Duration: 57.31 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9826861777395572, Val Loss: 0.7628742456436157, LR: 0.0008982649590120981, Duration: 57.30 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9998183857719853, Val Loss: 0.8349815011024475, LR: 0.0008961448216775954, Duration: 57.25 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8850870548554186, Val Loss: 0.7873641848564148, LR: 0.0008940053768033609, Duration: 57.44 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9145525896324302, Val Loss: 0.7884161472320557, LR: 0.0008918467286629199, Duration: 57.47 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9536561763511513, Val Loss: 0.7392507493495941, LR: 0.0008896689824657372, Duration: 57.30 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.93499027783016, Val Loss: 0.7845006883144379, LR: 0.0008874722443520898, Duration: 57.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9746391863193151, Val Loss: 0.7714657783508301, LR: 0.0008852566213878947, Duration: 57.42 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9977098276030343, Val Loss: 0.787999838590622, LR: 0.000883022221559489, Duration: 57.34 sec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.864000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.889893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.864000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.861214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.864000\n",
       "1  Precision  0.889893\n",
       "2     Recall  0.864000\n",
       "3   F1 Score  0.861214"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_time = 0\n",
    "losses = []\n",
    "val_losses = []\n",
    "lrs = []\n",
    "best_loss = float('inf')\n",
    "\n",
    "# GradScaler 초기화\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9466663520291168, Val Loss: 0.7414827644824982, LR: 0.0008807691537683684, Duration: 57.45 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9333367471425038, Val Loss: 0.7244854271411896, LR: 0.0008784975278258782, Duration: 57.39 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9052027756313108, Val Loss: 0.7668933570384979, LR: 0.0008762074544478622, Duration: 57.19 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.89121191681556, Val Loss: 0.7432261109352112, LR: 0.000873899045249266, Duration: 57.19 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8946708013426583, Val Loss: 0.7417789697647095, LR: 0.0008715724127386971, Duration: 57.28 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.981333484064858, Val Loss: 0.7039034068584442, LR: 0.0008692276703129421, Duration: 57.45 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8944814486323662, Val Loss: 0.7077163755893707, LR: 0.0008668649322514381, Duration: 57.24 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8906835879919663, Val Loss: 0.7360136210918427, LR: 0.0008644843137107057, Duration: 57.35 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9755526387466575, Val Loss: 0.8203836977481842, LR: 0.0008620859307187339, Duration: 57.25 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9173743218745825, Val Loss: 0.7716655433177948, LR: 0.0008596699001693256, Duration: 57.33 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9972542029506755, Val Loss: 0.7553088366985321, LR: 0.0008572363398164017, Duration: 57.19 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.858516295001192, Val Loss: 0.7116599082946777, LR: 0.0008547853682682604, Duration: 57.27 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9094286392319877, Val Loss: 0.7612875699996948, LR: 0.0008523171049817973, Duration: 57.24 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8845768177284385, Val Loss: 0.7557482719421387, LR: 0.0008498316702566827, Duration: 57.21 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.908603845902209, Val Loss: 0.728739321231842, LR: 0.0008473291852294987, Duration: 57.15 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7868631943216864, Val Loss: 0.7409617602825165, LR: 0.0008448097718678349, Duration: 57.12 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9682106746817536, Val Loss: 0.8263355493545532, LR: 0.0008422735529643444, Duration: 57.27 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9682897093161098, Val Loss: 0.7893812358379364, LR: 0.0008397206521307583, Duration: 57.23 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.958000363044019, Val Loss: 0.7598941922187805, LR: 0.0008371511937918616, Duration: 57.12 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.872883286116258, Val Loss: 0.8129240572452545, LR: 0.0008345653031794292, Duration: 57.15 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8947445289143976, Val Loss: 0.7917663753032684, LR: 0.0008319631063261208, Duration: 57.15 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 53/53 [00:55<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8633588338797946, Val Loss: 0.742882639169693, LR: 0.0008293447300593402, Duration: 57.00 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7837017785828069, Val Loss: 0.768426775932312, LR: 0.0008267103019950528, Duration: 57.19 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7910988499533456, Val Loss: 0.7241998612880707, LR: 0.0008240599505315655, Duration: 57.09 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8728023295132619, Val Loss: 0.7635068595409393, LR: 0.0008213938048432696, Duration: 57.09 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7883722366027113, Val Loss: 0.7495081722736359, LR: 0.0008187119948743449, Duration: 57.18 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8124289208987974, Val Loss: 0.7735747992992401, LR: 0.0008160146513324255, Duration: 57.16 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8853276698094494, Val Loss: 0.8306968510150909, LR: 0.0008133019056822303, Duration: 57.15 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.84355887152114, Val Loss: 0.7990265190601349, LR: 0.0008105738901391552, Duration: 57.14 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9100959829564363, Val Loss: 0.7570797502994537, LR: 0.0008078307376628291, Duration: 57.24 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7963133488061294, Val Loss: 0.7971529066562653, LR: 0.0008050725819506339, Duration: 57.10 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.758200519489792, Val Loss: 0.7547844052314758, LR: 0.0008022995574311875, Duration: 57.14 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7144436442627098, Val Loss: 0.7430776059627533, LR: 0.0007995117992577929, Duration: 57.15 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8531566835799307, Val Loss: 0.7851337790489197, LR: 0.0007967094433018508, Duration: 57.16 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 53/53 [00:55<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8338364857547689, Val Loss: 0.7445622086524963, LR: 0.0007938926261462366, Duration: 56.98 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7476188034381506, Val Loss: 0.817606508731842, LR: 0.0007910614850786447, Duration: 57.04 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.855930116941344, Val Loss: 0.7418228983879089, LR: 0.0007882161580848966, Duration: 57.13 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8267925887737635, Val Loss: 0.721845269203186, LR: 0.000785356783842216, Duration: 57.04 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7640559527109254, Val Loss: 0.7273684740066528, LR: 0.0007824835017124689, Duration: 57.12 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 53/53 [00:55<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8153253714993316, Val Loss: 0.7866406142711639, LR: 0.0007795964517353734, Duration: 56.99 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.828032229306563, Val Loss: 0.7880484163761139, LR: 0.000776695774621672, Duration: 57.09 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.890460289874167, Val Loss: 0.7604543566703796, LR: 0.0007737816117462751, Duration: 57.15 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7504594314773128, Val Loss: 0.7284151315689087, LR: 0.00077085410514137, Duration: 57.17 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.664753185128266, Val Loss: 0.682655930519104, LR: 0.0007679133974894983, Duration: 57.25 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7720322597701594, Val Loss: 0.6964995265007019, LR: 0.0007649596321166025, Duration: 57.10 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.77132688940696, Val Loss: 0.742405503988266, LR: 0.0007619929529850397, Duration: 57.18 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7295567202118207, Val Loss: 0.6699605584144592, LR: 0.0007590135046865651, Duration: 57.30 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8672435013753064, Val Loss: 0.796793133020401, LR: 0.0007560214324352858, Duration: 57.08 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7526051300876546, Val Loss: 0.7599876224994659, LR: 0.0007530168820605818, Duration: 57.16 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7925286517952972, Val Loss: 0.7534968256950378, LR: 0.00075, Duration: 57.26 sec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.884000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.906762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.884000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.880160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.884000\n",
       "1  Precision  0.906762\n",
       "2     Recall  0.884000\n",
       "3   F1 Score  0.880160"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_time = 0\n",
    "losses = []\n",
    "val_losses = []\n",
    "lrs = []\n",
    "best_loss = float('inf')\n",
    "\n",
    "# GradScaler 초기화\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8112626862975787, Val Loss: 0.7154137790203094, LR: 0.0007469709332921155, Duration: 57.54 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7161536509135984, Val Loss: 0.7408965229988098, LR: 0.0007439298295693664, Duration: 57.32 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7719888788349223, Val Loss: 0.7514114081859589, LR: 0.0007408768370508576, Duration: 57.35 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8523108801751766, Val Loss: 0.7744046151638031, LR: 0.0007378121045351377, Duration: 57.34 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7715232394776255, Val Loss: 0.6639634966850281, LR: 0.0007347357813929454, Duration: 57.47 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.824743057196995, Val Loss: 0.7433674931526184, LR: 0.0007316480175599309, Duration: 57.21 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8290754916532985, Val Loss: 0.7020823657512665, LR: 0.0007285489635293472, Duration: 57.16 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8255564750365492, Val Loss: 0.7143006324768066, LR: 0.0007254387703447154, Duration: 57.14 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8166965943462443, Val Loss: 0.7039549946784973, LR: 0.0007223175895924637, Duration: 57.18 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8048374754077983, Val Loss: 0.7261824011802673, LR: 0.0007191855733945387, Duration: 57.17 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.753001186082948, Val Loss: 0.7267617285251617, LR: 0.0007160428744009912, Duration: 57.10 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.70097172935054, Val Loss: 0.7026947736740112, LR: 0.0007128896457825364, Duration: 57.13 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.892185591301828, Val Loss: 0.7535611689090729, LR: 0.0007097260412230886, Duration: 57.14 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7879069346301961, Val Loss: 0.6849764585494995, LR: 0.000706552214912271, Duration: 57.23 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7587217137498676, Val Loss: 0.693489134311676, LR: 0.0007033683215379002, Duration: 57.21 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7581832791274448, Val Loss: 0.7792951166629791, LR: 0.0007001745162784476, Duration: 57.09 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7246726897527587, Val Loss: 0.6745752692222595, LR: 0.0006969709547954755, Duration: 57.22 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6821876573112775, Val Loss: 0.772614449262619, LR: 0.0006937577932260515, Duration: 57.14 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7593952327404383, Val Loss: 0.7832024395465851, LR: 0.0006905351881751372, Duration: 57.10 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7761182121510775, Val Loss: 0.7128190994262695, LR: 0.0006873032967079561, Duration: 57.14 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7262775358164086, Val Loss: 0.7355640530586243, LR: 0.0006840622763423391, Duration: 57.28 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8346934251065523, Val Loss: 0.7148697376251221, LR: 0.000680812285041046, Duration: 57.25 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7255950963722084, Val Loss: 0.7302066683769226, LR: 0.0006775534812040686, Duration: 57.18 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7755302415703826, Val Loss: 0.7257495820522308, LR: 0.0006742860236609076, Duration: 57.20 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7519839102367185, Val Loss: 0.6838313639163971, LR: 0.0006710100716628344, Duration: 57.30 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8332689055856668, Val Loss: 0.7967921495437622, LR: 0.0006677257848751275, Duration: 57.33 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7896595271128528, Val Loss: 0.7087506949901581, LR: 0.0006644333233692916, Duration: 57.34 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.719843550673071, Val Loss: 0.7255011796951294, LR: 0.0006611328476152556, Duration: 57.38 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6959889081289183, Val Loss: 0.6872437000274658, LR: 0.0006578245184735513, Duration: 57.37 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7102152210361552, Val Loss: 0.6619037389755249, LR: 0.0006545084971874737, Duration: 57.50 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7474318753998235, Val Loss: 0.7386810481548309, LR: 0.0006511849453752223, Duration: 57.37 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.733859951766032, Val Loss: 0.7066284716129303, LR: 0.0006478540250220234, Duration: 57.29 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6991113885393683, Val Loss: 0.6887407004833221, LR: 0.0006445158984722358, Duration: 57.42 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7336060854623903, Val Loss: 0.756367564201355, LR: 0.0006411707284214383, Duration: 57.25 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6810317196935978, Val Loss: 0.6522097885608673, LR: 0.0006378186779084996, Duration: 57.52 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6597701041203625, Val Loss: 0.6859714388847351, LR: 0.0006344599103076329, Duration: 57.25 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7143682106485907, Val Loss: 0.6623530387878418, LR: 0.0006310945893204324, Duration: 57.23 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6900084985876984, Val Loss: 0.6508991718292236, LR: 0.0006277228789678953, Duration: 57.36 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7572204335680548, Val Loss: 0.7775123715400696, LR: 0.0006243449435824276, Duration: 57.29 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6961059828974165, Val Loss: 0.6852997243404388, LR: 0.0006209609477998338, Duration: 57.17 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7922201628954906, Val Loss: 0.7192380130290985, LR: 0.0006175710565512949, Duration: 57.58 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6864195657226275, Val Loss: 0.6774426698684692, LR: 0.0006141754350553279, Duration: 57.80 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7452281690993399, Val Loss: 0.7179676592350006, LR: 0.0006107742488097338, Duration: 57.12 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6270019468271508, Val Loss: 0.6781303882598877, LR: 0.0006073676635835317, Duration: 57.18 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7256883821397457, Val Loss: 0.7026098966598511, LR: 0.0006039558454088796, Duration: 57.15 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6898189906804066, Val Loss: 0.7067002654075623, LR: 0.0006005389605729824, Duration: 57.12 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.805146261206213, Val Loss: 0.7376731634140015, LR: 0.0005971171756099861, Duration: 57.29 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5668304416368593, Val Loss: 0.6953170895576477, LR: 0.0005936906572928624, Duration: 57.32 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7427573698871541, Val Loss: 0.6746798753738403, LR: 0.0005902595726252801, Duration: 57.27 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7009685253197293, Val Loss: 0.6952160000801086, LR: 0.0005868240888334653, Duration: 57.52 sec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.904000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.922155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.904000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.899465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.904000\n",
       "1  Precision  0.922155\n",
       "2     Recall  0.904000\n",
       "3   F1 Score  0.899465"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_time = 0\n",
    "losses = []\n",
    "val_losses = []\n",
    "lrs = []\n",
    "best_loss = float('inf')\n",
    "\n",
    "# GradScaler 초기화\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6486827393747725, Val Loss: 0.7160912752151489, LR: 0.0005833843733580511, Duration: 57.49 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7212328640919812, Val Loss: 0.7131361663341522, LR: 0.0005799405938459175, Duration: 57.60 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6904663241134499, Val Loss: 0.7248687148094177, LR: 0.0005764929181420191, Duration: 57.24 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.707387073984686, Val Loss: 0.6739642322063446, LR: 0.0005730415142812059, Duration: 57.45 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6357402194221065, Val Loss: 0.6715317964553833, LR: 0.0005695865504800327, Duration: 57.48 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.665679468298858, Val Loss: 0.7045816481113434, LR: 0.0005661281951285613, Duration: 57.29 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6201864548449247, Val Loss: 0.6870218217372894, LR: 0.0005626666167821521, Duration: 57.29 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6868482828140259, Val Loss: 0.7249892354011536, LR: 0.0005592019841532506, Duration: 57.25 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7179890196278411, Val Loss: 0.6738898158073425, LR: 0.0005557344661031627, Duration: 57.36 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7037225545577284, Val Loss: 0.697343647480011, LR: 0.0005522642316338268, Duration: 57.29 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6737609123283963, Val Loss: 0.7238224148750305, LR: 0.0005487914498795748, Duration: 57.33 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5299477892101936, Val Loss: 0.6894601583480835, LR: 0.0005453162900988901, Duration: 57.32 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.570216657980433, Val Loss: 0.6842698752880096, LR: 0.0005418389216661579, Duration: 57.34 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.687762348157055, Val Loss: 0.6508609056472778, LR: 0.0005383595140634093, Duration: 57.35 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6273453640487958, Val Loss: 0.6579766273498535, LR: 0.0005348782368720626, Duration: 57.33 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6932558675981917, Val Loss: 0.6708256602287292, LR: 0.0005313952597646568, Duration: 57.18 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.710847277686281, Val Loss: 0.6972963511943817, LR: 0.0005279107524965819, Duration: 57.13 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6868894156420007, Val Loss: 0.6578286588191986, LR: 0.0005244248848978067, Duration: 57.25 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.693527339764361, Val Loss: 0.6765686869621277, LR: 0.0005209378268645998, Duration: 57.27 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.751521790927311, Val Loss: 0.6996891498565674, LR: 0.0005174497483512506, Duration: 57.37 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6439493725884635, Val Loss: 0.656184732913971, LR: 0.0005139608193617845, Duration: 57.23 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6367041367404866, Val Loss: 0.6580346822738647, LR: 0.0005104712099416785, Duration: 57.23 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6026121276729512, Val Loss: 0.6933588087558746, LR: 0.0005069810901695728, Duration: 57.16 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6335371541527082, Val Loss: 0.6764963269233704, LR: 0.0005034906301489807, Duration: 57.23 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6558120126994151, Val Loss: 0.6394736170768738, LR: 0.0005, Duration: 57.45 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6996659074189528, Val Loss: 0.7071658372879028, LR: 0.0004965093698510193, Duration: 57.21 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5872584918759904, Val Loss: 0.6586710512638092, LR: 0.0004930189098304274, Duration: 57.22 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6301282824210401, Val Loss: 0.6225307583808899, LR: 0.0004895287900583215, Duration: 57.54 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6588476491424273, Val Loss: 0.6878757476806641, LR: 0.00048603918063821566, Duration: 57.25 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6549064269605673, Val Loss: 0.6332210898399353, LR: 0.0004825502516487497, Duration: 57.27 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5495723598408249, Val Loss: 0.608677089214325, LR: 0.0004790621731354003, Duration: 57.46 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.619111344499408, Val Loss: 0.6526364982128143, LR: 0.00047557511510219335, Duration: 57.23 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5953816287922409, Val Loss: 0.63744056224823, LR: 0.00047208924750341807, Duration: 57.21 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7081950430600148, Val Loss: 0.7006129920482635, LR: 0.0004686047402353433, Duration: 57.21 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6974589104922313, Val Loss: 0.6667627990245819, LR: 0.00046512176312793734, Duration: 57.36 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5950039996291108, Val Loss: 0.6746988594532013, LR: 0.0004616404859365907, Duration: 57.37 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6778339057598475, Val Loss: 0.6079294383525848, LR: 0.00045816107833384235, Duration: 57.60 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5960646980213669, Val Loss: 0.6463775634765625, LR: 0.00045468370990111, Duration: 57.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6042890548706055, Val Loss: 0.6446662545204163, LR: 0.0004512085501204253, Duration: 57.22 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6042536800762393, Val Loss: 0.6103311777114868, LR: 0.00044773576836617336, Duration: 57.33 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.625341942850149, Val Loss: 0.6572642922401428, LR: 0.00044426553389683733, Duration: 57.28 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6673865374529138, Val Loss: 0.6420482099056244, LR: 0.0004407980158467495, Duration: 57.34 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.577147805465842, Val Loss: 0.6261628568172455, LR: 0.00043733338321784784, Duration: 57.21 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5805776490355439, Val Loss: 0.6234298944473267, LR: 0.0004338718048714387, Duration: 57.22 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5872012781647016, Val Loss: 0.6183189749717712, LR: 0.0004304134495199674, Duration: 57.25 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6238609867275886, Val Loss: 0.6628836989402771, LR: 0.00042695848571879425, Duration: 57.39 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4997824306757945, Val Loss: 0.5955558717250824, LR: 0.00042350708185798106, Duration: 57.50 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.649414596692571, Val Loss: 0.6337045729160309, LR: 0.0004200594061540826, Duration: 57.32 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.661429614390967, Val Loss: 0.6558534204959869, LR: 0.0004166156266419489, Duration: 57.37 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6376849660333597, Val Loss: 0.6159285306930542, LR: 0.00041317591116653486, Duration: 57.39 sec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.904000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.921821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.904000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.902692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.904000\n",
       "1  Precision  0.921821\n",
       "2     Recall  0.904000\n",
       "3   F1 Score  0.902692"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_time = 0\n",
    "losses = []\n",
    "val_losses = []\n",
    "lrs = []\n",
    "best_loss = float('inf')\n",
    "\n",
    "# GradScaler 초기화\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.610785962275739, Val Loss: 0.6425177156925201, LR: 0.00040974042737472005, Duration: 57.60 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5561358152695421, Val Loss: 0.6031283736228943, LR: 0.0004063093427071376, Duration: 57.62 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6430342872187775, Val Loss: 0.607377290725708, LR: 0.0004028828243900141, Duration: 57.37 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6187118741701234, Val Loss: 0.6315185129642487, LR: 0.0003994610394270178, Duration: 57.34 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6333734483089086, Val Loss: 0.6243675351142883, LR: 0.0003960441545911204, Duration: 57.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6380719789918863, Val Loss: 0.619968980550766, LR: 0.0003926323364164684, Duration: 57.31 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6155357653239988, Val Loss: 0.6416504979133606, LR: 0.0003892257511902664, Duration: 57.22 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6149210749932055, Val Loss: 0.6342713832855225, LR: 0.0003858245649446721, Duration: 57.16 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5652961258618336, Val Loss: 0.6331491768360138, LR: 0.000382428943448705, Duration: 57.25 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5576138822537549, Val Loss: 0.6214518845081329, LR: 0.0003790390522001662, Duration: 57.23 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5077273002210654, Val Loss: 0.6267729997634888, LR: 0.0003756550564175727, Duration: 57.24 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5826908338744685, Val Loss: 0.6424753367900848, LR: 0.0003722771210321048, Duration: 57.23 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6002273143462415, Val Loss: 0.6386392414569855, LR: 0.0003689054106795677, Duration: 57.31 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6106268572357465, Val Loss: 0.6235107183456421, LR: 0.00036554008969236717, Duration: 57.25 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5526488940670806, Val Loss: 0.694598376750946, LR: 0.00036218132209150044, Duration: 57.16 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5700787418293503, Val Loss: 0.6061311364173889, LR: 0.0003588292715785617, Duration: 57.18 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6483950086359709, Val Loss: 0.6432641744613647, LR: 0.0003554841015277641, Duration: 57.26 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6568430032370225, Val Loss: 0.6536759734153748, LR: 0.0003521459749779768, Duration: 57.36 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.544875148332344, Val Loss: 0.6322699189186096, LR: 0.00034881505462477783, Duration: 57.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.553489721046304, Val Loss: 0.6072441637516022, LR: 0.00034549150281252633, Duration: 57.31 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5195736435224425, Val Loss: 0.636880487203598, LR: 0.0003421754815264488, Duration: 57.26 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.581212579079394, Val Loss: 0.6149046719074249, LR: 0.00033886715238474455, Duration: 57.30 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.645657796904726, Val Loss: 0.5905761122703552, LR: 0.00033556667663070836, Duration: 57.46 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5339946251995158, Val Loss: 0.6497886478900909, LR: 0.00033227421512487253, Duration: 57.66 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.556637169055219, Val Loss: 0.6029933094978333, LR: 0.0003289899283371657, Duration: 57.61 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5689477088316433, Val Loss: 0.6310498416423798, LR: 0.0003257139763390925, Duration: 57.73 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.626054435406091, Val Loss: 0.6556592583656311, LR: 0.00032244651879593156, Duration: 57.47 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6311807002661363, Val Loss: 0.6449752449989319, LR: 0.00031918771495895393, Duration: 57.43 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6116385819777004, Val Loss: 0.6595206558704376, LR: 0.00031593772365766105, Duration: 57.36 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5716265057617764, Val Loss: 0.6218504011631012, LR: 0.00031269670329204396, Duration: 57.41 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.512797771759753, Val Loss: 0.6124059855937958, LR: 0.000309464811824863, Duration: 57.41 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5495973645516161, Val Loss: 0.635547935962677, LR: 0.0003062422067739485, Duration: 57.37 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5866875963390998, Val Loss: 0.6572145819664001, LR: 0.00030302904520452444, Duration: 57.33 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5482194637352567, Val Loss: 0.6053492724895477, LR: 0.0002998254837215526, Duration: 57.47 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.54158146651286, Val Loss: 0.6115133166313171, LR: 0.0002966316784621, Duration: 57.33 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5418636798858643, Val Loss: 0.6503313183784485, LR: 0.00029344778508772916, Duration: 57.32 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5267230047369904, Val Loss: 0.6384743750095367, LR: 0.00029027395877691145, Duration: 57.50 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.60121502966251, Val Loss: 0.6567253172397614, LR: 0.00028711035421746366, Duration: 57.39 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5987449299614385, Val Loss: 0.6474664211273193, LR: 0.0002839571255990088, Duration: 57.33 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5693176624909886, Val Loss: 0.6526170372962952, LR: 0.00028081442660546124, Duration: 57.77 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5674187664715749, Val Loss: 0.6275589168071747, LR: 0.00027768241040753637, Duration: 57.63 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.540545202651114, Val Loss: 0.6147891879081726, LR: 0.00027456122965528474, Duration: 57.71 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5820360892223861, Val Loss: 0.6257007122039795, LR: 0.0002714510364706531, Duration: 57.85 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5600502086135577, Val Loss: 0.6638104915618896, LR: 0.00026835198244006924, Duration: 57.87 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6097148027060166, Val Loss: 0.67800173163414, LR: 0.00026526421860705474, Duration: 57.82 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5417315577561002, Val Loss: 0.6220681965351105, LR: 0.00026218789546486235, Duration: 57.88 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5854397427360967, Val Loss: 0.629370778799057, LR: 0.0002591231629491423, Duration: 57.93 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5057037630171146, Val Loss: 0.6748811900615692, LR: 0.0002560701704306336, Duration: 57.57 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5317115390075828, Val Loss: 0.5959847271442413, LR: 0.0002530290667078846, Duration: 57.76 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5158764888655465, Val Loss: 0.6378338932991028, LR: 0.0002500000000000001, Duration: 57.42 sec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.926004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.907450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.910000\n",
       "1  Precision  0.926004\n",
       "2     Recall  0.910000\n",
       "3   F1 Score  0.907450"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_time = 0\n",
    "losses = []\n",
    "val_losses = []\n",
    "lrs = []\n",
    "best_loss = float('inf')\n",
    "\n",
    "# GradScaler 초기화\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.632792942928818, Val Loss: 0.642238974571228, LR: 0.0002469831179394182, Duration: 57.58 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4493781924247742, Val Loss: 0.5758794546127319, LR: 0.0002439785675647143, Duration: 57.57 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6123678999127082, Val Loss: 0.6472449004650116, LR: 0.00024098649531343496, Duration: 57.44 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5218996922924835, Val Loss: 0.6202114522457123, LR: 0.00023800704701496051, Duration: 57.38 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4944817963636146, Val Loss: 0.661650151014328, LR: 0.0002350403678833976, Duration: 57.29 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5878849243218045, Val Loss: 0.6790187060832977, LR: 0.00023208660251050156, Duration: 57.32 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5287336167299523, Val Loss: 0.6206959784030914, LR: 0.00022914589485863014, Duration: 57.37 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5482107400894165, Val Loss: 0.6506446599960327, LR: 0.00022621838825372491, Duration: 57.29 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4560086918327044, Val Loss: 0.6448995769023895, LR: 0.000223304225378328, Duration: 57.28 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5010144620571497, Val Loss: 0.6152307689189911, LR: 0.00022040354826462666, Duration: 57.37 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6015163322664656, Val Loss: 0.6472426950931549, LR: 0.00021751649828753106, Duration: 57.32 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5194428259471677, Val Loss: 0.649162620306015, LR: 0.0002146432161577842, Duration: 57.43 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.529147078406136, Val Loss: 0.6769522726535797, LR: 0.00021178384191510342, Duration: 57.35 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5596111011954974, Val Loss: 0.6513688564300537, LR: 0.00020893851492135535, Duration: 57.34 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5428848176632288, Val Loss: 0.6557198166847229, LR: 0.00020610737385376348, Duration: 57.36 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5480329338109717, Val Loss: 0.6130235493183136, LR: 0.00020329055669814934, Duration: 57.41 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5764054622290269, Val Loss: 0.6328059136867523, LR: 0.00020048820074220714, Duration: 57.43 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4548472458461545, Val Loss: 0.5980385541915894, LR: 0.00019770044256881258, Duration: 57.39 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5375683442601618, Val Loss: 0.6503657400608063, LR: 0.00019492741804936621, Duration: 57.42 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5395086250215206, Val Loss: 0.6060106754302979, LR: 0.00019216926233717085, Duration: 57.49 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5162867858724773, Val Loss: 0.5871965885162354, LR: 0.00018942610986084484, Duration: 57.41 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5288121689040706, Val Loss: 0.6274852454662323, LR: 0.0001866980943177699, Duration: 57.41 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.546056273973213, Val Loss: 0.6737980544567108, LR: 0.00018398534866757456, Duration: 57.46 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.530400442627241, Val Loss: 0.616728812456131, LR: 0.00018128800512565513, Duration: 57.59 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5387700380019422, Val Loss: 0.6374881565570831, LR: 0.0001786061951567303, Duration: 57.60 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5455521300153912, Val Loss: 0.625135213136673, LR: 0.00017594004946843456, Duration: 57.41 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5646577972286153, Val Loss: 0.6558699011802673, LR: 0.00017328969800494727, Duration: 57.44 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5172008489662747, Val Loss: 0.6145609319210052, LR: 0.00017065526994065972, Duration: 57.42 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5374274062660505, Val Loss: 0.6166812479496002, LR: 0.0001680368936738792, Duration: 57.45 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4426775619668781, Val Loss: 0.6205485463142395, LR: 0.00016543469682057105, Duration: 57.28 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5582705218836945, Val Loss: 0.6210351288318634, LR: 0.00016284880620813847, Duration: 57.52 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5167029140130528, Val Loss: 0.6390103995800018, LR: 0.00016027934786924186, Duration: 57.63 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5530954138287958, Val Loss: 0.6642053723335266, LR: 0.00015772644703565563, Duration: 57.49 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4727244961936519, Val Loss: 0.5638053119182587, LR: 0.0001551902281321651, Duration: 57.66 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5279894696091705, Val Loss: 0.6235700249671936, LR: 0.00015267081477050133, Duration: 57.55 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5750703541737683, Val Loss: 0.644135057926178, LR: 0.00015016832974331724, Duration: 57.43 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5064965025433954, Val Loss: 0.628805547952652, LR: 0.00014768289501820264, Duration: 57.48 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.463342638510578, Val Loss: 0.6250859200954437, LR: 0.00014521463173173966, Duration: 57.58 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5305393698080532, Val Loss: 0.6038281917572021, LR: 0.00014276366018359842, Duration: 57.59 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5610287279452917, Val Loss: 0.6316893100738525, LR: 0.00014033009983067452, Duration: 57.57 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4595125373804345, Val Loss: 0.5942093133926392, LR: 0.00013791406928126637, Duration: 57.44 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.450404904923349, Val Loss: 0.5936344563961029, LR: 0.00013551568628929433, Duration: 57.47 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.539539508099826, Val Loss: 0.6110487580299377, LR: 0.00013313506774856177, Duration: 57.58 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5248515009880066, Val Loss: 0.613547146320343, LR: 0.00013077232968705804, Duration: 57.55 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4880458476408474, Val Loss: 0.6045742034912109, LR: 0.00012842758726130281, Duration: 57.55 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4678833023557123, Val Loss: 0.6094714105129242, LR: 0.00012610095475073412, Duration: 57.50 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4567327960482184, Val Loss: 0.6170757114887238, LR: 0.00012379254555213787, Duration: 57.54 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5774425245680899, Val Loss: 0.6109102070331573, LR: 0.00012150247217412185, Duration: 57.34 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.495818094262537, Val Loss: 0.5980388820171356, LR: 0.00011923084623163172, Duration: 57.44 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5161545895180613, Val Loss: 0.6078267693519592, LR: 0.00011697777844051105, Duration: 57.55 sec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.906000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.922742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.906000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.902301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.906000\n",
       "1  Precision  0.922742\n",
       "2     Recall  0.906000\n",
       "3   F1 Score  0.902301"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_time = 0\n",
    "losses = []\n",
    "val_losses = []\n",
    "lrs = []\n",
    "best_loss = float('inf')\n",
    "\n",
    "# GradScaler 초기화\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4490266869652946, Val Loss: 0.6173547208309174, LR: 0.00011474337861210544, Duration: 57.48 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4958552571962465, Val Loss: 0.6181388795375824, LR: 0.00011252775564791024, Duration: 57.42 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5323669010738157, Val Loss: 0.6262271106243134, LR: 0.00011033101753426283, Duration: 57.51 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4825515870778065, Val Loss: 0.6186058819293976, LR: 0.00010815327133708014, Duration: 57.81 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5474175349721369, Val Loss: 0.6375161111354828, LR: 0.00010599462319663906, Duration: 57.39 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5302469752869516, Val Loss: 0.6063799262046814, LR: 0.00010385517832240471, Duration: 57.39 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4965779129064307, Val Loss: 0.6134440004825592, LR: 0.00010173504098790188, Duration: 57.32 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4902245627259307, Val Loss: 0.626085102558136, LR: 9.963431452563332e-05, Duration: 57.33 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4937019966683298, Val Loss: 0.5945049226284027, LR: 9.755310132204298e-05, Duration: 57.31 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4803586062395349, Val Loss: 0.6241017282009125, LR: 9.549150281252633e-05, Duration: 57.42 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.485025941200976, Val Loss: 0.6154597699642181, LR: 9.344961947648623e-05, Duration: 57.28 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.553384447997471, Val Loss: 0.6329891085624695, LR: 9.142755083243575e-05, Duration: 57.38 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5821156051923644, Val Loss: 0.6268258988857269, LR: 8.942539543314798e-05, Duration: 57.32 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4719902299485117, Val Loss: 0.6115709841251373, LR: 8.744325086085247e-05, Duration: 57.33 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4733827125351384, Val Loss: 0.6026633083820343, LR: 8.548121372247918e-05, Duration: 57.33 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.528831569653637, Val Loss: 0.6041788458824158, LR: 8.353937964495028e-05, Duration: 57.56 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5091091653086104, Val Loss: 0.5944601595401764, LR: 8.161784327051918e-05, Duration: 57.29 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5044805452508747, Val Loss: 0.6006887853145599, LR: 7.971669825215788e-05, Duration: 57.23 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.521805743001542, Val Loss: 0.606998473405838, LR: 7.783603724899258e-05, Duration: 57.24 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4625792098495196, Val Loss: 0.6168385148048401, LR: 7.597595192178702e-05, Duration: 57.13 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4866403768647392, Val Loss: 0.6143187284469604, LR: 7.413653292847617e-05, Duration: 57.21 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5016983173928171, Val Loss: 0.6458925902843475, LR: 7.23178699197467e-05, Duration: 57.23 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.507441355372375, Val Loss: 0.6079353094100952, LR: 7.052005153466778e-05, Duration: 57.36 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5002374176709157, Val Loss: 0.5930327773094177, LR: 6.874316539637127e-05, Duration: 57.38 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4524402022361755, Val Loss: 0.5831645429134369, LR: 6.698729810778065e-05, Duration: 57.31 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5349382173340276, Val Loss: 0.6230845153331757, LR: 6.52525352473905e-05, Duration: 57.21 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.421787510503013, Val Loss: 0.5770139396190643, LR: 6.353896136509524e-05, Duration: 57.14 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5038929919026933, Val Loss: 0.5950082540512085, LR: 6.184665997806832e-05, Duration: 57.23 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4581121892299291, Val Loss: 0.5947765707969666, LR: 6.0175713566691824e-05, Duration: 57.35 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4595062856404286, Val Loss: 0.5773532390594482, LR: 5.852620357053651e-05, Duration: 57.39 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4412906034937445, Val Loss: 0.5751276016235352, LR: 5.6898210384392636e-05, Duration: 57.65 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.455019417798744, Val Loss: 0.5986107885837555, LR: 5.529181335435124e-05, Duration: 57.28 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.423588048737004, Val Loss: 0.5951647460460663, LR: 5.370709077393721e-05, Duration: 57.14 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5657512354400922, Val Loss: 0.6297978460788727, LR: 5.214411988029355e-05, Duration: 57.29 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.481424019021808, Val Loss: 0.6027856171131134, LR: 5.060297685041659e-05, Duration: 57.35 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5334376287910174, Val Loss: 0.6602518558502197, LR: 4.908373679744316e-05, Duration: 57.20 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5417385056333721, Val Loss: 0.6222862899303436, LR: 4.758647376699032e-05, Duration: 57.28 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5391801494472432, Val Loss: 0.6154990792274475, LR: 4.6111260733545715e-05, Duration: 57.28 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.488630156472044, Val Loss: 0.6178792715072632, LR: 4.465816959691149e-05, Duration: 57.27 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4188867481249683, Val Loss: 0.6056208610534668, LR: 4.322727117869951e-05, Duration: 57.22 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5034427777776178, Val Loss: 0.6146332323551178, LR: 4.181863521888019e-05, Duration: 57.25 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5174613268870227, Val Loss: 0.628830760717392, LR: 4.043233037238281e-05, Duration: 57.26 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.414989175661555, Val Loss: 0.5856906175613403, LR: 3.90684242057498e-05, Duration: 57.16 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4669693989573784, Val Loss: 0.6285303235054016, LR: 3.772698319384349e-05, Duration: 57.34 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4298710260751113, Val Loss: 0.6047798693180084, LR: 3.6408072716606344e-05, Duration: 57.22 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4625622731334758, Val Loss: 0.6017948091030121, LR: 3.5111757055874326e-05, Duration: 57.29 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.480740912680356, Val Loss: 0.5980309545993805, LR: 3.383809939224392e-05, Duration: 57.22 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4870433143849642, Val Loss: 0.604668140411377, LR: 3.258716180199278e-05, Duration: 57.28 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.467815636463885, Val Loss: 0.6010154187679291, LR: 3.1359005254054274e-05, Duration: 57.18 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4352140437881902, Val Loss: 0.6062053442001343, LR: 3.0153689607045842e-05, Duration: 57.21 sec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.916000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.932234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.916000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.912997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.916000\n",
       "1  Precision  0.932234\n",
       "2     Recall  0.916000\n",
       "3   F1 Score  0.912997"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_time = 0\n",
    "losses = []\n",
    "val_losses = []\n",
    "lrs = []\n",
    "\n",
    "# GradScaler 초기화\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5280306991541162, Val Loss: 0.6110923886299133, LR: 2.8971273606351657e-05, Duration: 57.43 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4905251815633953, Val Loss: 0.6127850711345673, LR: 2.78118148812595e-05, Duration: 57.19 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4984422562257298, Val Loss: 0.6210318505764008, LR: 2.667536994215186e-05, Duration: 57.25 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.518578536105606, Val Loss: 0.6362796723842621, LR: 2.5561994177751735e-05, Duration: 57.34 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.458748829814623, Val Loss: 0.5860514938831329, LR: 2.4471741852423235e-05, Duration: 57.15 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4581791027536932, Val Loss: 0.5892983973026276, LR: 2.340466610352654e-05, Duration: 57.28 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5015826483942427, Val Loss: 0.6212189197540283, LR: 2.236081893882819e-05, Duration: 57.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4404812522654264, Val Loss: 0.596899151802063, LR: 2.134025123396638e-05, Duration: 57.32 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4900613190992824, Val Loss: 0.6268140375614166, LR: 2.0343012729971243e-05, Duration: 57.30 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5186341641084202, Val Loss: 0.6144694089889526, LR: 1.9369152030840554e-05, Duration: 57.64 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4248406830823646, Val Loss: 0.5964567959308624, LR: 1.841871660117095e-05, Duration: 57.41 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5392035594526328, Val Loss: 0.6169439256191254, LR: 1.7491752763844293e-05, Duration: 57.45 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4727878874202944, Val Loss: 0.589322566986084, LR: 1.658830569777031e-05, Duration: 57.47 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4900980333112321, Val Loss: 0.6169120371341705, LR: 1.5708419435684463e-05, Duration: 57.32 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4993295545847911, Val Loss: 0.6176842451095581, LR: 1.4852136862001764e-05, Duration: 57.31 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4628886872867368, Val Loss: 0.6365418434143066, LR: 1.4019499710726914e-05, Duration: 57.55 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5177183432399102, Val Loss: 0.6181221902370453, LR: 1.3210548563419855e-05, Duration: 57.31 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5225965897991973, Val Loss: 0.6520660519599915, LR: 1.2425322847218367e-05, Duration: 57.37 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4857992091268863, Val Loss: 0.5997631847858429, LR: 1.166386083291604e-05, Duration: 57.45 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5059116572703954, Val Loss: 0.6135885715484619, LR: 1.0926199633097156e-05, Duration: 57.37 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5654499013468903, Val Loss: 0.6218497157096863, LR: 1.0212375200327972e-05, Duration: 57.48 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4671588854969673, Val Loss: 0.6080151200294495, LR: 9.522422325404235e-06, Duration: 57.33 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5610716185479794, Val Loss: 0.6114985346794128, LR: 8.856374635655695e-06, Duration: 57.42 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5006897966816741, Val Loss: 0.6143405139446259, LR: 8.214264593307098e-06, Duration: 57.23 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5218750733249593, Val Loss: 0.639404833316803, LR: 7.59612349389599e-06, Duration: 57.25 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5324488799527007, Val Loss: 0.6320784389972687, LR: 7.001981464747565e-06, Duration: 57.18 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4745295846237327, Val Loss: 0.6148117780685425, LR: 6.431867463506047e-06, Duration: 57.14 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4756788712627482, Val Loss: 0.6332918703556061, LR: 5.885809276723608e-06, Duration: 57.13 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4376118925382506, Val Loss: 0.5928963422775269, LR: 5.363833518505834e-06, Duration: 57.37 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4981821314343866, Val Loss: 0.6131627261638641, LR: 4.865965629214819e-06, Duration: 57.27 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4831091165542603, Val Loss: 0.6185674369335175, LR: 4.392229874229159e-06, Duration: 57.35 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4803573376727555, Val Loss: 0.595588207244873, LR: 3.942649342761117e-06, Duration: 57.37 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4583532326626327, Val Loss: 0.5990894436836243, LR: 3.5172459467315286e-06, Duration: 57.43 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4643125061718922, Val Loss: 0.6052093505859375, LR: 3.1160404197018156e-06, Duration: 57.30 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4728420590454678, Val Loss: 0.6207599639892578, LR: 2.739052315863355e-06, Duration: 57.34 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5161107396179776, Val Loss: 0.6077085137367249, LR: 2.386300009084408e-06, Duration: 57.44 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5448707319655508, Val Loss: 0.6230514347553253, LR: 2.057800692014833e-06, Duration: 57.19 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4528729949357375, Val Loss: 0.5934816896915436, LR: 1.753570375247815e-06, Duration: 57.57 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5023160576820374, Val Loss: 0.6131519973278046, LR: 1.4736238865398766e-06, Duration: 57.12 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4799183944486223, Val Loss: 0.6096602082252502, LR: 1.2179748700879012e-06, Duration: 57.27 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.449043335779658, Val Loss: 0.6186847686767578, LR: 9.866357858642206e-07, Duration: 57.19 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4972283075440604, Val Loss: 0.6323939561843872, LR: 7.796179090094891e-07, Duration: 57.23 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5165725822718639, Val Loss: 0.6118695735931396, LR: 5.969313292830125e-07, Duration: 57.23 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.448775754784638, Val Loss: 0.5953233242034912, LR: 4.3858495057080837e-07, Duration: 57.29 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.497135873110789, Val Loss: 0.6048458516597748, LR: 3.0458649045211895e-07, Duration: 57.35 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.479329891924588, Val Loss: 0.622916579246521, LR: 1.9494247982282386e-07, Duration: 57.26 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4356963432060097, Val Loss: 0.6174989938735962, LR: 1.096582625772502e-07, Duration: 57.30 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4642352428076402, Val Loss: 0.5873866975307465, LR: 4.873799534788059e-08, Duration: 57.28 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 53/53 [00:56<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5013682392408263, Val Loss: 0.6082573533058167, LR: 1.2184647302626584e-08, Duration: 57.21 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 53/53 [00:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5085829248968161, Val Loss: 0.609005481004715, LR: 0.0, Duration: 57.48 sec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.914000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.930341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.914000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.911292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.914000\n",
       "1  Precision  0.930341\n",
       "2     Recall  0.914000\n",
       "3   F1 Score  0.911292"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_time = 0\n",
    "losses = []\n",
    "val_losses = []\n",
    "lrs = []\n",
    "\n",
    "# GradScaler 초기화\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5638053119182587"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "val_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for data in valid_loader:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "        \n",
    "val_loss /= len(valid_loader)\n",
    "val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.914000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.933012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.914000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.908102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.914000\n",
       "1  Precision  0.933012\n",
       "2     Recall  0.914000\n",
       "3   F1 Score  0.908102"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
