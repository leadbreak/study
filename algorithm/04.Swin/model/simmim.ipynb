{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/root/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: python-box in /usr/local/lib/python3.10/dist-packages (7.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install python-box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import yaml\n",
    "from box import Box\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import simmim\n",
    "from swin_v2 import SwinTransformerV2\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from timm.data import Mixup\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MODEL': {'TYPE': 'swinv2',\n",
       "  'NAME': 'simmim_pretrain',\n",
       "  'DROP_PATH_RATE': 0.0,\n",
       "  'SWIN': {'EMBED_DIM': 96,\n",
       "   'DEPTHS': [2, 2, 6, 2],\n",
       "   'NUM_HEADS': [3, 6, 12, 24],\n",
       "   'WINDOW_SIZE': 6,\n",
       "   'PATCH_SIZE': 4}},\n",
       " 'DATA': {'IMG_SIZE': 192,\n",
       "  'MASK_PATCH_SIZE': 32,\n",
       "  'MASK_RATIO': 0.6,\n",
       "  'BATCH_SIZE': 1024,\n",
       "  'NUM_WORKERS': 24,\n",
       "  'DATA_PATH': '../../data/sports'},\n",
       " 'TRAIN': {'EPOCHS': 100,\n",
       "  'WARMUP_EPOCHS': 10,\n",
       "  'BASE_LR': 0.0014,\n",
       "  'WEIGHT_DECAY': 0.05,\n",
       "  'CLIP_GRAD': 5}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simmim_config = yaml.load(open('config/pretrain.yaml'), Loader=yaml.FullLoader)\n",
    "simmim_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_config = {'img_size':simmim_config['DATA']['IMG_SIZE'], \n",
    "                'patch_size':simmim_config['MODEL']['SWIN']['PATCH_SIZE'], \n",
    "                'in_chans':3, \n",
    "                'num_classes':100,\n",
    "                'embed_dim':simmim_config['MODEL']['SWIN']['EMBED_DIM'], \n",
    "                'depths':simmim_config['MODEL']['SWIN']['DEPTHS'], \n",
    "                'num_heads':simmim_config['MODEL']['SWIN']['NUM_HEADS'],           \n",
    "                'window_size':simmim_config['MODEL']['SWIN']['WINDOW_SIZE'], \n",
    "                'mlp_ratio':4., \n",
    "                'qkv_bias':True, \n",
    "                'qk_scale':None,\n",
    "                'drop_rate':0., \n",
    "                'attn_drop_rate':0., \n",
    "                'drop_path_rate':simmim_config['MODEL']['DROP_PATH_RATE'],\n",
    "                'norm_layer':nn.LayerNorm, \n",
    "                'patch_norm':True, \n",
    "                'pretrained_window_sizes':[0,0,0,0],\n",
    "                'ape':True}\n",
    "\n",
    "encoder_stride = 32\n",
    "in_chans = encoder_config['in_chans']\n",
    "patch_size = encoder_config['patch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "encoder = simmim.SwinTransformerV2ForSimMIM(**encoder_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simmim.SimMIM( encoder=encoder, \n",
    "                       encoder_stride=encoder_stride, \n",
    "                       in_chans=in_chans, \n",
    "                       patch_size=patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 1, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 0],\n",
       "       [1, 0, 1, 1, 1, 1, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 1],\n",
       "       [0, 1, 1, 1, 0, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_generator = simmim.MaskGenerator(input_size=224,\n",
    "                                      mask_patch_size=28,\n",
    "                                      model_patch_size=28,\n",
    "                                      mask_ratio=.6)\n",
    "mask = mask_generator()\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 mask의 비율은 60.9375%\n"
     ]
    }
   ],
   "source": [
    "print(f\"생성된 mask의 비율은 {mask.sum() / (mask.shape[0]*mask.shape[1])*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simmim_config = Box(simmim_config)\n",
    "dataloader = simmim.build_loader_simmim(simmim_config)\n",
    "\n",
    "samples = next(iter(dataloader))\n",
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 3, 192, 192]),\n",
       " torch.Size([1024, 48, 48]),\n",
       " torch.Size([1024]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0].shape, samples[1].shape, samples[2].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 18:13:44.430872: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-15 18:13:44.430935: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-15 18:13:44.431673: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-15 18:13:44.436981: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-15 18:13:45.187024: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "base_lr = float(simmim_config.TRAIN.BASE_LR)\n",
    "weight_decay = simmim_config.TRAIN.WEIGHT_DECAY\n",
    "optimizer = optim.AdamW(model.parameters(), lr=base_lr, weight_decay=weight_decay)\n",
    "warmup_epochs = simmim_config.TRAIN.WARMUP_EPOCHS\n",
    "train_epochs = simmim_config.TRAIN.EPOCHS\n",
    "\n",
    "scheduler = transformers.get_cosine_schedule_with_warmup(optimizer, \n",
    "                                                        num_warmup_steps=warmup_epochs*len(dataloader), \n",
    "                                                        num_training_steps=train_epochs*len(dataloader),\n",
    "                                                        num_cycles=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:3'\n",
    "model.to(device)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "model_save = True\n",
    "simmim_path = '../../models/swin2/simmim.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 14/14 [00:19<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.1431, LR: 0.00014000000000000001, Duration: 20.80 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 14/14 [00:16<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.0948, LR: 0.00028000000000000003, Duration: 18.31 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 14/14 [00:17<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.0480, LR: 0.00041999999999999996, Duration: 18.71 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 14/14 [00:16<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.9340, LR: 0.0005600000000000001, Duration: 18.18 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 14/14 [00:17<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.8531, LR: 0.0007, Duration: 19.26 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 14/14 [00:16<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.8270, LR: 0.0008399999999999999, Duration: 18.23 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 14/14 [00:16<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.7686, LR: 0.00098, Duration: 18.27 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 14/14 [00:17<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.7524, LR: 0.0011200000000000001, Duration: 19.08 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 14/14 [00:16<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.7315, LR: 0.00126, Duration: 18.45 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 14/14 [00:17<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.7071, LR: 0.0014, Duration: 19.07 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 14/14 [00:18<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.6956, LR: 0.001399573578913367, Duration: 19.40 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 14/14 [00:17<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.6847, LR: 0.001398294835181877, Duration: 19.29 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 14/14 [00:17<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.6833, LR: 0.0013961653267577914, Duration: 18.49 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 14/14 [00:16<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.6623, LR: 0.0013931876481190993, Duration: 17.99 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 14/14 [00:17<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.6521, LR: 0.0013893654271085456, Duration: 19.18 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 14/14 [00:16<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.6384, LR: 0.001384703320513664, Duration: 18.03 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 14/14 [00:18<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.6315, LR: 0.0013792070083931975, Duration: 19.42 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 14/14 [00:18<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.6190, LR: 0.0013728831871568231, Duration: 19.62 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 14/14 [00:17<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.6035, LR: 0.0013657395614066075, Duration: 19.10 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 14/14 [00:16<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.6075, LR: 0.001357784834550136, Duration: 17.82 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 14/14 [00:17<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5977, LR: 0.0013490286981967512, Duration: 19.43 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 14/14 [00:18<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5994, LR: 0.0013394818203498204, Duration: 19.08 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23: 100%|██████████| 14/14 [00:16<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5893, LR: 0.0013291558324094168, Duration: 17.90 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 14/14 [00:17<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5946, LR: 0.0013180633150012488, Duration: 18.77 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25: 100%|██████████| 14/14 [00:17<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5932, LR: 0.0013062177826491071, Duration: 18.91 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26: 100%|██████████| 14/14 [00:16<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5922, LR: 0.001293633667309498, Duration: 17.75 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27: 100%|██████████| 14/14 [00:18<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5905, LR: 0.001280326300788529, Duration: 19.24 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28: 100%|██████████| 14/14 [00:17<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5792, LR: 0.0012663118960624632, Duration: 18.83 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 14/14 [00:17<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5897, LR: 0.0012516075275247052, Duration: 18.90 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30: 100%|██████████| 14/14 [00:16<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5771, LR: 0.0012362311101832846, Duration: 18.40 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 14/14 [00:17<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5723, LR: 0.001220201377834176, Duration: 19.26 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 14/14 [00:17<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5776, LR: 0.0012035378602370558, Duration: 18.77 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33: 100%|██████████| 14/14 [00:18<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5718, LR: 0.0011862608593212981, Duration: 19.73 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 14/14 [00:17<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5701, LR: 0.0011683914244512007, Duration: 18.63 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 14/14 [00:17<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5737, LR: 0.0011499513267805774, Duration: 18.99 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36: 100%|██████████| 14/14 [00:17<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5694, LR: 0.0011309630327279608, Duration: 18.95 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 14/14 [00:17<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5686, LR: 0.0011114496766047313, Duration: 18.53 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 14/14 [00:16<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5640, LR: 0.0010914350324295228, Duration: 18.14 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 14/14 [00:18<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5606, LR: 0.0010709434849632434, Duration: 19.64 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 14/14 [00:16<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5555, LR: 0.00105, Duration: 18.23 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 14/14 [00:17<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5513, LR: 0.0010286300939501235, Duration: 19.22 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 14/14 [00:17<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5524, LR: 0.001006859802752354, Duration: 19.17 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 43: 100%|██████████| 14/14 [00:17<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5520, LR: 0.0009847156501530602, Duration: 18.76 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 44: 100%|██████████| 14/14 [00:17<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5520, LR: 0.0009622246153911386, Duration: 19.18 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 45: 100%|██████████| 14/14 [00:17<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5608, LR: 0.0009394141003279682, Duration: 19.07 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 46: 100%|██████████| 14/14 [00:16<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5657, LR: 0.0009163118960624632, Duration: 18.10 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 47: 100%|██████████| 14/14 [00:17<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5494, LR: 0.0008929461490718994, Duration: 18.90 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 14/14 [00:17<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5461, LR: 0.0008693453269197673, Duration: 18.92 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 14/14 [00:17<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5436, LR: 0.0008455381835724314, Duration: 19.28 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 14/14 [00:18<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5433, LR: 0.0008215537243668514, Duration: 19.60 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 14/14 [00:16<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5417, LR: 0.0007974211706720458, Duration: 18.22 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 14/14 [00:16<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5434, LR: 0.0007731699242873575, Duration: 17.62 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 53: 100%|██████████| 14/14 [00:18<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5431, LR: 0.0007488295316208876, Duration: 19.35 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 54: 100%|██████████| 14/14 [00:17<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5378, LR: 0.0007244296476917508, Duration: 18.86 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 14/14 [00:16<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5424, LR: 0.0007, Duration: 18.14 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 56: 100%|██████████| 14/14 [00:17<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5508, LR: 0.0006755703523082495, Duration: 18.60 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 57: 100%|██████████| 14/14 [00:18<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5443, LR: 0.0006511704683791123, Duration: 19.53 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 14/14 [00:18<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5384, LR: 0.0006268300757126426, Duration: 19.36 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 59: 100%|██████████| 14/14 [00:18<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5340, LR: 0.0006025788293279544, Duration: 19.71 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|██████████| 14/14 [00:17<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5321, LR: 0.0005784462756331488, Duration: 18.53 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|██████████| 14/14 [00:17<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5317, LR: 0.0005544618164275686, Duration: 18.94 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|██████████| 14/14 [00:16<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5306, LR: 0.0005306546730802327, Duration: 18.01 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|██████████| 14/14 [00:18<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5293, LR: 0.0005070538509281006, Duration: 19.52 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|██████████| 14/14 [00:16<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5289, LR: 0.0004836881039375369, Duration: 18.33 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|██████████| 14/14 [00:16<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5300, LR: 0.0004605858996720319, Duration: 17.92 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 66: 100%|██████████| 14/14 [00:16<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5268, LR: 0.0004377753846088615, Duration: 18.08 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 100%|██████████| 14/14 [00:16<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5269, LR: 0.00041528434984693997, Duration: 17.91 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 68: 100%|██████████| 14/14 [00:17<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5264, LR: 0.00039314019724764573, Duration: 18.55 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 100%|██████████| 14/14 [00:17<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5269, LR: 0.00037136990604987665, Duration: 18.14 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 70: 100%|██████████| 14/14 [00:18<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5282, LR: 0.00035000000000000016, Duration: 19.32 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 71: 100%|██████████| 14/14 [00:17<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5256, LR: 0.00032905651503675667, Duration: 19.32 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72: 100%|██████████| 14/14 [00:17<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5257, LR: 0.0003085649675704773, Duration: 18.38 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 73: 100%|██████████| 14/14 [00:18<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5244, LR: 0.0002885503233952689, Duration: 19.74 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74: 100%|██████████| 14/14 [00:17<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5243, LR: 0.0002690369672720392, Duration: 19.29 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75: 100%|██████████| 14/14 [00:17<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5218, LR: 0.00025004867321942243, Duration: 18.66 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76: 100%|██████████| 14/14 [00:17<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5222, LR: 0.00023160857554879947, Duration: 18.90 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 77: 100%|██████████| 14/14 [00:17<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5220, LR: 0.00021373914067870185, Duration: 18.83 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 78: 100%|██████████| 14/14 [00:16<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5219, LR: 0.00019646213976294433, Duration: 17.80 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 79: 100%|██████████| 14/14 [00:18<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5215, LR: 0.00017979862216582396, Duration: 19.36 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80: 100%|██████████| 14/14 [00:16<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5205, LR: 0.00016376888981671546, Duration: 18.23 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81: 100%|██████████| 14/14 [00:18<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5209, LR: 0.00014839247247529466, Duration: 19.33 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 82: 100%|██████████| 14/14 [00:18<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5195, LR: 0.00013368810393753685, Duration: 20.06 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83: 100%|██████████| 14/14 [00:18<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5193, LR: 0.00011967369921147086, Duration: 19.76 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84: 100%|██████████| 14/14 [00:18<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5185, LR: 0.00010636633269050183, Duration: 19.81 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85: 100%|██████████| 14/14 [00:17<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5190, LR: 9.37822173508929e-05, Duration: 18.45 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86: 100%|██████████| 14/14 [00:16<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5186, LR: 8.19366849987511e-05, Duration: 17.74 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 87: 100%|██████████| 14/14 [00:16<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5181, LR: 7.084416759058323e-05, Duration: 18.28 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88: 100%|██████████| 14/14 [00:18<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5180, LR: 6.0518179650179314e-05, Duration: 19.41 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 14/14 [00:18<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5187, LR: 5.097130180324888e-05, Duration: 19.24 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 90: 100%|██████████| 14/14 [00:17<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5184, LR: 4.221516544986418e-05, Duration: 18.78 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 91: 100%|██████████| 14/14 [00:18<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5172, LR: 3.426043859339253e-05, Duration: 19.71 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92: 100%|██████████| 14/14 [00:16<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5179, LR: 2.7116812843176773e-05, Duration: 17.86 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 93: 100%|██████████| 14/14 [00:17<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5165, LR: 2.0792991606802468e-05, Duration: 19.20 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94: 100%|██████████| 14/14 [00:17<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5176, LR: 1.5296679486336016e-05, Duration: 18.48 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 95: 100%|██████████| 14/14 [00:17<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5168, LR: 1.0634572891454386e-05, Duration: 18.23 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 96: 100%|██████████| 14/14 [00:17<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5180, LR: 6.812351880900747e-06, Duration: 18.67 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 97: 100%|██████████| 14/14 [00:18<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5176, LR: 3.834673242208697e-06, Duration: 19.42 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 98: 100%|██████████| 14/14 [00:16<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5173, LR: 1.7051648181230617e-06, Duration: 17.74 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 99: 100%|██████████| 14/14 [00:17<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5166, LR: 4.264210866329665e-07, Duration: 18.66 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100: 100%|██████████| 14/14 [00:17<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.5177, LR: 0.0, Duration: 18.38 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_time = 0\n",
    "losses = []\n",
    "val_losses = []\n",
    "lrs = []\n",
    "best_loss = float('inf')\n",
    "\n",
    "# GradScaler 초기화\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(train_epochs):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        image, mask = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            loss = model(image, mask)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        if simmim_config.TRAIN.CLIP_GRAD:\n",
    "            clip_grad_norm_(model.parameters(), max_norm=simmim_config.TRAIN.CLIP_GRAD)\n",
    "        else:\n",
    "            clip_grad_norm_(model.parameters())\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    losses.append(epoch_loss)\n",
    "\n",
    "    # 모델 저장\n",
    "    if epoch_loss < best_loss:\n",
    "        \n",
    "        best_loss = epoch_loss\n",
    "        vit_save = model_save\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), simmim_path)\n",
    "        \n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss:.4f}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False    \n",
    "        \n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['absolute_pos_embed', 'embeddings.patch_embeddings.weight', 'embeddings.patch_embeddings.bias', 'embeddings.norm.weight', 'embeddings.norm.bias', 'stages.0.blocks.0.attn_mask', 'stages.0.blocks.0.attn.t_scale', 'stages.0.blocks.0.attn.relative_coords_table', 'stages.0.blocks.0.attn.relative_position_index', 'stages.0.blocks.0.attn.crpb_mlp.0.weight', 'stages.0.blocks.0.attn.crpb_mlp.0.bias', 'stages.0.blocks.0.attn.crpb_mlp.3.weight', 'stages.0.blocks.0.attn.qkv.weight', 'stages.0.blocks.0.attn.qkv.bias', 'stages.0.blocks.0.attn.proj.weight', 'stages.0.blocks.0.attn.proj.bias', 'stages.0.blocks.0.norm1.weight', 'stages.0.blocks.0.norm1.bias', 'stages.0.blocks.0.mlp.fc1.weight', 'stages.0.blocks.0.mlp.fc1.bias', 'stages.0.blocks.0.mlp.fc2.weight', 'stages.0.blocks.0.mlp.fc2.bias', 'stages.0.blocks.0.norm2.weight', 'stages.0.blocks.0.norm2.bias', 'stages.0.blocks.1.attn_mask', 'stages.0.blocks.1.attn.t_scale', 'stages.0.blocks.1.attn.relative_coords_table', 'stages.0.blocks.1.attn.relative_position_index', 'stages.0.blocks.1.attn.crpb_mlp.0.weight', 'stages.0.blocks.1.attn.crpb_mlp.0.bias', 'stages.0.blocks.1.attn.crpb_mlp.3.weight', 'stages.0.blocks.1.attn.qkv.weight', 'stages.0.blocks.1.attn.qkv.bias', 'stages.0.blocks.1.attn.proj.weight', 'stages.0.blocks.1.attn.proj.bias', 'stages.0.blocks.1.norm1.weight', 'stages.0.blocks.1.norm1.bias', 'stages.0.blocks.1.mlp.fc1.weight', 'stages.0.blocks.1.mlp.fc1.bias', 'stages.0.blocks.1.mlp.fc2.weight', 'stages.0.blocks.1.mlp.fc2.bias', 'stages.0.blocks.1.norm2.weight', 'stages.0.blocks.1.norm2.bias', 'stages.0.downsample.reduction.weight', 'stages.0.downsample.norm.weight', 'stages.0.downsample.norm.bias', 'stages.1.blocks.0.attn_mask', 'stages.1.blocks.0.attn.t_scale', 'stages.1.blocks.0.attn.relative_coords_table', 'stages.1.blocks.0.attn.relative_position_index', 'stages.1.blocks.0.attn.crpb_mlp.0.weight', 'stages.1.blocks.0.attn.crpb_mlp.0.bias', 'stages.1.blocks.0.attn.crpb_mlp.3.weight', 'stages.1.blocks.0.attn.qkv.weight', 'stages.1.blocks.0.attn.qkv.bias', 'stages.1.blocks.0.attn.proj.weight', 'stages.1.blocks.0.attn.proj.bias', 'stages.1.blocks.0.norm1.weight', 'stages.1.blocks.0.norm1.bias', 'stages.1.blocks.0.mlp.fc1.weight', 'stages.1.blocks.0.mlp.fc1.bias', 'stages.1.blocks.0.mlp.fc2.weight', 'stages.1.blocks.0.mlp.fc2.bias', 'stages.1.blocks.0.norm2.weight', 'stages.1.blocks.0.norm2.bias', 'stages.1.blocks.1.attn_mask', 'stages.1.blocks.1.attn.t_scale', 'stages.1.blocks.1.attn.relative_coords_table', 'stages.1.blocks.1.attn.relative_position_index', 'stages.1.blocks.1.attn.crpb_mlp.0.weight', 'stages.1.blocks.1.attn.crpb_mlp.0.bias', 'stages.1.blocks.1.attn.crpb_mlp.3.weight', 'stages.1.blocks.1.attn.qkv.weight', 'stages.1.blocks.1.attn.qkv.bias', 'stages.1.blocks.1.attn.proj.weight', 'stages.1.blocks.1.attn.proj.bias', 'stages.1.blocks.1.norm1.weight', 'stages.1.blocks.1.norm1.bias', 'stages.1.blocks.1.mlp.fc1.weight', 'stages.1.blocks.1.mlp.fc1.bias', 'stages.1.blocks.1.mlp.fc2.weight', 'stages.1.blocks.1.mlp.fc2.bias', 'stages.1.blocks.1.norm2.weight', 'stages.1.blocks.1.norm2.bias', 'stages.1.downsample.reduction.weight', 'stages.1.downsample.norm.weight', 'stages.1.downsample.norm.bias', 'stages.2.blocks.0.attn_mask', 'stages.2.blocks.0.attn.t_scale', 'stages.2.blocks.0.attn.relative_coords_table', 'stages.2.blocks.0.attn.relative_position_index', 'stages.2.blocks.0.attn.crpb_mlp.0.weight', 'stages.2.blocks.0.attn.crpb_mlp.0.bias', 'stages.2.blocks.0.attn.crpb_mlp.3.weight', 'stages.2.blocks.0.attn.qkv.weight', 'stages.2.blocks.0.attn.qkv.bias', 'stages.2.blocks.0.attn.proj.weight', 'stages.2.blocks.0.attn.proj.bias', 'stages.2.blocks.0.norm1.weight', 'stages.2.blocks.0.norm1.bias', 'stages.2.blocks.0.mlp.fc1.weight', 'stages.2.blocks.0.mlp.fc1.bias', 'stages.2.blocks.0.mlp.fc2.weight', 'stages.2.blocks.0.mlp.fc2.bias', 'stages.2.blocks.0.norm2.weight', 'stages.2.blocks.0.norm2.bias', 'stages.2.blocks.1.attn_mask', 'stages.2.blocks.1.attn.t_scale', 'stages.2.blocks.1.attn.relative_coords_table', 'stages.2.blocks.1.attn.relative_position_index', 'stages.2.blocks.1.attn.crpb_mlp.0.weight', 'stages.2.blocks.1.attn.crpb_mlp.0.bias', 'stages.2.blocks.1.attn.crpb_mlp.3.weight', 'stages.2.blocks.1.attn.qkv.weight', 'stages.2.blocks.1.attn.qkv.bias', 'stages.2.blocks.1.attn.proj.weight', 'stages.2.blocks.1.attn.proj.bias', 'stages.2.blocks.1.norm1.weight', 'stages.2.blocks.1.norm1.bias', 'stages.2.blocks.1.mlp.fc1.weight', 'stages.2.blocks.1.mlp.fc1.bias', 'stages.2.blocks.1.mlp.fc2.weight', 'stages.2.blocks.1.mlp.fc2.bias', 'stages.2.blocks.1.norm2.weight', 'stages.2.blocks.1.norm2.bias', 'stages.2.blocks.2.attn_mask', 'stages.2.blocks.2.attn.t_scale', 'stages.2.blocks.2.attn.relative_coords_table', 'stages.2.blocks.2.attn.relative_position_index', 'stages.2.blocks.2.attn.crpb_mlp.0.weight', 'stages.2.blocks.2.attn.crpb_mlp.0.bias', 'stages.2.blocks.2.attn.crpb_mlp.3.weight', 'stages.2.blocks.2.attn.qkv.weight', 'stages.2.blocks.2.attn.qkv.bias', 'stages.2.blocks.2.attn.proj.weight', 'stages.2.blocks.2.attn.proj.bias', 'stages.2.blocks.2.norm1.weight', 'stages.2.blocks.2.norm1.bias', 'stages.2.blocks.2.mlp.fc1.weight', 'stages.2.blocks.2.mlp.fc1.bias', 'stages.2.blocks.2.mlp.fc2.weight', 'stages.2.blocks.2.mlp.fc2.bias', 'stages.2.blocks.2.norm2.weight', 'stages.2.blocks.2.norm2.bias', 'stages.2.blocks.3.attn_mask', 'stages.2.blocks.3.attn.t_scale', 'stages.2.blocks.3.attn.relative_coords_table', 'stages.2.blocks.3.attn.relative_position_index', 'stages.2.blocks.3.attn.crpb_mlp.0.weight', 'stages.2.blocks.3.attn.crpb_mlp.0.bias', 'stages.2.blocks.3.attn.crpb_mlp.3.weight', 'stages.2.blocks.3.attn.qkv.weight', 'stages.2.blocks.3.attn.qkv.bias', 'stages.2.blocks.3.attn.proj.weight', 'stages.2.blocks.3.attn.proj.bias', 'stages.2.blocks.3.norm1.weight', 'stages.2.blocks.3.norm1.bias', 'stages.2.blocks.3.mlp.fc1.weight', 'stages.2.blocks.3.mlp.fc1.bias', 'stages.2.blocks.3.mlp.fc2.weight', 'stages.2.blocks.3.mlp.fc2.bias', 'stages.2.blocks.3.norm2.weight', 'stages.2.blocks.3.norm2.bias', 'stages.2.blocks.4.attn_mask', 'stages.2.blocks.4.attn.t_scale', 'stages.2.blocks.4.attn.relative_coords_table', 'stages.2.blocks.4.attn.relative_position_index', 'stages.2.blocks.4.attn.crpb_mlp.0.weight', 'stages.2.blocks.4.attn.crpb_mlp.0.bias', 'stages.2.blocks.4.attn.crpb_mlp.3.weight', 'stages.2.blocks.4.attn.qkv.weight', 'stages.2.blocks.4.attn.qkv.bias', 'stages.2.blocks.4.attn.proj.weight', 'stages.2.blocks.4.attn.proj.bias', 'stages.2.blocks.4.norm1.weight', 'stages.2.blocks.4.norm1.bias', 'stages.2.blocks.4.mlp.fc1.weight', 'stages.2.blocks.4.mlp.fc1.bias', 'stages.2.blocks.4.mlp.fc2.weight', 'stages.2.blocks.4.mlp.fc2.bias', 'stages.2.blocks.4.norm2.weight', 'stages.2.blocks.4.norm2.bias', 'stages.2.blocks.5.attn_mask', 'stages.2.blocks.5.attn.t_scale', 'stages.2.blocks.5.attn.relative_coords_table', 'stages.2.blocks.5.attn.relative_position_index', 'stages.2.blocks.5.attn.crpb_mlp.0.weight', 'stages.2.blocks.5.attn.crpb_mlp.0.bias', 'stages.2.blocks.5.attn.crpb_mlp.3.weight', 'stages.2.blocks.5.attn.qkv.weight', 'stages.2.blocks.5.attn.qkv.bias', 'stages.2.blocks.5.attn.proj.weight', 'stages.2.blocks.5.attn.proj.bias', 'stages.2.blocks.5.norm1.weight', 'stages.2.blocks.5.norm1.bias', 'stages.2.blocks.5.mlp.fc1.weight', 'stages.2.blocks.5.mlp.fc1.bias', 'stages.2.blocks.5.mlp.fc2.weight', 'stages.2.blocks.5.mlp.fc2.bias', 'stages.2.blocks.5.norm2.weight', 'stages.2.blocks.5.norm2.bias', 'stages.2.downsample.reduction.weight', 'stages.2.downsample.norm.weight', 'stages.2.downsample.norm.bias', 'stages.3.blocks.0.attn_mask', 'stages.3.blocks.0.attn.t_scale', 'stages.3.blocks.0.attn.relative_coords_table', 'stages.3.blocks.0.attn.relative_position_index', 'stages.3.blocks.0.attn.crpb_mlp.0.weight', 'stages.3.blocks.0.attn.crpb_mlp.0.bias', 'stages.3.blocks.0.attn.crpb_mlp.3.weight', 'stages.3.blocks.0.attn.qkv.weight', 'stages.3.blocks.0.attn.qkv.bias', 'stages.3.blocks.0.attn.proj.weight', 'stages.3.blocks.0.attn.proj.bias', 'stages.3.blocks.0.norm1.weight', 'stages.3.blocks.0.norm1.bias', 'stages.3.blocks.0.mlp.fc1.weight', 'stages.3.blocks.0.mlp.fc1.bias', 'stages.3.blocks.0.mlp.fc2.weight', 'stages.3.blocks.0.mlp.fc2.bias', 'stages.3.blocks.0.norm2.weight', 'stages.3.blocks.0.norm2.bias', 'stages.3.blocks.1.attn_mask', 'stages.3.blocks.1.attn.t_scale', 'stages.3.blocks.1.attn.relative_coords_table', 'stages.3.blocks.1.attn.relative_position_index', 'stages.3.blocks.1.attn.crpb_mlp.0.weight', 'stages.3.blocks.1.attn.crpb_mlp.0.bias', 'stages.3.blocks.1.attn.crpb_mlp.3.weight', 'stages.3.blocks.1.attn.qkv.weight', 'stages.3.blocks.1.attn.qkv.bias', 'stages.3.blocks.1.attn.proj.weight', 'stages.3.blocks.1.attn.proj.bias', 'stages.3.blocks.1.norm1.weight', 'stages.3.blocks.1.norm1.bias', 'stages.3.blocks.1.mlp.fc1.weight', 'stages.3.blocks.1.mlp.fc1.bias', 'stages.3.blocks.1.mlp.fc2.weight', 'stages.3.blocks.1.mlp.fc2.bias', 'stages.3.blocks.1.norm2.weight', 'stages.3.blocks.1.norm2.bias', 'layernorm.weight', 'layernorm.bias', 'classifier.weight', 'classifier.bias'])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SwinTransformerV2(pretrained_window_sizes=[6,6,6,6], ape=True, drop_path_rate=0.3)\n",
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0830,  0.1194,  0.1033, -0.0618],\n",
       "         [-0.0452, -0.0010,  0.0245,  0.0998],\n",
       "         [ 0.0673, -0.0723,  0.1352,  0.1109],\n",
       "         [ 0.1027,  0.0734,  0.0886, -0.1377]],\n",
       "\n",
       "        [[ 0.1120,  0.1359, -0.0219,  0.0250],\n",
       "         [ 0.0192, -0.0022, -0.0717, -0.0349],\n",
       "         [-0.0985,  0.0495,  0.0731,  0.1403],\n",
       "         [ 0.0597, -0.0444,  0.0440,  0.1281]],\n",
       "\n",
       "        [[ 0.0116,  0.0292,  0.0172, -0.1337],\n",
       "         [-0.1150,  0.0171, -0.0060, -0.1312],\n",
       "         [ 0.0137, -0.0317,  0.0986, -0.0627],\n",
       "         [-0.0626, -0.0838,  0.0119,  0.0636]]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['embeddings.patch_embeddings.weight'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0328,  0.0135,  0.0025, -0.0392,  0.0284, -0.0045, -0.0103, -0.0006,\n",
       "        -0.0028,  0.0062,  0.0049, -0.0020, -0.0225,  0.0086,  0.0056, -0.0130,\n",
       "         0.0148, -0.0415,  0.0096,  0.0207, -0.0064,  0.0079, -0.0041,  0.0384,\n",
       "         0.0001, -0.0082, -0.0096,  0.0080, -0.0094,  0.0036, -0.0073,  0.0298,\n",
       "         0.0184,  0.0070,  0.0067,  0.0127, -0.0013,  0.0212, -0.0090,  0.0016,\n",
       "         0.0107,  0.0123, -0.0002,  0.0295, -0.0177, -0.0127, -0.0237,  0.0018,\n",
       "         0.0116, -0.0168, -0.0194, -0.0190,  0.0367,  0.0396,  0.0250, -0.0085,\n",
       "         0.0220, -0.0386,  0.0394,  0.0310, -0.0080, -0.0173,  0.0035,  0.0094,\n",
       "        -0.0144, -0.0048,  0.0084, -0.0164,  0.0243, -0.0139,  0.0296, -0.0467,\n",
       "        -0.0184,  0.0130, -0.0216,  0.0245, -0.0582,  0.0193,  0.0250, -0.0057,\n",
       "        -0.0006, -0.0196,  0.0241, -0.0173, -0.0187, -0.0049,  0.0185,  0.0192,\n",
       "        -0.0130, -0.0217, -0.0250, -0.0028,  0.0036,  0.0015,  0.0019,  0.0076,\n",
       "         0.0318, -0.0063, -0.0278, -0.0048, -0.0058, -0.0078,  0.0236, -0.0083,\n",
       "         0.0273, -0.0157, -0.0185,  0.0098, -0.0135, -0.0006,  0.0063, -0.0004,\n",
       "        -0.0141, -0.0034, -0.0113, -0.0102, -0.0167, -0.0116,  0.0251,  0.0022,\n",
       "        -0.0415,  0.0155,  0.0139,  0.0141, -0.0511,  0.0491,  0.0105,  0.0196,\n",
       "        -0.0168, -0.0159, -0.0051, -0.0131,  0.0236,  0.0336, -0.0004,  0.0075,\n",
       "        -0.0118,  0.0036, -0.0081,  0.0343,  0.0418,  0.0162, -0.0286,  0.0393,\n",
       "        -0.0030,  0.0112,  0.0134,  0.0322,  0.0089, -0.0183, -0.0324, -0.0223,\n",
       "         0.0046, -0.0211, -0.0116,  0.0037,  0.0343, -0.0125, -0.0013,  0.0226,\n",
       "        -0.0354, -0.0086, -0.0402, -0.0082, -0.0179,  0.0049, -0.0205, -0.0117,\n",
       "        -0.0118, -0.0025,  0.0138, -0.0184,  0.0088, -0.0099, -0.0184, -0.0084,\n",
       "         0.0089, -0.0275, -0.0043,  0.0270, -0.0272, -0.0254, -0.0183,  0.0015,\n",
       "        -0.0125, -0.0254,  0.0195, -0.0113,  0.0186,  0.0167, -0.0060, -0.0116,\n",
       "        -0.0127, -0.0110, -0.0305,  0.0122,  0.0115,  0.0185,  0.0136,  0.0185,\n",
       "        -0.0283,  0.0079, -0.0300,  0.0143,  0.0282,  0.0075, -0.0266, -0.0289,\n",
       "        -0.0282,  0.0178, -0.0481, -0.0063, -0.0165,  0.0296,  0.0051,  0.0185,\n",
       "        -0.0290,  0.0537, -0.0003, -0.0088,  0.0009,  0.0169, -0.0011, -0.0270,\n",
       "         0.0156, -0.0146, -0.0193,  0.0083,  0.0306,  0.0107, -0.0004, -0.0321,\n",
       "         0.0286, -0.0308, -0.0268,  0.0459, -0.0166,  0.0058,  0.0106, -0.0176,\n",
       "         0.0193, -0.0189,  0.0240,  0.0056,  0.0090,  0.0254,  0.0006,  0.0040,\n",
       "         0.0107, -0.0156,  0.0073, -0.0270, -0.0324,  0.0130, -0.0123,  0.0092,\n",
       "        -0.0285,  0.0272,  0.0131,  0.0127,  0.0033,  0.0114,  0.0068,  0.0031,\n",
       "        -0.0171,  0.0050, -0.0281, -0.0034, -0.0229, -0.0111, -0.0159,  0.0091,\n",
       "        -0.0193, -0.0051,  0.0152,  0.0075,  0.0528,  0.0109,  0.0348, -0.0115,\n",
       "        -0.0144,  0.0027, -0.0269,  0.0114,  0.0012,  0.0273,  0.0159, -0.0113,\n",
       "        -0.0068, -0.0052,  0.0089, -0.0382,  0.0071,  0.0153, -0.0255,  0.0072,\n",
       "        -0.0145,  0.0415, -0.0221, -0.0065,  0.0151, -0.0345,  0.0112,  0.0266,\n",
       "         0.0061, -0.0059, -0.0282, -0.0121,  0.0020,  0.0024,  0.0159,  0.0269,\n",
       "        -0.0161, -0.0023,  0.0216, -0.0040,  0.0016,  0.0066, -0.0124,  0.0365,\n",
       "         0.0063, -0.0176, -0.0141, -0.0208,  0.0146,  0.0057, -0.0109,  0.0100,\n",
       "        -0.0023,  0.0036, -0.0048, -0.0166,  0.0174,  0.0101,  0.0291, -0.0318,\n",
       "         0.0180,  0.0428, -0.0170,  0.0050, -0.0062, -0.0102, -0.0115, -0.0237,\n",
       "        -0.0113,  0.0081, -0.0116,  0.0123,  0.0206,  0.0023,  0.0127, -0.0146,\n",
       "        -0.0078, -0.0222,  0.0013,  0.0032, -0.0014,  0.0289, -0.0009,  0.0151,\n",
       "        -0.0251, -0.0153, -0.0160,  0.0441, -0.0037,  0.0290,  0.0026, -0.0278,\n",
       "         0.0116, -0.0027, -0.0101,  0.0002, -0.0227,  0.0193, -0.0116,  0.0027,\n",
       "        -0.0186, -0.0567,  0.0010, -0.0368, -0.0091, -0.0051, -0.0185,  0.0255])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['stages.3.blocks.1.attn.crpb_mlp.3.weight'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MODEL': {'TYPE': 'swinv2',\n",
       "  'NAME': 'simmim_train',\n",
       "  'PRETRAINED': '../../models/swin2/simmim.pth',\n",
       "  'DROP_PATH_RATE': 0.2,\n",
       "  'SWIN': {'EMBED_DIM': 96,\n",
       "   'DEPTHS': [2, 2, 6, 2],\n",
       "   'NUM_HEADS': [3, 6, 12, 24],\n",
       "   'WINDOW_SIZE': 7,\n",
       "   'PATCH_SIZE': 4}},\n",
       " 'DATA': {'IMG_SIZE': 224,\n",
       "  'MASK_PATCH_SIZE': 32,\n",
       "  'MASK_RATIO': 0.6,\n",
       "  'BATCH_SIZE': 960,\n",
       "  'NUM_WORKERS': 24,\n",
       "  'DATA_PATH': '../../data/sports'},\n",
       " 'TRAIN': {'EPOCHS': 20,\n",
       "  'WARMUP_EPOCHS': 10,\n",
       "  'BASE_LR': '1e-4',\n",
       "  'WEIGHT_DECAY': 0.05,\n",
       "  'CLIP_GRAD': 5}}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swin_config = yaml.load(open('config/train.yaml'), Loader=yaml.FullLoader)\n",
    "swin_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained(config, model):\n",
    "    print(f\"==============> Loading weight {config.MODEL.PRETRAINED} for fine-tuning......\")\n",
    "    state_dict = torch.load(config.MODEL.PRETRAINED, map_location='cpu')\n",
    "\n",
    "    # remain encoder only\n",
    "    not_encoder_keys = [k for k in state_dict.keys() if 'encoder' not in k]\n",
    "    for k in not_encoder_keys:\n",
    "        del state_dict[k]\n",
    "        \n",
    "    # remove prefix encoder.\n",
    "    state_dict = {k.replace('encoder.', ''):v for k, v in state_dict.items()}\n",
    "\n",
    "    # delete relative_position_index since we always re-init it\n",
    "    relative_position_index_keys = [k for k in state_dict.keys() if \"relative_position_index\" in k]\n",
    "    for k in relative_position_index_keys:\n",
    "        del state_dict[k]\n",
    "\n",
    "    # delete relative_coords_table since we always re-init it\n",
    "    relative_position_index_keys = [k for k in state_dict.keys() if \"relative_coords_table\" in k]\n",
    "    for k in relative_position_index_keys:\n",
    "        del state_dict[k]\n",
    "\n",
    "    # delete attn_mask since we always re-init it\n",
    "    attn_mask_keys = [k for k in state_dict.keys() if \"attn_mask\" in k]\n",
    "    for k in attn_mask_keys:\n",
    "        del state_dict[k]\n",
    "\n",
    "    # bicubic interpolate relative_position_bias_table if not match\n",
    "    relative_position_bias_table_keys = [k for k in state_dict.keys() if \"relative_position_bias_table\" in k]\n",
    "    for k in relative_position_bias_table_keys:\n",
    "        relative_position_bias_table_pretrained = state_dict[k]\n",
    "        relative_position_bias_table_current = model.state_dict()[k]\n",
    "        L1, nH1 = relative_position_bias_table_pretrained.size()\n",
    "        L2, nH2 = relative_position_bias_table_current.size()\n",
    "        if nH1 != nH2:\n",
    "            print(f\"Error in loading {k}, passing......\")\n",
    "        else:\n",
    "            if L1 != L2:\n",
    "                # bicubic interpolate relative_position_bias_table if not match\n",
    "                S1 = int(L1 ** 0.5)\n",
    "                S2 = int(L2 ** 0.5)\n",
    "                relative_position_bias_table_pretrained_resized = torch.nn.functional.interpolate(\n",
    "                    relative_position_bias_table_pretrained.permute(1, 0).view(1, nH1, S1, S1), size=(S2, S2),\n",
    "                    mode='bicubic')\n",
    "                state_dict[k] = relative_position_bias_table_pretrained_resized.view(nH2, L2).permute(1, 0)\n",
    "\n",
    "    # bicubic interpolate absolute_pos_embed if not match\n",
    "    absolute_pos_embed_keys = [k for k in state_dict.keys() if \"absolute_pos_embed\" in k]\n",
    "    for k in absolute_pos_embed_keys:\n",
    "        # dpe\n",
    "        absolute_pos_embed_pretrained = state_dict[k]\n",
    "        absolute_pos_embed_current = model.state_dict()[k.replace('encoder.','')]\n",
    "        _, L1, C1 = absolute_pos_embed_pretrained.size()\n",
    "        _, L2, C2 = absolute_pos_embed_current.size()\n",
    "        if C1 != C1:\n",
    "            print(f\"Error in loading {k}, passing......\")\n",
    "        else:\n",
    "            if L1 != L2:\n",
    "                S1 = int(L1 ** 0.5)\n",
    "                S2 = int(L2 ** 0.5)\n",
    "                absolute_pos_embed_pretrained = absolute_pos_embed_pretrained.reshape(-1, S1, S1, C1)\n",
    "                absolute_pos_embed_pretrained = absolute_pos_embed_pretrained.permute(0, 3, 1, 2)\n",
    "                absolute_pos_embed_pretrained_resized = torch.nn.functional.interpolate(\n",
    "                    absolute_pos_embed_pretrained, size=(S2, S2), mode='bicubic')\n",
    "                absolute_pos_embed_pretrained_resized = absolute_pos_embed_pretrained_resized.permute(0, 2, 3, 1)\n",
    "                absolute_pos_embed_pretrained_resized = absolute_pos_embed_pretrained_resized.flatten(1, 2)\n",
    "                state_dict[k] = absolute_pos_embed_pretrained_resized\n",
    "\n",
    "    # check classifier, if not match, then re-init classifier to zero\n",
    "    head_bias_pretrained = state_dict['classifier.bias']\n",
    "    Nc1 = head_bias_pretrained.shape[0]\n",
    "    Nc2 = model.classifier.bias.shape[0]\n",
    "    if (Nc1 != Nc2):\n",
    "        torch.nn.init.constant_(model.classifier.bias, 0.)\n",
    "        torch.nn.init.constant_(model.classifier.weight, 0.)\n",
    "        del state_dict['classifier.weight']\n",
    "        del state_dict['classifier.bias']\n",
    "        print(f\"Error in loading classifier head, re-init classifier head to 0\")\n",
    "\n",
    "    msg = model.load_state_dict(state_dict, strict=False)\n",
    "    print(msg)\n",
    "\n",
    "    print(f\"=> loaded successfully '{config.MODEL.PRETRAINED}'\")\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============> Loading weight ../../models/swin2/simmim.pth for fine-tuning......\n",
      "_IncompatibleKeys(missing_keys=['stages.0.blocks.0.attn_mask', 'stages.0.blocks.0.attn.relative_coords_table', 'stages.0.blocks.0.attn.relative_position_index', 'stages.0.blocks.1.attn_mask', 'stages.0.blocks.1.attn.relative_coords_table', 'stages.0.blocks.1.attn.relative_position_index', 'stages.1.blocks.0.attn_mask', 'stages.1.blocks.0.attn.relative_coords_table', 'stages.1.blocks.0.attn.relative_position_index', 'stages.1.blocks.1.attn_mask', 'stages.1.blocks.1.attn.relative_coords_table', 'stages.1.blocks.1.attn.relative_position_index', 'stages.2.blocks.0.attn_mask', 'stages.2.blocks.0.attn.relative_coords_table', 'stages.2.blocks.0.attn.relative_position_index', 'stages.2.blocks.1.attn_mask', 'stages.2.blocks.1.attn.relative_coords_table', 'stages.2.blocks.1.attn.relative_position_index', 'stages.2.blocks.2.attn_mask', 'stages.2.blocks.2.attn.relative_coords_table', 'stages.2.blocks.2.attn.relative_position_index', 'stages.2.blocks.3.attn_mask', 'stages.2.blocks.3.attn.relative_coords_table', 'stages.2.blocks.3.attn.relative_position_index', 'stages.2.blocks.4.attn_mask', 'stages.2.blocks.4.attn.relative_coords_table', 'stages.2.blocks.4.attn.relative_position_index', 'stages.2.blocks.5.attn_mask', 'stages.2.blocks.5.attn.relative_coords_table', 'stages.2.blocks.5.attn.relative_position_index', 'stages.3.blocks.0.attn_mask', 'stages.3.blocks.0.attn.relative_coords_table', 'stages.3.blocks.0.attn.relative_position_index', 'stages.3.blocks.1.attn_mask', 'stages.3.blocks.1.attn.relative_coords_table', 'stages.3.blocks.1.attn.relative_position_index'], unexpected_keys=['mask_token'])\n",
      "=> loaded successfully '../../models/swin2/simmim.pth'\n"
     ]
    }
   ],
   "source": [
    "swin_config = Box(swin_config)\n",
    "load_pretrained(swin_config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0915,  0.0452,  0.0492, -0.1203],\n",
       "         [-0.0344, -0.0366, -0.0396, -0.1072],\n",
       "         [ 0.1185,  0.0418,  0.0388,  0.0307],\n",
       "         [ 0.1307,  0.0662, -0.1047,  0.1280]],\n",
       "\n",
       "        [[-0.1221, -0.0301, -0.1284,  0.0514],\n",
       "         [-0.0583,  0.0590, -0.0052, -0.0822],\n",
       "         [-0.0587, -0.0320,  0.0118, -0.0611],\n",
       "         [-0.1188,  0.1018,  0.0837, -0.0119]],\n",
       "\n",
       "        [[-0.0537, -0.0778, -0.0539,  0.1121],\n",
       "         [ 0.0669, -0.0011,  0.1144,  0.0723],\n",
       "         [ 0.0919, -0.0840, -0.0773,  0.0947],\n",
       "         [-0.0562, -0.0688, -0.0784,  0.0850]]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['embeddings.patch_embeddings.weight'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0378, -0.0356, -0.0572,  0.0410,  0.1083,  0.0806, -0.0449,  0.1297,\n",
       "         0.1483, -0.0354, -0.0157,  0.0207,  0.0078, -0.0074, -0.0733,  0.1325,\n",
       "         0.0424, -0.0151,  0.0299,  0.0710, -0.0764,  0.0846,  0.0357,  0.0234,\n",
       "         0.0228, -0.0675,  0.0554,  0.0503,  0.1562,  0.0724, -0.0679, -0.0528,\n",
       "        -0.0609, -0.0841,  0.0542,  0.0328, -0.0305, -0.0002, -0.0288,  0.1304,\n",
       "         0.0463,  0.0064, -0.0864, -0.0470, -0.0721, -0.0730, -0.0987, -0.0274,\n",
       "        -0.0715,  0.0071,  0.0931,  0.0537,  0.1133, -0.0511, -0.0168,  0.0127,\n",
       "         0.1350,  0.0222, -0.0723,  0.0142, -0.0255, -0.0166, -0.0845,  0.0744,\n",
       "         0.0075, -0.0324, -0.0903, -0.1243,  0.0328,  0.0239,  0.0102,  0.0438,\n",
       "        -0.1146, -0.0742, -0.0043,  0.0933,  0.0712, -0.0298, -0.0953,  0.1248,\n",
       "         0.0784, -0.0411, -0.0242,  0.1539,  0.0641,  0.0427, -0.0101, -0.0378,\n",
       "        -0.0225,  0.1030,  0.0277, -0.0708, -0.0067,  0.0402,  0.0110,  0.0257,\n",
       "        -0.0235,  0.0217,  0.0561,  0.0175, -0.0799,  0.0385,  0.0279, -0.0593,\n",
       "        -0.0823, -0.0612,  0.1048,  0.1771, -0.0283, -0.0709, -0.0557, -0.0512,\n",
       "        -0.0093, -0.0234,  0.1206, -0.0727,  0.0181,  0.0519, -0.0286, -0.0311,\n",
       "        -0.0764,  0.1362, -0.0010, -0.0664,  0.0623, -0.0651,  0.0161,  0.0735,\n",
       "        -0.0353, -0.0276,  0.0331,  0.0658,  0.0336, -0.0181,  0.1246, -0.0697,\n",
       "        -0.0045,  0.1517,  0.0102,  0.0103,  0.0486,  0.0412,  0.0255, -0.0257,\n",
       "         0.1179, -0.0610, -0.0237, -0.1096,  0.0281,  0.1092,  0.0103, -0.0517,\n",
       "        -0.0444, -0.0179, -0.0883,  0.0421, -0.0037, -0.0326, -0.0678, -0.0488,\n",
       "         0.0179, -0.1017, -0.0187, -0.0235,  0.0144,  0.0391,  0.1065,  0.1296,\n",
       "        -0.0096, -0.0594, -0.0571,  0.1469, -0.0865, -0.0257,  0.0275,  0.0243,\n",
       "         0.0451, -0.0243, -0.0307, -0.0088,  0.0274, -0.0630,  0.1179,  0.1540,\n",
       "         0.0448, -0.0672, -0.0574,  0.0691, -0.0698,  0.1260, -0.0718, -0.0169,\n",
       "        -0.0528, -0.0075, -0.0376,  0.0459,  0.0210,  0.0191, -0.0411, -0.0405,\n",
       "        -0.1075,  0.0615, -0.0672,  0.0413,  0.1195, -0.0500,  0.0114, -0.0009,\n",
       "         0.0155,  0.0063,  0.0998, -0.0667,  0.0482,  0.1320,  0.0108,  0.1832,\n",
       "        -0.0511, -0.0246, -0.0348,  0.0849, -0.0863, -0.0713, -0.0017,  0.0016,\n",
       "        -0.0124, -0.0952, -0.0937,  0.0217, -0.0226,  0.0385, -0.0299,  0.0478,\n",
       "        -0.0479, -0.0303,  0.0162, -0.0451, -0.0166, -0.0645,  0.1397, -0.0446,\n",
       "         0.0854, -0.0883, -0.0133,  0.0546, -0.0572, -0.0423, -0.0676, -0.0328,\n",
       "         0.0100,  0.0610, -0.0208, -0.0202, -0.0145,  0.0822,  0.0075, -0.0262,\n",
       "        -0.0625,  0.0914, -0.0392, -0.0577, -0.0717, -0.0347,  0.1291,  0.1139,\n",
       "        -0.0600, -0.0343,  0.1074, -0.0394,  0.0143,  0.0860, -0.0744,  0.0007,\n",
       "         0.0431, -0.0746, -0.0982, -0.0219, -0.0358, -0.0206, -0.0588, -0.0478,\n",
       "        -0.1144, -0.0063,  0.0167, -0.0764, -0.0366, -0.0091, -0.0735, -0.0699,\n",
       "         0.0434, -0.0854,  0.0628, -0.0429, -0.0181, -0.0742,  0.0164, -0.0785,\n",
       "        -0.0047, -0.0028, -0.0819,  0.0566, -0.0145,  0.0385,  0.1773, -0.0945,\n",
       "        -0.0023, -0.0370,  0.0642, -0.0929, -0.0671, -0.0649, -0.0340,  0.0219,\n",
       "         0.1202,  0.0715,  0.0036,  0.1203,  0.0212, -0.0362,  0.0531, -0.0638,\n",
       "        -0.0581,  0.0979,  0.0215,  0.0360,  0.0533, -0.0231, -0.0049, -0.0495,\n",
       "         0.0284, -0.0312,  0.0013,  0.0799, -0.0394,  0.1256,  0.0256,  0.1229,\n",
       "        -0.0768, -0.0849, -0.0211, -0.0265, -0.0249, -0.0177, -0.0762, -0.0300,\n",
       "         0.1326, -0.0536,  0.0525,  0.0655, -0.0528, -0.0194,  0.0544, -0.0878,\n",
       "        -0.0890, -0.0577,  0.0176, -0.0436, -0.0143, -0.0927, -0.0843, -0.0439,\n",
       "        -0.0933, -0.0650, -0.0650, -0.0419, -0.1098,  0.0247, -0.0105,  0.1306,\n",
       "         0.0270, -0.0373, -0.0626, -0.0516,  0.0957, -0.1038, -0.1022,  0.0454,\n",
       "        -0.1066, -0.0454,  0.0731,  0.0541, -0.0316,  0.0067,  0.0411, -0.0279])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['stages.3.blocks.1.attn.crpb_mlp.3.weight'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms 정의하기\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8,1), interpolation=transforms.InterpolationMode.LANCZOS),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.9, scale=(0.02, 0.33)),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "data_dir = '../../data/sports'\n",
    "batch_size = 960\n",
    "\n",
    "train_path = data_dir+'/train'\n",
    "valid_path = data_dir+'/valid'\n",
    "test_path = data_dir+'/test'\n",
    "\n",
    "# dataset load\n",
    "train_data = ImageFolder(train_path, transform=train_transform)\n",
    "valid_data = ImageFolder(valid_path, transform=test_transform)\n",
    "test_data = ImageFolder(test_path, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_norm = 1.0 # paper : 100 with G variants\n",
    "\n",
    "model.to(device)\n",
    "model_path = '../../models/swin2/model_w_simmim.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixup_fn = Mixup(mixup_alpha=.7, \n",
    "                cutmix_alpha=.7, \n",
    "                prob=.7, \n",
    "                switch_prob=0.5, \n",
    "                mode='batch',\n",
    "                label_smoothing=.1,\n",
    "                num_classes=100)\n",
    "\n",
    "epochs = 150\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: absolute_pos_embed\n",
      "1: embeddings.patch_embeddings.weight\n",
      "2: embeddings.patch_embeddings.bias\n",
      "3: embeddings.norm.weight\n",
      "4: embeddings.norm.bias\n",
      "5: stages.0.blocks.0.attn.t_scale\n",
      "6: stages.0.blocks.0.attn.crpb_mlp.0.weight\n",
      "7: stages.0.blocks.0.attn.crpb_mlp.0.bias\n",
      "8: stages.0.blocks.0.attn.crpb_mlp.3.weight\n",
      "9: stages.0.blocks.0.attn.qkv.weight\n",
      "10: stages.0.blocks.0.attn.qkv.bias\n",
      "11: stages.0.blocks.0.attn.proj.weight\n",
      "12: stages.0.blocks.0.attn.proj.bias\n",
      "13: stages.0.blocks.0.norm1.weight\n",
      "14: stages.0.blocks.0.norm1.bias\n",
      "15: stages.0.blocks.0.mlp.fc1.weight\n",
      "16: stages.0.blocks.0.mlp.fc1.bias\n",
      "17: stages.0.blocks.0.mlp.fc2.weight\n",
      "18: stages.0.blocks.0.mlp.fc2.bias\n",
      "19: stages.0.blocks.0.norm2.weight\n",
      "20: stages.0.blocks.0.norm2.bias\n",
      "21: stages.0.blocks.1.attn.t_scale\n",
      "22: stages.0.blocks.1.attn.crpb_mlp.0.weight\n",
      "23: stages.0.blocks.1.attn.crpb_mlp.0.bias\n",
      "24: stages.0.blocks.1.attn.crpb_mlp.3.weight\n",
      "25: stages.0.blocks.1.attn.qkv.weight\n",
      "26: stages.0.blocks.1.attn.qkv.bias\n",
      "27: stages.0.blocks.1.attn.proj.weight\n",
      "28: stages.0.blocks.1.attn.proj.bias\n",
      "29: stages.0.blocks.1.norm1.weight\n",
      "30: stages.0.blocks.1.norm1.bias\n",
      "31: stages.0.blocks.1.mlp.fc1.weight\n",
      "32: stages.0.blocks.1.mlp.fc1.bias\n",
      "33: stages.0.blocks.1.mlp.fc2.weight\n",
      "34: stages.0.blocks.1.mlp.fc2.bias\n",
      "35: stages.0.blocks.1.norm2.weight\n",
      "36: stages.0.blocks.1.norm2.bias\n",
      "37: stages.0.downsample.reduction.weight\n",
      "38: stages.0.downsample.norm.weight\n",
      "39: stages.0.downsample.norm.bias\n",
      "40: stages.1.blocks.0.attn.t_scale\n",
      "41: stages.1.blocks.0.attn.crpb_mlp.0.weight\n",
      "42: stages.1.blocks.0.attn.crpb_mlp.0.bias\n",
      "43: stages.1.blocks.0.attn.crpb_mlp.3.weight\n",
      "44: stages.1.blocks.0.attn.qkv.weight\n",
      "45: stages.1.blocks.0.attn.qkv.bias\n",
      "46: stages.1.blocks.0.attn.proj.weight\n",
      "47: stages.1.blocks.0.attn.proj.bias\n",
      "48: stages.1.blocks.0.norm1.weight\n",
      "49: stages.1.blocks.0.norm1.bias\n",
      "50: stages.1.blocks.0.mlp.fc1.weight\n",
      "51: stages.1.blocks.0.mlp.fc1.bias\n",
      "52: stages.1.blocks.0.mlp.fc2.weight\n",
      "53: stages.1.blocks.0.mlp.fc2.bias\n",
      "54: stages.1.blocks.0.norm2.weight\n",
      "55: stages.1.blocks.0.norm2.bias\n",
      "56: stages.1.blocks.1.attn.t_scale\n",
      "57: stages.1.blocks.1.attn.crpb_mlp.0.weight\n",
      "58: stages.1.blocks.1.attn.crpb_mlp.0.bias\n",
      "59: stages.1.blocks.1.attn.crpb_mlp.3.weight\n",
      "60: stages.1.blocks.1.attn.qkv.weight\n",
      "61: stages.1.blocks.1.attn.qkv.bias\n",
      "62: stages.1.blocks.1.attn.proj.weight\n",
      "63: stages.1.blocks.1.attn.proj.bias\n",
      "64: stages.1.blocks.1.norm1.weight\n",
      "65: stages.1.blocks.1.norm1.bias\n",
      "66: stages.1.blocks.1.mlp.fc1.weight\n",
      "67: stages.1.blocks.1.mlp.fc1.bias\n",
      "68: stages.1.blocks.1.mlp.fc2.weight\n",
      "69: stages.1.blocks.1.mlp.fc2.bias\n",
      "70: stages.1.blocks.1.norm2.weight\n",
      "71: stages.1.blocks.1.norm2.bias\n",
      "72: stages.1.downsample.reduction.weight\n",
      "73: stages.1.downsample.norm.weight\n",
      "74: stages.1.downsample.norm.bias\n",
      "75: stages.2.blocks.0.attn.t_scale\n",
      "76: stages.2.blocks.0.attn.crpb_mlp.0.weight\n",
      "77: stages.2.blocks.0.attn.crpb_mlp.0.bias\n",
      "78: stages.2.blocks.0.attn.crpb_mlp.3.weight\n",
      "79: stages.2.blocks.0.attn.qkv.weight\n",
      "80: stages.2.blocks.0.attn.qkv.bias\n",
      "81: stages.2.blocks.0.attn.proj.weight\n",
      "82: stages.2.blocks.0.attn.proj.bias\n",
      "83: stages.2.blocks.0.norm1.weight\n",
      "84: stages.2.blocks.0.norm1.bias\n",
      "85: stages.2.blocks.0.mlp.fc1.weight\n",
      "86: stages.2.blocks.0.mlp.fc1.bias\n",
      "87: stages.2.blocks.0.mlp.fc2.weight\n",
      "88: stages.2.blocks.0.mlp.fc2.bias\n",
      "89: stages.2.blocks.0.norm2.weight\n",
      "90: stages.2.blocks.0.norm2.bias\n",
      "91: stages.2.blocks.1.attn.t_scale\n",
      "92: stages.2.blocks.1.attn.crpb_mlp.0.weight\n",
      "93: stages.2.blocks.1.attn.crpb_mlp.0.bias\n",
      "94: stages.2.blocks.1.attn.crpb_mlp.3.weight\n",
      "95: stages.2.blocks.1.attn.qkv.weight\n",
      "96: stages.2.blocks.1.attn.qkv.bias\n",
      "97: stages.2.blocks.1.attn.proj.weight\n",
      "98: stages.2.blocks.1.attn.proj.bias\n",
      "99: stages.2.blocks.1.norm1.weight\n",
      "100: stages.2.blocks.1.norm1.bias\n",
      "101: stages.2.blocks.1.mlp.fc1.weight\n",
      "102: stages.2.blocks.1.mlp.fc1.bias\n",
      "103: stages.2.blocks.1.mlp.fc2.weight\n",
      "104: stages.2.blocks.1.mlp.fc2.bias\n",
      "105: stages.2.blocks.1.norm2.weight\n",
      "106: stages.2.blocks.1.norm2.bias\n",
      "107: stages.2.blocks.2.attn.t_scale\n",
      "108: stages.2.blocks.2.attn.crpb_mlp.0.weight\n",
      "109: stages.2.blocks.2.attn.crpb_mlp.0.bias\n",
      "110: stages.2.blocks.2.attn.crpb_mlp.3.weight\n",
      "111: stages.2.blocks.2.attn.qkv.weight\n",
      "112: stages.2.blocks.2.attn.qkv.bias\n",
      "113: stages.2.blocks.2.attn.proj.weight\n",
      "114: stages.2.blocks.2.attn.proj.bias\n",
      "115: stages.2.blocks.2.norm1.weight\n",
      "116: stages.2.blocks.2.norm1.bias\n",
      "117: stages.2.blocks.2.mlp.fc1.weight\n",
      "118: stages.2.blocks.2.mlp.fc1.bias\n",
      "119: stages.2.blocks.2.mlp.fc2.weight\n",
      "120: stages.2.blocks.2.mlp.fc2.bias\n",
      "121: stages.2.blocks.2.norm2.weight\n",
      "122: stages.2.blocks.2.norm2.bias\n",
      "123: stages.2.blocks.3.attn.t_scale\n",
      "124: stages.2.blocks.3.attn.crpb_mlp.0.weight\n",
      "125: stages.2.blocks.3.attn.crpb_mlp.0.bias\n",
      "126: stages.2.blocks.3.attn.crpb_mlp.3.weight\n",
      "127: stages.2.blocks.3.attn.qkv.weight\n",
      "128: stages.2.blocks.3.attn.qkv.bias\n",
      "129: stages.2.blocks.3.attn.proj.weight\n",
      "130: stages.2.blocks.3.attn.proj.bias\n",
      "131: stages.2.blocks.3.norm1.weight\n",
      "132: stages.2.blocks.3.norm1.bias\n",
      "133: stages.2.blocks.3.mlp.fc1.weight\n",
      "134: stages.2.blocks.3.mlp.fc1.bias\n",
      "135: stages.2.blocks.3.mlp.fc2.weight\n",
      "136: stages.2.blocks.3.mlp.fc2.bias\n",
      "137: stages.2.blocks.3.norm2.weight\n",
      "138: stages.2.blocks.3.norm2.bias\n",
      "139: stages.2.blocks.4.attn.t_scale\n",
      "140: stages.2.blocks.4.attn.crpb_mlp.0.weight\n",
      "141: stages.2.blocks.4.attn.crpb_mlp.0.bias\n",
      "142: stages.2.blocks.4.attn.crpb_mlp.3.weight\n",
      "143: stages.2.blocks.4.attn.qkv.weight\n",
      "144: stages.2.blocks.4.attn.qkv.bias\n",
      "145: stages.2.blocks.4.attn.proj.weight\n",
      "146: stages.2.blocks.4.attn.proj.bias\n",
      "147: stages.2.blocks.4.norm1.weight\n",
      "148: stages.2.blocks.4.norm1.bias\n",
      "149: stages.2.blocks.4.mlp.fc1.weight\n",
      "150: stages.2.blocks.4.mlp.fc1.bias\n",
      "151: stages.2.blocks.4.mlp.fc2.weight\n",
      "152: stages.2.blocks.4.mlp.fc2.bias\n",
      "153: stages.2.blocks.4.norm2.weight\n",
      "154: stages.2.blocks.4.norm2.bias\n",
      "155: stages.2.blocks.5.attn.t_scale\n",
      "156: stages.2.blocks.5.attn.crpb_mlp.0.weight\n",
      "157: stages.2.blocks.5.attn.crpb_mlp.0.bias\n",
      "158: stages.2.blocks.5.attn.crpb_mlp.3.weight\n",
      "159: stages.2.blocks.5.attn.qkv.weight\n",
      "160: stages.2.blocks.5.attn.qkv.bias\n",
      "161: stages.2.blocks.5.attn.proj.weight\n",
      "162: stages.2.blocks.5.attn.proj.bias\n",
      "163: stages.2.blocks.5.norm1.weight\n",
      "164: stages.2.blocks.5.norm1.bias\n",
      "165: stages.2.blocks.5.mlp.fc1.weight\n",
      "166: stages.2.blocks.5.mlp.fc1.bias\n",
      "167: stages.2.blocks.5.mlp.fc2.weight\n",
      "168: stages.2.blocks.5.mlp.fc2.bias\n",
      "169: stages.2.blocks.5.norm2.weight\n",
      "170: stages.2.blocks.5.norm2.bias\n",
      "171: stages.2.downsample.reduction.weight\n",
      "172: stages.2.downsample.norm.weight\n",
      "173: stages.2.downsample.norm.bias\n",
      "174: stages.3.blocks.0.attn.t_scale\n",
      "175: stages.3.blocks.0.attn.crpb_mlp.0.weight\n",
      "176: stages.3.blocks.0.attn.crpb_mlp.0.bias\n",
      "177: stages.3.blocks.0.attn.crpb_mlp.3.weight\n",
      "178: stages.3.blocks.0.attn.qkv.weight\n",
      "179: stages.3.blocks.0.attn.qkv.bias\n",
      "180: stages.3.blocks.0.attn.proj.weight\n",
      "181: stages.3.blocks.0.attn.proj.bias\n",
      "182: stages.3.blocks.0.norm1.weight\n",
      "183: stages.3.blocks.0.norm1.bias\n",
      "184: stages.3.blocks.0.mlp.fc1.weight\n",
      "185: stages.3.blocks.0.mlp.fc1.bias\n",
      "186: stages.3.blocks.0.mlp.fc2.weight\n",
      "187: stages.3.blocks.0.mlp.fc2.bias\n",
      "188: stages.3.blocks.0.norm2.weight\n",
      "189: stages.3.blocks.0.norm2.bias\n",
      "190: stages.3.blocks.1.attn.t_scale\n",
      "191: stages.3.blocks.1.attn.crpb_mlp.0.weight\n",
      "192: stages.3.blocks.1.attn.crpb_mlp.0.bias\n",
      "193: stages.3.blocks.1.attn.crpb_mlp.3.weight\n",
      "194: stages.3.blocks.1.attn.qkv.weight\n",
      "195: stages.3.blocks.1.attn.qkv.bias\n",
      "196: stages.3.blocks.1.attn.proj.weight\n",
      "197: stages.3.blocks.1.attn.proj.bias\n",
      "198: stages.3.blocks.1.norm1.weight\n",
      "199: stages.3.blocks.1.norm1.bias\n",
      "200: stages.3.blocks.1.mlp.fc1.weight\n",
      "201: stages.3.blocks.1.mlp.fc1.bias\n",
      "202: stages.3.blocks.1.mlp.fc2.weight\n",
      "203: stages.3.blocks.1.mlp.fc2.bias\n",
      "204: stages.3.blocks.1.norm2.weight\n",
      "205: stages.3.blocks.1.norm2.bias\n",
      "206: layernorm.weight\n",
      "207: layernorm.bias\n",
      "208: classifier.weight\n",
      "209: classifier.bias\n"
     ]
    }
   ],
   "source": [
    "layer_names = []\n",
    "for i, (name, params) in enumerate(model.named_parameters()):\n",
    "    lr = base_lr\n",
    "    print(f'{i}: {name}')\n",
    "    layer_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classifier.bias',\n",
       " 'classifier.weight',\n",
       " 'layernorm.bias',\n",
       " 'layernorm.weight',\n",
       " 'stages.3.blocks.1.norm2.bias']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_names.reverse()\n",
    "layer_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: classifier.bias's lr=0.0014\n",
      "1: classifier.weight's lr=0.0014\n",
      "2: layernorm.bias's lr=0.001218\n",
      "3: layernorm.weight's lr=0.001218\n",
      "4: stages.3.blocks.1.norm2.bias's lr=0.0010596599999999998\n",
      "5: stages.3.blocks.1.norm2.weight's lr=0.0010596599999999998\n",
      "6: stages.3.blocks.1.mlp.fc2.bias's lr=0.0010596599999999998\n",
      "7: stages.3.blocks.1.mlp.fc2.weight's lr=0.0010596599999999998\n",
      "8: stages.3.blocks.1.mlp.fc1.bias's lr=0.0010596599999999998\n",
      "9: stages.3.blocks.1.mlp.fc1.weight's lr=0.0010596599999999998\n",
      "10: stages.3.blocks.1.norm1.bias's lr=0.0010596599999999998\n",
      "11: stages.3.blocks.1.norm1.weight's lr=0.0010596599999999998\n",
      "12: stages.3.blocks.1.attn.proj.bias's lr=0.0010596599999999998\n",
      "13: stages.3.blocks.1.attn.proj.weight's lr=0.0010596599999999998\n",
      "14: stages.3.blocks.1.attn.qkv.bias's lr=0.0010596599999999998\n",
      "15: stages.3.blocks.1.attn.qkv.weight's lr=0.0010596599999999998\n",
      "16: stages.3.blocks.1.attn.crpb_mlp.3.weight's lr=0.0010596599999999998\n",
      "17: stages.3.blocks.1.attn.crpb_mlp.0.bias's lr=0.0010596599999999998\n",
      "18: stages.3.blocks.1.attn.crpb_mlp.0.weight's lr=0.0010596599999999998\n",
      "19: stages.3.blocks.1.attn.t_scale's lr=0.0010596599999999998\n",
      "20: stages.3.blocks.0.norm2.bias's lr=0.0010596599999999998\n",
      "21: stages.3.blocks.0.norm2.weight's lr=0.0010596599999999998\n",
      "22: stages.3.blocks.0.mlp.fc2.bias's lr=0.0010596599999999998\n",
      "23: stages.3.blocks.0.mlp.fc2.weight's lr=0.0010596599999999998\n",
      "24: stages.3.blocks.0.mlp.fc1.bias's lr=0.0010596599999999998\n",
      "25: stages.3.blocks.0.mlp.fc1.weight's lr=0.0010596599999999998\n",
      "26: stages.3.blocks.0.norm1.bias's lr=0.0010596599999999998\n",
      "27: stages.3.blocks.0.norm1.weight's lr=0.0010596599999999998\n",
      "28: stages.3.blocks.0.attn.proj.bias's lr=0.0010596599999999998\n",
      "29: stages.3.blocks.0.attn.proj.weight's lr=0.0010596599999999998\n",
      "30: stages.3.blocks.0.attn.qkv.bias's lr=0.0010596599999999998\n",
      "31: stages.3.blocks.0.attn.qkv.weight's lr=0.0010596599999999998\n",
      "32: stages.3.blocks.0.attn.crpb_mlp.3.weight's lr=0.0010596599999999998\n",
      "33: stages.3.blocks.0.attn.crpb_mlp.0.bias's lr=0.0010596599999999998\n",
      "34: stages.3.blocks.0.attn.crpb_mlp.0.weight's lr=0.0010596599999999998\n",
      "35: stages.3.blocks.0.attn.t_scale's lr=0.0010596599999999998\n",
      "36: stages.2.downsample.norm.bias's lr=0.0010596599999999998\n",
      "37: stages.2.downsample.norm.weight's lr=0.0010596599999999998\n",
      "38: stages.2.downsample.reduction.weight's lr=0.0010596599999999998\n",
      "39: stages.2.blocks.5.norm2.bias's lr=0.0010596599999999998\n",
      "40: stages.2.blocks.5.norm2.weight's lr=0.0010596599999999998\n",
      "41: stages.2.blocks.5.mlp.fc2.bias's lr=0.0010596599999999998\n",
      "42: stages.2.blocks.5.mlp.fc2.weight's lr=0.0010596599999999998\n",
      "43: stages.2.blocks.5.mlp.fc1.bias's lr=0.0010596599999999998\n",
      "44: stages.2.blocks.5.mlp.fc1.weight's lr=0.0010596599999999998\n",
      "45: stages.2.blocks.5.norm1.bias's lr=0.0010596599999999998\n",
      "46: stages.2.blocks.5.norm1.weight's lr=0.0010596599999999998\n",
      "47: stages.2.blocks.5.attn.proj.bias's lr=0.0010596599999999998\n",
      "48: stages.2.blocks.5.attn.proj.weight's lr=0.0010596599999999998\n",
      "49: stages.2.blocks.5.attn.qkv.bias's lr=0.0010596599999999998\n",
      "50: stages.2.blocks.5.attn.qkv.weight's lr=0.0010596599999999998\n",
      "51: stages.2.blocks.5.attn.crpb_mlp.3.weight's lr=0.0010596599999999998\n",
      "52: stages.2.blocks.5.attn.crpb_mlp.0.bias's lr=0.0010596599999999998\n",
      "53: stages.2.blocks.5.attn.crpb_mlp.0.weight's lr=0.0010596599999999998\n",
      "54: stages.2.blocks.5.attn.t_scale's lr=0.0010596599999999998\n",
      "55: stages.2.blocks.4.norm2.bias's lr=0.0010596599999999998\n",
      "56: stages.2.blocks.4.norm2.weight's lr=0.0010596599999999998\n",
      "57: stages.2.blocks.4.mlp.fc2.bias's lr=0.0010596599999999998\n",
      "58: stages.2.blocks.4.mlp.fc2.weight's lr=0.0010596599999999998\n",
      "59: stages.2.blocks.4.mlp.fc1.bias's lr=0.0010596599999999998\n",
      "60: stages.2.blocks.4.mlp.fc1.weight's lr=0.0010596599999999998\n",
      "61: stages.2.blocks.4.norm1.bias's lr=0.0010596599999999998\n",
      "62: stages.2.blocks.4.norm1.weight's lr=0.0010596599999999998\n",
      "63: stages.2.blocks.4.attn.proj.bias's lr=0.0010596599999999998\n",
      "64: stages.2.blocks.4.attn.proj.weight's lr=0.0010596599999999998\n",
      "65: stages.2.blocks.4.attn.qkv.bias's lr=0.0010596599999999998\n",
      "66: stages.2.blocks.4.attn.qkv.weight's lr=0.0010596599999999998\n",
      "67: stages.2.blocks.4.attn.crpb_mlp.3.weight's lr=0.0010596599999999998\n",
      "68: stages.2.blocks.4.attn.crpb_mlp.0.bias's lr=0.0010596599999999998\n",
      "69: stages.2.blocks.4.attn.crpb_mlp.0.weight's lr=0.0010596599999999998\n",
      "70: stages.2.blocks.4.attn.t_scale's lr=0.0010596599999999998\n",
      "71: stages.2.blocks.3.norm2.bias's lr=0.0010596599999999998\n",
      "72: stages.2.blocks.3.norm2.weight's lr=0.0010596599999999998\n",
      "73: stages.2.blocks.3.mlp.fc2.bias's lr=0.0010596599999999998\n",
      "74: stages.2.blocks.3.mlp.fc2.weight's lr=0.0010596599999999998\n",
      "75: stages.2.blocks.3.mlp.fc1.bias's lr=0.0010596599999999998\n",
      "76: stages.2.blocks.3.mlp.fc1.weight's lr=0.0010596599999999998\n",
      "77: stages.2.blocks.3.norm1.bias's lr=0.0010596599999999998\n",
      "78: stages.2.blocks.3.norm1.weight's lr=0.0010596599999999998\n",
      "79: stages.2.blocks.3.attn.proj.bias's lr=0.0010596599999999998\n",
      "80: stages.2.blocks.3.attn.proj.weight's lr=0.0010596599999999998\n",
      "81: stages.2.blocks.3.attn.qkv.bias's lr=0.0010596599999999998\n",
      "82: stages.2.blocks.3.attn.qkv.weight's lr=0.0010596599999999998\n",
      "83: stages.2.blocks.3.attn.crpb_mlp.3.weight's lr=0.0010596599999999998\n",
      "84: stages.2.blocks.3.attn.crpb_mlp.0.bias's lr=0.0010596599999999998\n",
      "85: stages.2.blocks.3.attn.crpb_mlp.0.weight's lr=0.0010596599999999998\n",
      "86: stages.2.blocks.3.attn.t_scale's lr=0.0010596599999999998\n",
      "87: stages.2.blocks.2.norm2.bias's lr=0.0010596599999999998\n",
      "88: stages.2.blocks.2.norm2.weight's lr=0.0010596599999999998\n",
      "89: stages.2.blocks.2.mlp.fc2.bias's lr=0.0010596599999999998\n",
      "90: stages.2.blocks.2.mlp.fc2.weight's lr=0.0010596599999999998\n",
      "91: stages.2.blocks.2.mlp.fc1.bias's lr=0.0010596599999999998\n",
      "92: stages.2.blocks.2.mlp.fc1.weight's lr=0.0010596599999999998\n",
      "93: stages.2.blocks.2.norm1.bias's lr=0.0010596599999999998\n",
      "94: stages.2.blocks.2.norm1.weight's lr=0.0010596599999999998\n",
      "95: stages.2.blocks.2.attn.proj.bias's lr=0.0010596599999999998\n",
      "96: stages.2.blocks.2.attn.proj.weight's lr=0.0010596599999999998\n",
      "97: stages.2.blocks.2.attn.qkv.bias's lr=0.0010596599999999998\n",
      "98: stages.2.blocks.2.attn.qkv.weight's lr=0.0010596599999999998\n",
      "99: stages.2.blocks.2.attn.crpb_mlp.3.weight's lr=0.0010596599999999998\n",
      "100: stages.2.blocks.2.attn.crpb_mlp.0.bias's lr=0.0010596599999999998\n",
      "101: stages.2.blocks.2.attn.crpb_mlp.0.weight's lr=0.0010596599999999998\n",
      "102: stages.2.blocks.2.attn.t_scale's lr=0.0010596599999999998\n",
      "103: stages.2.blocks.1.norm2.bias's lr=0.0010596599999999998\n",
      "104: stages.2.blocks.1.norm2.weight's lr=0.0010596599999999998\n",
      "105: stages.2.blocks.1.mlp.fc2.bias's lr=0.0010596599999999998\n",
      "106: stages.2.blocks.1.mlp.fc2.weight's lr=0.0010596599999999998\n",
      "107: stages.2.blocks.1.mlp.fc1.bias's lr=0.0010596599999999998\n",
      "108: stages.2.blocks.1.mlp.fc1.weight's lr=0.0010596599999999998\n",
      "109: stages.2.blocks.1.norm1.bias's lr=0.0010596599999999998\n",
      "110: stages.2.blocks.1.norm1.weight's lr=0.0010596599999999998\n",
      "111: stages.2.blocks.1.attn.proj.bias's lr=0.0010596599999999998\n",
      "112: stages.2.blocks.1.attn.proj.weight's lr=0.0010596599999999998\n",
      "113: stages.2.blocks.1.attn.qkv.bias's lr=0.0010596599999999998\n",
      "114: stages.2.blocks.1.attn.qkv.weight's lr=0.0010596599999999998\n",
      "115: stages.2.blocks.1.attn.crpb_mlp.3.weight's lr=0.0010596599999999998\n",
      "116: stages.2.blocks.1.attn.crpb_mlp.0.bias's lr=0.0010596599999999998\n",
      "117: stages.2.blocks.1.attn.crpb_mlp.0.weight's lr=0.0010596599999999998\n",
      "118: stages.2.blocks.1.attn.t_scale's lr=0.0010596599999999998\n",
      "119: stages.2.blocks.0.norm2.bias's lr=0.0010596599999999998\n",
      "120: stages.2.blocks.0.norm2.weight's lr=0.0010596599999999998\n",
      "121: stages.2.blocks.0.mlp.fc2.bias's lr=0.0010596599999999998\n",
      "122: stages.2.blocks.0.mlp.fc2.weight's lr=0.0010596599999999998\n",
      "123: stages.2.blocks.0.mlp.fc1.bias's lr=0.0010596599999999998\n",
      "124: stages.2.blocks.0.mlp.fc1.weight's lr=0.0010596599999999998\n",
      "125: stages.2.blocks.0.norm1.bias's lr=0.0010596599999999998\n",
      "126: stages.2.blocks.0.norm1.weight's lr=0.0010596599999999998\n",
      "127: stages.2.blocks.0.attn.proj.bias's lr=0.0010596599999999998\n",
      "128: stages.2.blocks.0.attn.proj.weight's lr=0.0010596599999999998\n",
      "129: stages.2.blocks.0.attn.qkv.bias's lr=0.0010596599999999998\n",
      "130: stages.2.blocks.0.attn.qkv.weight's lr=0.0010596599999999998\n",
      "131: stages.2.blocks.0.attn.crpb_mlp.3.weight's lr=0.0010596599999999998\n",
      "132: stages.2.blocks.0.attn.crpb_mlp.0.bias's lr=0.0010596599999999998\n",
      "133: stages.2.blocks.0.attn.crpb_mlp.0.weight's lr=0.0010596599999999998\n",
      "134: stages.2.blocks.0.attn.t_scale's lr=0.0010596599999999998\n",
      "135: stages.1.downsample.norm.bias's lr=0.0010596599999999998\n",
      "136: stages.1.downsample.norm.weight's lr=0.0010596599999999998\n",
      "137: stages.1.downsample.reduction.weight's lr=0.0010596599999999998\n",
      "138: stages.1.blocks.1.norm2.bias's lr=0.0010596599999999998\n",
      "139: stages.1.blocks.1.norm2.weight's lr=0.0010596599999999998\n",
      "140: stages.1.blocks.1.mlp.fc2.bias's lr=0.0010596599999999998\n",
      "141: stages.1.blocks.1.mlp.fc2.weight's lr=0.0010596599999999998\n",
      "142: stages.1.blocks.1.mlp.fc1.bias's lr=0.0010596599999999998\n",
      "143: stages.1.blocks.1.mlp.fc1.weight's lr=0.0010596599999999998\n",
      "144: stages.1.blocks.1.norm1.bias's lr=0.0010596599999999998\n",
      "145: stages.1.blocks.1.norm1.weight's lr=0.0010596599999999998\n",
      "146: stages.1.blocks.1.attn.proj.bias's lr=0.0010596599999999998\n",
      "147: stages.1.blocks.1.attn.proj.weight's lr=0.0010596599999999998\n",
      "148: stages.1.blocks.1.attn.qkv.bias's lr=0.0010596599999999998\n",
      "149: stages.1.blocks.1.attn.qkv.weight's lr=0.0010596599999999998\n",
      "150: stages.1.blocks.1.attn.crpb_mlp.3.weight's lr=0.0010596599999999998\n",
      "151: stages.1.blocks.1.attn.crpb_mlp.0.bias's lr=0.0010596599999999998\n",
      "152: stages.1.blocks.1.attn.crpb_mlp.0.weight's lr=0.0010596599999999998\n",
      "153: stages.1.blocks.1.attn.t_scale's lr=0.0010596599999999998\n",
      "154: stages.1.blocks.0.norm2.bias's lr=0.0010596599999999998\n",
      "155: stages.1.blocks.0.norm2.weight's lr=0.0010596599999999998\n",
      "156: stages.1.blocks.0.mlp.fc2.bias's lr=0.0010596599999999998\n",
      "157: stages.1.blocks.0.mlp.fc2.weight's lr=0.0010596599999999998\n",
      "158: stages.1.blocks.0.mlp.fc1.bias's lr=0.0010596599999999998\n",
      "159: stages.1.blocks.0.mlp.fc1.weight's lr=0.0010596599999999998\n",
      "160: stages.1.blocks.0.norm1.bias's lr=0.0010596599999999998\n",
      "161: stages.1.blocks.0.norm1.weight's lr=0.0010596599999999998\n",
      "162: stages.1.blocks.0.attn.proj.bias's lr=0.0010596599999999998\n",
      "163: stages.1.blocks.0.attn.proj.weight's lr=0.0010596599999999998\n",
      "164: stages.1.blocks.0.attn.qkv.bias's lr=0.0010596599999999998\n",
      "165: stages.1.blocks.0.attn.qkv.weight's lr=0.0010596599999999998\n",
      "166: stages.1.blocks.0.attn.crpb_mlp.3.weight's lr=0.0010596599999999998\n",
      "167: stages.1.blocks.0.attn.crpb_mlp.0.bias's lr=0.0010596599999999998\n",
      "168: stages.1.blocks.0.attn.crpb_mlp.0.weight's lr=0.0010596599999999998\n",
      "169: stages.1.blocks.0.attn.t_scale's lr=0.0010596599999999998\n",
      "170: stages.0.downsample.norm.bias's lr=0.0010596599999999998\n",
      "171: stages.0.downsample.norm.weight's lr=0.0010596599999999998\n",
      "172: stages.0.downsample.reduction.weight's lr=0.0010596599999999998\n",
      "173: stages.0.blocks.1.norm2.bias's lr=0.0010596599999999998\n",
      "174: stages.0.blocks.1.norm2.weight's lr=0.0010596599999999998\n",
      "175: stages.0.blocks.1.mlp.fc2.bias's lr=0.0010596599999999998\n",
      "176: stages.0.blocks.1.mlp.fc2.weight's lr=0.0010596599999999998\n",
      "177: stages.0.blocks.1.mlp.fc1.bias's lr=0.0010596599999999998\n",
      "178: stages.0.blocks.1.mlp.fc1.weight's lr=0.0010596599999999998\n",
      "179: stages.0.blocks.1.norm1.bias's lr=0.0010596599999999998\n",
      "180: stages.0.blocks.1.norm1.weight's lr=0.0010596599999999998\n",
      "181: stages.0.blocks.1.attn.proj.bias's lr=0.0010596599999999998\n",
      "182: stages.0.blocks.1.attn.proj.weight's lr=0.0010596599999999998\n",
      "183: stages.0.blocks.1.attn.qkv.bias's lr=0.0010596599999999998\n",
      "184: stages.0.blocks.1.attn.qkv.weight's lr=0.0010596599999999998\n",
      "185: stages.0.blocks.1.attn.crpb_mlp.3.weight's lr=0.0010596599999999998\n",
      "186: stages.0.blocks.1.attn.crpb_mlp.0.bias's lr=0.0010596599999999998\n",
      "187: stages.0.blocks.1.attn.crpb_mlp.0.weight's lr=0.0010596599999999998\n",
      "188: stages.0.blocks.1.attn.t_scale's lr=0.0010596599999999998\n",
      "189: stages.0.blocks.0.norm2.bias's lr=0.0010596599999999998\n",
      "190: stages.0.blocks.0.norm2.weight's lr=0.0010596599999999998\n",
      "191: stages.0.blocks.0.mlp.fc2.bias's lr=0.0010596599999999998\n",
      "192: stages.0.blocks.0.mlp.fc2.weight's lr=0.0010596599999999998\n",
      "193: stages.0.blocks.0.mlp.fc1.bias's lr=0.0010596599999999998\n",
      "194: stages.0.blocks.0.mlp.fc1.weight's lr=0.0010596599999999998\n",
      "195: stages.0.blocks.0.norm1.bias's lr=0.0010596599999999998\n",
      "196: stages.0.blocks.0.norm1.weight's lr=0.0010596599999999998\n",
      "197: stages.0.blocks.0.attn.proj.bias's lr=0.0010596599999999998\n",
      "198: stages.0.blocks.0.attn.proj.weight's lr=0.0010596599999999998\n",
      "199: stages.0.blocks.0.attn.qkv.bias's lr=0.0010596599999999998\n",
      "200: stages.0.blocks.0.attn.qkv.weight's lr=0.0010596599999999998\n",
      "201: stages.0.blocks.0.attn.crpb_mlp.3.weight's lr=0.0010596599999999998\n",
      "202: stages.0.blocks.0.attn.crpb_mlp.0.bias's lr=0.0010596599999999998\n",
      "203: stages.0.blocks.0.attn.crpb_mlp.0.weight's lr=0.0010596599999999998\n",
      "204: stages.0.blocks.0.attn.t_scale's lr=0.0010596599999999998\n",
      "205: embeddings.norm.bias's lr=0.0009219041999999998\n",
      "206: embeddings.norm.weight's lr=0.0009219041999999998\n",
      "207: embeddings.patch_embeddings.bias's lr=0.0009219041999999998\n",
      "208: embeddings.patch_embeddings.weight's lr=0.0009219041999999998\n",
      "209: absolute_pos_embed's lr=0.0008020566539999999\n"
     ]
    }
   ],
   "source": [
    "lr      = 1.4e-3      # paper : 1.4e-3\n",
    "lr_mult = 0.87  # paper : 0.87\n",
    "weight_decay = 0.01 # paper : 0.1\n",
    "\n",
    "param_groups = []\n",
    "prev_group_name = layer_names[0].split('.')[0]\n",
    "\n",
    "for idx, name in enumerate(layer_names):\n",
    "    \n",
    "    cur_group_name = name.split('.')[0]\n",
    "    \n",
    "    if cur_group_name != prev_group_name:\n",
    "        lr *= lr_mult\n",
    "    prev_group_name = cur_group_name\n",
    "    \n",
    "    print(f\"{idx}: {name}'s lr={lr}\")\n",
    "    \n",
    "    param_groups += [{'params': [ p for n, p in model.named_parameters() if n == name and p.requires_grad],\n",
    "                      'lr' : lr,\n",
    "                      'weight_decay': weight_decay}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 레이어의 이름 추출\n",
    "# layer_names = []\n",
    "# for i, (name, params) in enumerate(model.named_parameters()):\n",
    "#     lr = base_lr\n",
    "#     print(f'{i}: {name}')\n",
    "#     layer_names.append(name)\n",
    "\n",
    "# # 뒷 레이어부터 시작하도록 뒤집기    \n",
    "# layer_names.reverse()\n",
    "\n",
    "# # 하이퍼 파라미터 정의\n",
    "# lr      = 1.4e-3      # paper : 1.4e-3\n",
    "# lr_mult = 0.87  # paper : 0.87\n",
    "# weight_decay = 0.01 # paper : 0.1\n",
    "\n",
    "# param_groups = []\n",
    "# prev_group_name = layer_names[0].split('.')[0] # 그룹명 초기화\n",
    "\n",
    "# for idx, name in enumerate(layer_names):    \n",
    "#     cur_group_name = name.split('.')[0]    \n",
    "#     if cur_group_name != prev_group_name: # 동일한 그룹에 속하면 동일한 학습율\n",
    "#         lr *= lr_mult\n",
    "#     prev_group_name = cur_group_name    \n",
    "    \n",
    "#     param_groups += [{'params': [ p for n, p in model.named_parameters() if n == name and p.requires_grad],\n",
    "#                       'lr' : lr,\n",
    "#                       'weight_decay': weight_decay}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(param_groups)\n",
    "warmup_steps = int(len(train_loader)*(epochs)*0.1)\n",
    "train_steps = len(train_loader)*(epochs)\n",
    "scheduler = transformers.get_cosine_schedule_with_warmup(optimizer, \n",
    "                                                        num_warmup_steps=warmup_steps, \n",
    "                                                        num_training_steps=train_steps,\n",
    "                                                        num_cycles=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 15/15 [00:50<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.640709622701009, Val Loss: 4.525732517242432, LR: 9.333333333333333e-05, Duration: 51.90 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 15/15 [00:50<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.465182367960612, Val Loss: 4.235929489135742, LR: 0.00018666666666666666, Duration: 51.52 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [00:50<00:00,  3.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.285793622334798, Val Loss: 3.9897332191467285, LR: 0.00028000000000000003, Duration: 51.46 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [00:50<00:00,  3.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.223414929707845, Val Loss: 3.925478458404541, LR: 0.0003733333333333333, Duration: 51.77 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [00:50<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.131762758890788, Val Loss: 3.800685167312622, LR: 0.00046666666666666666, Duration: 51.54 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 15/15 [00:50<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.08875257174174, Val Loss: 3.5996603965759277, LR: 0.0005600000000000001, Duration: 51.54 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 15/15 [00:50<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.03374293645223, Val Loss: 3.5427401065826416, LR: 0.0006533333333333333, Duration: 51.53 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [00:50<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.928725337982178, Val Loss: 3.4848854541778564, LR: 0.0007466666666666666, Duration: 51.51 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 15/15 [00:50<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.04330514272054, Val Loss: 3.4428153038024902, LR: 0.0008399999999999999, Duration: 51.55 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 15/15 [00:50<00:00,  3.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.853068971633911, Val Loss: 3.192392587661743, LR: 0.0009333333333333333, Duration: 51.36 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 15/15 [00:50<00:00,  3.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.940928411483765, Val Loss: 3.074150800704956, LR: 0.0010266666666666666, Duration: 51.44 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 15/15 [00:50<00:00,  3.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.586457697550456, Val Loss: 2.8808090686798096, LR: 0.0011200000000000001, Duration: 51.75 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 15/15 [00:50<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.808212073644002, Val Loss: 2.9665651321411133, LR: 0.0012133333333333334, Duration: 51.29 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 15/15 [00:50<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.603448422749837, Val Loss: 2.853593349456787, LR: 0.0013066666666666667, Duration: 51.53 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 15/15 [00:50<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7452565828959146, Val Loss: 2.857118844985962, LR: 0.0014, Duration: 51.37 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 15/15 [00:50<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7859806219736734, Val Loss: 2.7394979000091553, LR: 0.001399810468825623, Duration: 51.57 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 15/15 [00:50<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6915764172871905, Val Loss: 2.658094882965088, LR: 0.0013992419779369672, Duration: 51.57 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 15/15 [00:50<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5827109018961587, Val Loss: 2.610522508621216, LR: 0.001398294835181877, Duration: 51.57 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 15/15 [00:50<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.3371769269307454, Val Loss: 2.4410219192504883, LR: 0.001396969553454863, Duration: 51.61 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 15/15 [00:50<00:00,  3.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4988106727600097, Val Loss: 2.4959654808044434, LR: 0.0013952668504193602, Duration: 51.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 15/15 [00:50<00:00,  3.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4955929120381675, Val Loss: 2.3629655838012695, LR: 0.0013931876481190993, Duration: 51.46 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 15/15 [00:50<00:00,  3.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5100342591603595, Val Loss: 2.165684461593628, LR: 0.0013907330724788056, Duration: 51.31 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 15/15 [00:50<00:00,  3.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.465053017934163, Val Loss: 2.37201189994812, LR: 0.0013879044526944892, Duration: 51.22 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 15/15 [00:50<00:00,  3.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5234920978546143, Val Loss: 2.2359769344329834, LR: 0.001384703320513664, Duration: 51.14 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 15/15 [00:50<00:00,  3.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2505664507548016, Val Loss: 2.0291783809661865, LR: 0.0013811314094058767, Duration: 51.69 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 15/15 [00:50<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.34499306678772, Val Loss: 2.0712969303131104, LR: 0.0013771906536240047, Duration: 51.25 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27:   7%|▋         | 1/15 [00:03<00:49,  3.57s/it]"
     ]
    }
   ],
   "source": [
    "training_time = 0\n",
    "losses = []\n",
    "val_losses = []\n",
    "lrs = []\n",
    "best_loss = float('inf')\n",
    "\n",
    "# GradScaler 초기화\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "text = f\"Epoch 당 평균 소요시간 : {training_time / epochs:.2f}초\"      \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.816000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.829698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.816000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.799969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.816000\n",
       "1  Precision  0.829698\n",
       "2     Recall  0.816000\n",
       "3   F1 Score  0.799969"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6922353823979694, Val Loss: 0.9384442567825317, LR: 0.0002913307727590911, Duration: 49.89 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 15/15 [00:48<00:00,  3.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.657900913556417, Val Loss: 0.9159315824508667, LR: 0.00028081442660546124, Duration: 49.68 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [00:48<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7689472595850626, Val Loss: 0.950180172920227, LR: 0.0002704167733064941, Duration: 49.88 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.521797521909078, Val Loss: 0.9163442254066467, LR: 0.0002601434433748771, Duration: 49.97 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [00:48<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.568425250053406, Val Loss: 0.8977269530296326, LR: 0.0002500000000000001, Duration: 50.11 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7730035543441773, Val Loss: 0.8929747343063354, LR: 0.00023999193603539232, Duration: 50.21 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7291774272918703, Val Loss: 0.9171628355979919, LR: 0.00023012467102424372, Duration: 49.96 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [00:49<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7100916067759195, Val Loss: 0.9216888546943665, LR: 0.00022040354826462666, Duration: 50.11 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.713088115056356, Val Loss: 0.8970794081687927, LR: 0.00021083383191600674, Duration: 49.97 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.761340061823527, Val Loss: 0.904382586479187, LR: 0.00020142070414860702, Duration: 49.98 sec\n",
      "Epoch 당 평균 소요시간 : 55.61초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.804000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.829040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.804000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.793341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.804000\n",
       "1  Precision  0.829040\n",
       "2     Recall  0.804000\n",
       "3   F1 Score  0.793341"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "text = f\"Epoch 당 평균 소요시간 : {training_time / epochs:.2f}초\"      \n",
    "print(text)\n",
    "\n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4435115416844684, Val Loss: 0.8637356162071228, LR: 0.00019216926233717085, Duration: 50.26 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 15/15 [00:48<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6883505662282308, Val Loss: 0.8625206351280212, LR: 0.0001830845163006448, Duration: 50.11 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [00:49<00:00,  3.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4792883078257244, Val Loss: 0.8568503260612488, LR: 0.00017417138558927244, Duration: 50.58 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [00:49<00:00,  3.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7088448286056517, Val Loss: 0.8607507348060608, LR: 0.00016543469682057105, Duration: 50.38 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [00:49<00:00,  3.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.614908711115519, Val Loss: 0.8643636703491211, LR: 0.00015687918106563326, Duration: 50.34 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 15/15 [00:48<00:00,  3.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.411665678024292, Val Loss: 0.8612100481987, LR: 0.00014850947128716913, Duration: 49.84 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 15/15 [00:49<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.604859987894694, Val Loss: 0.8613155484199524, LR: 0.00014033009983067452, Duration: 50.01 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.504119610786438, Val Loss: 0.8607224822044373, LR: 0.00013234549597008571, Duration: 50.01 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7026391585667926, Val Loss: 0.8616685271263123, LR: 0.0001245599835092504, Duration: 49.96 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 15/15 [00:49<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2587844928105674, Val Loss: 0.831054151058197, LR: 0.00011697777844051105, Duration: 50.40 sec - model saved!\n",
      "Epoch 당 평균 소요시간 : 60.63초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.836000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.851548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.836000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.826320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.836000\n",
       "1  Precision  0.851548\n",
       "2     Recall  0.836000\n",
       "3   F1 Score  0.826320"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "text = f\"Epoch 당 평균 소요시간 : {training_time / epochs:.2f}초\"      \n",
    "print(text)\n",
    "\n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.585992956161499, Val Loss: 0.8371878862380981, LR: 0.0001096029866616704, Duration: 49.97 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 15/15 [00:49<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2336838006973267, Val Loss: 0.8162788152694702, LR: 0.00010243960175257604, Duration: 50.28 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [00:49<00:00,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.600951560338338, Val Loss: 0.8022180199623108, LR: 9.549150281252633e-05, Duration: 50.92 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7257570187250773, Val Loss: 0.8217611908912659, LR: 8.876245235966885e-05, Duration: 49.95 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.461031977335612, Val Loss: 0.8239462375640869, LR: 8.225609429353187e-05, Duration: 49.94 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 15/15 [00:48<00:00,  3.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.575312360127767, Val Loss: 0.8151116371154785, LR: 7.597595192178702e-05, Duration: 49.85 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 15/15 [00:49<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5168095588684083, Val Loss: 0.8133642077445984, LR: 6.992542605231739e-05, Duration: 50.07 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.538121747970581, Val Loss: 0.8043501377105713, LR: 6.410779315161885e-05, Duration: 49.98 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 15/15 [00:49<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4347947597503663, Val Loss: 0.8149065375328064, LR: 5.852620357053651e-05, Duration: 50.17 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.482781473795573, Val Loss: 0.7992389798164368, LR: 5.318367983829392e-05, Duration: 50.22 sec - model saved!\n",
      "Epoch 당 평균 소요시간 : 65.64초\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.832000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.854385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.832000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.824710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.832000\n",
       "1  Precision  0.854385\n",
       "2     Recall  0.832000\n",
       "3   F1 Score  0.824710"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "text = f\"Epoch 당 평균 소요시간 : {training_time / epochs:.2f}초\"      \n",
    "print(text)\n",
    "\n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.156569306055705, Val Loss: 0.8060244917869568, LR: 4.8083115025739754e-05, Duration: 49.93 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.29921023050944, Val Loss: 0.7820650339126587, LR: 4.322727117869951e-05, Duration: 50.15 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.451512368520101, Val Loss: 0.79397052526474, LR: 3.861877782227885e-05, Duration: 49.97 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [00:49<00:00,  3.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.636488103866577, Val Loss: 0.7902220487594604, LR: 3.426013053692878e-05, Duration: 50.22 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.39673334757487, Val Loss: 0.7954288721084595, LR: 3.0153689607045842e-05, Duration: 49.98 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4496769825617473, Val Loss: 0.7924708724021912, LR: 2.63016787428354e-05, Duration: 49.92 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 15/15 [00:49<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.685069513320923, Val Loss: 0.7937246561050415, LR: 2.2706183876134045e-05, Duration: 50.06 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [00:49<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.662763730684916, Val Loss: 0.8041825890541077, LR: 1.9369152030840554e-05, Duration: 50.13 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 15/15 [00:49<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.558410406112671, Val Loss: 0.8004736304283142, LR: 1.6292390268568102e-05, Duration: 50.07 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3674689133961997, Val Loss: 0.8002943396568298, LR: 1.3477564710088097e-05, Duration: 49.93 sec\n",
      "Epoch 당 평균 소요시간 : 70.65초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.850464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.821716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.830000\n",
       "1  Precision  0.850464\n",
       "2     Recall  0.830000\n",
       "3   F1 Score  0.821716"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "text = f\"Epoch 당 평균 소요시간 : {training_time / epochs:.2f}초\"      \n",
    "print(text)\n",
    "\n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 15/15 [00:49<00:00,  3.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5325933933258056, Val Loss: 0.7967063784599304, LR: 1.0926199633097156e-05, Duration: 50.19 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5717090368270874, Val Loss: 0.8010687232017517, LR: 8.639676646793382e-06, Duration: 49.94 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [00:49<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3656076908111574, Val Loss: 0.7969766855239868, LR: 6.61923394371039e-06, Duration: 50.06 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [00:48<00:00,  3.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4497125864028932, Val Loss: 0.7960164546966553, LR: 4.865965629214819e-06, Duration: 49.85 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.407879130045573, Val Loss: 0.794651985168457, LR: 3.3808211290284885e-06, Duration: 50.00 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.454337787628174, Val Loss: 0.7948555946350098, LR: 2.1646046750978256e-06, Duration: 50.01 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.474202871322632, Val Loss: 0.7953035831451416, LR: 1.2179748700879012e-06, Duration: 50.02 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4273924191792804, Val Loss: 0.7954041361808777, LR: 5.41444330737717e-07, Duration: 49.92 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 15/15 [00:49<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3542084137598676, Val Loss: 0.7953218221664429, LR: 1.3537941026914301e-07, Duration: 50.01 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 15/15 [00:48<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.427381428082784, Val Loss: 0.7953270673751831, LR: 0.0, Duration: 49.87 sec\n",
      "Epoch 당 평균 소요시간 : 75.64초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.826000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.846056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.826000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.816980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.826000\n",
       "1  Precision  0.846056\n",
       "2     Recall  0.826000\n",
       "3   F1 Score  0.816980"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "text = f\"Epoch 당 평균 소요시간 : {training_time / epochs:.2f}초\"      \n",
    "print(text)\n",
    "\n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
