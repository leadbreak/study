{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "- Stage-2 학습 시 Paper에서 제시한 Parameter와 달리\n",
    "  - 더 낮은 weight decay와 ReduceLROnPlateau Scheduler를 이용해 보다 높은 학습율을 끝까지 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from box import Box\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from swin_v2 import SwinTransformerV2\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from timm.data import Mixup\n",
    "import transformers\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:2'\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "model_save = False\n",
    "simmim_path = '../../models/swin2/simmim.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "odict_keys(['absolute_pos_embed', 'embeddings.patch_embeddings.weight', 'embeddings.patch_embeddings.bias', 'embeddings.norm.weight', 'embeddings.norm.bias', 'stages.0.blocks.0.attn_mask', 'stages.0.blocks.0.attn.t_scale', 'stages.0.blocks.0.attn.relative_coords_table', 'stages.0.blocks.0.attn.relative_position_index', 'stages.0.blocks.0.attn.crpb_mlp.0.weight', 'stages.0.blocks.0.attn.crpb_mlp.0.bias', 'stages.0.blocks.0.attn.crpb_mlp.3.weight', 'stages.0.blocks.0.attn.qkv.weight', 'stages.0.blocks.0.attn.qkv.bias', 'stages.0.blocks.0.attn.proj.weight', 'stages.0.blocks.0.attn.proj.bias', 'stages.0.blocks.0.norm1.weight', 'stages.0.blocks.0.norm1.bias', 'stages.0.blocks.0.mlp.fc1.weight', 'stages.0.blocks.0.mlp.fc1.bias', 'stages.0.blocks.0.mlp.fc2.weight', 'stages.0.blocks.0.mlp.fc2.bias', 'stages.0.blocks.0.norm2.weight', 'stages.0.blocks.0.norm2.bias', 'stages.0.blocks.1.attn_mask', 'stages.0.blocks.1.attn.t_scale', 'stages.0.blocks.1.attn.relative_coords_table', 'stages.0.blocks.1.attn.relative_position_index', 'stages.0.blocks.1.attn.crpb_mlp.0.weight', 'stages.0.blocks.1.attn.crpb_mlp.0.bias', 'stages.0.blocks.1.attn.crpb_mlp.3.weight', 'stages.0.blocks.1.attn.qkv.weight', 'stages.0.blocks.1.attn.qkv.bias', 'stages.0.blocks.1.attn.proj.weight', 'stages.0.blocks.1.attn.proj.bias', 'stages.0.blocks.1.norm1.weight', 'stages.0.blocks.1.norm1.bias', 'stages.0.blocks.1.mlp.fc1.weight', 'stages.0.blocks.1.mlp.fc1.bias', 'stages.0.blocks.1.mlp.fc2.weight', 'stages.0.blocks.1.mlp.fc2.bias', 'stages.0.blocks.1.norm2.weight', 'stages.0.blocks.1.norm2.bias', 'stages.0.downsample.reduction.weight', 'stages.0.downsample.norm.weight', 'stages.0.downsample.norm.bias', 'stages.1.blocks.0.attn_mask', 'stages.1.blocks.0.attn.t_scale', 'stages.1.blocks.0.attn.relative_coords_table', 'stages.1.blocks.0.attn.relative_position_index', 'stages.1.blocks.0.attn.crpb_mlp.0.weight', 'stages.1.blocks.0.attn.crpb_mlp.0.bias', 'stages.1.blocks.0.attn.crpb_mlp.3.weight', 'stages.1.blocks.0.attn.qkv.weight', 'stages.1.blocks.0.attn.qkv.bias', 'stages.1.blocks.0.attn.proj.weight', 'stages.1.blocks.0.attn.proj.bias', 'stages.1.blocks.0.norm1.weight', 'stages.1.blocks.0.norm1.bias', 'stages.1.blocks.0.mlp.fc1.weight', 'stages.1.blocks.0.mlp.fc1.bias', 'stages.1.blocks.0.mlp.fc2.weight', 'stages.1.blocks.0.mlp.fc2.bias', 'stages.1.blocks.0.norm2.weight', 'stages.1.blocks.0.norm2.bias', 'stages.1.blocks.1.attn_mask', 'stages.1.blocks.1.attn.t_scale', 'stages.1.blocks.1.attn.relative_coords_table', 'stages.1.blocks.1.attn.relative_position_index', 'stages.1.blocks.1.attn.crpb_mlp.0.weight', 'stages.1.blocks.1.attn.crpb_mlp.0.bias', 'stages.1.blocks.1.attn.crpb_mlp.3.weight', 'stages.1.blocks.1.attn.qkv.weight', 'stages.1.blocks.1.attn.qkv.bias', 'stages.1.blocks.1.attn.proj.weight', 'stages.1.blocks.1.attn.proj.bias', 'stages.1.blocks.1.norm1.weight', 'stages.1.blocks.1.norm1.bias', 'stages.1.blocks.1.mlp.fc1.weight', 'stages.1.blocks.1.mlp.fc1.bias', 'stages.1.blocks.1.mlp.fc2.weight', 'stages.1.blocks.1.mlp.fc2.bias', 'stages.1.blocks.1.norm2.weight', 'stages.1.blocks.1.norm2.bias', 'stages.1.downsample.reduction.weight', 'stages.1.downsample.norm.weight', 'stages.1.downsample.norm.bias', 'stages.2.blocks.0.attn_mask', 'stages.2.blocks.0.attn.t_scale', 'stages.2.blocks.0.attn.relative_coords_table', 'stages.2.blocks.0.attn.relative_position_index', 'stages.2.blocks.0.attn.crpb_mlp.0.weight', 'stages.2.blocks.0.attn.crpb_mlp.0.bias', 'stages.2.blocks.0.attn.crpb_mlp.3.weight', 'stages.2.blocks.0.attn.qkv.weight', 'stages.2.blocks.0.attn.qkv.bias', 'stages.2.blocks.0.attn.proj.weight', 'stages.2.blocks.0.attn.proj.bias', 'stages.2.blocks.0.norm1.weight', 'stages.2.blocks.0.norm1.bias', 'stages.2.blocks.0.mlp.fc1.weight', 'stages.2.blocks.0.mlp.fc1.bias', 'stages.2.blocks.0.mlp.fc2.weight', 'stages.2.blocks.0.mlp.fc2.bias', 'stages.2.blocks.0.norm2.weight', 'stages.2.blocks.0.norm2.bias', 'stages.2.blocks.1.attn_mask', 'stages.2.blocks.1.attn.t_scale', 'stages.2.blocks.1.attn.relative_coords_table', 'stages.2.blocks.1.attn.relative_position_index', 'stages.2.blocks.1.attn.crpb_mlp.0.weight', 'stages.2.blocks.1.attn.crpb_mlp.0.bias', 'stages.2.blocks.1.attn.crpb_mlp.3.weight', 'stages.2.blocks.1.attn.qkv.weight', 'stages.2.blocks.1.attn.qkv.bias', 'stages.2.blocks.1.attn.proj.weight', 'stages.2.blocks.1.attn.proj.bias', 'stages.2.blocks.1.norm1.weight', 'stages.2.blocks.1.norm1.bias', 'stages.2.blocks.1.mlp.fc1.weight', 'stages.2.blocks.1.mlp.fc1.bias', 'stages.2.blocks.1.mlp.fc2.weight', 'stages.2.blocks.1.mlp.fc2.bias', 'stages.2.blocks.1.norm2.weight', 'stages.2.blocks.1.norm2.bias', 'stages.2.blocks.2.attn_mask', 'stages.2.blocks.2.attn.t_scale', 'stages.2.blocks.2.attn.relative_coords_table', 'stages.2.blocks.2.attn.relative_position_index', 'stages.2.blocks.2.attn.crpb_mlp.0.weight', 'stages.2.blocks.2.attn.crpb_mlp.0.bias', 'stages.2.blocks.2.attn.crpb_mlp.3.weight', 'stages.2.blocks.2.attn.qkv.weight', 'stages.2.blocks.2.attn.qkv.bias', 'stages.2.blocks.2.attn.proj.weight', 'stages.2.blocks.2.attn.proj.bias', 'stages.2.blocks.2.norm1.weight', 'stages.2.blocks.2.norm1.bias', 'stages.2.blocks.2.mlp.fc1.weight', 'stages.2.blocks.2.mlp.fc1.bias', 'stages.2.blocks.2.mlp.fc2.weight', 'stages.2.blocks.2.mlp.fc2.bias', 'stages.2.blocks.2.norm2.weight', 'stages.2.blocks.2.norm2.bias', 'stages.2.blocks.3.attn_mask', 'stages.2.blocks.3.attn.t_scale', 'stages.2.blocks.3.attn.relative_coords_table', 'stages.2.blocks.3.attn.relative_position_index', 'stages.2.blocks.3.attn.crpb_mlp.0.weight', 'stages.2.blocks.3.attn.crpb_mlp.0.bias', 'stages.2.blocks.3.attn.crpb_mlp.3.weight', 'stages.2.blocks.3.attn.qkv.weight', 'stages.2.blocks.3.attn.qkv.bias', 'stages.2.blocks.3.attn.proj.weight', 'stages.2.blocks.3.attn.proj.bias', 'stages.2.blocks.3.norm1.weight', 'stages.2.blocks.3.norm1.bias', 'stages.2.blocks.3.mlp.fc1.weight', 'stages.2.blocks.3.mlp.fc1.bias', 'stages.2.blocks.3.mlp.fc2.weight', 'stages.2.blocks.3.mlp.fc2.bias', 'stages.2.blocks.3.norm2.weight', 'stages.2.blocks.3.norm2.bias', 'stages.2.blocks.4.attn_mask', 'stages.2.blocks.4.attn.t_scale', 'stages.2.blocks.4.attn.relative_coords_table', 'stages.2.blocks.4.attn.relative_position_index', 'stages.2.blocks.4.attn.crpb_mlp.0.weight', 'stages.2.blocks.4.attn.crpb_mlp.0.bias', 'stages.2.blocks.4.attn.crpb_mlp.3.weight', 'stages.2.blocks.4.attn.qkv.weight', 'stages.2.blocks.4.attn.qkv.bias', 'stages.2.blocks.4.attn.proj.weight', 'stages.2.blocks.4.attn.proj.bias', 'stages.2.blocks.4.norm1.weight', 'stages.2.blocks.4.norm1.bias', 'stages.2.blocks.4.mlp.fc1.weight', 'stages.2.blocks.4.mlp.fc1.bias', 'stages.2.blocks.4.mlp.fc2.weight', 'stages.2.blocks.4.mlp.fc2.bias', 'stages.2.blocks.4.norm2.weight', 'stages.2.blocks.4.norm2.bias', 'stages.2.blocks.5.attn_mask', 'stages.2.blocks.5.attn.t_scale', 'stages.2.blocks.5.attn.relative_coords_table', 'stages.2.blocks.5.attn.relative_position_index', 'stages.2.blocks.5.attn.crpb_mlp.0.weight', 'stages.2.blocks.5.attn.crpb_mlp.0.bias', 'stages.2.blocks.5.attn.crpb_mlp.3.weight', 'stages.2.blocks.5.attn.qkv.weight', 'stages.2.blocks.5.attn.qkv.bias', 'stages.2.blocks.5.attn.proj.weight', 'stages.2.blocks.5.attn.proj.bias', 'stages.2.blocks.5.norm1.weight', 'stages.2.blocks.5.norm1.bias', 'stages.2.blocks.5.mlp.fc1.weight', 'stages.2.blocks.5.mlp.fc1.bias', 'stages.2.blocks.5.mlp.fc2.weight', 'stages.2.blocks.5.mlp.fc2.bias', 'stages.2.blocks.5.norm2.weight', 'stages.2.blocks.5.norm2.bias', 'stages.2.downsample.reduction.weight', 'stages.2.downsample.norm.weight', 'stages.2.downsample.norm.bias', 'stages.3.blocks.0.attn_mask', 'stages.3.blocks.0.attn.t_scale', 'stages.3.blocks.0.attn.relative_coords_table', 'stages.3.blocks.0.attn.relative_position_index', 'stages.3.blocks.0.attn.crpb_mlp.0.weight', 'stages.3.blocks.0.attn.crpb_mlp.0.bias', 'stages.3.blocks.0.attn.crpb_mlp.3.weight', 'stages.3.blocks.0.attn.qkv.weight', 'stages.3.blocks.0.attn.qkv.bias', 'stages.3.blocks.0.attn.proj.weight', 'stages.3.blocks.0.attn.proj.bias', 'stages.3.blocks.0.norm1.weight', 'stages.3.blocks.0.norm1.bias', 'stages.3.blocks.0.mlp.fc1.weight', 'stages.3.blocks.0.mlp.fc1.bias', 'stages.3.blocks.0.mlp.fc2.weight', 'stages.3.blocks.0.mlp.fc2.bias', 'stages.3.blocks.0.norm2.weight', 'stages.3.blocks.0.norm2.bias', 'stages.3.blocks.1.attn_mask', 'stages.3.blocks.1.attn.t_scale', 'stages.3.blocks.1.attn.relative_coords_table', 'stages.3.blocks.1.attn.relative_position_index', 'stages.3.blocks.1.attn.crpb_mlp.0.weight', 'stages.3.blocks.1.attn.crpb_mlp.0.bias', 'stages.3.blocks.1.attn.crpb_mlp.3.weight', 'stages.3.blocks.1.attn.qkv.weight', 'stages.3.blocks.1.attn.qkv.bias', 'stages.3.blocks.1.attn.proj.weight', 'stages.3.blocks.1.attn.proj.bias', 'stages.3.blocks.1.norm1.weight', 'stages.3.blocks.1.norm1.bias', 'stages.3.blocks.1.mlp.fc1.weight', 'stages.3.blocks.1.mlp.fc1.bias', 'stages.3.blocks.1.mlp.fc2.weight', 'stages.3.blocks.1.mlp.fc2.bias', 'stages.3.blocks.1.norm2.weight', 'stages.3.blocks.1.norm2.bias', 'layernorm.weight', 'layernorm.bias', 'classifier.weight', 'classifier.bias'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SwinTransformerV2(pretrained_window_sizes=[6,6,6,6], ape=True, drop_path_rate=0.3)\n",
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0792,  0.1244,  0.0957, -0.1216],\n",
       "         [-0.0783,  0.0223,  0.0873,  0.0398],\n",
       "         [-0.1184,  0.1201, -0.1103, -0.0016],\n",
       "         [ 0.0301, -0.1299, -0.0872,  0.0785]],\n",
       "\n",
       "        [[ 0.0979, -0.0671, -0.0581,  0.0656],\n",
       "         [ 0.0121, -0.1216, -0.0343,  0.0989],\n",
       "         [ 0.0417,  0.0732,  0.0061, -0.1179],\n",
       "         [-0.1371, -0.1285,  0.0351,  0.0815]],\n",
       "\n",
       "        [[-0.0510, -0.1322, -0.0627,  0.0280],\n",
       "         [ 0.1036, -0.0328, -0.0967,  0.0296],\n",
       "         [-0.0208,  0.0712, -0.0767, -0.1385],\n",
       "         [-0.1126, -0.1337,  0.1350,  0.0165]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['embeddings.patch_embeddings.weight'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0268,  0.0063, -0.0093,  0.0258,  0.0516, -0.0442,  0.0010, -0.0318,\n",
       "         0.0405,  0.0066,  0.0012,  0.0332,  0.0072,  0.0353,  0.0065,  0.0091,\n",
       "         0.0017,  0.0015,  0.0059, -0.0399,  0.0087,  0.0218, -0.0113,  0.0059,\n",
       "        -0.0273, -0.0099, -0.0024,  0.0301, -0.0160,  0.0034,  0.0128,  0.0015,\n",
       "         0.0040,  0.0218, -0.0004,  0.0022,  0.0055, -0.0323,  0.0076, -0.0036,\n",
       "         0.0011,  0.0241,  0.0009,  0.0180,  0.0053,  0.0182,  0.0191,  0.0246,\n",
       "         0.0307,  0.0044,  0.0049,  0.0117, -0.0275,  0.0274, -0.0096, -0.0058,\n",
       "         0.0055,  0.0168, -0.0227,  0.0362, -0.0039, -0.0234, -0.0037,  0.0235,\n",
       "        -0.0169,  0.0232, -0.0165, -0.0203,  0.0115,  0.0259, -0.0276,  0.0065,\n",
       "        -0.0029, -0.0102, -0.0104,  0.0113, -0.0385,  0.0484, -0.0407,  0.0041,\n",
       "         0.0014, -0.0134,  0.0133, -0.0072, -0.0334,  0.0077, -0.0090,  0.0151,\n",
       "         0.0126,  0.0027, -0.0019,  0.0208,  0.0097,  0.0029, -0.0172, -0.0038,\n",
       "         0.0137, -0.0279, -0.0168,  0.0123, -0.0272,  0.0362, -0.0357, -0.0191,\n",
       "         0.0146,  0.0425, -0.0081, -0.0231, -0.0099,  0.0140,  0.0107,  0.0131,\n",
       "        -0.0305, -0.0083, -0.0367,  0.0130,  0.0226, -0.0031, -0.0202, -0.0471,\n",
       "        -0.0091, -0.0140, -0.0357, -0.0233,  0.0287, -0.0049,  0.0183, -0.0085,\n",
       "        -0.0196, -0.0152, -0.0561, -0.0048,  0.0295, -0.0010,  0.0098, -0.0041,\n",
       "        -0.0036, -0.0043, -0.0357,  0.0099,  0.0174,  0.0016,  0.0097, -0.0248,\n",
       "        -0.0049, -0.0001,  0.0179,  0.0434,  0.0176,  0.0282,  0.0006, -0.0008,\n",
       "         0.0612, -0.0072,  0.0392,  0.0141, -0.0126,  0.0081,  0.0110,  0.0138,\n",
       "         0.0124,  0.0009,  0.0273,  0.0205, -0.0169, -0.0346,  0.0016, -0.0045,\n",
       "         0.0113,  0.0088,  0.0242, -0.0031, -0.0236,  0.0023,  0.0197,  0.0031,\n",
       "         0.0100,  0.0188, -0.0154,  0.0144,  0.0007, -0.0146,  0.0017,  0.0037,\n",
       "         0.0011,  0.0055,  0.0119, -0.0066,  0.0106,  0.0170, -0.0140, -0.0139,\n",
       "         0.0043, -0.0188,  0.0069,  0.0020,  0.0055, -0.0014,  0.0227,  0.0094,\n",
       "        -0.0089, -0.0023,  0.0205,  0.0290,  0.0071,  0.0109,  0.0170,  0.0239,\n",
       "        -0.0042,  0.0263, -0.0003, -0.0154,  0.0105, -0.0099, -0.0076, -0.0142,\n",
       "        -0.0133, -0.0010, -0.0144, -0.0141,  0.0069, -0.0071, -0.0005,  0.0274,\n",
       "         0.0182,  0.0145,  0.0385,  0.0310, -0.0019, -0.0461,  0.0035, -0.0090,\n",
       "        -0.0150,  0.0123, -0.0147, -0.0168, -0.0112, -0.0078,  0.0141,  0.0040,\n",
       "        -0.0409,  0.0256,  0.0166, -0.0095, -0.0047, -0.0019,  0.0378,  0.0091,\n",
       "        -0.0308,  0.0349, -0.0110, -0.0067,  0.0275,  0.0135, -0.0098,  0.0022,\n",
       "        -0.0028, -0.0035,  0.0035,  0.0217,  0.0274, -0.0026, -0.0125, -0.0100,\n",
       "        -0.0023,  0.0058,  0.0297,  0.0148, -0.0082,  0.0191,  0.0532, -0.0124,\n",
       "        -0.0027, -0.0074,  0.0096,  0.0025,  0.0073,  0.0011,  0.0118,  0.0266,\n",
       "        -0.0375,  0.0074, -0.0152,  0.0016,  0.0260, -0.0230,  0.0122,  0.0185,\n",
       "         0.0214, -0.0112, -0.0119,  0.0009, -0.0028, -0.0399, -0.0271, -0.0061,\n",
       "        -0.0293, -0.0075, -0.0211, -0.0019, -0.0030,  0.0024, -0.0057,  0.0299,\n",
       "        -0.0096, -0.0205, -0.0032,  0.0033, -0.0225, -0.0172, -0.0105,  0.0399,\n",
       "        -0.0478,  0.0238, -0.0313, -0.0079,  0.0242, -0.0063, -0.0114, -0.0065,\n",
       "        -0.0013,  0.0331,  0.0050, -0.0034,  0.0071, -0.0210,  0.0246,  0.0495,\n",
       "        -0.0209, -0.0174,  0.0105,  0.0018,  0.0074,  0.0069,  0.0042,  0.0154,\n",
       "         0.0193,  0.0215, -0.0326, -0.0063, -0.0266, -0.0149,  0.0151, -0.0051,\n",
       "         0.0422,  0.0039,  0.0258, -0.0347,  0.0191,  0.0083,  0.0007, -0.0029,\n",
       "         0.0058, -0.0019, -0.0130, -0.0101,  0.0255, -0.0284,  0.0210, -0.0010,\n",
       "         0.0250,  0.0051, -0.0290,  0.0012, -0.0301,  0.0114, -0.0086, -0.0035,\n",
       "         0.0089, -0.0286,  0.0527,  0.0007, -0.0046, -0.0025,  0.0137,  0.0382,\n",
       "        -0.0248,  0.0003, -0.0077,  0.0113, -0.0188,  0.0124,  0.0167,  0.0005])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['stages.3.blocks.1.attn.crpb_mlp.3.weight'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MODEL': {'TYPE': 'swinv2',\n",
       "  'NAME': 'simmim_train',\n",
       "  'PRETRAINED': '../../models/swin2/simmim.pth',\n",
       "  'DROP_PATH_RATE': 0.2,\n",
       "  'SWIN': {'EMBED_DIM': 96,\n",
       "   'DEPTHS': [2, 2, 6, 2],\n",
       "   'NUM_HEADS': [3, 6, 12, 24],\n",
       "   'WINDOW_SIZE': 7,\n",
       "   'PATCH_SIZE': 4}},\n",
       " 'DATA': {'IMG_SIZE': 224,\n",
       "  'MASK_PATCH_SIZE': 32,\n",
       "  'MASK_RATIO': 0.6,\n",
       "  'BATCH_SIZE': 960,\n",
       "  'NUM_WORKERS': 24,\n",
       "  'DATA_PATH': '../../data/sports'},\n",
       " 'TRAIN': {'EPOCHS': 20,\n",
       "  'WARMUP_EPOCHS': 10,\n",
       "  'BASE_LR': '1e-4',\n",
       "  'WEIGHT_DECAY': 0.05,\n",
       "  'CLIP_GRAD': 5}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swin_config = yaml.load(open('config/train.yaml'), Loader=yaml.FullLoader)\n",
    "swin_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained(config, model):\n",
    "    print(f\"==============> Loading weight {config.MODEL.PRETRAINED} for fine-tuning......\")\n",
    "    state_dict = torch.load(config.MODEL.PRETRAINED, map_location='cpu')\n",
    "\n",
    "    # remain encoder only\n",
    "    not_encoder_keys = [k for k in state_dict.keys() if 'encoder' not in k]\n",
    "    for k in not_encoder_keys:\n",
    "        del state_dict[k]\n",
    "        \n",
    "    # remove prefix encoder.\n",
    "    state_dict = {k.replace('encoder.', ''):v for k, v in state_dict.items()}\n",
    "\n",
    "    # delete relative_position_index since we always re-init it\n",
    "    relative_position_index_keys = [k for k in state_dict.keys() if \"relative_position_index\" in k]\n",
    "    for k in relative_position_index_keys:\n",
    "        del state_dict[k]\n",
    "\n",
    "    # delete relative_coords_table since we always re-init it\n",
    "    relative_position_index_keys = [k for k in state_dict.keys() if \"relative_coords_table\" in k]\n",
    "    for k in relative_position_index_keys:\n",
    "        del state_dict[k]\n",
    "\n",
    "    # delete attn_mask since we always re-init it\n",
    "    attn_mask_keys = [k for k in state_dict.keys() if \"attn_mask\" in k]\n",
    "    for k in attn_mask_keys:\n",
    "        del state_dict[k]\n",
    "\n",
    "    # bicubic interpolate relative_position_bias_table if not match\n",
    "    relative_position_bias_table_keys = [k for k in state_dict.keys() if \"relative_position_bias_table\" in k]\n",
    "    for k in relative_position_bias_table_keys:\n",
    "        relative_position_bias_table_pretrained = state_dict[k]\n",
    "        relative_position_bias_table_current = model.state_dict()[k]\n",
    "        L1, nH1 = relative_position_bias_table_pretrained.size()\n",
    "        L2, nH2 = relative_position_bias_table_current.size()\n",
    "        if nH1 != nH2:\n",
    "            print(f\"Error in loading {k}, passing......\")\n",
    "        else:\n",
    "            if L1 != L2:\n",
    "                # bicubic interpolate relative_position_bias_table if not match\n",
    "                S1 = int(L1 ** 0.5)\n",
    "                S2 = int(L2 ** 0.5)\n",
    "                relative_position_bias_table_pretrained_resized = torch.nn.functional.interpolate(\n",
    "                    relative_position_bias_table_pretrained.permute(1, 0).view(1, nH1, S1, S1), size=(S2, S2),\n",
    "                    mode='bicubic')\n",
    "                state_dict[k] = relative_position_bias_table_pretrained_resized.view(nH2, L2).permute(1, 0)\n",
    "\n",
    "    # bicubic interpolate absolute_pos_embed if not match\n",
    "    absolute_pos_embed_keys = [k for k in state_dict.keys() if \"absolute_pos_embed\" in k]\n",
    "    for k in absolute_pos_embed_keys:\n",
    "        # dpe\n",
    "        absolute_pos_embed_pretrained = state_dict[k]\n",
    "        absolute_pos_embed_current = model.state_dict()[k.replace('encoder.','')]\n",
    "        _, L1, C1 = absolute_pos_embed_pretrained.size()\n",
    "        _, L2, C2 = absolute_pos_embed_current.size()\n",
    "        if C1 != C1:\n",
    "            print(f\"Error in loading {k}, passing......\")\n",
    "        else:\n",
    "            if L1 != L2:\n",
    "                S1 = int(L1 ** 0.5)\n",
    "                S2 = int(L2 ** 0.5)\n",
    "                absolute_pos_embed_pretrained = absolute_pos_embed_pretrained.reshape(-1, S1, S1, C1)\n",
    "                absolute_pos_embed_pretrained = absolute_pos_embed_pretrained.permute(0, 3, 1, 2)\n",
    "                absolute_pos_embed_pretrained_resized = torch.nn.functional.interpolate(\n",
    "                    absolute_pos_embed_pretrained, size=(S2, S2), mode='bicubic')\n",
    "                absolute_pos_embed_pretrained_resized = absolute_pos_embed_pretrained_resized.permute(0, 2, 3, 1)\n",
    "                absolute_pos_embed_pretrained_resized = absolute_pos_embed_pretrained_resized.flatten(1, 2)\n",
    "                state_dict[k] = absolute_pos_embed_pretrained_resized\n",
    "\n",
    "    # check classifier, if not match, then re-init classifier to zero\n",
    "    head_bias_pretrained = state_dict['classifier.bias']\n",
    "    Nc1 = head_bias_pretrained.shape[0]\n",
    "    Nc2 = model.classifier.bias.shape[0]\n",
    "    if (Nc1 != Nc2):\n",
    "        torch.nn.init.constant_(model.classifier.bias, 0.)\n",
    "        torch.nn.init.constant_(model.classifier.weight, 0.)\n",
    "        del state_dict['classifier.weight']\n",
    "        del state_dict['classifier.bias']\n",
    "        print(f\"Error in loading classifier head, re-init classifier head to 0\")\n",
    "\n",
    "    msg = model.load_state_dict(state_dict, strict=False)\n",
    "    print(msg)\n",
    "\n",
    "    print(f\"=> loaded successfully '{config.MODEL.PRETRAINED}'\")\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============> Loading weight ../../models/swin2/simmim.pth for fine-tuning......\n",
      "_IncompatibleKeys(missing_keys=['stages.0.blocks.0.attn_mask', 'stages.0.blocks.0.attn.relative_coords_table', 'stages.0.blocks.0.attn.relative_position_index', 'stages.0.blocks.1.attn_mask', 'stages.0.blocks.1.attn.relative_coords_table', 'stages.0.blocks.1.attn.relative_position_index', 'stages.1.blocks.0.attn_mask', 'stages.1.blocks.0.attn.relative_coords_table', 'stages.1.blocks.0.attn.relative_position_index', 'stages.1.blocks.1.attn_mask', 'stages.1.blocks.1.attn.relative_coords_table', 'stages.1.blocks.1.attn.relative_position_index', 'stages.2.blocks.0.attn_mask', 'stages.2.blocks.0.attn.relative_coords_table', 'stages.2.blocks.0.attn.relative_position_index', 'stages.2.blocks.1.attn_mask', 'stages.2.blocks.1.attn.relative_coords_table', 'stages.2.blocks.1.attn.relative_position_index', 'stages.2.blocks.2.attn_mask', 'stages.2.blocks.2.attn.relative_coords_table', 'stages.2.blocks.2.attn.relative_position_index', 'stages.2.blocks.3.attn_mask', 'stages.2.blocks.3.attn.relative_coords_table', 'stages.2.blocks.3.attn.relative_position_index', 'stages.2.blocks.4.attn_mask', 'stages.2.blocks.4.attn.relative_coords_table', 'stages.2.blocks.4.attn.relative_position_index', 'stages.2.blocks.5.attn_mask', 'stages.2.blocks.5.attn.relative_coords_table', 'stages.2.blocks.5.attn.relative_position_index', 'stages.3.blocks.0.attn_mask', 'stages.3.blocks.0.attn.relative_coords_table', 'stages.3.blocks.0.attn.relative_position_index', 'stages.3.blocks.1.attn_mask', 'stages.3.blocks.1.attn.relative_coords_table', 'stages.3.blocks.1.attn.relative_position_index'], unexpected_keys=['mask_token'])\n",
      "=> loaded successfully '../../models/swin2/simmim.pth'\n"
     ]
    }
   ],
   "source": [
    "swin_config = Box(swin_config)\n",
    "load_pretrained(swin_config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0301,  0.0009,  0.0505, -0.0364],\n",
       "         [ 0.1105, -0.0453, -0.0787, -0.0376],\n",
       "         [-0.0682, -0.0893,  0.0535, -0.0659],\n",
       "         [-0.0380,  0.0854,  0.0976,  0.0287]],\n",
       "\n",
       "        [[-0.0771, -0.1077, -0.0139,  0.0576],\n",
       "         [-0.1156,  0.0058,  0.0420, -0.0442],\n",
       "         [-0.1327,  0.1288, -0.0719,  0.0688],\n",
       "         [ 0.0249,  0.1164, -0.0735, -0.0361]],\n",
       "\n",
       "        [[ 0.0094,  0.1149, -0.0851,  0.1097],\n",
       "         [ 0.1142, -0.1260,  0.1255, -0.0553],\n",
       "         [ 0.0574, -0.0123, -0.0088,  0.0854],\n",
       "         [-0.0981,  0.0671, -0.1177,  0.0822]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['embeddings.patch_embeddings.weight'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3441,  0.2157, -0.2093,  0.3680, -0.0128, -0.1047,  0.3628,  0.1783,\n",
       "        -0.1962, -0.0918,  0.2762,  0.3604, -0.1071,  0.3773, -0.0933, -0.0062,\n",
       "        -0.1436, -0.1425, -0.1067,  0.2658, -0.0970,  0.2234,  0.0165,  0.3350,\n",
       "        -0.1316, -0.1465,  0.3168, -0.1226, -0.1506, -0.0127,  0.3362, -0.1885,\n",
       "        -0.1618, -0.1210,  0.3268,  0.2339, -0.1220, -0.0818, -0.0878, -0.1294,\n",
       "        -0.0691,  0.1114, -0.0910, -0.1057,  0.2985,  0.3047, -0.1025, -0.0852,\n",
       "        -0.0855,  0.1312, -0.0273, -0.1521,  0.3055,  0.1763, -0.0781,  0.3170,\n",
       "        -0.0057, -0.0150, -0.0239, -0.1214, -0.0623, -0.2075, -0.0569,  0.2784,\n",
       "        -0.0833, -0.1258, -0.1253,  0.1136, -0.1609,  0.1525,  0.3013, -0.1182,\n",
       "         0.0469, -0.1002, -0.1370, -0.1209,  0.2787,  0.0903, -0.1388, -0.1924,\n",
       "        -0.1242,  0.0175, -0.1391, -0.0981,  0.3561,  0.3985, -0.0734,  0.3098,\n",
       "         0.0680, -0.1240,  0.2772, -0.0027,  0.2672,  0.3719, -0.1221,  0.2322,\n",
       "        -0.1118, -0.1924, -0.1657, -0.1465, -0.2035,  0.1239, -0.1328, -0.1246,\n",
       "        -0.1630, -0.1243,  0.0183,  0.1933,  0.3206,  0.0840, -0.1172, -0.1619,\n",
       "         0.2803, -0.1315, -0.0774, -0.1813, -0.1353, -0.1154, -0.1547,  0.0035,\n",
       "        -0.1676, -0.2131,  0.3817,  0.1613, -0.1180, -0.1891,  0.1556,  0.0457,\n",
       "        -0.1123,  0.1500, -0.1252, -0.1942,  0.0070,  0.3842, -0.1383, -0.1451,\n",
       "        -0.0104,  0.1070,  0.0060,  0.2915, -0.1389,  0.3873, -0.1191,  0.2119,\n",
       "         0.2249, -0.1321,  0.1351,  0.2725, -0.1091, -0.0455, -0.1145,  0.4053,\n",
       "         0.0386, -0.1343,  0.1865, -0.1044, -0.1041,  0.1070, -0.1304,  0.3231,\n",
       "         0.1755, -0.0995, -0.0674, -0.1109,  0.4288, -0.1018, -0.0100, -0.1207,\n",
       "        -0.1190, -0.1947, -0.1189,  0.1013, -0.0164, -0.1201,  0.3990, -0.0315,\n",
       "        -0.1000,  0.0497, -0.1145, -0.1840,  0.3667, -0.0871,  0.4341,  0.1278,\n",
       "        -0.1869,  0.2664, -0.1631,  0.3120,  0.2145, -0.1874, -0.1540, -0.0987,\n",
       "         0.1388, -0.0884,  0.0712, -0.1132, -0.1430,  0.1176, -0.1269,  0.1296,\n",
       "         0.1934,  0.2749, -0.1208, -0.1594, -0.0258, -0.0776, -0.1429,  0.1138,\n",
       "         0.1264,  0.2032,  0.2603, -0.0740, -0.2104, -0.0999,  0.0597, -0.1706,\n",
       "        -0.1895, -0.1468, -0.0890,  0.0882, -0.1409, -0.1187,  0.3585, -0.1258,\n",
       "         0.2729, -0.1978, -0.1840, -0.1468,  0.1739,  0.3891,  0.0774, -0.0752,\n",
       "         0.1035, -0.1300,  0.1101,  0.3737,  0.2278, -0.1651, -0.0667,  0.2701,\n",
       "         0.1460,  0.0951,  0.2819,  0.3445,  0.0975, -0.1205, -0.1011,  0.3742,\n",
       "        -0.1751, -0.2178,  0.0689, -0.0998, -0.1064,  0.1043, -0.0924, -0.0146,\n",
       "         0.1142, -0.1045, -0.1307, -0.1781, -0.1173, -0.1025,  0.2247,  0.0297,\n",
       "        -0.1058,  0.0530,  0.3087,  0.1489,  0.0973, -0.0852,  0.0206, -0.1205,\n",
       "        -0.0589, -0.1306,  0.3215,  0.0807, -0.1712,  0.2878, -0.1484,  0.2949,\n",
       "        -0.1277, -0.0067, -0.1076,  0.1325,  0.0985, -0.1223,  0.0184, -0.1417,\n",
       "        -0.1038, -0.1312,  0.1919, -0.1557,  0.2966,  0.3421,  0.2683,  0.3130,\n",
       "        -0.1660, -0.0919, -0.1215,  0.3667,  0.3266, -0.1250,  0.3586, -0.0910,\n",
       "        -0.1648, -0.1452, -0.1346, -0.1591, -0.1129, -0.0977, -0.0852,  0.3798,\n",
       "        -0.0844,  0.3037, -0.1081,  0.3366,  0.3138, -0.1073, -0.1729, -0.1409,\n",
       "         0.1763, -0.1172, -0.1060,  0.1426,  0.3322,  0.3639,  0.2781, -0.2158,\n",
       "        -0.1003,  0.3241, -0.0173, -0.1263, -0.1019,  0.3160,  0.1903, -0.1880,\n",
       "        -0.1185,  0.3448,  0.1412,  0.2618, -0.1933, -0.1846, -0.1656, -0.1857,\n",
       "        -0.1341, -0.1656, -0.0982, -0.0887,  0.3037, -0.1127,  0.0946,  0.2976,\n",
       "         0.3293,  0.3636,  0.1178,  0.1094, -0.0866,  0.2487,  0.1525,  0.2924,\n",
       "         0.1803, -0.1963, -0.0903, -0.1952,  0.0780, -0.1051, -0.0864, -0.1440,\n",
       "         0.1882,  0.2569, -0.1023, -0.1234, -0.1498,  0.0518, -0.1104, -0.0058,\n",
       "         0.3766,  0.2990, -0.0930, -0.0172, -0.1035,  0.1263,  0.1493, -0.1194])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['stages.3.blocks.1.attn.crpb_mlp.3.weight'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms 정의하기\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8,1), interpolation=transforms.InterpolationMode.LANCZOS),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.9, scale=(0.02, 0.33)),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "data_dir = '../../data/sports'\n",
    "batch_size = 960\n",
    "\n",
    "train_path = data_dir+'/train'\n",
    "valid_path = data_dir+'/valid'\n",
    "test_path = data_dir+'/test'\n",
    "\n",
    "# dataset load\n",
    "train_data = ImageFolder(train_path, transform=train_transform)\n",
    "valid_data = ImageFolder(valid_path, transform=test_transform)\n",
    "test_data = ImageFolder(test_path, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_norm = 1.0 # paper : 100 with G variants\n",
    "\n",
    "model.to(device)\n",
    "model_path = '../../models/swin2/model_w_simmim2.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixup_fn = Mixup(mixup_alpha=.7, \n",
    "                cutmix_alpha=.7, \n",
    "                prob=.7, \n",
    "                switch_prob=0.5, \n",
    "                mode='batch',\n",
    "                label_smoothing=.1,\n",
    "                num_classes=100)\n",
    "\n",
    "epochs = 150\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: absolute_pos_embed\n",
      "1: embeddings.patch_embeddings.weight\n",
      "2: embeddings.patch_embeddings.bias\n",
      "3: embeddings.norm.weight\n",
      "4: embeddings.norm.bias\n",
      "5: stages.0.blocks.0.attn.t_scale\n",
      "6: stages.0.blocks.0.attn.crpb_mlp.0.weight\n",
      "7: stages.0.blocks.0.attn.crpb_mlp.0.bias\n",
      "8: stages.0.blocks.0.attn.crpb_mlp.3.weight\n",
      "9: stages.0.blocks.0.attn.qkv.weight\n",
      "10: stages.0.blocks.0.attn.qkv.bias\n",
      "11: stages.0.blocks.0.attn.proj.weight\n",
      "12: stages.0.blocks.0.attn.proj.bias\n",
      "13: stages.0.blocks.0.norm1.weight\n",
      "14: stages.0.blocks.0.norm1.bias\n",
      "15: stages.0.blocks.0.mlp.fc1.weight\n",
      "16: stages.0.blocks.0.mlp.fc1.bias\n",
      "17: stages.0.blocks.0.mlp.fc2.weight\n",
      "18: stages.0.blocks.0.mlp.fc2.bias\n",
      "19: stages.0.blocks.0.norm2.weight\n",
      "20: stages.0.blocks.0.norm2.bias\n",
      "21: stages.0.blocks.1.attn.t_scale\n",
      "22: stages.0.blocks.1.attn.crpb_mlp.0.weight\n",
      "23: stages.0.blocks.1.attn.crpb_mlp.0.bias\n",
      "24: stages.0.blocks.1.attn.crpb_mlp.3.weight\n",
      "25: stages.0.blocks.1.attn.qkv.weight\n",
      "26: stages.0.blocks.1.attn.qkv.bias\n",
      "27: stages.0.blocks.1.attn.proj.weight\n",
      "28: stages.0.blocks.1.attn.proj.bias\n",
      "29: stages.0.blocks.1.norm1.weight\n",
      "30: stages.0.blocks.1.norm1.bias\n",
      "31: stages.0.blocks.1.mlp.fc1.weight\n",
      "32: stages.0.blocks.1.mlp.fc1.bias\n",
      "33: stages.0.blocks.1.mlp.fc2.weight\n",
      "34: stages.0.blocks.1.mlp.fc2.bias\n",
      "35: stages.0.blocks.1.norm2.weight\n",
      "36: stages.0.blocks.1.norm2.bias\n",
      "37: stages.0.downsample.reduction.weight\n",
      "38: stages.0.downsample.norm.weight\n",
      "39: stages.0.downsample.norm.bias\n",
      "40: stages.1.blocks.0.attn.t_scale\n",
      "41: stages.1.blocks.0.attn.crpb_mlp.0.weight\n",
      "42: stages.1.blocks.0.attn.crpb_mlp.0.bias\n",
      "43: stages.1.blocks.0.attn.crpb_mlp.3.weight\n",
      "44: stages.1.blocks.0.attn.qkv.weight\n",
      "45: stages.1.blocks.0.attn.qkv.bias\n",
      "46: stages.1.blocks.0.attn.proj.weight\n",
      "47: stages.1.blocks.0.attn.proj.bias\n",
      "48: stages.1.blocks.0.norm1.weight\n",
      "49: stages.1.blocks.0.norm1.bias\n",
      "50: stages.1.blocks.0.mlp.fc1.weight\n",
      "51: stages.1.blocks.0.mlp.fc1.bias\n",
      "52: stages.1.blocks.0.mlp.fc2.weight\n",
      "53: stages.1.blocks.0.mlp.fc2.bias\n",
      "54: stages.1.blocks.0.norm2.weight\n",
      "55: stages.1.blocks.0.norm2.bias\n",
      "56: stages.1.blocks.1.attn.t_scale\n",
      "57: stages.1.blocks.1.attn.crpb_mlp.0.weight\n",
      "58: stages.1.blocks.1.attn.crpb_mlp.0.bias\n",
      "59: stages.1.blocks.1.attn.crpb_mlp.3.weight\n",
      "60: stages.1.blocks.1.attn.qkv.weight\n",
      "61: stages.1.blocks.1.attn.qkv.bias\n",
      "62: stages.1.blocks.1.attn.proj.weight\n",
      "63: stages.1.blocks.1.attn.proj.bias\n",
      "64: stages.1.blocks.1.norm1.weight\n",
      "65: stages.1.blocks.1.norm1.bias\n",
      "66: stages.1.blocks.1.mlp.fc1.weight\n",
      "67: stages.1.blocks.1.mlp.fc1.bias\n",
      "68: stages.1.blocks.1.mlp.fc2.weight\n",
      "69: stages.1.blocks.1.mlp.fc2.bias\n",
      "70: stages.1.blocks.1.norm2.weight\n",
      "71: stages.1.blocks.1.norm2.bias\n",
      "72: stages.1.downsample.reduction.weight\n",
      "73: stages.1.downsample.norm.weight\n",
      "74: stages.1.downsample.norm.bias\n",
      "75: stages.2.blocks.0.attn.t_scale\n",
      "76: stages.2.blocks.0.attn.crpb_mlp.0.weight\n",
      "77: stages.2.blocks.0.attn.crpb_mlp.0.bias\n",
      "78: stages.2.blocks.0.attn.crpb_mlp.3.weight\n",
      "79: stages.2.blocks.0.attn.qkv.weight\n",
      "80: stages.2.blocks.0.attn.qkv.bias\n",
      "81: stages.2.blocks.0.attn.proj.weight\n",
      "82: stages.2.blocks.0.attn.proj.bias\n",
      "83: stages.2.blocks.0.norm1.weight\n",
      "84: stages.2.blocks.0.norm1.bias\n",
      "85: stages.2.blocks.0.mlp.fc1.weight\n",
      "86: stages.2.blocks.0.mlp.fc1.bias\n",
      "87: stages.2.blocks.0.mlp.fc2.weight\n",
      "88: stages.2.blocks.0.mlp.fc2.bias\n",
      "89: stages.2.blocks.0.norm2.weight\n",
      "90: stages.2.blocks.0.norm2.bias\n",
      "91: stages.2.blocks.1.attn.t_scale\n",
      "92: stages.2.blocks.1.attn.crpb_mlp.0.weight\n",
      "93: stages.2.blocks.1.attn.crpb_mlp.0.bias\n",
      "94: stages.2.blocks.1.attn.crpb_mlp.3.weight\n",
      "95: stages.2.blocks.1.attn.qkv.weight\n",
      "96: stages.2.blocks.1.attn.qkv.bias\n",
      "97: stages.2.blocks.1.attn.proj.weight\n",
      "98: stages.2.blocks.1.attn.proj.bias\n",
      "99: stages.2.blocks.1.norm1.weight\n",
      "100: stages.2.blocks.1.norm1.bias\n",
      "101: stages.2.blocks.1.mlp.fc1.weight\n",
      "102: stages.2.blocks.1.mlp.fc1.bias\n",
      "103: stages.2.blocks.1.mlp.fc2.weight\n",
      "104: stages.2.blocks.1.mlp.fc2.bias\n",
      "105: stages.2.blocks.1.norm2.weight\n",
      "106: stages.2.blocks.1.norm2.bias\n",
      "107: stages.2.blocks.2.attn.t_scale\n",
      "108: stages.2.blocks.2.attn.crpb_mlp.0.weight\n",
      "109: stages.2.blocks.2.attn.crpb_mlp.0.bias\n",
      "110: stages.2.blocks.2.attn.crpb_mlp.3.weight\n",
      "111: stages.2.blocks.2.attn.qkv.weight\n",
      "112: stages.2.blocks.2.attn.qkv.bias\n",
      "113: stages.2.blocks.2.attn.proj.weight\n",
      "114: stages.2.blocks.2.attn.proj.bias\n",
      "115: stages.2.blocks.2.norm1.weight\n",
      "116: stages.2.blocks.2.norm1.bias\n",
      "117: stages.2.blocks.2.mlp.fc1.weight\n",
      "118: stages.2.blocks.2.mlp.fc1.bias\n",
      "119: stages.2.blocks.2.mlp.fc2.weight\n",
      "120: stages.2.blocks.2.mlp.fc2.bias\n",
      "121: stages.2.blocks.2.norm2.weight\n",
      "122: stages.2.blocks.2.norm2.bias\n",
      "123: stages.2.blocks.3.attn.t_scale\n",
      "124: stages.2.blocks.3.attn.crpb_mlp.0.weight\n",
      "125: stages.2.blocks.3.attn.crpb_mlp.0.bias\n",
      "126: stages.2.blocks.3.attn.crpb_mlp.3.weight\n",
      "127: stages.2.blocks.3.attn.qkv.weight\n",
      "128: stages.2.blocks.3.attn.qkv.bias\n",
      "129: stages.2.blocks.3.attn.proj.weight\n",
      "130: stages.2.blocks.3.attn.proj.bias\n",
      "131: stages.2.blocks.3.norm1.weight\n",
      "132: stages.2.blocks.3.norm1.bias\n",
      "133: stages.2.blocks.3.mlp.fc1.weight\n",
      "134: stages.2.blocks.3.mlp.fc1.bias\n",
      "135: stages.2.blocks.3.mlp.fc2.weight\n",
      "136: stages.2.blocks.3.mlp.fc2.bias\n",
      "137: stages.2.blocks.3.norm2.weight\n",
      "138: stages.2.blocks.3.norm2.bias\n",
      "139: stages.2.blocks.4.attn.t_scale\n",
      "140: stages.2.blocks.4.attn.crpb_mlp.0.weight\n",
      "141: stages.2.blocks.4.attn.crpb_mlp.0.bias\n",
      "142: stages.2.blocks.4.attn.crpb_mlp.3.weight\n",
      "143: stages.2.blocks.4.attn.qkv.weight\n",
      "144: stages.2.blocks.4.attn.qkv.bias\n",
      "145: stages.2.blocks.4.attn.proj.weight\n",
      "146: stages.2.blocks.4.attn.proj.bias\n",
      "147: stages.2.blocks.4.norm1.weight\n",
      "148: stages.2.blocks.4.norm1.bias\n",
      "149: stages.2.blocks.4.mlp.fc1.weight\n",
      "150: stages.2.blocks.4.mlp.fc1.bias\n",
      "151: stages.2.blocks.4.mlp.fc2.weight\n",
      "152: stages.2.blocks.4.mlp.fc2.bias\n",
      "153: stages.2.blocks.4.norm2.weight\n",
      "154: stages.2.blocks.4.norm2.bias\n",
      "155: stages.2.blocks.5.attn.t_scale\n",
      "156: stages.2.blocks.5.attn.crpb_mlp.0.weight\n",
      "157: stages.2.blocks.5.attn.crpb_mlp.0.bias\n",
      "158: stages.2.blocks.5.attn.crpb_mlp.3.weight\n",
      "159: stages.2.blocks.5.attn.qkv.weight\n",
      "160: stages.2.blocks.5.attn.qkv.bias\n",
      "161: stages.2.blocks.5.attn.proj.weight\n",
      "162: stages.2.blocks.5.attn.proj.bias\n",
      "163: stages.2.blocks.5.norm1.weight\n",
      "164: stages.2.blocks.5.norm1.bias\n",
      "165: stages.2.blocks.5.mlp.fc1.weight\n",
      "166: stages.2.blocks.5.mlp.fc1.bias\n",
      "167: stages.2.blocks.5.mlp.fc2.weight\n",
      "168: stages.2.blocks.5.mlp.fc2.bias\n",
      "169: stages.2.blocks.5.norm2.weight\n",
      "170: stages.2.blocks.5.norm2.bias\n",
      "171: stages.2.downsample.reduction.weight\n",
      "172: stages.2.downsample.norm.weight\n",
      "173: stages.2.downsample.norm.bias\n",
      "174: stages.3.blocks.0.attn.t_scale\n",
      "175: stages.3.blocks.0.attn.crpb_mlp.0.weight\n",
      "176: stages.3.blocks.0.attn.crpb_mlp.0.bias\n",
      "177: stages.3.blocks.0.attn.crpb_mlp.3.weight\n",
      "178: stages.3.blocks.0.attn.qkv.weight\n",
      "179: stages.3.blocks.0.attn.qkv.bias\n",
      "180: stages.3.blocks.0.attn.proj.weight\n",
      "181: stages.3.blocks.0.attn.proj.bias\n",
      "182: stages.3.blocks.0.norm1.weight\n",
      "183: stages.3.blocks.0.norm1.bias\n",
      "184: stages.3.blocks.0.mlp.fc1.weight\n",
      "185: stages.3.blocks.0.mlp.fc1.bias\n",
      "186: stages.3.blocks.0.mlp.fc2.weight\n",
      "187: stages.3.blocks.0.mlp.fc2.bias\n",
      "188: stages.3.blocks.0.norm2.weight\n",
      "189: stages.3.blocks.0.norm2.bias\n",
      "190: stages.3.blocks.1.attn.t_scale\n",
      "191: stages.3.blocks.1.attn.crpb_mlp.0.weight\n",
      "192: stages.3.blocks.1.attn.crpb_mlp.0.bias\n",
      "193: stages.3.blocks.1.attn.crpb_mlp.3.weight\n",
      "194: stages.3.blocks.1.attn.qkv.weight\n",
      "195: stages.3.blocks.1.attn.qkv.bias\n",
      "196: stages.3.blocks.1.attn.proj.weight\n",
      "197: stages.3.blocks.1.attn.proj.bias\n",
      "198: stages.3.blocks.1.norm1.weight\n",
      "199: stages.3.blocks.1.norm1.bias\n",
      "200: stages.3.blocks.1.mlp.fc1.weight\n",
      "201: stages.3.blocks.1.mlp.fc1.bias\n",
      "202: stages.3.blocks.1.mlp.fc2.weight\n",
      "203: stages.3.blocks.1.mlp.fc2.bias\n",
      "204: stages.3.blocks.1.norm2.weight\n",
      "205: stages.3.blocks.1.norm2.bias\n",
      "206: layernorm.weight\n",
      "207: layernorm.bias\n",
      "208: classifier.weight\n",
      "209: classifier.bias\n"
     ]
    }
   ],
   "source": [
    "layer_names = []\n",
    "for i, (name, params) in enumerate(model.named_parameters()):\n",
    "    print(f'{i}: {name}')\n",
    "    layer_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classifier.bias',\n",
       " 'classifier.weight',\n",
       " 'layernorm.bias',\n",
       " 'layernorm.weight',\n",
       " 'stages.3.blocks.1.norm2.bias']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_names.reverse()\n",
    "layer_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: classifier.bias's lr=0.0014, weight_decay=0\n",
      "1: classifier.weight's lr=0.0014, weight_decay=0.001\n",
      "2: layernorm.bias's lr=0.001218, weight_decay=0\n",
      "3: layernorm.weight's lr=0.001218, weight_decay=0\n",
      "4: stages.3.blocks.1.norm2.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "5: stages.3.blocks.1.norm2.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "6: stages.3.blocks.1.mlp.fc2.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "7: stages.3.blocks.1.mlp.fc2.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "8: stages.3.blocks.1.mlp.fc1.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "9: stages.3.blocks.1.mlp.fc1.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "10: stages.3.blocks.1.norm1.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "11: stages.3.blocks.1.norm1.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "12: stages.3.blocks.1.attn.proj.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "13: stages.3.blocks.1.attn.proj.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "14: stages.3.blocks.1.attn.qkv.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "15: stages.3.blocks.1.attn.qkv.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "16: stages.3.blocks.1.attn.crpb_mlp.3.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "17: stages.3.blocks.1.attn.crpb_mlp.0.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "18: stages.3.blocks.1.attn.crpb_mlp.0.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "19: stages.3.blocks.1.attn.t_scale's lr=0.0010596599999999998, weight_decay=0\n",
      "20: stages.3.blocks.0.norm2.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "21: stages.3.blocks.0.norm2.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "22: stages.3.blocks.0.mlp.fc2.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "23: stages.3.blocks.0.mlp.fc2.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "24: stages.3.blocks.0.mlp.fc1.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "25: stages.3.blocks.0.mlp.fc1.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "26: stages.3.blocks.0.norm1.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "27: stages.3.blocks.0.norm1.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "28: stages.3.blocks.0.attn.proj.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "29: stages.3.blocks.0.attn.proj.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "30: stages.3.blocks.0.attn.qkv.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "31: stages.3.blocks.0.attn.qkv.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "32: stages.3.blocks.0.attn.crpb_mlp.3.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "33: stages.3.blocks.0.attn.crpb_mlp.0.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "34: stages.3.blocks.0.attn.crpb_mlp.0.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "35: stages.3.blocks.0.attn.t_scale's lr=0.0010596599999999998, weight_decay=0\n",
      "36: stages.2.downsample.norm.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "37: stages.2.downsample.norm.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "38: stages.2.downsample.reduction.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "39: stages.2.blocks.5.norm2.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "40: stages.2.blocks.5.norm2.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "41: stages.2.blocks.5.mlp.fc2.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "42: stages.2.blocks.5.mlp.fc2.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "43: stages.2.blocks.5.mlp.fc1.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "44: stages.2.blocks.5.mlp.fc1.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "45: stages.2.blocks.5.norm1.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "46: stages.2.blocks.5.norm1.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "47: stages.2.blocks.5.attn.proj.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "48: stages.2.blocks.5.attn.proj.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "49: stages.2.blocks.5.attn.qkv.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "50: stages.2.blocks.5.attn.qkv.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "51: stages.2.blocks.5.attn.crpb_mlp.3.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "52: stages.2.blocks.5.attn.crpb_mlp.0.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "53: stages.2.blocks.5.attn.crpb_mlp.0.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "54: stages.2.blocks.5.attn.t_scale's lr=0.0010596599999999998, weight_decay=0\n",
      "55: stages.2.blocks.4.norm2.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "56: stages.2.blocks.4.norm2.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "57: stages.2.blocks.4.mlp.fc2.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "58: stages.2.blocks.4.mlp.fc2.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "59: stages.2.blocks.4.mlp.fc1.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "60: stages.2.blocks.4.mlp.fc1.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "61: stages.2.blocks.4.norm1.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "62: stages.2.blocks.4.norm1.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "63: stages.2.blocks.4.attn.proj.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "64: stages.2.blocks.4.attn.proj.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "65: stages.2.blocks.4.attn.qkv.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "66: stages.2.blocks.4.attn.qkv.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "67: stages.2.blocks.4.attn.crpb_mlp.3.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "68: stages.2.blocks.4.attn.crpb_mlp.0.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "69: stages.2.blocks.4.attn.crpb_mlp.0.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "70: stages.2.blocks.4.attn.t_scale's lr=0.0010596599999999998, weight_decay=0\n",
      "71: stages.2.blocks.3.norm2.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "72: stages.2.blocks.3.norm2.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "73: stages.2.blocks.3.mlp.fc2.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "74: stages.2.blocks.3.mlp.fc2.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "75: stages.2.blocks.3.mlp.fc1.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "76: stages.2.blocks.3.mlp.fc1.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "77: stages.2.blocks.3.norm1.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "78: stages.2.blocks.3.norm1.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "79: stages.2.blocks.3.attn.proj.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "80: stages.2.blocks.3.attn.proj.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "81: stages.2.blocks.3.attn.qkv.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "82: stages.2.blocks.3.attn.qkv.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "83: stages.2.blocks.3.attn.crpb_mlp.3.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "84: stages.2.blocks.3.attn.crpb_mlp.0.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "85: stages.2.blocks.3.attn.crpb_mlp.0.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "86: stages.2.blocks.3.attn.t_scale's lr=0.0010596599999999998, weight_decay=0\n",
      "87: stages.2.blocks.2.norm2.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "88: stages.2.blocks.2.norm2.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "89: stages.2.blocks.2.mlp.fc2.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "90: stages.2.blocks.2.mlp.fc2.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "91: stages.2.blocks.2.mlp.fc1.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "92: stages.2.blocks.2.mlp.fc1.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "93: stages.2.blocks.2.norm1.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "94: stages.2.blocks.2.norm1.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "95: stages.2.blocks.2.attn.proj.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "96: stages.2.blocks.2.attn.proj.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "97: stages.2.blocks.2.attn.qkv.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "98: stages.2.blocks.2.attn.qkv.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "99: stages.2.blocks.2.attn.crpb_mlp.3.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "100: stages.2.blocks.2.attn.crpb_mlp.0.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "101: stages.2.blocks.2.attn.crpb_mlp.0.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "102: stages.2.blocks.2.attn.t_scale's lr=0.0010596599999999998, weight_decay=0\n",
      "103: stages.2.blocks.1.norm2.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "104: stages.2.blocks.1.norm2.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "105: stages.2.blocks.1.mlp.fc2.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "106: stages.2.blocks.1.mlp.fc2.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "107: stages.2.blocks.1.mlp.fc1.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "108: stages.2.blocks.1.mlp.fc1.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "109: stages.2.blocks.1.norm1.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "110: stages.2.blocks.1.norm1.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "111: stages.2.blocks.1.attn.proj.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "112: stages.2.blocks.1.attn.proj.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "113: stages.2.blocks.1.attn.qkv.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "114: stages.2.blocks.1.attn.qkv.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "115: stages.2.blocks.1.attn.crpb_mlp.3.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "116: stages.2.blocks.1.attn.crpb_mlp.0.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "117: stages.2.blocks.1.attn.crpb_mlp.0.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "118: stages.2.blocks.1.attn.t_scale's lr=0.0010596599999999998, weight_decay=0\n",
      "119: stages.2.blocks.0.norm2.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "120: stages.2.blocks.0.norm2.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "121: stages.2.blocks.0.mlp.fc2.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "122: stages.2.blocks.0.mlp.fc2.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "123: stages.2.blocks.0.mlp.fc1.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "124: stages.2.blocks.0.mlp.fc1.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "125: stages.2.blocks.0.norm1.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "126: stages.2.blocks.0.norm1.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "127: stages.2.blocks.0.attn.proj.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "128: stages.2.blocks.0.attn.proj.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "129: stages.2.blocks.0.attn.qkv.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "130: stages.2.blocks.0.attn.qkv.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "131: stages.2.blocks.0.attn.crpb_mlp.3.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "132: stages.2.blocks.0.attn.crpb_mlp.0.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "133: stages.2.blocks.0.attn.crpb_mlp.0.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "134: stages.2.blocks.0.attn.t_scale's lr=0.0010596599999999998, weight_decay=0\n",
      "135: stages.1.downsample.norm.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "136: stages.1.downsample.norm.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "137: stages.1.downsample.reduction.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "138: stages.1.blocks.1.norm2.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "139: stages.1.blocks.1.norm2.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "140: stages.1.blocks.1.mlp.fc2.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "141: stages.1.blocks.1.mlp.fc2.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "142: stages.1.blocks.1.mlp.fc1.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "143: stages.1.blocks.1.mlp.fc1.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "144: stages.1.blocks.1.norm1.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "145: stages.1.blocks.1.norm1.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "146: stages.1.blocks.1.attn.proj.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "147: stages.1.blocks.1.attn.proj.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "148: stages.1.blocks.1.attn.qkv.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "149: stages.1.blocks.1.attn.qkv.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "150: stages.1.blocks.1.attn.crpb_mlp.3.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "151: stages.1.blocks.1.attn.crpb_mlp.0.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "152: stages.1.blocks.1.attn.crpb_mlp.0.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "153: stages.1.blocks.1.attn.t_scale's lr=0.0010596599999999998, weight_decay=0\n",
      "154: stages.1.blocks.0.norm2.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "155: stages.1.blocks.0.norm2.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "156: stages.1.blocks.0.mlp.fc2.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "157: stages.1.blocks.0.mlp.fc2.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "158: stages.1.blocks.0.mlp.fc1.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "159: stages.1.blocks.0.mlp.fc1.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "160: stages.1.blocks.0.norm1.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "161: stages.1.blocks.0.norm1.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "162: stages.1.blocks.0.attn.proj.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "163: stages.1.blocks.0.attn.proj.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "164: stages.1.blocks.0.attn.qkv.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "165: stages.1.blocks.0.attn.qkv.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "166: stages.1.blocks.0.attn.crpb_mlp.3.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "167: stages.1.blocks.0.attn.crpb_mlp.0.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "168: stages.1.blocks.0.attn.crpb_mlp.0.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "169: stages.1.blocks.0.attn.t_scale's lr=0.0010596599999999998, weight_decay=0\n",
      "170: stages.0.downsample.norm.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "171: stages.0.downsample.norm.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "172: stages.0.downsample.reduction.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "173: stages.0.blocks.1.norm2.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "174: stages.0.blocks.1.norm2.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "175: stages.0.blocks.1.mlp.fc2.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "176: stages.0.blocks.1.mlp.fc2.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "177: stages.0.blocks.1.mlp.fc1.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "178: stages.0.blocks.1.mlp.fc1.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "179: stages.0.blocks.1.norm1.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "180: stages.0.blocks.1.norm1.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "181: stages.0.blocks.1.attn.proj.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "182: stages.0.blocks.1.attn.proj.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "183: stages.0.blocks.1.attn.qkv.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "184: stages.0.blocks.1.attn.qkv.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "185: stages.0.blocks.1.attn.crpb_mlp.3.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "186: stages.0.blocks.1.attn.crpb_mlp.0.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "187: stages.0.blocks.1.attn.crpb_mlp.0.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "188: stages.0.blocks.1.attn.t_scale's lr=0.0010596599999999998, weight_decay=0\n",
      "189: stages.0.blocks.0.norm2.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "190: stages.0.blocks.0.norm2.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "191: stages.0.blocks.0.mlp.fc2.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "192: stages.0.blocks.0.mlp.fc2.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "193: stages.0.blocks.0.mlp.fc1.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "194: stages.0.blocks.0.mlp.fc1.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "195: stages.0.blocks.0.norm1.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "196: stages.0.blocks.0.norm1.weight's lr=0.0010596599999999998, weight_decay=0\n",
      "197: stages.0.blocks.0.attn.proj.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "198: stages.0.blocks.0.attn.proj.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "199: stages.0.blocks.0.attn.qkv.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "200: stages.0.blocks.0.attn.qkv.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "201: stages.0.blocks.0.attn.crpb_mlp.3.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "202: stages.0.blocks.0.attn.crpb_mlp.0.bias's lr=0.0010596599999999998, weight_decay=0\n",
      "203: stages.0.blocks.0.attn.crpb_mlp.0.weight's lr=0.0010596599999999998, weight_decay=0.001\n",
      "204: stages.0.blocks.0.attn.t_scale's lr=0.0010596599999999998, weight_decay=0\n",
      "205: embeddings.norm.bias's lr=0.0009219041999999998, weight_decay=0\n",
      "206: embeddings.norm.weight's lr=0.0009219041999999998, weight_decay=0\n",
      "207: embeddings.patch_embeddings.bias's lr=0.0009219041999999998, weight_decay=0\n",
      "208: embeddings.patch_embeddings.weight's lr=0.0009219041999999998, weight_decay=0.001\n",
      "209: absolute_pos_embed's lr=0.0008020566539999999, weight_decay=0\n"
     ]
    }
   ],
   "source": [
    "lr      = 1.4e-3   # paper : 1.4e-3\n",
    "lr_mult = 0.87     # paper : 0.87\n",
    "\n",
    "param_groups = []\n",
    "prev_group_name = layer_names[0].split('.')[0]\n",
    "\n",
    "for idx, name in enumerate(layer_names):\n",
    "    \n",
    "    cur_group_name = name.split('.')[0]\n",
    "    \n",
    "    if cur_group_name != prev_group_name:\n",
    "        lr *= lr_mult\n",
    "    prev_group_name = cur_group_name\n",
    "    weight_decay = 0.001 if ('weight' in name) and ('norm' not in name) else 0\n",
    "    \n",
    "    print(f\"{idx}: {name}'s lr={lr}, weight_decay={weight_decay}\")\n",
    "    \n",
    "    \n",
    "    param_groups += [{'params': [ p for n, p in model.named_parameters() if n == name and p.requires_grad],\n",
    "                      'lr' : lr,\n",
    "                      'weight_decay': weight_decay}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(param_groups)\n",
    "warmup_steps = int(len(train_loader)*(epochs)*0.1)\n",
    "train_steps = len(train_loader)*(epochs)\n",
    "# scheduler = transformers.get_cosine_schedule_with_warmup(optimizer, \n",
    "#                                                         num_warmup_steps=warmup_steps, \n",
    "#                                                         num_training_steps=train_steps,\n",
    "#                                                         num_cycles=0.5)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.995, patience=15, cooldown=0, min_lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_time = 0\n",
    "losses = []\n",
    "val_losses = []\n",
    "lrs = []\n",
    "best_loss = float('inf')\n",
    "\n",
    "# GradScaler 초기화\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 15/15 [01:01<00:00,  4.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.340172322591146, Val Loss: 4.035436153411865, LR: 0.0014, Duration: 63.12 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 15/15 [00:59<00:00,  3.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.153358205159505, Val Loss: 3.8062660694122314, LR: 0.0014, Duration: 60.24 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [00:59<00:00,  3.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.144686317443847, Val Loss: 3.5342018604278564, LR: 0.0014, Duration: 60.98 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [01:01<00:00,  4.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.052048126856486, Val Loss: 3.339047908782959, LR: 0.0014, Duration: 62.37 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [00:59<00:00,  3.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.933760325113932, Val Loss: 3.2138733863830566, LR: 0.0014, Duration: 61.09 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 15/15 [00:56<00:00,  3.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.9216849486033123, Val Loss: 3.142751455307007, LR: 0.0014, Duration: 57.46 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 15/15 [00:58<00:00,  3.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.916878620783488, Val Loss: 2.9953112602233887, LR: 0.0014, Duration: 59.98 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [01:02<00:00,  4.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.83636204401652, Val Loss: 2.920471668243408, LR: 0.0013986, Duration: 63.86 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 15/15 [00:59<00:00,  3.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6132465680440267, Val Loss: 2.76223087310791, LR: 0.0013986, Duration: 60.46 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 15/15 [01:02<00:00,  4.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7269989331563314, Val Loss: 2.7945940494537354, LR: 0.0013972014, Duration: 62.99 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 15/15 [01:01<00:00,  4.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6351690451304117, Val Loss: 2.635697364807129, LR: 0.0013972014, Duration: 63.29 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 15/15 [01:00<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.609499454498291, Val Loss: 2.5390453338623047, LR: 0.0013958041986, Duration: 62.26 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 15/15 [01:06<00:00,  4.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.591928799947103, Val Loss: 2.433502674102783, LR: 0.0013958041986, Duration: 68.44 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 15/15 [01:00<00:00,  4.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.610432195663452, Val Loss: 2.505781412124634, LR: 0.0013944083944014, Duration: 60.95 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 15/15 [00:58<00:00,  3.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5229860146840415, Val Loss: 2.4967780113220215, LR: 0.0013930139860069985, Duration: 59.09 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 15/15 [00:57<00:00,  3.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6343870798746747, Val Loss: 2.317534923553467, LR: 0.0013916209720209916, Duration: 58.49 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 15/15 [00:59<00:00,  3.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.3731011072794597, Val Loss: 2.209482431411743, LR: 0.0013902293510489705, Duration: 60.78 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 15/15 [00:57<00:00,  3.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2338952382405597, Val Loss: 2.107006788253784, LR: 0.0013888391216979215, Duration: 59.11 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 15/15 [00:58<00:00,  3.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.110334587097168, Val Loss: 2.318549871444702, LR: 0.0013888391216979215, Duration: 59.07 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 15/15 [01:03<00:00,  4.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.030100917816162, Val Loss: 1.955147385597229, LR: 0.0013874502825762236, Duration: 64.61 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 15/15 [01:01<00:00,  4.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.295830774307251, Val Loss: 2.01959490776062, LR: 0.0013860628322936474, Duration: 63.00 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 15/15 [01:00<00:00,  4.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.291981744766235, Val Loss: 2.0262670516967773, LR: 0.0013846767694613538, Duration: 61.34 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 15/15 [01:01<00:00,  4.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.352715508143107, Val Loss: 2.0961084365844727, LR: 0.0013832920926918925, Duration: 63.11 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 15/15 [00:57<00:00,  3.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.414275852839152, Val Loss: 1.9594488143920898, LR: 0.0013819088005992007, Duration: 58.85 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 15/15 [00:57<00:00,  3.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.428544537226359, Val Loss: 1.9673447608947754, LR: 0.0013791463649068028, Duration: 59.46 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 15/15 [00:59<00:00,  3.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2207149187723796, Val Loss: 1.8286243677139282, LR: 0.001377767218541896, Duration: 61.05 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 15/15 [01:00<00:00,  4.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2281993865966796, Val Loss: 1.8270021677017212, LR: 0.0013763894513233541, Duration: 61.82 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 15/15 [01:00<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1570994377136232, Val Loss: 1.854514718055725, LR: 0.0013750130618720307, Duration: 61.77 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 15/15 [00:57<00:00,  3.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0753050486246747, Val Loss: 1.7451640367507935, LR: 0.0013736380488101588, Duration: 58.27 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 15/15 [00:57<00:00,  3.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9017706712086997, Val Loss: 1.7104002237319946, LR: 0.0013736380488101588, Duration: 58.42 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 15/15 [00:56<00:00,  3.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.075744406382243, Val Loss: 1.6675705909729004, LR: 0.0013722644107613485, Duration: 58.14 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 15/15 [00:57<00:00,  3.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0526379267374675, Val Loss: 1.6157807111740112, LR: 0.001370892146350587, Duration: 58.49 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 15/15 [00:56<00:00,  3.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4476917107899983, Val Loss: 1.7044223546981812, LR: 0.0013681517329500322, Duration: 57.25 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 15/15 [00:57<00:00,  3.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8289339383443197, Val Loss: 1.5626744031906128, LR: 0.0013667835812170822, Duration: 58.80 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 15/15 [00:57<00:00,  3.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.09781543413798, Val Loss: 1.575901985168457, LR: 0.001365416797635865, Duration: 58.79 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 15/15 [00:59<00:00,  3.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7721808274586994, Val Loss: 1.5254740715026855, LR: 0.0013640513808382292, Duration: 60.97 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 15/15 [00:54<00:00,  3.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.69331685702006, Val Loss: 1.363842248916626, LR: 0.0013640513808382292, Duration: 56.04 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 15/15 [00:59<00:00,  4.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.932337172826131, Val Loss: 1.4765781164169312, LR: 0.001362687329457391, Duration: 61.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 15/15 [00:59<00:00,  3.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9058008035024008, Val Loss: 1.4038830995559692, LR: 0.0013613246421279336, Duration: 61.26 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 15/15 [00:56<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.720502249399821, Val Loss: 1.3214634656906128, LR: 0.0013599633174858057, Duration: 58.19 sec - model saved!\n",
      "Epoch 당 평균 소요시간 : 17.32초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.692000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.728646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.692000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.680410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.692000\n",
       "1  Precision  0.728646\n",
       "2     Recall  0.692000\n",
       "3   F1 Score  0.680410"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.patience = 10\n",
    "scheduler.factor = 0.999\n",
    "\n",
    "for epoch in range(40):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step(loss)\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "text = f\"Epoch 당 평균 소요시간 : {training_time / 140:.2f}초\"      \n",
    "print(text)\n",
    "\n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 15/15 [01:00<00:00,  4.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.808193063735962, Val Loss: 1.3134479522705078, LR: 0.0013558834275333484, Duration: 61.69 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 15/15 [00:55<00:00,  3.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.73260277112325, Val Loss: 1.307052731513977, LR: 0.0013518157772507483, Duration: 57.16 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [00:58<00:00,  3.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8334129174550373, Val Loss: 1.3000553846359253, LR: 0.0013518157772507483, Duration: 60.11 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [00:56<00:00,  3.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5652300993601482, Val Loss: 1.1967358589172363, LR: 0.001347760329918996, Duration: 57.38 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [00:59<00:00,  3.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7339720567067465, Val Loss: 1.2641109228134155, LR: 0.0013437170489292388, Duration: 60.29 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 15/15 [01:00<00:00,  4.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.815976142883301, Val Loss: 1.233073353767395, LR: 0.0013356668400891039, Duration: 61.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 15/15 [00:57<00:00,  3.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7207348187764486, Val Loss: 1.237260341644287, LR: 0.0013316598395688366, Duration: 58.51 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [00:49<00:00,  3.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.704908092816671, Val Loss: 1.2616735696792603, LR: 0.00132766486005013, Duration: 50.86 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 15/15 [00:51<00:00,  3.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.675797971089681, Val Loss: 1.2073650360107422, LR: 0.0013197108198735696, Duration: 51.91 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 15/15 [00:50<00:00,  3.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6111996014912924, Val Loss: 1.1273128986358643, LR: 0.0013157516874139489, Duration: 51.90 sec - model saved!\n",
      "Epoch 당 평균 소요시간 : 21.40초\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.784343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.724010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.740000\n",
       "1  Precision  0.784343\n",
       "2     Recall  0.740000\n",
       "3   F1 Score  0.724010"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.patience = 10\n",
    "scheduler.factor = 0.997\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step(loss)\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "text = f\"Epoch 당 평균 소요시간 : {training_time / 140:.2f}초\"      \n",
    "print(text)\n",
    "\n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 15/15 [00:50<00:00,  3.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.842980949083964, Val Loss: 1.2635961771011353, LR: 0.001309172928976879, Duration: 51.78 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 15/15 [00:49<00:00,  3.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9042539596557617, Val Loss: 1.2232556343078613, LR: 0.0013026270643319946, Duration: 50.38 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [00:50<00:00,  3.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.646748733520508, Val Loss: 1.174555778503418, LR: 0.0012961139290103346, Duration: 51.45 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [00:49<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7460702816645304, Val Loss: 1.1397051811218262, LR: 0.0012831851925684565, Duration: 50.54 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [00:49<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.694928463300069, Val Loss: 1.0958162546157837, LR: 0.0012767692666056142, Duration: 50.71 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 15/15 [00:50<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.847249666849772, Val Loss: 1.1196513175964355, LR: 0.0012640334931712232, Duration: 51.36 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 15/15 [00:49<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6048757314682005, Val Loss: 1.0698407888412476, LR: 0.0012577133257053671, Duration: 50.84 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [00:50<00:00,  3.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.533098077774048, Val Loss: 1.0733193159103394, LR: 0.0012577133257053671, Duration: 51.63 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 15/15 [00:49<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.595039129257202, Val Loss: 1.060990333557129, LR: 0.001245167635281456, Duration: 50.68 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 15/15 [00:50<00:00,  3.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4993491729100543, Val Loss: 1.0835155248641968, LR: 0.0012389417971050488, Duration: 51.63 sec\n",
      "Epoch 당 평균 소요시간 : 25.05초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.756000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.788567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.756000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.742999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.756000\n",
       "1  Precision  0.788567\n",
       "2     Recall  0.756000\n",
       "3   F1 Score  0.742999"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.patience = 10\n",
    "scheduler.factor = 0.995\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step(loss)\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "text = f\"Epoch 당 평균 소요시간 : {training_time / 140:.2f}초\"      \n",
    "print(text)\n",
    "\n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 15/15 [00:51<00:00,  3.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7743065198262533, Val Loss: 1.062842845916748, LR: 0.0012265523791339982, Duration: 52.58 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 15/15 [00:51<00:00,  3.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.658196528752645, Val Loss: 1.0067086219787598, LR: 0.0012142868553426582, Duration: 52.93 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [00:50<00:00,  3.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8289355595906573, Val Loss: 1.0778735876083374, LR: 0.0012021439867892316, Duration: 51.84 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [00:50<00:00,  3.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.644362473487854, Val Loss: 1.1049858331680298, LR: 0.0011901225469213392, Duration: 51.53 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [00:51<00:00,  3.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.920937196413676, Val Loss: 1.112850308418274, LR: 0.001178221321452126, Duration: 52.64 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 15/15 [00:54<00:00,  3.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.644992470741272, Val Loss: 1.0265334844589233, LR: 0.0011664391082376047, Duration: 55.28 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 15/15 [00:50<00:00,  3.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4822524229685468, Val Loss: 1.0359721183776855, LR: 0.0011432269699836763, Duration: 50.94 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [00:49<00:00,  3.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6694626331329347, Val Loss: 0.9785546660423279, LR: 0.0011317947002838396, Duration: 51.03 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 15/15 [00:50<00:00,  3.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.595569348335266, Val Loss: 1.0423051118850708, LR: 0.0011204767532810012, Duration: 51.48 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 15/15 [00:50<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.310609229405721, Val Loss: 0.8720196485519409, LR: 0.0010981792658907093, Duration: 51.43 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 15/15 [00:50<00:00,  3.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5829378763834634, Val Loss: 0.8686122298240662, LR: 0.0010871974732318023, Duration: 52.02 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 15/15 [00:50<00:00,  3.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.100257086753845, Val Loss: 0.9158116579055786, LR: 0.0010763254984994843, Duration: 51.48 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 15/15 [00:50<00:00,  3.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.596622172991435, Val Loss: 0.9369667172431946, LR: 0.0010549066210793444, Duration: 51.89 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 15/15 [00:50<00:00,  3.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4120136976242064, Val Loss: 0.8889124989509583, LR: 0.001044357554868551, Duration: 51.06 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 15/15 [00:49<00:00,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.549227492014567, Val Loss: 0.8845806121826172, LR: 0.0010235748395266667, Duration: 50.69 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 15/15 [00:50<00:00,  3.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6580675999323526, Val Loss: 0.9230980277061462, LR: 0.0010133390911314, Duration: 51.69 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 15/15 [00:49<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.415466531117757, Val Loss: 0.8858816623687744, LR: 0.001003205700220086, Duration: 50.56 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 15/15 [00:51<00:00,  3.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.584823568662008, Val Loss: 0.9156133532524109, LR: 0.0009931736432178852, Duration: 52.57 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 15/15 [00:50<00:00,  3.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1454006830851235, Val Loss: 0.8316169381141663, LR: 0.0009832419067857064, Duration: 51.40 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 15/15 [00:49<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.273539145787557, Val Loss: 0.9453110694885254, LR: 0.0009636753928406707, Duration: 50.60 sec\n",
      "Epoch 당 평균 소요시간 : 32.45초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.788000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.831946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.788000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.776648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.788000\n",
       "1  Precision  0.831946\n",
       "2     Recall  0.788000\n",
       "3   F1 Score  0.776648"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.patience = 10\n",
    "scheduler.factor = 0.99\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step(loss)\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "text = f\"Epoch 당 평균 소요시간 : {training_time / 140:.2f}초\"      \n",
    "print(text)\n",
    "\n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 15/15 [00:49<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2106648763020833, Val Loss: 0.8211269378662109, LR: 0.000954062730797085, Duration: 50.67 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 15/15 [00:51<00:00,  3.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.239103651046753, Val Loss: 0.8326651453971863, LR: 0.0009398232252820971, Duration: 52.00 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [00:50<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.523933005332947, Val Loss: 0.8309059739112854, LR: 0.0009304484886099081, Duration: 51.21 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [00:50<00:00,  3.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.228919585545858, Val Loss: 0.8204583525657654, LR: 0.0009165614286113441, Duration: 51.39 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [00:50<00:00,  3.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.526839240392049, Val Loss: 0.8175793290138245, LR: 0.0009074187283609459, Duration: 51.83 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 15/15 [00:49<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4790159384409587, Val Loss: 0.8352329134941101, LR: 0.0008938753904128178, Duration: 50.59 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 15/15 [00:49<00:00,  3.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.098499361673991, Val Loss: 0.8064895272254944, LR: 0.0008849589833934499, Duration: 50.66 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [00:49<00:00,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2405723412831624, Val Loss: 0.8198403716087341, LR: 0.0008717508599464297, Duration: 50.72 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 15/15 [00:49<00:00,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.113305083910624, Val Loss: 0.7535692453384399, LR: 0.0008630551451184641, Duration: 50.87 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 15/15 [00:49<00:00,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0740604480107625, Val Loss: 0.8467116355895996, LR: 0.0008501739391956779, Duration: 50.63 sec\n",
      "Epoch 당 평균 소요시간 : 36.10초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.798000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.832226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.798000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.785678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.798000\n",
       "1  Precision  0.832226\n",
       "2     Recall  0.798000\n",
       "3   F1 Score  0.785678"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.patience = 5\n",
    "scheduler.factor = 0.995\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step(loss)\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "text = f\"Epoch 당 평균 소요시간 : {training_time / 140:.2f}초\"      \n",
    "print(text)\n",
    "\n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 15/15 [00:49<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2757031202316282, Val Loss: 0.7478190064430237, LR: 0.0008416934541522011, Duration: 50.86 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 15/15 [00:49<00:00,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2322168668111164, Val Loss: 0.7736088633537292, LR: 0.0008291310741372976, Duration: 50.69 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [00:49<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2529861370722455, Val Loss: 0.7956263422966003, LR: 0.0008208604916727781, Duration: 50.51 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [00:49<00:00,  3.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1227898279825848, Val Loss: 0.7767680883407593, LR: 0.000812672408268342, Duration: 50.39 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [00:49<00:00,  3.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3194057941436768, Val Loss: 0.8005263805389404, LR: 0.000800543170990886, Duration: 50.32 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 15/15 [00:49<00:00,  3.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4707831382751464, Val Loss: 0.792820394039154, LR: 0.0007925577528602518, Duration: 50.31 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 15/15 [00:49<00:00,  3.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2356916824976603, Val Loss: 0.7687862515449524, LR: 0.0007807287293290935, Duration: 50.30 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [00:49<00:00,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3557947874069214, Val Loss: 0.7340813279151917, LR: 0.0007729409602540357, Duration: 50.90 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 15/15 [00:55<00:00,  3.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.876155670483907, Val Loss: 0.7329203486442566, LR: 0.0007614047198046242, Duration: 56.71 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 15/15 [00:58<00:00,  3.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.298151969909668, Val Loss: 0.765203058719635, LR: 0.0007538097077245731, Duration: 60.03 sec\n",
      "Epoch 당 평균 소요시간 : 39.82초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.862500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.828327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.840000\n",
       "1  Precision  0.862500\n",
       "2     Recall  0.840000\n",
       "3   F1 Score  0.828327"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.patience = 5\n",
    "scheduler.factor = 0.995\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step(loss)\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "text = f\"Epoch 당 평균 소요시간 : {training_time / 140:.2f}초\"      \n",
    "print(text)\n",
    "\n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 15/15 [00:58<00:00,  3.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.60145210425059, Val Loss: 0.7812684774398804, LR: 0.0007425590036105703, Duration: 59.17 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 15/15 [00:57<00:00,  3.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.346863055229187, Val Loss: 0.7327495813369751, LR: 0.0007351519775495549, Duration: 59.20 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [01:00<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1364832719167075, Val Loss: 0.7528130412101746, LR: 0.0007278188365734982, Duration: 61.74 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [00:59<00:00,  3.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.102743212381999, Val Loss: 0.7640179395675659, LR: 0.0007169560494602841, Duration: 60.44 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [00:56<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.315244611104329, Val Loss: 0.7154175043106079, LR: 0.0007098044128669178, Duration: 58.04 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 15/15 [00:55<00:00,  3.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8862164576848348, Val Loss: 0.7408918738365173, LR: 0.0006992104932793276, Duration: 56.26 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 15/15 [00:58<00:00,  3.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.21046667098999, Val Loss: 0.7008274793624878, LR: 0.0006922358686088663, Duration: 59.62 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [01:00<00:00,  4.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.129128090540568, Val Loss: 0.6816051602363586, LR: 0.0006819041617403954, Duration: 61.82 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 15/15 [01:00<00:00,  4.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0872928857803346, Val Loss: 0.7515966296195984, LR: 0.000675102167727035, Duration: 61.49 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 15/15 [01:01<00:00,  4.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.252559773127238, Val Loss: 0.724753737449646, LR: 0.000665026183485938, Duration: 62.40 sec\n",
      "Epoch 당 평균 소요시간 : 44.11초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.858000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.870497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.858000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.847282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.858000\n",
       "1  Precision  0.870497\n",
       "2     Recall  0.858000\n",
       "3   F1 Score  0.847282"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 110epoch\n",
    "\n",
    "scheduler.patience = 5\n",
    "scheduler.factor = 0.995\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step(loss)\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "text = f\"Epoch 당 평균 소요시간 : {training_time / 140:.2f}초\"      \n",
    "print(text)\n",
    "\n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 15/15 [01:02<00:00,  4.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.218955906232198, Val Loss: 0.7537941932678223, LR: 0.0006544283262259061, Duration: 65.04 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 15/15 [00:58<00:00,  3.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8485124746958415, Val Loss: 0.7182289958000183, LR: 0.00064399935641917, Duration: 59.26 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [00:59<00:00,  3.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8642268180847168, Val Loss: 0.6804907917976379, LR: 0.0006337365826752742, Duration: 60.86 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [00:59<00:00,  3.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2650489091873167, Val Loss: 0.7456719279289246, LR: 0.000618648257641811, Duration: 60.85 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [01:00<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.017345102628072, Val Loss: 0.7414253354072571, LR: 0.000608789479008031, Duration: 62.24 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 15/15 [00:59<00:00,  3.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8815668900807698, Val Loss: 0.6825773119926453, LR: 0.0005942951073915944, Duration: 60.12 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 15/15 [00:56<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2079657316207886, Val Loss: 0.7189444303512573, LR: 0.000584824420560202, Duration: 57.87 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [00:59<00:00,  3.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8801514466603597, Val Loss: 0.7250614762306213, LR: 0.0005755046585941546, Duration: 60.68 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 15/15 [01:01<00:00,  4.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.001438927650452, Val Loss: 0.7246949672698975, LR: 0.0005709006213254013, Duration: 62.73 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 15/15 [00:56<00:00,  3.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0894200483957928, Val Loss: 0.7067505717277527, LR: 0.000557308327031768, Duration: 58.07 sec\n",
      "Epoch 당 평균 소요시간 : 48.45초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.858000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.867700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.858000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.847296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.858000\n",
       "1  Precision  0.867700\n",
       "2     Recall  0.858000\n",
       "3   F1 Score  0.847296"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 120epoch\n",
    "\n",
    "scheduler.patience = 5\n",
    "scheduler.factor = 0.992\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step(loss)\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "text = f\"Epoch 당 평균 소요시간 : {training_time / 140:.2f}초\"      \n",
    "print(text)\n",
    "\n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 15/15 [01:04<00:00,  4.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1907376686731976, Val Loss: 0.7075365781784058, LR: 0.0005484270615321898, Duration: 65.46 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 15/15 [00:57<00:00,  3.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9191447257995606, Val Loss: 0.7136329412460327, LR: 0.0005396873278796128, Duration: 58.92 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [00:59<00:00,  3.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.039937233924866, Val Loss: 0.7116752862930298, LR: 0.000526838175657543, Duration: 60.97 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [00:59<00:00,  3.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.114402914047241, Val Loss: 0.6783581972122192, LR: 0.0005184424824902645, Duration: 60.33 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [00:58<00:00,  3.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2357025146484375, Val Loss: 0.7294452786445618, LR: 0.0005101805830892997, Duration: 60.54 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 15/15 [00:59<00:00,  3.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7399816751480102, Val Loss: 0.696643054485321, LR: 0.000498033942554651, Duration: 60.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 15/15 [00:59<00:00,  3.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0515719254811606, Val Loss: 0.7121743559837341, LR: 0.0004900972736461001, Duration: 60.90 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [01:00<00:00,  4.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9442116657892863, Val Loss: 0.6686605215072632, LR: 0.0004784287868253297, Duration: 61.92 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 15/15 [00:58<00:00,  3.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.861712646484375, Val Loss: 0.6996737122535706, LR: 0.0004708045456784812, Duration: 59.51 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 15/15 [01:01<00:00,  4.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0569488843282064, Val Loss: 0.7071292400360107, LR: 0.0004633018044385489, Duration: 62.24 sec\n",
      "Epoch 당 평균 소요시간 : 52.81초\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.846000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.871258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.846000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.841373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.846000\n",
       "1  Precision  0.871258\n",
       "2     Recall  0.846000\n",
       "3   F1 Score  0.841373"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 130epoch\n",
    "\n",
    "scheduler.patience = 5\n",
    "scheduler.factor = 0.992\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step(loss)\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "text = f\"Epoch 당 평균 소요시간 : {training_time / 140:.2f}초\"      \n",
    "print(text)\n",
    "\n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 15/15 [01:00<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1174822251001992, Val Loss: 0.678213894367218, LR: 0.00046098529541635616, Duration: 61.91 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 15/15 [01:01<00:00,  4.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7602103710174561, Val Loss: 0.6407973170280457, LR: 0.00045868036893927436, Duration: 62.52 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [00:57<00:00,  3.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8254571199417113, Val Loss: 0.7213470339775085, LR: 0.000456386967094578, Duration: 58.14 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [00:58<00:00,  3.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.117799750963847, Val Loss: 0.6914110779762268, LR: 0.00045183450709780957, Duration: 59.82 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [00:57<00:00,  3.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8514612913131714, Val Loss: 0.6645406484603882, LR: 0.00044732745788950894, Duration: 58.90 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 15/15 [00:57<00:00,  3.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0382359345753986, Val Loss: 0.7137114405632019, LR: 0.0004450908206000614, Duration: 58.71 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 15/15 [01:03<00:00,  4.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7497926473617553, Val Loss: 0.6960091590881348, LR: 0.0004428653664970611, Duration: 64.54 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [00:58<00:00,  3.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0644738753636678, Val Loss: 0.6879010796546936, LR: 0.00043844778446625293, Duration: 59.47 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 15/15 [00:59<00:00,  3.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0992001136144003, Val Loss: 0.6802278161048889, LR: 0.00043407426781620205, Duration: 60.82 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 15/15 [01:04<00:00,  4.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.826917052268982, Val Loss: 0.656933069229126, LR: 0.00043190389647712103, Duration: 65.66 sec\n",
      "Epoch 당 평균 소요시간 : 57.17초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.862000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.868069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.862000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.850902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.862000\n",
       "1  Precision  0.868069\n",
       "2     Recall  0.862000\n",
       "3   F1 Score  0.850902"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 140epoch\n",
    "\n",
    "scheduler.patience = 8\n",
    "scheduler.factor = 0.995\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step(loss)\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "text = f\"Epoch 당 평균 소요시간 : {training_time / 140:.2f}초\"      \n",
    "print(text)\n",
    "\n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 15/15 [00:59<00:00,  3.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.009361656506856, Val Loss: 0.6809298992156982, LR: 0.00042759565510976175, Duration: 60.44 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 15/15 [00:59<00:00,  3.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.901632340749105, Val Loss: 0.6821280121803284, LR: 0.00042545767683421293, Duration: 60.45 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [00:59<00:00,  3.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.923009745279948, Val Loss: 0.6584545969963074, LR: 0.00042333038845004185, Duration: 60.83 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [00:58<00:00,  3.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7790445804595947, Val Loss: 0.6871077418327332, LR: 0.00041910766782525267, Duration: 59.47 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [00:55<00:00,  3.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.079659406344096, Val Loss: 0.6806285381317139, LR: 0.0004170121294861264, Duration: 56.87 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 15/15 [01:01<00:00,  4.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.960542416572571, Val Loss: 0.6873165965080261, LR: 0.00041492706883869575, Duration: 62.20 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 15/15 [00:56<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9141552289326986, Val Loss: 0.6622278690338135, LR: 0.0004128524334945023, Duration: 57.79 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [00:58<00:00,  3.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6106655756632486, Val Loss: 0.7387936115264893, LR: 0.0004107881713270298, Duration: 59.73 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 15/15 [00:57<00:00,  3.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7791875044504801, Val Loss: 0.6787972450256348, LR: 0.0004066905593180427, Duration: 58.86 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 15/15 [00:57<00:00,  3.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7576055844624838, Val Loss: 0.7582470178604126, LR: 0.00040465710652145246, Duration: 58.87 sec\n",
      "Epoch 당 평균 소요시간 : 61.43초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.868000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.880440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.868000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.857877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.868000\n",
       "1  Precision  0.880440\n",
       "2     Recall  0.868000\n",
       "3   F1 Score  0.857877"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 150epoch\n",
    "\n",
    "scheduler.patience = 10\n",
    "scheduler.factor = 0.995\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step(loss)\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "text = f\"Epoch 당 평균 소요시간 : {training_time / 140:.2f}초\"      \n",
    "print(text)\n",
    "\n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 15/15 [01:00<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4397730668385824, Val Loss: 0.7236201167106628, LR: 0.00039982302905675694, Duration: 61.86 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 15/15 [00:55<00:00,  3.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.106094495455424, Val Loss: 0.706957995891571, LR: 0.0003950467000031435, Duration: 56.34 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [00:58<00:00,  3.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1171084086100262, Val Loss: 0.6975387930870056, LR: 0.0003903274294918611, Duration: 59.35 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [00:55<00:00,  3.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0503268877665204, Val Loss: 0.7165981531143188, LR: 0.00038682501092819003, Duration: 56.69 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [00:57<00:00,  3.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.287882669766744, Val Loss: 0.7083922624588013, LR: 0.00038220395760187346, Duration: 58.37 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 15/15 [01:02<00:00,  4.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.018454607327779, Val Loss: 0.6772413849830627, LR: 0.00037763810787729257, Duration: 63.61 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 15/15 [00:59<00:00,  3.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8184475580851236, Val Loss: 0.687101423740387, LR: 0.0003742495509390807, Duration: 61.30 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [00:59<00:00,  3.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8136982282002767, Val Loss: 0.6594724655151367, LR: 0.00037089139961376643, Duration: 60.76 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 15/15 [01:00<00:00,  4.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.96997180779775, Val Loss: 0.7123927474021912, LR: 0.00036756338107096434, Duration: 61.29 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 15/15 [01:01<00:00,  4.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7425193071365357, Val Loss: 0.7457737326622009, LR: 0.0003631724292536181, Duration: 62.92 sec\n",
      "Epoch 당 평균 소요시간 : 65.73초\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.862000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.887795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.862000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.853060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.862000\n",
       "1  Precision  0.887795\n",
       "2     Recall  0.862000\n",
       "3   F1 Score  0.853060"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 160epoch\n",
    "\n",
    "scheduler.patience = 3\n",
    "scheduler.factor = 0.997\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step(loss)\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "text = f\"Epoch 당 평균 소요시간 : {training_time / 140:.2f}초\"      \n",
    "print(text)\n",
    "\n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 15/15 [00:59<00:00,  3.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9909067233403523, Val Loss: 0.6516016721725464, LR: 0.0003631724292536181, Duration: 60.84 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 15/15 [00:59<00:00,  3.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1272001028060914, Val Loss: 0.7385002374649048, LR: 0.00035954978427181326, Duration: 61.08 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [00:59<00:00,  3.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.051247787475586, Val Loss: 0.6641517281532288, LR: 0.0003577520353504542, Duration: 59.98 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [00:58<00:00,  3.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3228017648061114, Val Loss: 0.701945424079895, LR: 0.0003559632751737019, Duration: 59.50 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [01:01<00:00,  4.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.075009806950887, Val Loss: 0.6820447444915771, LR: 0.00035241254150384423, Duration: 62.77 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 15/15 [00:57<00:00,  3.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9885664304097495, Val Loss: 0.7403964400291443, LR: 0.000350650478796325, Duration: 58.66 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 15/15 [00:59<00:00,  3.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9281107346216837, Val Loss: 0.7190037965774536, LR: 0.00034889722640234336, Duration: 60.56 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [01:00<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.29264444510142, Val Loss: 0.696998119354248, LR: 0.0003471527402703316, Duration: 62.05 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 15/15 [00:55<00:00,  3.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.780273691813151, Val Loss: 0.6922479867935181, LR: 0.00034541697656897995, Duration: 56.66 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 15/15 [00:57<00:00,  3.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7368985414505005, Val Loss: 0.681572437286377, LR: 0.000343689891686135, Duration: 59.34 sec\n",
      "Epoch 당 평균 소요시간 : 70.03초\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.902619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.874180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.880000\n",
       "1  Precision  0.902619\n",
       "2     Recall  0.880000\n",
       "3   F1 Score  0.874180"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 170epoch\n",
    "\n",
    "scheduler.patience = 10\n",
    "scheduler.factor = 0.995\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step(loss)\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "text = f\"Epoch 당 평균 소요시간 : {training_time / 140:.2f}초\"      \n",
    "print(text)\n",
    "\n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 15/15 [00:58<00:00,  3.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9207942485809326, Val Loss: 0.7247791290283203, LR: 0.0003419714422277044, Duration: 59.22 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 15/15 [01:02<00:00,  4.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6695809841156006, Val Loss: 0.6604286432266235, LR: 0.00034026158501656586, Duration: 63.47 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [01:00<00:00,  4.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.869263776143392, Val Loss: 0.6799898743629456, LR: 0.000338560277091483, Duration: 61.21 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [01:00<00:00,  4.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.123620788256327, Val Loss: 0.7066653966903687, LR: 0.0003368674757060256, Duration: 61.65 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [00:59<00:00,  3.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9896815776824952, Val Loss: 0.6960533857345581, LR: 0.0003368674757060256, Duration: 61.02 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 15/15 [00:55<00:00,  3.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0518582661946616, Val Loss: 0.738064169883728, LR: 0.0003351831383274955, Duration: 56.54 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 15/15 [00:59<00:00,  3.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.125382494926453, Val Loss: 0.7477477192878723, LR: 0.00033350722263585797, Duration: 60.31 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [01:00<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8776395797729493, Val Loss: 0.6630567908287048, LR: 0.00033183968652267866, Duration: 62.24 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 15/15 [00:58<00:00,  3.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0711019396781922, Val Loss: 0.7425994873046875, LR: 0.0003301804880900653, Duration: 59.43 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 15/15 [01:01<00:00,  4.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.061288364728292, Val Loss: 0.6886123418807983, LR: 0.0003301804880900653, Duration: 62.90 sec\n",
      "Epoch 당 평균 소요시간 : 74.37초\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.866000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.894123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.866000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.858753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.866000\n",
       "1  Precision  0.894123\n",
       "2     Recall  0.866000\n",
       "3   F1 Score  0.858753"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 180epoch\n",
    "\n",
    "scheduler.patience = 15\n",
    "scheduler.factor = 0.995\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step(loss)\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "text = f\"Epoch 당 평균 소요시간 : {training_time / 140:.2f}초\"      \n",
    "print(text)\n",
    "\n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 15/15 [00:58<00:00,  3.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8282082637151083, Val Loss: 0.697726845741272, LR: 0.0003220081093150083, Duration: 59.10 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 15/15 [00:59<00:00,  3.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7329445044199625, Val Loss: 0.6981560587882996, LR: 0.00031403800710459436, Duration: 60.45 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [00:59<00:00,  3.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4091460466384889, Val Loss: 0.7025995254516602, LR: 0.00030626517486163413, Duration: 60.73 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [00:58<00:00,  3.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0311330636342366, Val Loss: 0.7139566540718079, LR: 0.00029868472990846176, Duration: 59.15 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [00:55<00:00,  3.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7982971350351968, Val Loss: 0.7342901825904846, LR: 0.00029129191041977136, Duration: 56.69 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 15/15 [00:59<00:00,  3.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7751157363255818, Val Loss: 0.709559440612793, LR: 0.0002840820724313709, Duration: 60.35 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 15/15 [00:57<00:00,  3.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.016057848930359, Val Loss: 0.7293341755867004, LR: 0.00027705068692297264, Duration: 59.28 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [00:59<00:00,  3.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6244744539260865, Val Loss: 0.7450340986251831, LR: 0.00027019333697318797, Duration: 60.71 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 15/15 [00:56<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.6998414595921834, Val Loss: 0.6657052040100098, LR: 0.0002635057149849401, Duration: 57.83 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 15/15 [00:57<00:00,  3.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8506046136220295, Val Loss: 0.7529097199440002, LR: 0.000256983619979551, Duration: 59.15 sec\n",
      "Epoch 당 평균 소요시간 : 78.61초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.878000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.889270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.878000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.869401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.878000\n",
       "1  Precision  0.889270\n",
       "2     Recall  0.878000\n",
       "3   F1 Score  0.869401"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 190epoch\n",
    "\n",
    "scheduler.patience = 2\n",
    "scheduler.factor = 0.995\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step(loss)\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "text = f\"Epoch 당 평균 소요시간 : {training_time / 140:.2f}초\"      \n",
    "print(text)\n",
    "\n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 15/15 [00:56<00:00,  3.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7007097721099853, Val Loss: 0.7343989014625549, LR: 0.00024688237602718825, Duration: 57.12 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 15/15 [01:02<00:00,  4.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.224654499689738, Val Loss: 0.723198652267456, LR: 0.00023837003138763317, Duration: 63.56 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [00:58<00:00,  3.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5341689149538675, Val Loss: 0.7037097215652466, LR: 0.0002290004309509577, Duration: 59.93 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [00:59<00:00,  3.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5219367106755575, Val Loss: 0.7519549131393433, LR: 0.00022110464421141933, Duration: 60.18 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [01:00<00:00,  4.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8539026578267415, Val Loss: 0.6919386982917786, LR: 0.00021241369359613251, Duration: 63.09 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 15/15 [00:59<00:00,  3.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8236084183057149, Val Loss: 0.7143480181694031, LR: 0.00020508980683212947, Duration: 60.42 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 15/15 [00:58<00:00,  3.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.081143919626872, Val Loss: 0.7369121313095093, LR: 0.00019801844294658983, Duration: 59.13 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [00:59<00:00,  3.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5185951550801595, Val Loss: 0.7258985638618469, LR: 0.00019023494063842835, Duration: 60.01 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 15/15 [00:56<00:00,  3.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9321374495824177, Val Loss: 0.7295048832893372, LR: 0.0001836757629309792, Duration: 57.42 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 15/15 [00:58<00:00,  3.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5431052923202515, Val Loss: 0.6950064301490784, LR: 0.00017645602772120285, Duration: 59.05 sec\n",
      "Epoch 당 평균 소요시간 : 82.89초\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.878000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.904091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.878000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.871493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.878000\n",
       "1  Precision  0.904091\n",
       "2     Recall  0.878000\n",
       "3   F1 Score  0.871493"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 200epoch\n",
    "\n",
    "scheduler.patience = 1\n",
    "scheduler.factor = 0.995\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs, labels = mixup_fn(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AutoCast 적용\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 스케일링된 그라디언트 계산\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 그라디언트 클리핑 전에 스케일링 제거\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "        # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step(loss)\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        vit_save = True\n",
    "        if vit_save:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss}, Val Loss: {val_loss}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "    \n",
    "    if vit_save:\n",
    "        text += f' - model saved!'\n",
    "        vit_save = False\n",
    "\n",
    "    print(text)\n",
    "        \n",
    "text = f\"Epoch 당 평균 소요시간 : {training_time / 140:.2f}초\"      \n",
    "print(text)\n",
    "\n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "performance_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
