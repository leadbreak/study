{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51243cb9",
   "metadata": {},
   "source": [
    "```\n",
    "[pre-works]\n",
    "compare with open source code of [lucidrains](https://github.com/lucidrains/minGRU-pytorch)\n",
    "to check my code\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20ec8bf0",
   "metadata": {
    "id": "20ec8bf0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3390f4",
   "metadata": {
    "id": "5a3390f4"
   },
   "source": [
    "## Hyperparameters and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0c61f36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1732703737281,
     "user": {
      "displayName": "Hugman Sangkeun Jung",
      "userId": "08689291704194029524"
     },
     "user_tz": -540
    },
    "id": "d0c61f36",
    "outputId": "45d9894c-a14d-4164-9f2d-699025751e72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "# Modified hyperparameters\n",
    "SEQUENCE_LENGTH = 128\n",
    "\n",
    "EMBEDDING_DIM = SEQUENCE_LENGTH\n",
    "HIDDEN_DIM = EMBEDDING_DIM*2\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 1e-4\n",
    "VALIDATION_SPLIT = 0.1\n",
    "\n",
    "NUM_LAYERS = 3\n",
    "NUM_HEADS = 4\n",
    "FFN_DIM = SEQUENCE_LENGTH\n",
    "DROPOUT = 0.1\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c9b962",
   "metadata": {
    "id": "89c9b962"
   },
   "source": [
    "## Data Preparation\n",
    "\n",
    "We are using the TinyShakespeare dataset, a small character-level text corpus consisting of a subset of Shakespeare's plays. It's often used for testing sequence models, as it includes a rich set of vocabulary and provides a challenging task for next-character prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "089830e2",
   "metadata": {
    "id": "089830e2"
   },
   "outputs": [],
   "source": [
    "## Utility Functions\n",
    "\n",
    "def load_data(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "def create_char_mappings(text):\n",
    "    chars = sorted(list(set(text)))\n",
    "    char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
    "    idx_to_char = {i: ch for i, ch in enumerate(chars)}\n",
    "    return chars, char_to_idx, idx_to_char"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fc6452",
   "metadata": {
    "id": "30fc6452"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f07670d9",
   "metadata": {
    "id": "f07670d9"
   },
   "outputs": [],
   "source": [
    "class CharDataset(Dataset):\n",
    "    def __init__(self, text, seq_length, char_to_idx):\n",
    "        self.text = text\n",
    "        self.seq_length = seq_length\n",
    "        self.char_to_idx = char_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text) - self.seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = [self.char_to_idx[ch] for ch in self.text[idx:idx+self.seq_length]]\n",
    "        y = [self.char_to_idx[ch] for ch in self.text[idx+1:idx+self.seq_length+1]]\n",
    "        return torch.tensor(x), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9172da13",
   "metadata": {
    "id": "9172da13"
   },
   "outputs": [],
   "source": [
    "def prepare_data(text, seq_length, batch_size, val_split):\n",
    "    chars, char_to_idx, idx_to_char = create_char_mappings(text)\n",
    "\n",
    "    # Split data into train and validation\n",
    "    val_size = int(len(text) * val_split)\n",
    "    train_text, val_text = text[:-val_size], text[-val_size:]\n",
    "\n",
    "    train_dataset = CharDataset(train_text, seq_length, char_to_idx)\n",
    "    val_dataset = CharDataset(val_text, seq_length, char_to_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=12, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=12, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader, chars, char_to_idx, idx_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "nEwKFB_8L6AG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3706,
     "status": "ok",
     "timestamp": 1732704246464,
     "user": {
      "displayName": "Hugman Sangkeun Jung",
      "userId": "08689291704194029524"
     },
     "user_tz": -540
    },
    "id": "nEwKFB_8L6AG",
    "outputId": "e75cdff9-3775-461e-d930-0ced534bf74d"
   },
   "outputs": [],
   "source": [
    "# !wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=19zosLuU0z4MxIMKbGVYEGlg52QyfbTIy' -O input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47d03398",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 668,
     "status": "ok",
     "timestamp": 1732704255324,
     "user": {
      "displayName": "Hugman Sangkeun Jung",
      "userId": "08689291704194029524"
     },
     "user_tz": -540
    },
    "id": "47d03398",
    "outputId": "f247f5b3-88ff-4ecb-e8a3-4b2e42a2820b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 1115394\n",
      "Vocabulary size: 65\n",
      "Train dataset size: 1003727\n",
      "Validation dataset size: 111411\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "text = load_data('../data/input.txt')\n",
    "train_loader, val_loader, chars, char_to_idx, idx_to_char = prepare_data(text, SEQUENCE_LENGTH, BATCH_SIZE, VALIDATION_SPLIT)\n",
    "vocab_size = len(chars)\n",
    "\n",
    "print(f\"Total characters: {len(text)}\")\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "print(f\"Train dataset size: {len(train_loader.dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9442b104",
   "metadata": {
    "id": "9442b104"
   },
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1f0a6a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 916,
     "status": "ok",
     "timestamp": 1732704257555,
     "user": {
      "displayName": "Hugman Sangkeun Jung",
      "userId": "08689291704194029524"
     },
     "user_tz": -540
    },
    "id": "f1f0a6a1",
    "outputId": "9ef6eb5a-0015-40ad-f143-236e3d38fb7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([512, 128])\n",
      "Target shape: torch.Size([512, 128])\n",
      "Sample 1: ------------------------------\n",
      "Input sequence :  to thee, for I will fightAgainst my canker'd country with the spleenOf all the under fiends. But if so beThou darest not thi\n",
      "Target sequence: to thee, for I will fightAgainst my canker'd country with the spleenOf all the under fiends. But if so beThou darest not this\n",
      "\n",
      "Sample 2: ------------------------------\n",
      "Input sequence :  slay the innocent? What is my offence?Where are the evidence that do accuse me?What lawful quest have given their verdict up\n",
      "Target sequence: slay the innocent? What is my offence?Where are the evidence that do accuse me?What lawful quest have given their verdict upU\n",
      "\n",
      "Sample 3: ------------------------------\n",
      "Input sequence : peace be with you, sir: here comes my man.MERCUTIO:But I'll be hanged, sir, if he wear your livery:Marry, go before to field\n",
      "Target sequence: eace be with you, sir: here comes my man.MERCUTIO:But I'll be hanged, sir, if he wear your livery:Marry, go before to field,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to convert index sequence to character sequence\n",
    "def indices_to_text(indices, idx_to_char):\n",
    "    return ''.join([idx_to_char[idx.item()] for idx in indices])\n",
    "\n",
    "# Get a batch of data\n",
    "dataiter = iter(train_loader)\n",
    "batch_x, batch_y = next(dataiter)\n",
    "\n",
    "print(f\"Input shape: {batch_x.shape}\")\n",
    "print(f\"Target shape: {batch_y.shape}\")\n",
    "\n",
    "# Print a few samples from the batch\n",
    "num_samples = 3\n",
    "for i in range(num_samples):\n",
    "    print(f\"Sample {i+1}: ------------------------------\" )\n",
    "    print(\"Input sequence :\", indices_to_text(batch_x[i], idx_to_char).replace('\\n',''))\n",
    "    print(\"Target sequence:\", indices_to_text(batch_y[i], idx_to_char).replace('\\n',''))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5486f73f",
   "metadata": {
    "id": "5486f73f"
   },
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61a52f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_vram_usage(device=\"cuda\"):\n",
    "    allocated = torch.cuda.memory_allocated(device) / (1024**2)  # in MB\n",
    "    reserved = torch.cuda.memory_reserved(device) / (1024**2)    # in MB\n",
    "    max_allocated = torch.cuda.max_memory_allocated(device) / (1024**2)  # in MB\n",
    "    print(f\"Allocated: {allocated:.2f} MB, Reserved: {reserved:.2f} MB, Max Allocated: {max_allocated:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59178a11",
   "metadata": {
    "id": "59178a11"
   },
   "outputs": [],
   "source": [
    "def validate(model, dataloader, criterion, device, epoch, step):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output, _ = model(x)\n",
    "            loss = criterion(output.view(-1, output.size(-1)), y.view(-1))\n",
    "            losses.append((step, epoch, loss.item()))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea5e61f5",
   "metadata": {
    "id": "ea5e61f5"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, dataloader, criterion, optimizer, device, epoch, step):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    vram_usage = []\n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch}\", leave=False)\n",
    "    for batch, (x, y) in enumerate(pbar):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.amp.autocast('cuda'):\n",
    "            output, _ = model(x)\n",
    "            loss = criterion(output.view(-1, output.size(-1)), y.view(-1))\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        step += 1\n",
    "        losses.append((step, epoch, loss.item()))\n",
    "        \n",
    "        # VRAM 사용량을 progress bar의 postfix로 업데이트\n",
    "        allocated = torch.cuda.memory_allocated(device) / (1024**2)\n",
    "        vram_usage.append(allocated)\n",
    "        pbar.set_postfix(loss=f'{loss.item():.4f}', step=step, vram=f'{allocated:.2f} MB')\n",
    "    return losses, step, vram_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbedfd61",
   "metadata": {
    "id": "cbedfd61"
   },
   "source": [
    "## Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e91075e8",
   "metadata": {
    "id": "e91075e8"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs):\n",
    "    all_train_losses = []\n",
    "    all_val_losses = []\n",
    "    all_vram_usages = []\n",
    "    step = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        # Training phase with tqdm updates\n",
    "        epoch_train_losses, step, vram_usage = train(model, train_loader, criterion, optimizer, device, epoch, step)\n",
    "        all_train_losses.extend(epoch_train_losses)\n",
    "        all_vram_usages.append(vram_usage)\n",
    "        \n",
    "        # Validation phase\n",
    "        epoch_val_losses = validate(model, val_loader, criterion, device, epoch, step)\n",
    "        all_val_losses.extend(epoch_val_losses)\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        print(f'Epoch {epoch}/{epochs}, Train Loss: {epoch_train_losses[-1][2]:.4f}, '\n",
    "              f'Val Loss: {epoch_val_losses[-1][2]:.4f}, Epoch Time: {epoch_time:.2f}s',\n",
    "              f'Average Vram Usage: {np.mean(vram_usage):.2f}MB')\n",
    "\n",
    "    train_losses_df = pd.DataFrame(all_train_losses, columns=['step', 'epoch', 'loss_value'])\n",
    "    val_losses_df = pd.DataFrame(all_val_losses, columns=['step', 'epoch', 'loss_value'])\n",
    "    # average_vram_usage = np.mean(all_vram_usages)\n",
    "    return model, train_losses_df, val_losses_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4535c886",
   "metadata": {
    "id": "4535c886"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, char_to_idx, idx_to_char, start_text, device, max_length=500):\n",
    "    model.eval()\n",
    "    current_text = start_text\n",
    "    hidden = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            x = torch.tensor([[char_to_idx[ch] for ch in current_text[-SEQUENCE_LENGTH:]]]).to(device)\n",
    "            output, hidden = model(x, hidden)\n",
    "            probs = torch.softmax(output[0, -1], dim=0)\n",
    "            next_char_idx = torch.multinomial(probs, 1).item()\n",
    "            next_char = idx_to_char[next_char_idx]\n",
    "            current_text += next_char\n",
    "\n",
    "    return current_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aef1cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_comparison_dict = {}\n",
    "\n",
    "def add_loss_to_comparison(model_name, train_losses_df, val_losses_df):\n",
    "    \"\"\"\n",
    "    Adds training and validation losses from a model to the comparison dictionary.\n",
    "    \"\"\"\n",
    "    loss_comparison_dict[model_name] = {\n",
    "        'train': train_losses_df,\n",
    "        'val': val_losses_df\n",
    "    }\n",
    "\n",
    "def print_final_losses(loss_dict):\n",
    "    for model_name, losses in loss_dict.items():\n",
    "        train_df = losses['train']\n",
    "        val_df = losses['val']\n",
    "        final_train = train_df.groupby('epoch')['loss_value'].last().iloc[-1]\n",
    "        final_val = val_df.groupby('epoch')['loss_value'].last().iloc[-1]\n",
    "        print(f\"{model_name}: Final Train Loss: {final_train:.4f}, Final Val Loss: {final_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "973b4a80",
   "metadata": {
    "id": "973b4a80"
   },
   "outputs": [],
   "source": [
    "# Function to plot loss curves\n",
    "def plot_loss(train_losses_df, val_losses_df):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Plot training losses\n",
    "    for epoch in train_losses_df['epoch'].unique():\n",
    "        epoch_train_losses = train_losses_df[train_losses_df['epoch'] == epoch]\n",
    "        plt.plot(epoch_train_losses['step'], epoch_train_losses['loss_value'],\n",
    "                 color='blue', alpha=0.3)\n",
    "\n",
    "    # scatter training loss at the end of each epoch\n",
    "    last_train_losses = train_losses_df.groupby('epoch').last().reset_index()\n",
    "    plt.scatter(last_train_losses['step'], last_train_losses['loss_value'],\n",
    "                color='blue')\n",
    "\n",
    "    # Plot and scatter validation loss at the end of each epoch\n",
    "    last_val_losses = val_losses_df.groupby('epoch').last().reset_index()\n",
    "    plt.plot(last_val_losses['step'], last_val_losses['loss_value'],\n",
    "             color='orange', label='Validation Loss')\n",
    "    plt.scatter(last_val_losses['step'], last_val_losses['loss_value'],\n",
    "                color='orange')\n",
    "\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Function to print final loss values\n",
    "def print_final_losses(train_losses_df, val_losses_df):\n",
    "    print(\"Final Training Loss:\", train_losses_df.groupby('epoch')['loss_value'].last().iloc[-1])\n",
    "    print(\"Final Validation Loss:\", val_losses_df.groupby('epoch')['loss_value'].last().iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5001e203",
   "metadata": {
    "id": "5001e203"
   },
   "outputs": [],
   "source": [
    "# Function to plot loss curves for multiple models stored in loss_comparison_dict\n",
    "def plot_loss_comparisons():\n",
    "    \"\"\"\n",
    "    Plots the training loss curves and average validation loss per epoch for multiple models added to the loss comparison dictionary.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Get the last model in the dictionary (for special final-point highlighting)\n",
    "    last_model_name = list(loss_comparison_dict.keys())[-1]\n",
    "\n",
    "    # Loop through each model in the loss dictionary\n",
    "    for model_name, losses in loss_comparison_dict.items():\n",
    "        train_losses_df = losses['train']\n",
    "        val_losses_df = losses['val']\n",
    "\n",
    "        # Plot training losses for each model\n",
    "        plt.plot(train_losses_df['step'], train_losses_df['loss_value'],\n",
    "                 label=f'{model_name} train', linestyle='-', alpha=0.7)\n",
    "\n",
    "        # Scatter training loss at the end of each epoch\n",
    "        last_train_losses = train_losses_df.groupby('epoch').last().reset_index()\n",
    "        plt.scatter(last_train_losses['step'], last_train_losses['loss_value'], marker='o', s=50)\n",
    "\n",
    "        # Compute average validation loss per epoch (using the last step of each epoch for x-axis)\n",
    "        avg_val_losses = val_losses_df.groupby('epoch').agg({'loss_value': 'mean', 'step': 'last'}).reset_index()\n",
    "        # Scatter the average validation loss for each epoch\n",
    "        plt.scatter(avg_val_losses['step'], avg_val_losses['loss_value'], marker='s', s=50,\n",
    "                    label=f'{model_name} val avg')\n",
    "\n",
    "        # For the last model, highlight the final training loss with a star\n",
    "        if model_name == last_model_name:\n",
    "            final_step = train_losses_df['step'].iloc[-1]\n",
    "            final_loss = train_losses_df['loss_value'].iloc[-1]\n",
    "            plt.scatter(final_step, final_loss, marker='*', s=100, color='red', zorder=5)\n",
    "\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Comparison')\n",
    "    plt.legend()  # Legend shows both training and validation average labels\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16777ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_separate_train_val(loss_dict):\n",
    "    \"\"\"\n",
    "    모델별 Training Loss와 Validation Loss를 각각 별도의 그래프로 그립니다.\n",
    "    단, Validation Loss는 에포크별 평균으로 계산합니다.\n",
    "    \"\"\"\n",
    "    # 1. Training Loss Plot (원본 그대로)\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.subplot(1, 2, 1)  # 1행 2열 중 첫 번째\n",
    "    for model_name, losses in loss_dict.items():\n",
    "        train_df = losses['train']\n",
    "        steps_train = train_df['step'].values\n",
    "        loss_train = train_df['loss_value'].values\n",
    "        plt.plot(steps_train, loss_train, label=f'{model_name} Train')\n",
    "    plt.title('Training Loss Comparison')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # 2. Validation Loss Plot (에포크별 평균 처리)\n",
    "    plt.subplot(1, 2, 2)  # 1행 2열 중 두 번째\n",
    "    for model_name, losses in loss_dict.items():\n",
    "        val_df = losses['val']\n",
    "        # 에포크별 평균 loss와 마지막 step을 계산\n",
    "        val_avg = val_df.groupby('epoch').agg({'loss_value': 'mean', 'step': 'last'}).reset_index()\n",
    "        plt.plot(val_avg['step'], val_avg['loss_value'], label=f'{model_name} Val')\n",
    "    plt.title('Validation Loss (Epoch Avg) Comparison')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "396c469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text generation using validation data\n",
    "val_sample, _ = next(iter(val_loader))\n",
    "start_text = ''.join([idx_to_char[idx.item()] for idx in val_sample[0][:SEQUENCE_LENGTH]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98b72703",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1732704396861,
     "user": {
      "displayName": "Hugman Sangkeun Jung",
      "userId": "08689291704194029524"
     },
     "user_tz": -540
    },
    "id": "98b72703",
    "outputId": "ece1620a-8690-4750-97c1-ada645d59a08"
   },
   "outputs": [],
   "source": [
    "# Decoder Input/Output Example\n",
    "sample_input, _ = next(iter(val_loader))\n",
    "sample_input = sample_input[0].unsqueeze(0).to(device)  # Add batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2d8a352",
   "metadata": {
    "id": "a2d8a352"
   },
   "outputs": [],
   "source": [
    "def generate_text_attention(model, char_to_idx, idx_to_char, start_text, device, max_length=500):\n",
    "    model.eval()\n",
    "    current_text = start_text\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            # Convert the last sequence of characters to indices and feed it to the model\n",
    "            x = torch.tensor([[char_to_idx[ch] for ch in current_text[-SEQUENCE_LENGTH:]]]).to(device)\n",
    "            output = model(x)[0]  # No hidden state needed for attention-based models\n",
    "            probs = torch.softmax(output[0, -1], dim=0)\n",
    "            next_char_idx = torch.multinomial(probs, 1).item()\n",
    "            next_char = idx_to_char[next_char_idx]\n",
    "            current_text += next_char\n",
    "\n",
    "    return current_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32c936b1",
   "metadata": {
    "id": "32c936b1"
   },
   "outputs": [],
   "source": [
    "def train_and_test(model_desc, model, start_text):\n",
    "    # Initialize the model\n",
    "    model = model.to(device)\n",
    "    # Use the same optimizer and criterion\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, fused=True)\n",
    "    \n",
    "    # Train the model\n",
    "    trained_model, train_losses_df, val_losses_df = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer, device, EPOCHS\n",
    "    )\n",
    "\n",
    "    # Generate text\n",
    "    generated_text = generate_text_attention(trained_model, char_to_idx, idx_to_char, start_text, device)\n",
    "    print(f\"Generated text [{start_text}]:\")\n",
    "    print(\"-\"*50)\n",
    "    print(generated_text)\n",
    "    \n",
    "    add_loss_to_comparison(model_desc, train_losses_df, val_losses_df)\n",
    "\n",
    "    # Plot loss comparisons including this model\n",
    "    plot_loss_comparisons()\n",
    "    \n",
    "    plot_separate_train_val(loss_comparison_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbb22cc",
   "metadata": {},
   "source": [
    "## mingru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d73586ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math # math.log 및 상수 사용을 위함\n",
    "from tqdm import tqdm # tqdm 임포트 추가\n",
    "\n",
    "# Lion 옵티마이저 임포트 (설치 필요: pip install lion-pytorch)\n",
    "# from lion_pytorch import Lion # 주석 처리 - 실제 사용 시 주석 해제\n",
    "\n",
    "def log_g(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    은닉 상태 후보를 로그 공간으로 변환하는 함수.\n",
    "    x >= 0 이면 log(x + 0.5)\n",
    "    x < 0 이면 log(sigmoid(x))\n",
    "    \"\"\"\n",
    "    return torch.where(x >= 0, (F.relu(x) + 0.5).log(), -F.softplus(-x))\n",
    "\n",
    "def parallel_scan_log(log_coeffs: torch.Tensor, log_values: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    로그 공간에서 병렬 스캔 연산을 수행합니다. (클램핑 제거됨)\n",
    "    Args:\n",
    "        log_coeffs (torch.Tensor): [B, L, H_internal] 형태의 텐서로, log(alpha_t)를 나타냅니다.\n",
    "        log_values (torch.Tensor): [B, L+1, H_internal] 형태의 텐서로, [log_h_initial, log(beta_1), ..., log(beta_L)]를 나타냅니다.\n",
    "    Returns:\n",
    "        torch.Tensor: [B, L, H_internal] 형태의 텐서로, 지수 함수가 적용된 은닉 상태 (h_1 부터 h_L까지)를 나타냅니다.\n",
    "    \"\"\"\n",
    "    log_proda_coeffs_prefix = F.pad(torch.cumsum(log_coeffs, dim=1), (0, 0, 1, 0), value=0.0)\n",
    "    terms_for_logcumsumexp = log_values - log_proda_coeffs_prefix\n",
    "    log_sum_exp_terms = torch.logcumsumexp(terms_for_logcumsumexp, dim=1) \n",
    "    log_hidden_states = log_proda_coeffs_prefix + log_sum_exp_terms\n",
    "    output_hidden_states = torch.exp(log_hidden_states[:, 1:, :]) \n",
    "    return output_hidden_states\n",
    "\n",
    "class ParallelLogMinGRU(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, expansion_factor: float = 1.0, epsilon: float = 1e-7):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size \n",
    "        self.expansion_factor = expansion_factor # GRU 셀 내부의 확장 계수\n",
    "        # GRU 셀 내부에서 사용될 확장된 차원 (hidden_size는 이 셀의 기본 출력 차원을 의미)\n",
    "        self.internal_expanded_dim = int(hidden_size * self.expansion_factor)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        # 입력 input_size를 internal_expanded_dim * 2 (은닉 상태 후보용, 게이트용)로 프로젝션\n",
    "        self.to_hidden_and_gate = nn.Linear(input_size, self.internal_expanded_dim * 2)\n",
    "        \n",
    "        # GRU 셀 내부 확장이 있었다면, 다시 hidden_size로 프로젝션\n",
    "        if self.expansion_factor != 1.0:\n",
    "            self.to_out = nn.Linear(self.internal_expanded_dim, hidden_size)\n",
    "        else:\n",
    "            self.to_out = nn.Identity()\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'linear' in name or 'to_hidden_and_gate' in name or 'to_out' in name :\n",
    "                if 'weight' in name:\n",
    "                    nn.init.xavier_uniform_(param)\n",
    "                elif 'bias' in name and param is not None: # bias가 있을 경우에만 초기화\n",
    "                    nn.init.zeros_(param)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: [B, L, input_size]\n",
    "        B, L, _ = x.size()\n",
    "        hidden_and_gate = self.to_hidden_and_gate(x) # [B, L, internal_expanded_dim * 2]\n",
    "        h_candidate_input_expanded, logits_z_expanded = hidden_and_gate.chunk(2, dim=-1) # 각각 [B, L, internal_expanded_dim]\n",
    "        \n",
    "        log_A = F.logsigmoid(-logits_z_expanded)\n",
    "        log_Z_expanded = F.logsigmoid(logits_z_expanded)\n",
    "        log_h_candidate_contrib_expanded = log_g(h_candidate_input_expanded)\n",
    "        log_B = log_Z_expanded + log_h_candidate_contrib_expanded\n",
    "\n",
    "        log_h0_val = torch.full((B, 1, self.internal_expanded_dim),\n",
    "                                math.log(self.epsilon),\n",
    "                                device=x.device, dtype=x.dtype)\n",
    "        log_vals = torch.cat([log_h0_val, log_B], dim=1) # [B, L+1, internal_expanded_dim]\n",
    "        h_expanded_scan_out = parallel_scan_log(log_A, log_vals) # [B, L, internal_expanded_dim]\n",
    "        \n",
    "        output = self.to_out(h_expanded_scan_out) # [B, L, hidden_size]\n",
    "        return output\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-8):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.gamma = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        variance = x.pow(2).mean(dim=-1, keepdim=True)\n",
    "        return x * torch.rsqrt(variance + self.eps) * self.gamma\n",
    "\n",
    "class CausalDepthWiseConv1d(nn.Module):\n",
    "    def __init__(self, dim: int, kernel_size: int):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(dim, dim, kernel_size=kernel_size, groups=dim), \n",
    "            nn.Conv1d(dim, dim, kernel_size=1)                       \n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_orig_shape = x.shape\n",
    "        # x.ndim 대신 len(x.shape) 또는 x.dim() 사용\n",
    "        if x.dim() == 2: \n",
    "            x = x.unsqueeze(0) \n",
    "        x_transposed = x.transpose(1, 2) \n",
    "        x_padded = F.pad(x_transposed, (self.kernel_size - 1, 0), value=0.)\n",
    "        x_conv_out = self.net(x_padded)\n",
    "        x_restored = x_conv_out.transpose(1, 2) \n",
    "        # len(x_orig_shape) 사용\n",
    "        if len(x_orig_shape) == 2 and x_restored.shape[0] == 1:\n",
    "            x_restored = x_restored.squeeze(0) \n",
    "        return x_restored\n",
    "\n",
    "class SwiGLUFFN(nn.Module):\n",
    "    def __init__(self, dim: int, expansion_factor: float = 4.0, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        ffn_hidden_dim = int(dim * expansion_factor)\n",
    "        \n",
    "        self.w1_w3 = nn.Linear(dim, ffn_hidden_dim * 2, bias=False) \n",
    "        self.w2 = nn.Linear(ffn_hidden_dim, dim, bias=False)       \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_proj = self.w1_w3(x)\n",
    "        x1, x3_gate = x_proj.chunk(2, dim=-1) \n",
    "        hidden_states = F.silu(x1) * x3_gate\n",
    "        hidden_states = self.dropout(hidden_states) \n",
    "        return self.w2(hidden_states)\n",
    "\n",
    "class MinGRUDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embedding_dim: int,\n",
    "        hidden_dim: int,\n",
    "        num_layers: int = 2,\n",
    "        dropout: float = 0.1, \n",
    "        expansion_factor_gru: float = 1.0, \n",
    "        epsilon_gru: float = 1e-7,\n",
    "        rms_norm_eps: float = 1e-8,\n",
    "        enable_conv: bool = True, \n",
    "        conv_kernel_size: int = 3, \n",
    "        ffn_expansion_factor: float = 1.0 \n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.input_projection = nn.Linear(embedding_dim, hidden_dim) if embedding_dim != hidden_dim else nn.Identity()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            ffn_layer = SwiGLUFFN(\n",
    "                dim=hidden_dim, \n",
    "                expansion_factor=ffn_expansion_factor, \n",
    "                dropout=dropout \n",
    "            )\n",
    "\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                CausalDepthWiseConv1d(hidden_dim, conv_kernel_size) if enable_conv else nn.Identity(), \n",
    "                RMSNorm(hidden_dim, eps=rms_norm_eps),                                                 \n",
    "                ParallelLogMinGRU(\n",
    "                    input_size=hidden_dim, \n",
    "                    hidden_size=hidden_dim, \n",
    "                    expansion_factor=expansion_factor_gru, \n",
    "                    epsilon=epsilon_gru\n",
    "                ),                                                                                     \n",
    "                RMSNorm(hidden_dim, eps=rms_norm_eps),                                                 \n",
    "                ffn_layer,                                                                             \n",
    "                nn.Dropout(dropout) if dropout > 0. else nn.Identity()                                 \n",
    "            ]))\n",
    "\n",
    "        self.final_norm = RMSNorm(hidden_dim, eps=rms_norm_eps) \n",
    "        self.output_fc1 = nn.Linear(hidden_dim, hidden_dim * 4) \n",
    "        self.output_fc2 = nn.Linear(hidden_dim * 4, vocab_size)\n",
    "        self.final_dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, None]:\n",
    "        h = self.embedding(x)\n",
    "        h = self.input_projection(h)\n",
    "\n",
    "        for block_idx, block_modules in enumerate(self.layers):\n",
    "            conv_layer, norm_gru_input, gru_cell, norm_ff_input, ffn_module, dropout_block_output = block_modules\n",
    "\n",
    "            h_conv_input = h\n",
    "            if not isinstance(conv_layer, nn.Identity): \n",
    "                h_conv_out = conv_layer(h)\n",
    "                h = h_conv_input + h_conv_out \n",
    "            \n",
    "            h_gru_residual_source = h\n",
    "            h_normed_for_gru = norm_gru_input(h)\n",
    "            h_gru_out = gru_cell(h_normed_for_gru)\n",
    "            h = h_gru_residual_source + h_gru_out \n",
    "\n",
    "            h_ff_residual_source = h\n",
    "            h_normed_for_ff = norm_ff_input(h)\n",
    "            h_ff_out = ffn_module(h_normed_for_ff) \n",
    "            h = h_ff_residual_source + h_ff_out \n",
    "            \n",
    "            h = dropout_block_output(h)\n",
    "        \n",
    "        h_norm_final = self.final_norm(h)\n",
    "        h_dropped_final = self.final_dropout(h_norm_final) \n",
    "        \n",
    "        output_expanded = F.gelu(self.output_fc1(h_dropped_final)) \n",
    "        logits = self.output_fc2(output_expanded)\n",
    "        \n",
    "        return logits, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c86a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Initialization\n",
    "mingru = MinGRUDecoder(vocab_size, EMBEDDING_DIM, int(HIDDEN_DIM*0.8), NUM_LAYERS).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8199acd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "MinGRUDecoder                                 [512, 128, 65]            --\n",
       "├─Embedding: 1-1                              [512, 128, 128]           8,320\n",
       "├─Linear: 1-2                                 [512, 128, 204]           26,316\n",
       "├─ModuleList: 1-3                             --                        --\n",
       "│    └─ModuleList: 2-1                        --                        --\n",
       "│    │    └─CausalDepthWiseConv1d: 3-1        [512, 128, 204]           42,636\n",
       "│    │    └─RMSNorm: 3-2                      [512, 128, 204]           204\n",
       "│    │    └─ParallelLogMinGRU: 3-3            [512, 128, 204]           83,640\n",
       "│    │    └─RMSNorm: 3-4                      [512, 128, 204]           204\n",
       "│    │    └─SwiGLUFFN: 3-5                    [512, 128, 204]           124,848\n",
       "│    │    └─Dropout: 3-6                      [512, 128, 204]           --\n",
       "│    └─ModuleList: 2-2                        --                        --\n",
       "│    │    └─CausalDepthWiseConv1d: 3-7        [512, 128, 204]           42,636\n",
       "│    │    └─RMSNorm: 3-8                      [512, 128, 204]           204\n",
       "│    │    └─ParallelLogMinGRU: 3-9            [512, 128, 204]           83,640\n",
       "│    │    └─RMSNorm: 3-10                     [512, 128, 204]           204\n",
       "│    │    └─SwiGLUFFN: 3-11                   [512, 128, 204]           124,848\n",
       "│    │    └─Dropout: 3-12                     [512, 128, 204]           --\n",
       "│    └─ModuleList: 2-3                        --                        --\n",
       "│    │    └─CausalDepthWiseConv1d: 3-13       [512, 128, 204]           42,636\n",
       "│    │    └─RMSNorm: 3-14                     [512, 128, 204]           204\n",
       "│    │    └─ParallelLogMinGRU: 3-15           [512, 128, 204]           83,640\n",
       "│    │    └─RMSNorm: 3-16                     [512, 128, 204]           204\n",
       "│    │    └─SwiGLUFFN: 3-17                   [512, 128, 204]           124,848\n",
       "│    │    └─Dropout: 3-18                     [512, 128, 204]           --\n",
       "├─RMSNorm: 1-4                                [512, 128, 204]           204\n",
       "├─Dropout: 1-5                                [512, 128, 204]           --\n",
       "├─Linear: 1-6                                 [512, 128, 816]           167,280\n",
       "├─Linear: 1-7                                 [512, 128, 65]            53,105\n",
       "===============================================================================================\n",
       "Total params: 1,009,821\n",
       "Trainable params: 1,009,821\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 8.83\n",
       "===============================================================================================\n",
       "Input size (MB): 0.52\n",
       "Forward/backward pass size (MB): 3630.69\n",
       "Params size (MB): 4.04\n",
       "Estimated Total Size (MB): 3635.26\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(mingru, input_size=(BATCH_SIZE, SEQUENCE_LENGTH), dtypes=[torch.long])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f66c397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/1961 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "train_and_test(\"minGRU\", mingru, start_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc62ef77",
   "metadata": {},
   "source": [
    "## mingru of cheind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f1278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import abc\n",
    "from typing import Final, List, Tuple, Optional\n",
    "\n",
    "# --- Functional components for MinGRU (from cheind/mingru) ---\n",
    "\n",
    "def _g_func(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Activation function for hidden state.\"\"\"\n",
    "    out = torch.empty_like(x)\n",
    "    mask = x >= 0\n",
    "    # Ensure 0.5 has the same dtype as x\n",
    "    out[mask] = x[mask] + torch.tensor(0.5, dtype=x.dtype, device=x.device)\n",
    "    out[~mask] = torch.sigmoid(x[~mask])\n",
    "    return out\n",
    "\n",
    "def _log_g_func(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Log-activation function for hidden state.\"\"\"\n",
    "    out = torch.empty_like(x) # out will have the same dtype as x (e.g., float16 under autocast)\n",
    "    mask = x >= 0\n",
    "    # Perform calculation and ensure result is cast back to x's dtype before assignment\n",
    "    # (x[mask] + constant_of_x_dtype) results in x_dtype\n",
    "    # .log() might upcast to float32 for precision\n",
    "    # .to(x.dtype) casts it back to the original dtype for assignment\n",
    "    out[mask] = (x[mask] + torch.tensor(0.5, dtype=x.dtype, device=x.device)).log().to(x.dtype)\n",
    "    \n",
    "    # Ensure the output of F.softplus is also cast to the correct dtype\n",
    "    out[~mask] = (-F.softplus(-x[~mask])).to(x.dtype)\n",
    "    return out\n",
    "\n",
    "def _parallel_scan_log_func(log_a: torch.Tensor, log_b: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Parallel scan in log-space.\"\"\"\n",
    "    pad_dims = [0] * (log_a.ndim - 2) * 2 + [1, 0]\n",
    "    a_star = F.pad(torch.cumsum(log_a, dim=1), pad_dims)\n",
    "    \n",
    "    # Placeholder for torch.logcumsumexp if not available in older PyTorch versions\n",
    "    if not hasattr(torch, 'logcumsumexp'):\n",
    "        def _logcumsumexp(x_val, dim_val):\n",
    "            if x_val.ndim == 0: return x_val\n",
    "            if x_val.shape[dim_val] == 0: return x_val\n",
    "            elements = torch.unbind(x_val, dim=dim_val)\n",
    "            out_elements = [elements[0]]\n",
    "            current_log_sum_exp = elements[0]\n",
    "            for i in range(1, len(elements)):\n",
    "                m = torch.maximum(current_log_sum_exp, elements[i])\n",
    "                current_log_sum_exp = m + torch.log1p(torch.exp(-torch.abs(current_log_sum_exp - elements[i])))\n",
    "                out_elements.append(current_log_sum_exp)\n",
    "            return torch.stack(out_elements, dim=dim_val)\n",
    "        x0_plus_b_star = _logcumsumexp(log_b - a_star, dim=1)\n",
    "    else:\n",
    "        x0_plus_b_star = torch.logcumsumexp(log_b - a_star, dim=1)\n",
    "    \n",
    "    log_x = a_star + x0_plus_b_star\n",
    "    return torch.exp(log_x)\n",
    "\n",
    "def _mingru_parallel_func(h_prev_log: torch.Tensor, gate: torch.Tensor, hidden: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Parallel MinGRU forward computation.\"\"\"\n",
    "    log_z = -F.softplus(-gate)\n",
    "    log_one_minus_z = -F.softplus(gate)\n",
    "    log_tilde_h = _log_g_func(hidden) # `hidden` tensor's dtype will propagate into _log_g_func\n",
    "    log_b_for_scan = torch.cat((h_prev_log, log_z + log_tilde_h), dim=1)\n",
    "    h_sequence_plus_initial = _parallel_scan_log_func(log_one_minus_z, log_b_for_scan)\n",
    "    return h_sequence_plus_initial[:, 1:]\n",
    "\n",
    "def _mingru_gate_hidden_func(gate: torch.Tensor, hidden: torch.Tensor, h_prev: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Evaluate the MinGRU using the parallel approach.\"\"\"\n",
    "    # Ensure h_prev is positive before log. g_activation in init_hidden_state should handle this.\n",
    "    # Adding epsilon for numerical stability, cast to h_prev's dtype.\n",
    "    epsilon = torch.tensor(1e-12, dtype=h_prev.dtype, device=h_prev.device)\n",
    "    log_h_prev = (h_prev + epsilon).log() \n",
    "    return _mingru_parallel_func(log_h_prev, gate, hidden)\n",
    "\n",
    "class mF: # Simulated namespace to match the repository's structure\n",
    "    g = _g_func\n",
    "    mingru_gate_hidden = _mingru_gate_hidden_func\n",
    "\n",
    "# --- MinGRU Base and Multi-layer MinGRU Class (from cheind/mingru) ---\n",
    "\n",
    "class MinGRUBase(torch.nn.Module, metaclass=abc.ABCMeta):\n",
    "    \"\"\"Common base interface for all MinGRU implementations.\"\"\"\n",
    "    @abc.abstractmethod\n",
    "    @torch.jit.export\n",
    "    def init_hidden_state(self, x: torch.Tensor) -> List[torch.Tensor]:\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def forward(self, x: torch.Tensor, h: Optional[List[torch.Tensor]] = None) -> Tuple[torch.Tensor, List[torch.Tensor]]:\n",
    "        pass\n",
    "\n",
    "class MinGRU(MinGRUBase):\n",
    "    \"\"\"A multi-layer minimal gated recurrent unit (MinGRU).\"\"\"\n",
    "    layer_sizes: Final[Tuple[int, ...]]\n",
    "    num_layers: Final[int]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        hidden_sizes: List[int],\n",
    "        *,\n",
    "        bias: bool = True,\n",
    "        norm: bool = False,\n",
    "        dropout: float = 0.0,\n",
    "        residual: bool = False,\n",
    "        device: Optional[torch.device] = None,\n",
    "        dtype: Optional[torch.dtype] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.layer_sizes = tuple([input_size] + hidden_sizes)\n",
    "        self.num_layers = len(hidden_sizes)\n",
    "        self.dropout_p = dropout\n",
    "        self.residual = residual\n",
    "        self.use_internal_norm = norm\n",
    "        \n",
    "        layers = []\n",
    "        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "        gen = zip(self.layer_sizes[:-1], self.layer_sizes[1:])\n",
    "        for lidx, (ind, outd) in enumerate(gen):\n",
    "            mdict = {}\n",
    "            if self.use_internal_norm:\n",
    "                mdict[\"norm\"] = torch.nn.LayerNorm(ind, **factory_kwargs)\n",
    "            else:\n",
    "                mdict[\"norm\"] = torch.nn.Identity()\n",
    "\n",
    "            mdict[\"gate_hidden\"] = torch.nn.Linear(ind, outd * 2, bias=bias, **factory_kwargs)\n",
    "            mdict[\"res_align\"] = torch.nn.Linear(ind, outd, bias=False, **factory_kwargs) if residual and ind != outd else torch.nn.Identity()\n",
    "            mdict[\"dropout\"] = torch.nn.Dropout(p=self.dropout_p) if self.dropout_p > 0.0 and lidx < (self.num_layers - 1) else torch.nn.Identity()\n",
    "            layers.append(torch.nn.ModuleDict(mdict))\n",
    "        self.layers = torch.nn.ModuleList(layers)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        h: Optional[List[torch.Tensor]] = None,\n",
    "    ) -> Tuple[torch.Tensor, List[torch.Tensor]]:\n",
    "        assert (x.ndim == 3 and x.shape[2] == self.layer_sizes[0]), \"x should be (B,S,input_size)\"\n",
    "        if h is None: h = self.init_hidden_state(x)\n",
    "\n",
    "        inp = x\n",
    "        next_hidden_states = []\n",
    "        for lidx, layer_module_dict in enumerate(self.layers):\n",
    "            norm_out = layer_module_dict.norm(inp)\n",
    "            gate, hidden = layer_module_dict.gate_hidden(norm_out).chunk(2, dim=2)\n",
    "            # h[lidx] is the specific hidden state for this layer\n",
    "            out_sequence = mF.mingru_gate_hidden(gate, hidden, h[lidx])\n",
    "            next_hidden_states.append(out_sequence[:, -1:]) # Get last time step for next hidden state\n",
    "            \n",
    "            if self.residual:\n",
    "                # The residual should be added to the output of the GRU operation for this layer\n",
    "                # inp is the input to this specific GRU layer\n",
    "                out_sequence = out_sequence + layer_module_dict.res_align(inp) \n",
    "            \n",
    "            inp = layer_module_dict.dropout(out_sequence) # Output of this layer becomes input to next\n",
    "        return inp, next_hidden_states # inp is the output of the last layer\n",
    "\n",
    "    @torch.jit.export\n",
    "    def init_hidden_state(self, x: torch.Tensor) -> List[torch.Tensor]:\n",
    "        # x is the initial input to the MinGRU module (B, S, input_size)\n",
    "        # We need to initialize hidden states for each layer.\n",
    "        initial_states = [mF.g(x.new_zeros(x.shape[0], 1, hs, dtype=x.dtype)) for hs in self.layer_sizes[1:]]\n",
    "        return initial_states\n",
    "\n",
    "# --- Standard Components for MinGRUDecoder2 ---\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.scale = dim ** -0.5\n",
    "        self.eps = eps\n",
    "        self.g = nn.Parameter(torch.ones(dim))\n",
    "    def forward(self, x):\n",
    "        # Cast to float32 for norm calculation for stability, then cast back if needed.\n",
    "        # This is a common practice with RMSNorm/LayerNorm when using float16.\n",
    "        original_dtype = x.dtype\n",
    "        x_float32 = x.to(torch.float32)\n",
    "        norm_val = torch.norm(x_float32, dim=-1, keepdim=True) * self.scale\n",
    "        normalized_x = x_float32 / norm_val.clamp(min=self.eps)\n",
    "        return normalized_x.to(original_dtype) * self.g\n",
    "\n",
    "class CausalDepthWiseConv1d(nn.Module):\n",
    "    def __init__(self, dim, kernel_size):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(dim, dim, kernel_size=kernel_size, groups=dim),\n",
    "            nn.Conv1d(dim, dim, kernel_size=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x_transposed = x.transpose(1, 2)\n",
    "        # Padding value should ideally match the distribution, but 0 is common.\n",
    "        x_padded = F.pad(x_transposed, (self.kernel_size - 1, 0), value=0.0)\n",
    "        x_out = self.net(x_padded)\n",
    "        return x_out.transpose(1, 2)\n",
    "\n",
    "class SwiGLUFFN(nn.Module):\n",
    "    def __init__(self, dim: int, expansion_factor: float = 2.0, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(dim * expansion_factor * (2/3))\n",
    "        hidden_dim = (hidden_dim + 7) // 8 * 8\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w3 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.act_fn = nn.SiLU()\n",
    "    def forward(self, x):\n",
    "        return self.dropout(self.w3(self.act_fn(self.w1(x)) * self.w2(x)))\n",
    "\n",
    "# --- Reconstructed MinGRUDecoder2 ---\n",
    "class MinGRUDecoder4(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embedding_dim: int,\n",
    "        hidden_dim: int,\n",
    "        num_layers: int = 2, # This now controls the depth of the MinGRU module\n",
    "        dropout: float = 0.1,\n",
    "        rms_norm_eps: float = 1e-8,\n",
    "        enable_conv: bool = True,\n",
    "        conv_kernel_size: int = 3,\n",
    "        ffn_expansion_factor: float = 1.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.input_projection = nn.Linear(embedding_dim, hidden_dim) if embedding_dim != hidden_dim else nn.Identity()\n",
    "        \n",
    "        self.conv_block = CausalDepthWiseConv1d(hidden_dim, conv_kernel_size) if enable_conv else nn.Identity()\n",
    "        \n",
    "        self.norm_pre_gru = RMSNorm(hidden_dim, eps=rms_norm_eps)\n",
    "        \n",
    "        self.mingru_module = MinGRU(\n",
    "            input_size=hidden_dim,\n",
    "            hidden_sizes=[hidden_dim] * num_layers, # All internal layers have hidden_dim\n",
    "            norm=False,  # MinGRUDecoder2 uses RMSNorm externally before MinGRU\n",
    "            dropout=dropout, # Pass dropout to MinGRU for inter-layer dropout\n",
    "            residual=True  # Enable internal residuals in MinGRU\n",
    "        )\n",
    "        \n",
    "        self.norm_post_gru = RMSNorm(hidden_dim, eps=rms_norm_eps) # Norm after GRU block, before FFN\n",
    "        self.ffn_module = SwiGLUFFN(dim=hidden_dim, expansion_factor=ffn_expansion_factor, dropout=dropout)\n",
    "        \n",
    "        self.final_norm = RMSNorm(hidden_dim, eps=rms_norm_eps)\n",
    "        self.output_projection = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, None]:\n",
    "        # 1. Input Embedding & Projection\n",
    "        h = self.input_projection(self.embedding(x)) # (B, S, H)\n",
    "        \n",
    "        # 2. Convolutional Block (h_res_conv is h before conv)\n",
    "        h_res_conv = h\n",
    "        h_conv_out = self.conv_block(h_res_conv)\n",
    "        h = h_res_conv + h_conv_out if isinstance(self.conv_block, CausalDepthWiseConv1d) else h_res_conv\n",
    "\n",
    "        # 3. GRU Block (h_res_gru is h before GRU block)\n",
    "        h_res_gru = h \n",
    "        h_gru_input = self.norm_pre_gru(h_res_gru)\n",
    "        # MinGRU's forward expects initial hidden states or will create them.\n",
    "        # It's better to explicitly create them based on the input to MinGRU.\n",
    "        # The init_hidden_state method of MinGRU is designed for this.\n",
    "        initial_mingru_h = self.mingru_module.init_hidden_state(h_gru_input)\n",
    "        h_gru_out, _ = self.mingru_module(h_gru_input, h=initial_mingru_h) # h_gru_out is (B,S,H)\n",
    "        h = h_res_gru + h_gru_out # Residual connection around GRU block (Norm -> MinGRU)\n",
    "\n",
    "        # 4. FFN Block (h_res_ffn is h before FFN block)\n",
    "        h_res_ffn = h\n",
    "        h_ffn_input = self.norm_post_gru(h_res_ffn) # Norm output of GRU block\n",
    "        h_ffn_out = self.ffn_module(h_ffn_input)\n",
    "        h = h_res_ffn + h_ffn_out # Residual connection around FFN block (Norm -> FFN)\n",
    "        \n",
    "        # 5. Final Projection\n",
    "        h_final = self.final_norm(h) # Norm before final linear layer\n",
    "        logits = self.output_projection(h_final) # (B, S, V)\n",
    "        \n",
    "        return logits, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14896964",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Initialization\n",
    "mingru4 = MinGRUDecoder4(vocab_size, EMBEDDING_DIM, 316, NUM_LAYERS).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af623fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(mingru4, input_size=(BATCH_SIZE, SEQUENCE_LENGTH), dtypes=[torch.long])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e27af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test(\"minGRU4\", mingru4, start_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5bc838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import abc\n",
    "from typing import Final, List, Tuple, Optional\n",
    "\n",
    "# --- Functional components for MinGRU (from cheind/mingru) ---\n",
    "\n",
    "def _g_func(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Activation function for hidden state.\"\"\"\n",
    "    out = torch.empty_like(x)\n",
    "    mask = x >= 0\n",
    "    # Ensure 0.5 has the same dtype as x\n",
    "    out[mask] = x[mask] + torch.tensor(0.5, dtype=x.dtype, device=x.device)\n",
    "    out[~mask] = torch.sigmoid(x[~mask])\n",
    "    return out\n",
    "\n",
    "def _log_g_func(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Log-activation function for hidden state.\"\"\"\n",
    "    out = torch.empty_like(x) # out will have the same dtype as x (e.g., float16 under autocast)\n",
    "    mask = x >= 0\n",
    "    # Perform calculation and ensure result is cast back to x's dtype before assignment\n",
    "    # (x[mask] + constant_of_x_dtype) results in x_dtype\n",
    "    # .log() might upcast to float32 for precision\n",
    "    # .to(x.dtype) casts it back to the original dtype for assignment\n",
    "    out[mask] = (x[mask] + torch.tensor(0.5, dtype=x.dtype, device=x.device)).log().to(x.dtype)\n",
    "    \n",
    "    # Ensure the output of F.softplus is also cast to the correct dtype\n",
    "    out[~mask] = (-F.softplus(-x[~mask])).to(x.dtype)\n",
    "    return out\n",
    "\n",
    "def _parallel_scan_log_func(log_a: torch.Tensor, log_b: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Parallel scan in log-space.\"\"\"\n",
    "    pad_dims = [0] * (log_a.ndim - 2) * 2 + [1, 0]\n",
    "    a_star = F.pad(torch.cumsum(log_a, dim=1), pad_dims)\n",
    "    \n",
    "    # Placeholder for torch.logcumsumexp if not available in older PyTorch versions\n",
    "    if not hasattr(torch, 'logcumsumexp'):\n",
    "        def _logcumsumexp(x_val, dim_val):\n",
    "            if x_val.ndim == 0: return x_val\n",
    "            if x_val.shape[dim_val] == 0: return x_val\n",
    "            elements = torch.unbind(x_val, dim=dim_val)\n",
    "            out_elements = [elements[0]]\n",
    "            current_log_sum_exp = elements[0]\n",
    "            for i in range(1, len(elements)):\n",
    "                m = torch.maximum(current_log_sum_exp, elements[i])\n",
    "                current_log_sum_exp = m + torch.log1p(torch.exp(-torch.abs(current_log_sum_exp - elements[i])))\n",
    "                out_elements.append(current_log_sum_exp)\n",
    "            return torch.stack(out_elements, dim=dim_val)\n",
    "        x0_plus_b_star = _logcumsumexp(log_b - a_star, dim=1)\n",
    "    else:\n",
    "        x0_plus_b_star = torch.logcumsumexp(log_b - a_star, dim=1)\n",
    "    \n",
    "    log_x = a_star + x0_plus_b_star\n",
    "    return torch.exp(log_x)\n",
    "\n",
    "def _mingru_parallel_func(h_prev_log: torch.Tensor, gate: torch.Tensor, hidden: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Parallel MinGRU forward computation.\"\"\"\n",
    "    log_z = -F.softplus(-gate)\n",
    "    log_one_minus_z = -F.softplus(gate)\n",
    "    log_tilde_h = _log_g_func(hidden) # `hidden` tensor's dtype will propagate into _log_g_func\n",
    "    log_b_for_scan = torch.cat((h_prev_log, log_z + log_tilde_h), dim=1)\n",
    "    h_sequence_plus_initial = _parallel_scan_log_func(log_one_minus_z, log_b_for_scan)\n",
    "    return h_sequence_plus_initial[:, 1:]\n",
    "\n",
    "def _mingru_gate_hidden_func(gate: torch.Tensor, hidden: torch.Tensor, h_prev: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Evaluate the MinGRU using the parallel approach.\"\"\"\n",
    "    # Ensure h_prev is positive before log. g_activation in init_hidden_state should handle this.\n",
    "    # Adding epsilon for numerical stability, cast to h_prev's dtype.\n",
    "    epsilon = torch.tensor(1e-12, dtype=h_prev.dtype, device=h_prev.device)\n",
    "    log_h_prev = (h_prev + epsilon).log() \n",
    "    return _mingru_parallel_func(log_h_prev, gate, hidden)\n",
    "\n",
    "class mF: # Simulated namespace to match the repository's structure\n",
    "    g = _g_func\n",
    "    mingru_gate_hidden = _mingru_gate_hidden_func\n",
    "\n",
    "# --- MinGRU Base and Multi-layer MinGRU Class (from cheind/mingru) ---\n",
    "\n",
    "class MinGRUBase(torch.nn.Module, metaclass=abc.ABCMeta):\n",
    "    \"\"\"Common base interface for all MinGRU implementations.\"\"\"\n",
    "    @abc.abstractmethod\n",
    "    @torch.jit.export\n",
    "    def init_hidden_state(self, x: torch.Tensor) -> List[torch.Tensor]:\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def forward(self, x: torch.Tensor, h: Optional[List[torch.Tensor]] = None) -> Tuple[torch.Tensor, List[torch.Tensor]]:\n",
    "        pass\n",
    "\n",
    "class MinGRU(MinGRUBase):\n",
    "    \"\"\"A multi-layer minimal gated recurrent unit (MinGRU).\"\"\"\n",
    "    layer_sizes: Final[Tuple[int, ...]] # Includes input_size as the first element\n",
    "    num_layers: Final[int] # Number of actual GRU layers\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        hidden_sizes: List[int], # List of hidden_size for each GRU layer\n",
    "        *,\n",
    "        bias: bool = True,\n",
    "        norm: bool = False,\n",
    "        dropout: float = 0.0,\n",
    "        residual: bool = False,\n",
    "        device: Optional[torch.device] = None,\n",
    "        dtype: Optional[torch.dtype] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # layer_sizes will be [input_size, hidden_sizes[0], hidden_sizes[1], ...]\n",
    "        self.layer_sizes = tuple([input_size] + hidden_sizes)\n",
    "        self.num_layers = len(hidden_sizes) # This is the actual number of GRU layers\n",
    "        self.dropout_p = dropout\n",
    "        self.residual = residual\n",
    "        self.use_internal_norm = norm\n",
    "        \n",
    "        layers = []\n",
    "        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "        # gen iterates from input_size to hidden_sizes[0], then hidden_sizes[0] to hidden_sizes[1], etc.\n",
    "        gen = zip(self.layer_sizes[:-1], self.layer_sizes[1:])\n",
    "        for lidx, (ind, outd) in enumerate(gen): # ind is input_dim to layer, outd is output_dim of layer\n",
    "            mdict = {}\n",
    "            if self.use_internal_norm:\n",
    "                mdict[\"norm\"] = torch.nn.LayerNorm(ind, **factory_kwargs)\n",
    "            else:\n",
    "                mdict[\"norm\"] = torch.nn.Identity()\n",
    "\n",
    "            mdict[\"gate_hidden\"] = torch.nn.Linear(ind, outd * 2, bias=bias, **factory_kwargs)\n",
    "            mdict[\"res_align\"] = torch.nn.Linear(ind, outd, bias=False, **factory_kwargs) if residual and ind != outd else torch.nn.Identity()\n",
    "            # Dropout is applied to the output of each layer except the last one within MinGRU\n",
    "            mdict[\"dropout\"] = torch.nn.Dropout(p=self.dropout_p) if self.dropout_p > 0.0 and lidx < (self.num_layers - 1) else torch.nn.Identity()\n",
    "            layers.append(torch.nn.ModuleDict(mdict))\n",
    "        self.layers = torch.nn.ModuleList(layers)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor, # Input to the MinGRU module, shape (B, S, input_size)\n",
    "        h: Optional[List[torch.Tensor]] = None, # List of hidden states, one for each layer\n",
    "    ) -> Tuple[torch.Tensor, List[torch.Tensor]]:\n",
    "        # x.shape[2] should match self.layer_sizes[0] which is input_size for MinGRU\n",
    "        assert (x.ndim == 3 and x.shape[2] == self.layer_sizes[0]), \\\n",
    "            f\"MinGRU input x shape[2] ({x.shape[2]}) does not match its input_size ({self.layer_sizes[0]})\"\n",
    "        if h is None: h = self.init_hidden_state(x)\n",
    "        assert len(h) == self.num_layers, \\\n",
    "            f\"Number of initial hidden states ({len(h)}) must match number of MinGRU layers ({self.num_layers})\"\n",
    "\n",
    "\n",
    "        inp = x # Current input to a layer, starts with x\n",
    "        next_hidden_states = []\n",
    "        for lidx, layer_module_dict in enumerate(self.layers):\n",
    "            # h[lidx] is the initial hidden state for the lidx-th GRU layer.\n",
    "            # Its shape should be (B, 1, self.layer_sizes[lidx+1])\n",
    "            # inp is the input sequence to this lidx-th GRU layer.\n",
    "            # Its shape should be (B, S, self.layer_sizes[lidx])\n",
    "            \n",
    "            norm_out = layer_module_dict.norm(inp)\n",
    "            gate, hidden = layer_module_dict.gate_hidden(norm_out).chunk(2, dim=2)\n",
    "            \n",
    "            out_sequence = mF.mingru_gate_hidden(gate, hidden, h[lidx])\n",
    "            next_hidden_states.append(out_sequence[:, -1:]) \n",
    "            \n",
    "            if self.residual:\n",
    "                out_sequence = out_sequence + layer_module_dict.res_align(inp) \n",
    "            \n",
    "            inp = layer_module_dict.dropout(out_sequence)\n",
    "        return inp, next_hidden_states\n",
    "\n",
    "    @torch.jit.export\n",
    "    def init_hidden_state(self, x: torch.Tensor) -> List[torch.Tensor]:\n",
    "        # x is the input to the entire MinGRU module (B, S, self.layer_sizes[0])\n",
    "        # We need to initialize hidden states for each of the self.num_layers GRU layers.\n",
    "        # The hidden size for the i-th GRU layer is self.layer_sizes[i+1]\n",
    "        initial_states = [mF.g(x.new_zeros(x.shape[0], 1, self.layer_sizes[lidx+1], dtype=x.dtype)) for lidx in range(self.num_layers)]\n",
    "        return initial_states\n",
    "\n",
    "# --- Standard Components for MinGRUDecoder2 ---\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.scale = dim ** -0.5\n",
    "        self.eps = eps\n",
    "        self.g = nn.Parameter(torch.ones(dim))\n",
    "    def forward(self, x):\n",
    "        original_dtype = x.dtype\n",
    "        x_float32 = x.to(torch.float32)\n",
    "        norm_val = torch.norm(x_float32, dim=-1, keepdim=True) * self.scale\n",
    "        normalized_x = x_float32 / norm_val.clamp(min=self.eps)\n",
    "        return normalized_x.to(original_dtype) * self.g\n",
    "\n",
    "class CausalDepthWiseConv1d(nn.Module):\n",
    "    def __init__(self, dim, kernel_size):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(dim, dim, kernel_size=kernel_size, groups=dim),\n",
    "            nn.Conv1d(dim, dim, kernel_size=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x_transposed = x.transpose(1, 2)\n",
    "        x_padded = F.pad(x_transposed, (self.kernel_size - 1, 0), value=0.0)\n",
    "        x_out = self.net(x_padded)\n",
    "        return x_out.transpose(1, 2)\n",
    "\n",
    "class SwiGLUFFN(nn.Module):\n",
    "    def __init__(self, dim: int, expansion_factor: float = 2.0, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        hidden_dim_ffn = int(dim * expansion_factor * (2/3))\n",
    "        hidden_dim_ffn = (hidden_dim_ffn + 7) // 8 * 8\n",
    "        self.w1 = nn.Linear(dim, hidden_dim_ffn, bias=False)\n",
    "        self.w2 = nn.Linear(dim, hidden_dim_ffn, bias=False)\n",
    "        self.w3 = nn.Linear(hidden_dim_ffn, dim, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.act_fn = nn.SiLU()\n",
    "    def forward(self, x):\n",
    "        return self.dropout(self.w3(self.act_fn(self.w1(x)) * self.w2(x)))\n",
    "\n",
    "# --- Reconstructed MinGRUDecoder2 ---\n",
    "class MinGRUDecoder3(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embedding_dim: int,\n",
    "        # hidden_dim is now the input dimension to the first MinGRU layer\n",
    "        # and the output dimension of the last MinGRU layer for consistency\n",
    "        # with other modules in MinGRUDecoder2.\n",
    "        # MinGRU's internal hidden_sizes can vary.\n",
    "        mingru_input_hidden_dim: int, \n",
    "        mingru_internal_hidden_sizes: List[int], # List of hidden sizes for each MinGRU layer\n",
    "        dropout: float = 0.1,\n",
    "        rms_norm_eps: float = 1e-8,\n",
    "        enable_conv: bool = True,\n",
    "        conv_kernel_size: int = 3,\n",
    "        ffn_expansion_factor: float = 1.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # The overall hidden_dim for MinGRUDecoder2 components (Conv, Norms, FFN)\n",
    "        # will be based on the output of the MinGRU stack.\n",
    "        # If mingru_internal_hidden_sizes is empty, it implies num_layers = 0 for MinGRU,\n",
    "        # which is not typical. We assume mingru_internal_hidden_sizes is not empty.\n",
    "        # The input to the first MinGRU layer is mingru_input_hidden_dim.\n",
    "        # The output of the last MinGRU layer is mingru_internal_hidden_sizes[-1].\n",
    "        # This final output dimension will be used for subsequent RMSNorm and FFN.\n",
    "        \n",
    "        if not mingru_internal_hidden_sizes:\n",
    "            raise ValueError(\"mingru_internal_hidden_sizes list cannot be empty.\")\n",
    "            \n",
    "        self.final_mingru_output_dim = mingru_internal_hidden_sizes[-1]\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # Input projection projects embedding_dim to the input_dim of the first MinGRU layer\n",
    "        self.input_projection = nn.Linear(embedding_dim, mingru_input_hidden_dim) if embedding_dim != mingru_input_hidden_dim else nn.Identity()\n",
    "        \n",
    "        self.conv_block = CausalDepthWiseConv1d(mingru_input_hidden_dim, conv_kernel_size) if enable_conv else nn.Identity()\n",
    "        \n",
    "        # Norm before MinGRU operates on mingru_input_hidden_dim\n",
    "        self.norm_pre_gru = RMSNorm(mingru_input_hidden_dim, eps=rms_norm_eps)\n",
    "        \n",
    "        self.mingru_module = MinGRU(\n",
    "            input_size=mingru_input_hidden_dim, # Input to the MinGRU stack\n",
    "            hidden_sizes=mingru_internal_hidden_sizes, # List of hidden sizes for each layer\n",
    "            norm=False,\n",
    "            dropout=dropout,\n",
    "            residual=True\n",
    "        )\n",
    "        \n",
    "        # Norm after MinGRU and FFN operate on the output dimension of the last MinGRU layer\n",
    "        self.norm_post_gru = RMSNorm(self.final_mingru_output_dim, eps=rms_norm_eps)\n",
    "        self.ffn_module = SwiGLUFFN(dim=self.final_mingru_output_dim, expansion_factor=ffn_expansion_factor, dropout=dropout)\n",
    "        \n",
    "        self.final_norm = RMSNorm(self.final_mingru_output_dim, eps=rms_norm_eps)\n",
    "        self.output_projection = nn.Linear(self.final_mingru_output_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, None]:\n",
    "        # 1. Input Embedding & Projection\n",
    "        h = self.input_projection(self.embedding(x)) \n",
    "        \n",
    "        # 2. Convolutional Block\n",
    "        h_res_conv = h\n",
    "        h_conv_out = self.conv_block(h_res_conv)\n",
    "        h = h_res_conv + h_conv_out if isinstance(self.conv_block, CausalDepthWiseConv1d) else h_res_conv\n",
    "\n",
    "        # 3. GRU Block\n",
    "        h_res_gru = h \n",
    "        h_gru_input = self.norm_pre_gru(h_res_gru)\n",
    "        initial_mingru_h = self.mingru_module.init_hidden_state(h_gru_input)\n",
    "        h_gru_out, _ = self.mingru_module(h_gru_input, h=initial_mingru_h)\n",
    "        # The residual for the GRU block should connect inputs and outputs of compatible dimensions.\n",
    "        # If mingru_input_hidden_dim != final_mingru_output_dim, a simple sum is not possible\n",
    "        # without a projection. The MinGRU module itself has internal residuals.\n",
    "        # For the outer residual, we assume the input to the block (h_res_gru)\n",
    "        # has the same dimension as the output of the MinGRU stack (h_gru_out) if a residual\n",
    "        # is applied here.\n",
    "        # If dimensions differ, this residual needs adjustment or removal.\n",
    "        # For now, let's assume the MinGRU module handles its dimensionality changes and\n",
    "        # the outer residual connects the input to the *GRU block* (h_res_gru) with the\n",
    "        # output of the *GRU module* (h_gru_out). This requires h_res_gru and h_gru_out\n",
    "        # to have the same dimension, meaning mingru_input_hidden_dim == final_mingru_output_dim.\n",
    "        \n",
    "        # If mingru_input_hidden_dim == self.final_mingru_output_dim:\n",
    "        if h_res_gru.shape[-1] == h_gru_out.shape[-1]:\n",
    "             h = h_res_gru + h_gru_out\n",
    "        else:\n",
    "            # If dimensions don't match, we cannot directly add.\n",
    "            # Option 1: Project h_res_gru to match h_gru_out.shape[-1]\n",
    "            # Option 2: Do not apply this outer residual, rely on MinGRU's internal residuals.\n",
    "            # For simplicity, if they don't match, we just take the output of MinGRU.\n",
    "            # This implies the MinGRU block is responsible for its full transformation.\n",
    "            print(f\"Warning: Dimensions mismatch for GRU block residual. Input: {h_res_gru.shape[-1]}, Output: {h_gru_out.shape[-1]}. Skipping outer residual for GRU block.\")\n",
    "            h = h_gru_out\n",
    "\n",
    "\n",
    "        # 4. FFN Block\n",
    "        h_res_ffn = h # Input to the FFN block\n",
    "        h_ffn_input = self.norm_post_gru(h_res_ffn)\n",
    "        h_ffn_out = self.ffn_module(h_ffn_input)\n",
    "        h = h_res_ffn + h_ffn_out\n",
    "        \n",
    "        # 5. Final Projection\n",
    "        h_final = self.final_norm(h)\n",
    "        logits = self.output_projection(h_final)\n",
    "        \n",
    "        return logits, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99b966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Initialization\n",
    "mingru3 = MinGRUDecoder3(vocab_size, EMBEDDING_DIM, HIDDEN_DIM, [HIDDEN_DIM, 384, HIDDEN_DIM], 0.1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54d5ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(mingru3, input_size=(BATCH_SIZE, SEQUENCE_LENGTH), dtypes=[torch.long])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419fb0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test(\"minGRU3\", mingru3, start_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c581695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
