{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47d8efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_489590/3862123857.py:221: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast()  # Enable automatic mixed precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([4, 128])\n",
      "Output shape: torch.Size([4, 128, 10000])\n",
      "Model parameters: 12,623,632\n",
      "Peak GPU memory usage: 0.42 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Tuple, Optional, Union\n",
    "\n",
    "\n",
    "class CausalConv1D(nn.Module):\n",
    "    \"\"\"Causal 1D Depthwise Convolution\"\"\"\n",
    "    \n",
    "    def __init__(self, dim: int, kernel_size: int):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.depthwise = nn.Conv1d(dim, dim, kernel_size, groups=dim)\n",
    "        self.pointwise = nn.Conv1d(dim, dim, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (batch, seq_len, dim)\n",
    "        x = x.transpose(1, 2)  # (batch, dim, seq_len)\n",
    "        x = F.pad(x, (self.kernel_size - 1, 0))  # causal padding\n",
    "        x = self.pointwise(self.depthwise(x))\n",
    "        return x.transpose(1, 2)  # (batch, seq_len, dim)\n",
    "\n",
    "\n",
    "class MinGRUFunctions:\n",
    "    \"\"\"MinGRU core mathematical functions\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def g_activation(x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Custom activation function - optimized with inplace ops\"\"\"\n",
    "        positive_mask = x >= 0\n",
    "        result = x.clone()  # More efficient than empty_like + assignment\n",
    "        result[positive_mask] += 0.5\n",
    "        result[~positive_mask] = torch.sigmoid_(result[~positive_mask])  # inplace sigmoid\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def log_g_activation(x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Log version of g activation\"\"\"\n",
    "        positive_mask = x >= 0\n",
    "        result = torch.empty_like(x)\n",
    "        result[positive_mask] = torch.log(x[positive_mask] + 0.5).to(x.dtype)\n",
    "        result[~positive_mask] = -F.softplus(-x[~positive_mask]).to(x.dtype)\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def parallel_scan(log_gates: torch.Tensor, log_values: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Parallel scan operation - fixed dimension handling\"\"\"\n",
    "        # Cumulative sum of log gates with proper padding\n",
    "        cumsum_gates = F.pad(torch.cumsum(log_gates, dim=1), [0, 0, 1, 0])  # pad dim=1 (seq_len)\n",
    "        \n",
    "        # Log-cumsum-exp operation\n",
    "        adjusted_values = log_values - cumsum_gates\n",
    "        cumsum_values = torch.logcumsumexp(adjusted_values, dim=1)\n",
    "        \n",
    "        # Combine results\n",
    "        log_output = cumsum_gates + cumsum_values\n",
    "        return torch.exp(log_output)\n",
    "    \n",
    "    @staticmethod\n",
    "    def mingru_step(gate: torch.Tensor, hidden: torch.Tensor, prev_state: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Single MinGRU computation step - fused operations\"\"\"\n",
    "        eps = 1e-12\n",
    "        \n",
    "        # Fused log computation with numerical stability\n",
    "        log_prev = torch.log(torch.clamp(prev_state, min=eps))\n",
    "        \n",
    "        # Fused softplus operations (more numerically stable)\n",
    "        gate_clamped = torch.clamp(gate, min=-20, max=20)  # Prevent overflow\n",
    "        log_forget = -F.softplus(gate_clamped)\n",
    "        log_update = -F.softplus(-gate_clamped)\n",
    "        \n",
    "        # Fused activation\n",
    "        log_candidate = MinGRUFunctions.log_g_activation(hidden)\n",
    "        \n",
    "        # Concatenate with pre-allocation\n",
    "        batch_size, seq_len, hidden_dim = gate.shape\n",
    "        log_states = torch.empty(batch_size, seq_len + 1, hidden_dim, \n",
    "                                dtype=gate.dtype, device=gate.device)\n",
    "        log_states[:, :1] = log_prev\n",
    "        log_states[:, 1:] = log_update + log_candidate\n",
    "        \n",
    "        sequence_output = MinGRUFunctions.parallel_scan(log_forget, log_states)\n",
    "        return sequence_output[:, 1:]\n",
    "\n",
    "\n",
    "class MinGRULayer(nn.Module):\n",
    "    \"\"\"Single MinGRU layer with optimized initialization\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, hidden_dim: int, use_bias: bool = True):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.gate_projection = nn.Linear(input_dim, hidden_dim * 2, bias=use_bias)\n",
    "        self.residual_projection = nn.Linear(input_dim, hidden_dim, bias=False) if input_dim != hidden_dim else nn.Identity()\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Optimized weight initialization\"\"\"\n",
    "        # Xavier/Glorot initialization for better gradient flow\n",
    "        nn.init.xavier_uniform_(self.gate_projection.weight)\n",
    "        if self.gate_projection.bias is not None:\n",
    "            # Initialize gate bias to favor forgetting (negative bias)\n",
    "            nn.init.constant_(self.gate_projection.bias[:self.hidden_dim], -1.0)  # forget gate\n",
    "            nn.init.constant_(self.gate_projection.bias[self.hidden_dim:], 0.0)   # input gate\n",
    "        \n",
    "        if not isinstance(self.residual_projection, nn.Identity):\n",
    "            nn.init.xavier_uniform_(self.residual_projection.weight)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, prev_state: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # Project input to gate and hidden\n",
    "        gate_hidden = self.gate_projection(x)\n",
    "        gate, hidden = gate_hidden.chunk(2, dim=-1)\n",
    "        \n",
    "        # Apply MinGRU computation\n",
    "        output = MinGRUFunctions.mingru_step(gate, hidden, prev_state)\n",
    "        \n",
    "        # Residual connection\n",
    "        if not isinstance(self.residual_projection, nn.Identity):\n",
    "            output = output + self.residual_projection(x)\n",
    "        \n",
    "        # Return output and last hidden state\n",
    "        next_state = output[:, -1:, :]\n",
    "        return output, next_state\n",
    "\n",
    "\n",
    "class MinGRU(nn.Module):\n",
    "    \"\"\"Multi-layer MinGRU with state caching\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, hidden_dims: List[int], dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.num_layers = len(hidden_dims)\n",
    "        \n",
    "        # Build layers\n",
    "        layer_dims = [input_dim] + hidden_dims\n",
    "        self.layers = nn.ModuleList([\n",
    "            MinGRULayer(layer_dims[i], layer_dims[i + 1])\n",
    "            for i in range(self.num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Dropout (except for last layer)\n",
    "        self.dropouts = nn.ModuleList([\n",
    "            nn.Dropout(dropout) if i < self.num_layers - 1 else nn.Identity()\n",
    "            for i in range(self.num_layers)\n",
    "        ])\n",
    "        \n",
    "        # State cache for inference optimization\n",
    "        self._cached_states: Optional[List[torch.Tensor]] = None\n",
    "        self._cache_batch_size: int = 0\n",
    "    \n",
    "    def init_states(self, batch_size: int, device: torch.device) -> List[torch.Tensor]:\n",
    "        \"\"\"Initialize hidden states with optimized memory layout\"\"\"\n",
    "        states = [\n",
    "            MinGRUFunctions.g_activation(torch.zeros(batch_size, 1, dim, device=device, dtype=torch.float32))\n",
    "            for dim in self.hidden_dims\n",
    "        ]\n",
    "        \n",
    "        # Cache states for inference\n",
    "        if not self.training:\n",
    "            self._cached_states = [state.clone() for state in states]\n",
    "            self._cache_batch_size = batch_size\n",
    "            \n",
    "        return states\n",
    "    \n",
    "    def get_cached_states(self, batch_size: int, device: torch.device) -> Optional[List[torch.Tensor]]:\n",
    "        \"\"\"Get cached states if available and valid\"\"\"\n",
    "        if (self._cached_states is not None and \n",
    "            self._cache_batch_size == batch_size and \n",
    "            not self.training):\n",
    "            return [state.clone() for state in self._cached_states]\n",
    "        return None\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, states: Optional[List[torch.Tensor]] = None) -> Tuple[torch.Tensor, List[torch.Tensor]]:\n",
    "        if states is None:\n",
    "            # Try to use cached states first\n",
    "            states = self.get_cached_states(x.size(0), x.device)\n",
    "            if states is None:\n",
    "                states = self.init_states(x.size(0), x.device)\n",
    "        \n",
    "        output = x\n",
    "        next_states = []\n",
    "        \n",
    "        for i, (layer, dropout) in enumerate(zip(self.layers, self.dropouts)):\n",
    "            output, next_state = layer(output, states[i])\n",
    "            output = dropout(output)\n",
    "            next_states.append(next_state)\n",
    "        \n",
    "        # Update cache for next inference\n",
    "        if not self.training:\n",
    "            self._cached_states = [state.clone() for state in next_states]\n",
    "        \n",
    "        return output, next_states\n",
    "\n",
    "\n",
    "class SwiGLU(nn.Module):\n",
    "    \"\"\"SwiGLU Feed-Forward Network with mixed precision support\"\"\"\n",
    "    \n",
    "    def __init__(self, dim: int, expansion_factor: float = 2.0, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(dim * expansion_factor * 2/3)\n",
    "        hidden_dim = ((hidden_dim + 7) // 8) * 8  # Round to multiple of 8 for tensor cores\n",
    "        \n",
    "        self.gate_proj = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.up_proj = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.down_proj = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = nn.SiLU()\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize weights for mixed precision training\"\"\"\n",
    "        for module in [self.gate_proj, self.up_proj, self.down_proj]:\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            # Scale down weights for numerical stability in fp16\n",
    "            module.weight.data *= 0.5\n",
    "    \n",
    "    @torch.amp.autocast('cuda',)  # Enable automatic mixed precision\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Fused gating operation\n",
    "        gate = self.activation(self.gate_proj(x))\n",
    "        up = self.up_proj(x)\n",
    "        \n",
    "        # Element-wise multiplication in fp16, but accumulate in fp32\n",
    "        gated = gate * up\n",
    "        return self.dropout(self.down_proj(gated))\n",
    "\n",
    "\n",
    "class MinGRUDecoder(nn.Module):\n",
    "    \"\"\"Complete MinGRU-based decoder model with optimizations\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embed_dim: int,\n",
    "        hidden_dims: Union[int, List[int]],\n",
    "        num_layers: Optional[int] = None,\n",
    "        dropout: float = 0.1,\n",
    "        use_conv: bool = True,\n",
    "        conv_kernel: int = 3,\n",
    "        ffn_expansion: float = 1.0,\n",
    "        norm_eps: float = 1e-8,\n",
    "        use_gradient_checkpointing: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Handle hidden dimensions\n",
    "        if isinstance(hidden_dims, int):\n",
    "            if num_layers is None:\n",
    "                raise ValueError(\"num_layers must be specified when hidden_dims is int\")\n",
    "            hidden_dims = [hidden_dims] * num_layers\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.use_gradient_checkpointing = use_gradient_checkpointing\n",
    "        \n",
    "        # Input layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.input_proj = nn.Linear(embed_dim, hidden_dims[0]) if embed_dim != hidden_dims[0] else nn.Identity()\n",
    "        \n",
    "        # Optional convolution\n",
    "        self.conv = CausalConv1D(hidden_dims[0], conv_kernel) if use_conv else None\n",
    "        \n",
    "        # Core MinGRU\n",
    "        self.pre_gru_norm = nn.RMSNorm(hidden_dims[0], eps=norm_eps)\n",
    "        self.mingru = MinGRU(hidden_dims[0], hidden_dims, dropout)\n",
    "        \n",
    "        # Feed-forward network\n",
    "        self.post_gru_norm = nn.RMSNorm(hidden_dims[-1], eps=norm_eps)\n",
    "        self.ffn = SwiGLU(hidden_dims[-1], ffn_expansion, dropout)\n",
    "        \n",
    "        # Output layers\n",
    "        self.final_norm = nn.RMSNorm(hidden_dims[-1], eps=norm_eps)\n",
    "        self.output_proj = nn.Linear(hidden_dims[-1], vocab_size)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize all model weights\"\"\"\n",
    "        # Embedding initialization\n",
    "        nn.init.normal_(self.embedding.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        # Linear layer initialization\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def _forward_block(self, h: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass through MinGRU and FFN blocks\"\"\"\n",
    "        # MinGRU processing\n",
    "        h_norm = self.pre_gru_norm(h)\n",
    "        gru_out, _ = self.mingru(h_norm)\n",
    "        h = h + gru_out  # Residual connection\n",
    "        \n",
    "        # Feed-forward with residual\n",
    "        h_norm = self.post_gru_norm(h)\n",
    "        ffn_out = self.ffn(h_norm)\n",
    "        h = h + ffn_out  # Residual connection\n",
    "        \n",
    "        return h\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Embedding and input projection\n",
    "        h = self.embedding(x)\n",
    "        h = self.input_proj(h)\n",
    "        \n",
    "        # Optional convolution with residual\n",
    "        if self.conv is not None:\n",
    "            h = h + self.conv(h)\n",
    "        \n",
    "        # Main processing with optional gradient checkpointing\n",
    "        if self.use_gradient_checkpointing and self.training:\n",
    "            h = torch.utils.checkpoint.checkpoint(self._forward_block, h, use_reentrant=False)\n",
    "        else:\n",
    "            h = self._forward_block(h)\n",
    "        \n",
    "        # Final output\n",
    "        h = self.final_norm(h)\n",
    "        logits = self.output_proj(h)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "# Example usage with optimizations\n",
    "if __name__ == \"__main__\":\n",
    "    # Enable optimizations\n",
    "    torch.backends.cudnn.benchmark = True  # Optimize for fixed input sizes\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True  # Enable TF32 on Ampere GPUs\n",
    "    \n",
    "    model = MinGRUDecoder(\n",
    "        vocab_size=10000,\n",
    "        embed_dim=512,\n",
    "        hidden_dims=[512, 512],\n",
    "        dropout=0.1,\n",
    "        use_conv=True,\n",
    "        conv_kernel=3,\n",
    "        ffn_expansion=2.0,\n",
    "        use_gradient_checkpointing=True  # Enable memory-efficient training\n",
    "    )\n",
    "    \n",
    "    # Compile model for optimization (PyTorch 2.0+)\n",
    "    model = torch.compile(model, mode=\"reduce-overhead\")\n",
    "    \n",
    "    # Test forward pass\n",
    "    batch_size, seq_len = 4, 128\n",
    "    input_ids = torch.randint(0, 10000, (batch_size, seq_len))\n",
    "    \n",
    "    # Mixed precision training\n",
    "    with torch.amp.autocast('cuda'):\n",
    "        output = model(input_ids)\n",
    "    \n",
    "    print(f\"Input shape: {input_ids.shape}\")\n",
    "    print(f\"Output shape: {output.shape}\")  # Should be (4, 128, 10000)\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # Memory usage optimization example\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        input_ids = input_ids.cuda()\n",
    "        \n",
    "        # Clear cache and measure memory\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        \n",
    "        with torch.amp.autocast('cuda'):\n",
    "            output = model(input_ids)\n",
    "        \n",
    "        peak_memory = torch.cuda.max_memory_allocated() / 1024**3  # GB\n",
    "        print(f\"Peak GPU memory usage: {peak_memory:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "996bf426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_489590/1564922489.py:218: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast()  # Enable automatic mixed precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([4, 128])\n",
      "Output shape: torch.Size([4, 128, 10000])\n",
      "Model parameters: 12,623,632\n",
      "Peak GPU memory usage: 0.19 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Tuple, Optional, Union\n",
    "\n",
    "\n",
    "class CausalConv1D(nn.Module):\n",
    "    \"\"\"Causal 1D Depthwise Convolution\"\"\"\n",
    "    \n",
    "    def __init__(self, dim: int, kernel_size: int):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.depthwise = nn.Conv1d(dim, dim, kernel_size, groups=dim)\n",
    "        self.pointwise = nn.Conv1d(dim, dim, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (batch, seq_len, dim)\n",
    "        x = x.transpose(1, 2)  # (batch, dim, seq_len)\n",
    "        x = F.pad(x, (self.kernel_size - 1, 0))  # causal padding\n",
    "        x = self.pointwise(self.depthwise(x))\n",
    "        return x.transpose(1, 2)  # (batch, seq_len, dim)\n",
    "\n",
    "\n",
    "class MinGRUFunctions:\n",
    "    \"\"\"MinGRU core mathematical functions\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def g_activation(x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Custom activation function - optimized with inplace ops\"\"\"\n",
    "        positive_mask = x >= 0\n",
    "        result = x.clone()  # More efficient than empty_like + assignment\n",
    "        result[positive_mask] += 0.5\n",
    "        result[~positive_mask] = torch.sigmoid_(result[~positive_mask])  # inplace sigmoid\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def log_g_activation(x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Log version of g activation\"\"\"\n",
    "        positive_mask = x >= 0\n",
    "        result = torch.empty_like(x)\n",
    "        result[positive_mask] = torch.log(x[positive_mask] + 0.5).to(x.dtype)\n",
    "        result[~positive_mask] = -F.softplus(-x[~positive_mask]).to(x.dtype)\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def parallel_scan(log_gates: torch.Tensor, log_values: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Parallel scan operation - fixed dimension handling\"\"\"\n",
    "        # Cumulative sum of log gates with proper padding\n",
    "        cumsum_gates = F.pad(torch.cumsum(log_gates, dim=1), [0, 0, 1, 0])  # pad dim=1 (seq_len)\n",
    "        \n",
    "        # Log-cumsum-exp operation\n",
    "        adjusted_values = log_values - cumsum_gates\n",
    "        cumsum_values = torch.logcumsumexp(adjusted_values, dim=1)\n",
    "        \n",
    "        # Combine results\n",
    "        log_output = cumsum_gates + cumsum_values\n",
    "        return torch.exp(log_output)\n",
    "    \n",
    "    @staticmethod\n",
    "    def mingru_step(gate: torch.Tensor, hidden: torch.Tensor, prev_state: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Single MinGRU computation step - fixed concatenation\"\"\"\n",
    "        eps = 1e-12\n",
    "        \n",
    "        # Safe log computation with numerical stability\n",
    "        log_prev = torch.log(torch.clamp(prev_state, min=eps))\n",
    "        \n",
    "        # Compute log probabilities with clamping for stability\n",
    "        gate_clamped = torch.clamp(gate, min=-20, max=20)\n",
    "        log_forget = -F.softplus(gate_clamped)\n",
    "        log_update = -F.softplus(-gate_clamped)\n",
    "        \n",
    "        # Compute log candidate\n",
    "        log_candidate = MinGRUFunctions.log_g_activation(hidden)\n",
    "        \n",
    "        # Concatenate along sequence dimension (dim=1)\n",
    "        log_states = torch.cat([log_prev, log_update + log_candidate], dim=1)\n",
    "        \n",
    "        # Apply parallel scan\n",
    "        sequence_output = MinGRUFunctions.parallel_scan(log_forget, log_states)\n",
    "        return sequence_output[:, 1:]  # Remove initial state\n",
    "\n",
    "\n",
    "class MinGRULayer(nn.Module):\n",
    "    \"\"\"Single MinGRU layer with optimized initialization\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, hidden_dim: int, use_bias: bool = True):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.gate_projection = nn.Linear(input_dim, hidden_dim * 2, bias=use_bias)\n",
    "        self.residual_projection = nn.Linear(input_dim, hidden_dim, bias=False) if input_dim != hidden_dim else nn.Identity()\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Optimized weight initialization\"\"\"\n",
    "        # Xavier/Glorot initialization for better gradient flow\n",
    "        nn.init.xavier_uniform_(self.gate_projection.weight)\n",
    "        if self.gate_projection.bias is not None:\n",
    "            # Initialize gate bias to favor forgetting (negative bias)\n",
    "            nn.init.constant_(self.gate_projection.bias[:self.hidden_dim], -1.0)  # forget gate\n",
    "            nn.init.constant_(self.gate_projection.bias[self.hidden_dim:], 0.0)   # input gate\n",
    "        \n",
    "        if not isinstance(self.residual_projection, nn.Identity):\n",
    "            nn.init.xavier_uniform_(self.residual_projection.weight)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, prev_state: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # Project input to gate and hidden\n",
    "        gate_hidden = self.gate_projection(x)\n",
    "        gate, hidden = gate_hidden.chunk(2, dim=-1)\n",
    "        \n",
    "        # Apply MinGRU computation\n",
    "        output = MinGRUFunctions.mingru_step(gate, hidden, prev_state)\n",
    "        \n",
    "        # Residual connection\n",
    "        if not isinstance(self.residual_projection, nn.Identity):\n",
    "            output = output + self.residual_projection(x)\n",
    "        \n",
    "        # Return output and last hidden state\n",
    "        next_state = output[:, -1:, :]\n",
    "        return output, next_state\n",
    "\n",
    "\n",
    "class MinGRU(nn.Module):\n",
    "    \"\"\"Multi-layer MinGRU with state caching\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, hidden_dims: List[int], dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.num_layers = len(hidden_dims)\n",
    "        \n",
    "        # Build layers\n",
    "        layer_dims = [input_dim] + hidden_dims\n",
    "        self.layers = nn.ModuleList([\n",
    "            MinGRULayer(layer_dims[i], layer_dims[i + 1])\n",
    "            for i in range(self.num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Dropout (except for last layer)\n",
    "        self.dropouts = nn.ModuleList([\n",
    "            nn.Dropout(dropout) if i < self.num_layers - 1 else nn.Identity()\n",
    "            for i in range(self.num_layers)\n",
    "        ])\n",
    "        \n",
    "        # State cache for inference optimization\n",
    "        self._cached_states: Optional[List[torch.Tensor]] = None\n",
    "        self._cache_batch_size: int = 0\n",
    "    \n",
    "    def init_states(self, batch_size: int, device: torch.device) -> List[torch.Tensor]:\n",
    "        \"\"\"Initialize hidden states with optimized memory layout\"\"\"\n",
    "        states = [\n",
    "            MinGRUFunctions.g_activation(torch.zeros(batch_size, 1, dim, device=device, dtype=torch.float32))\n",
    "            for dim in self.hidden_dims\n",
    "        ]\n",
    "        \n",
    "        # Cache states for inference\n",
    "        if not self.training:\n",
    "            self._cached_states = [state.clone() for state in states]\n",
    "            self._cache_batch_size = batch_size\n",
    "            \n",
    "        return states\n",
    "    \n",
    "    def get_cached_states(self, batch_size: int, device: torch.device) -> Optional[List[torch.Tensor]]:\n",
    "        \"\"\"Get cached states if available and valid\"\"\"\n",
    "        if (self._cached_states is not None and \n",
    "            self._cache_batch_size == batch_size and \n",
    "            not self.training):\n",
    "            return [state.clone() for state in self._cached_states]\n",
    "        return None\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, states: Optional[List[torch.Tensor]] = None) -> Tuple[torch.Tensor, List[torch.Tensor]]:\n",
    "        if states is None:\n",
    "            # Try to use cached states first\n",
    "            states = self.get_cached_states(x.size(0), x.device)\n",
    "            if states is None:\n",
    "                states = self.init_states(x.size(0), x.device)\n",
    "        \n",
    "        output = x\n",
    "        next_states = []\n",
    "        \n",
    "        for i, (layer, dropout) in enumerate(zip(self.layers, self.dropouts)):\n",
    "            output, next_state = layer(output, states[i])\n",
    "            output = dropout(output)\n",
    "            next_states.append(next_state)\n",
    "        \n",
    "        # Update cache for next inference\n",
    "        if not self.training:\n",
    "            self._cached_states = [state.clone() for state in next_states]\n",
    "        \n",
    "        return output, next_states\n",
    "\n",
    "\n",
    "class SwiGLU(nn.Module):\n",
    "    \"\"\"SwiGLU Feed-Forward Network with mixed precision support\"\"\"\n",
    "    \n",
    "    def __init__(self, dim: int, expansion_factor: float = 2.0, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(dim * expansion_factor * 2/3)\n",
    "        hidden_dim = ((hidden_dim + 7) // 8) * 8  # Round to multiple of 8 for tensor cores\n",
    "        \n",
    "        self.gate_proj = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.up_proj = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.down_proj = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = nn.SiLU()\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize weights for mixed precision training\"\"\"\n",
    "        for module in [self.gate_proj, self.up_proj, self.down_proj]:\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            # Scale down weights for numerical stability in fp16\n",
    "            module.weight.data *= 0.5\n",
    "    \n",
    "    @torch.cuda.amp.autocast()  # Enable automatic mixed precision\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Fused gating operation\n",
    "        gate = self.activation(self.gate_proj(x))\n",
    "        up = self.up_proj(x)\n",
    "        \n",
    "        # Element-wise multiplication in fp16, but accumulate in fp32\n",
    "        gated = gate * up\n",
    "        return self.dropout(self.down_proj(gated))\n",
    "\n",
    "\n",
    "class MinGRUDecoder(nn.Module):\n",
    "    \"\"\"Complete MinGRU-based decoder model with optimizations\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embed_dim: int,\n",
    "        hidden_dims: Union[int, List[int]],\n",
    "        num_layers: Optional[int] = None,\n",
    "        dropout: float = 0.1,\n",
    "        use_conv: bool = True,\n",
    "        conv_kernel: int = 3,\n",
    "        ffn_expansion: float = 1.0,\n",
    "        norm_eps: float = 1e-8,\n",
    "        use_gradient_checkpointing: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Handle hidden dimensions\n",
    "        if isinstance(hidden_dims, int):\n",
    "            if num_layers is None:\n",
    "                raise ValueError(\"num_layers must be specified when hidden_dims is int\")\n",
    "            hidden_dims = [hidden_dims] * num_layers\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.use_gradient_checkpointing = use_gradient_checkpointing\n",
    "        \n",
    "        # Input layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.input_proj = nn.Linear(embed_dim, hidden_dims[0]) if embed_dim != hidden_dims[0] else nn.Identity()\n",
    "        \n",
    "        # Optional convolution\n",
    "        self.conv = CausalConv1D(hidden_dims[0], conv_kernel) if use_conv else None\n",
    "        \n",
    "        # Core MinGRU\n",
    "        self.pre_gru_norm = nn.RMSNorm(hidden_dims[0], eps=norm_eps)\n",
    "        self.mingru = MinGRU(hidden_dims[0], hidden_dims, dropout)\n",
    "        \n",
    "        # Feed-forward network\n",
    "        self.post_gru_norm = nn.RMSNorm(hidden_dims[-1], eps=norm_eps)\n",
    "        self.ffn = SwiGLU(hidden_dims[-1], ffn_expansion, dropout)\n",
    "        \n",
    "        # Output layers\n",
    "        self.final_norm = nn.RMSNorm(hidden_dims[-1], eps=norm_eps)\n",
    "        self.output_proj = nn.Linear(hidden_dims[-1], vocab_size)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize all model weights\"\"\"\n",
    "        # Embedding initialization\n",
    "        nn.init.normal_(self.embedding.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        # Linear layer initialization\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def _forward_block(self, h: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass through MinGRU and FFN blocks\"\"\"\n",
    "        # MinGRU processing\n",
    "        h_norm = self.pre_gru_norm(h)\n",
    "        gru_out, _ = self.mingru(h_norm)\n",
    "        h = h + gru_out  # Residual connection\n",
    "        \n",
    "        # Feed-forward with residual\n",
    "        h_norm = self.post_gru_norm(h)\n",
    "        ffn_out = self.ffn(h_norm)\n",
    "        h = h + ffn_out  # Residual connection\n",
    "        \n",
    "        return h\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Embedding and input projection\n",
    "        h = self.embedding(x)\n",
    "        h = self.input_proj(h)\n",
    "        \n",
    "        # Optional convolution with residual\n",
    "        if self.conv is not None:\n",
    "            h = h + self.conv(h)\n",
    "        \n",
    "        # Main processing with optional gradient checkpointing\n",
    "        if self.use_gradient_checkpointing and self.training:\n",
    "            h = torch.utils.checkpoint.checkpoint(self._forward_block, h, use_reentrant=False)\n",
    "        else:\n",
    "            h = self._forward_block(h)\n",
    "        \n",
    "        # Final output\n",
    "        h = self.final_norm(h)\n",
    "        logits = self.output_proj(h)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "# Example usage with optimizations\n",
    "if __name__ == \"__main__\":\n",
    "    # Enable optimizations\n",
    "    torch.backends.cudnn.benchmark = True  # Optimize for fixed input sizes\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True  # Enable TF32 on Ampere GPUs\n",
    "    \n",
    "    model = MinGRUDecoder(\n",
    "        vocab_size=10000,\n",
    "        embed_dim=512,\n",
    "        hidden_dims=[512, 512],\n",
    "        dropout=0.1,\n",
    "        use_conv=True,\n",
    "        conv_kernel=3,\n",
    "        ffn_expansion=2.0,\n",
    "        use_gradient_checkpointing=True  # Enable memory-efficient training\n",
    "    )\n",
    "    \n",
    "    # Compile model for optimization (PyTorch 2.0+)\n",
    "    model = torch.compile(model, mode=\"reduce-overhead\")\n",
    "    \n",
    "    # Test forward pass\n",
    "    batch_size, seq_len = 4, 128\n",
    "    input_ids = torch.randint(0, 10000, (batch_size, seq_len))\n",
    "    \n",
    "    # Mixed precision training\n",
    "    with torch.amp.autocast('cuda'):\n",
    "        output = model(input_ids)\n",
    "    \n",
    "    print(f\"Input shape: {input_ids.shape}\")\n",
    "    print(f\"Output shape: {output.shape}\")  # Should be (4, 128, 10000)\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # Memory usage optimization example\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        input_ids = input_ids.cuda()\n",
    "        \n",
    "        # Clear cache and measure memory\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        \n",
    "        with torch.amp.autocast('cuda'):\n",
    "            output = model(input_ids)\n",
    "        \n",
    "        peak_memory = torch.cuda.max_memory_allocated() / 1024**3  # GB\n",
    "        print(f\"Peak GPU memory usage: {peak_memory:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e082f963",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_489590/834961635.py:223: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast()  # Enable automatic mixed precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([4, 128])\n",
      "Output shape: torch.Size([4, 128, 10000])\n",
      "Model parameters: 12,623,632\n",
      "Peak GPU memory usage: 0.19 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Tuple, Optional, Union\n",
    "\n",
    "\n",
    "class CausalConv1D(nn.Module):\n",
    "    \"\"\"Causal 1D Depthwise Convolution\"\"\"\n",
    "    \n",
    "    def __init__(self, dim: int, kernel_size: int):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.depthwise = nn.Conv1d(dim, dim, kernel_size, groups=dim)\n",
    "        self.pointwise = nn.Conv1d(dim, dim, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (batch, seq_len, dim)\n",
    "        x = x.transpose(1, 2)  # (batch, dim, seq_len)\n",
    "        x = F.pad(x, (self.kernel_size - 1, 0))  # causal padding\n",
    "        x = self.pointwise(self.depthwise(x))\n",
    "        return x.transpose(1, 2)  # (batch, seq_len, dim)\n",
    "\n",
    "\n",
    "class MinGRUFunctions:\n",
    "    \"\"\"MinGRU core mathematical functions\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def g_activation(x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Custom activation function - optimized with inplace ops\"\"\"\n",
    "        positive_mask = x >= 0\n",
    "        result = x.clone()  # More efficient than empty_like + assignment\n",
    "        result[positive_mask] += 0.5\n",
    "        result[~positive_mask] = torch.sigmoid_(result[~positive_mask])  # inplace sigmoid\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def log_g_activation(x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Log version of g activation - improved numerical stability\"\"\"\n",
    "        positive_mask = x >= 0\n",
    "        result = torch.empty_like(x)\n",
    "        \n",
    "        # For positive values: log(x + 0.5)\n",
    "        result[positive_mask] = torch.log(x[positive_mask] + 0.5).to(x.dtype)\n",
    "        \n",
    "        # For negative values: log(sigmoid(x)) = -softplus(-x)\n",
    "        result[~positive_mask] = -F.softplus(-x[~positive_mask]).to(x.dtype)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def parallel_scan(log_gates: torch.Tensor, log_values: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Parallel scan operation - fixed dimension handling\"\"\"\n",
    "        # Cumulative sum of log gates with proper padding\n",
    "        cumsum_gates = F.pad(torch.cumsum(log_gates, dim=1), [0, 0, 1, 0])  # pad dim=1 (seq_len)\n",
    "        \n",
    "        # Log-cumsum-exp operation\n",
    "        adjusted_values = log_values - cumsum_gates\n",
    "        cumsum_values = torch.logcumsumexp(adjusted_values, dim=1)\n",
    "        \n",
    "        # Combine results\n",
    "        log_output = cumsum_gates + cumsum_values\n",
    "        return torch.exp(log_output)\n",
    "    \n",
    "    @staticmethod\n",
    "    def mingru_step(gate: torch.Tensor, hidden: torch.Tensor, prev_state: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Single MinGRU computation step - fixed concatenation\"\"\"\n",
    "        eps = 1e-12\n",
    "        \n",
    "        # Safe log computation with numerical stability\n",
    "        log_prev = torch.log(torch.clamp(prev_state, min=eps))\n",
    "        \n",
    "        # Compute log probabilities with clamping for stability\n",
    "        gate_clamped = torch.clamp(gate, min=-20, max=20)\n",
    "        log_forget = -F.softplus(gate_clamped)\n",
    "        log_update = -F.softplus(-gate_clamped)\n",
    "        \n",
    "        # Compute log candidate\n",
    "        log_candidate = MinGRUFunctions.log_g_activation(hidden)\n",
    "        \n",
    "        # Concatenate along sequence dimension (dim=1)\n",
    "        log_states = torch.cat([log_prev, log_update + log_candidate], dim=1)\n",
    "        \n",
    "        # Apply parallel scan\n",
    "        sequence_output = MinGRUFunctions.parallel_scan(log_forget, log_states)\n",
    "        return sequence_output[:, 1:]  # Remove initial state\n",
    "\n",
    "\n",
    "class MinGRULayer(nn.Module):\n",
    "    \"\"\"Single MinGRU layer with optimized initialization\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, hidden_dim: int, use_bias: bool = True):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.gate_projection = nn.Linear(input_dim, hidden_dim * 2, bias=use_bias)\n",
    "        self.residual_projection = nn.Linear(input_dim, hidden_dim, bias=False) if input_dim != hidden_dim else nn.Identity()\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Optimized weight initialization\"\"\"\n",
    "        # Xavier/Glorot initialization for better gradient flow\n",
    "        nn.init.xavier_uniform_(self.gate_projection.weight)\n",
    "        if self.gate_projection.bias is not None:\n",
    "            # Initialize gate bias to favor forgetting (negative bias)\n",
    "            nn.init.constant_(self.gate_projection.bias[:self.hidden_dim], -1.0)  # forget gate\n",
    "            nn.init.constant_(self.gate_projection.bias[self.hidden_dim:], 0.0)   # input gate\n",
    "        \n",
    "        if not isinstance(self.residual_projection, nn.Identity):\n",
    "            nn.init.xavier_uniform_(self.residual_projection.weight)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, prev_state: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # Project input to gate and hidden\n",
    "        gate_hidden = self.gate_projection(x)\n",
    "        gate, hidden = gate_hidden.chunk(2, dim=-1)\n",
    "        \n",
    "        # Apply MinGRU computation\n",
    "        output = MinGRUFunctions.mingru_step(gate, hidden, prev_state)\n",
    "        \n",
    "        # Residual connection\n",
    "        if not isinstance(self.residual_projection, nn.Identity):\n",
    "            output = output + self.residual_projection(x)\n",
    "        \n",
    "        # Return output and last hidden state\n",
    "        next_state = output[:, -1:, :]\n",
    "        return output, next_state\n",
    "\n",
    "\n",
    "class MinGRU(nn.Module):\n",
    "    \"\"\"Multi-layer MinGRU with state caching\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, hidden_dims: List[int], dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.num_layers = len(hidden_dims)\n",
    "        \n",
    "        # Build layers\n",
    "        layer_dims = [input_dim] + hidden_dims\n",
    "        self.layers = nn.ModuleList([\n",
    "            MinGRULayer(layer_dims[i], layer_dims[i + 1])\n",
    "            for i in range(self.num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Dropout (except for last layer)\n",
    "        self.dropouts = nn.ModuleList([\n",
    "            nn.Dropout(dropout) if i < self.num_layers - 1 else nn.Identity()\n",
    "            for i in range(self.num_layers)\n",
    "        ])\n",
    "        \n",
    "        # State cache for inference optimization\n",
    "        self._cached_states: Optional[List[torch.Tensor]] = None\n",
    "        self._cache_batch_size: int = 0\n",
    "    \n",
    "    def init_states(self, batch_size: int, device: torch.device) -> List[torch.Tensor]:\n",
    "        \"\"\"Initialize hidden states with optimized memory layout\"\"\"\n",
    "        states = [\n",
    "            MinGRUFunctions.g_activation(torch.zeros(batch_size, 1, dim, device=device, dtype=torch.float32))\n",
    "            for dim in self.hidden_dims\n",
    "        ]\n",
    "        \n",
    "        # Cache states for inference\n",
    "        if not self.training:\n",
    "            self._cached_states = [state.clone() for state in states]\n",
    "            self._cache_batch_size = batch_size\n",
    "            \n",
    "        return states\n",
    "    \n",
    "    def get_cached_states(self, batch_size: int, device: torch.device) -> Optional[List[torch.Tensor]]:\n",
    "        \"\"\"Get cached states if available and valid\"\"\"\n",
    "        if (self._cached_states is not None and \n",
    "            self._cache_batch_size == batch_size and \n",
    "            not self.training):\n",
    "            return [state.clone() for state in self._cached_states]\n",
    "        return None\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, states: Optional[List[torch.Tensor]] = None) -> Tuple[torch.Tensor, List[torch.Tensor]]:\n",
    "        if states is None:\n",
    "            # Try to use cached states first\n",
    "            states = self.get_cached_states(x.size(0), x.device)\n",
    "            if states is None:\n",
    "                states = self.init_states(x.size(0), x.device)\n",
    "        \n",
    "        output = x\n",
    "        next_states = []\n",
    "        \n",
    "        for i, (layer, dropout) in enumerate(zip(self.layers, self.dropouts)):\n",
    "            output, next_state = layer(output, states[i])\n",
    "            output = dropout(output)\n",
    "            next_states.append(next_state)\n",
    "        \n",
    "        # Update cache for next inference\n",
    "        if not self.training:\n",
    "            self._cached_states = [state.clone() for state in next_states]\n",
    "        \n",
    "        return output, next_states\n",
    "\n",
    "\n",
    "class SwiGLU(nn.Module):\n",
    "    \"\"\"SwiGLU Feed-Forward Network with mixed precision support\"\"\"\n",
    "    \n",
    "    def __init__(self, dim: int, expansion_factor: float = 2.0, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(dim * expansion_factor * 2/3)\n",
    "        hidden_dim = ((hidden_dim + 7) // 8) * 8  # Round to multiple of 8 for tensor cores\n",
    "        \n",
    "        self.gate_proj = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.up_proj = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.down_proj = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = nn.SiLU()\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize weights for mixed precision training\"\"\"\n",
    "        for module in [self.gate_proj, self.up_proj, self.down_proj]:\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            # Scale down weights for numerical stability in fp16\n",
    "            module.weight.data *= 0.5\n",
    "    \n",
    "    @torch.cuda.amp.autocast()  # Enable automatic mixed precision\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Fused gating operation\n",
    "        gate = self.activation(self.gate_proj(x))\n",
    "        up = self.up_proj(x)\n",
    "        \n",
    "        # Element-wise multiplication in fp16, but accumulate in fp32\n",
    "        gated = gate * up\n",
    "        return self.dropout(self.down_proj(gated))\n",
    "\n",
    "\n",
    "class MinGRUDecoder(nn.Module):\n",
    "    \"\"\"Complete MinGRU-based decoder model with optimizations\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embed_dim: int,\n",
    "        hidden_dims: Union[int, List[int]],\n",
    "        num_layers: Optional[int] = None,\n",
    "        dropout: float = 0.1,\n",
    "        use_conv: bool = True,\n",
    "        conv_kernel: int = 3,\n",
    "        ffn_expansion: float = 1.0,\n",
    "        norm_eps: float = 1e-8,\n",
    "        use_gradient_checkpointing: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Handle hidden dimensions\n",
    "        if isinstance(hidden_dims, int):\n",
    "            if num_layers is None:\n",
    "                raise ValueError(\"num_layers must be specified when hidden_dims is int\")\n",
    "            hidden_dims = [hidden_dims] * num_layers\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.use_gradient_checkpointing = use_gradient_checkpointing\n",
    "        \n",
    "        # Input layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.input_proj = nn.Linear(embed_dim, hidden_dims[0]) if embed_dim != hidden_dims[0] else nn.Identity()\n",
    "        \n",
    "        # Optional convolution\n",
    "        self.conv = CausalConv1D(hidden_dims[0], conv_kernel) if use_conv else None\n",
    "        \n",
    "        # Core MinGRU\n",
    "        self.pre_gru_norm = nn.RMSNorm(hidden_dims[0], eps=norm_eps)\n",
    "        self.mingru = MinGRU(hidden_dims[0], hidden_dims, dropout)\n",
    "        \n",
    "        # Feed-forward network\n",
    "        self.post_gru_norm = nn.RMSNorm(hidden_dims[-1], eps=norm_eps)\n",
    "        self.ffn = SwiGLU(hidden_dims[-1], ffn_expansion, dropout)\n",
    "        \n",
    "        # Output layers\n",
    "        self.final_norm = nn.RMSNorm(hidden_dims[-1], eps=norm_eps)\n",
    "        self.output_proj = nn.Linear(hidden_dims[-1], vocab_size)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize all model weights\"\"\"\n",
    "        # Embedding initialization\n",
    "        nn.init.normal_(self.embedding.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        # Linear layer initialization\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def _forward_block(self, h: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass through MinGRU and FFN blocks\"\"\"\n",
    "        # MinGRU processing\n",
    "        h_norm = self.pre_gru_norm(h)\n",
    "        gru_out, _ = self.mingru(h_norm)\n",
    "        h = h + gru_out  # Residual connection\n",
    "        \n",
    "        # Feed-forward with residual\n",
    "        h_norm = self.post_gru_norm(h)\n",
    "        ffn_out = self.ffn(h_norm)\n",
    "        h = h + ffn_out  # Residual connection\n",
    "        \n",
    "        return h\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Embedding and input projection\n",
    "        h = self.embedding(x)\n",
    "        h = self.input_proj(h)\n",
    "        \n",
    "        # Optional convolution with residual\n",
    "        if self.conv is not None:\n",
    "            h = h + self.conv(h)\n",
    "        \n",
    "        # Main processing with optional gradient checkpointing\n",
    "        if self.use_gradient_checkpointing and self.training:\n",
    "            h = torch.utils.checkpoint.checkpoint(self._forward_block, h, use_reentrant=False)\n",
    "        else:\n",
    "            h = self._forward_block(h)\n",
    "        \n",
    "        # Final output\n",
    "        h = self.final_norm(h)\n",
    "        logits = self.output_proj(h)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "# Example usage with optimizations\n",
    "if __name__ == \"__main__\":\n",
    "    # Enable optimizations\n",
    "    torch.backends.cudnn.benchmark = True  # Optimize for fixed input sizes\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True  # Enable TF32 on Ampere GPUs\n",
    "    \n",
    "    model = MinGRUDecoder(\n",
    "        vocab_size=10000,\n",
    "        embed_dim=512,\n",
    "        hidden_dims=[512, 512],\n",
    "        dropout=0.1,\n",
    "        use_conv=True,\n",
    "        conv_kernel=3,\n",
    "        ffn_expansion=2.0,\n",
    "        use_gradient_checkpointing=True  # Enable memory-efficient training\n",
    "    )\n",
    "    \n",
    "    # Compile model for optimization (PyTorch 2.0+)\n",
    "    model = torch.compile(model, mode=\"reduce-overhead\")\n",
    "    \n",
    "    # Test forward pass\n",
    "    batch_size, seq_len = 4, 128\n",
    "    input_ids = torch.randint(0, 10000, (batch_size, seq_len))\n",
    "    \n",
    "    # Mixed precision training\n",
    "    with torch.amp.autocast('cuda'):\n",
    "        output = model(input_ids)\n",
    "    \n",
    "    print(f\"Input shape: {input_ids.shape}\")\n",
    "    print(f\"Output shape: {output.shape}\")  # Should be (4, 128, 10000)\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # Memory usage optimization example\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        input_ids = input_ids.cuda()\n",
    "        \n",
    "        # Clear cache and measure memory\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        \n",
    "        with torch.amp.autocast('cuda'):\n",
    "            output = model(input_ids)\n",
    "        \n",
    "        peak_memory = torch.cuda.max_memory_allocated() / 1024**3  # GB\n",
    "        print(f\"Peak GPU memory usage: {peak_memory:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "013a35c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_489590/3505940746.py:235: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast()  # Enable automatic mixed precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([4, 128])\n",
      "Output shape: torch.Size([4, 128, 10000])\n",
      "Model parameters: 12,623,632\n",
      "Peak GPU memory usage: 0.19 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Tuple, Optional, Union\n",
    "\n",
    "# Conditional import for mixed precision\n",
    "try:\n",
    "    from torch.amp import autocast\n",
    "    HAS_AMP = True\n",
    "except ImportError:\n",
    "    HAS_AMP = False\n",
    "    # Dummy decorator if AMP is not available\n",
    "    def autocast():\n",
    "        def decorator(func):\n",
    "            return func('cuda')\n",
    "        return decorator\n",
    "\n",
    "\n",
    "class CausalConv1D(nn.Module):\n",
    "    \"\"\"Causal 1D Depthwise Convolution\"\"\"\n",
    "    \n",
    "    def __init__(self, dim: int, kernel_size: int):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.depthwise = nn.Conv1d(dim, dim, kernel_size, groups=dim)\n",
    "        self.pointwise = nn.Conv1d(dim, dim, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (batch, seq_len, dim)\n",
    "        x = x.transpose(1, 2)  # (batch, dim, seq_len)\n",
    "        x = F.pad(x, (self.kernel_size - 1, 0))  # causal padding\n",
    "        x = self.pointwise(self.depthwise(x))\n",
    "        return x.transpose(1, 2)  # (batch, seq_len, dim)\n",
    "\n",
    "\n",
    "class MinGRUFunctions:\n",
    "    \"\"\"MinGRU core mathematical functions\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def g_activation(x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Custom activation function - optimized with inplace ops\"\"\"\n",
    "        positive_mask = x >= 0\n",
    "        result = x.clone()  # More efficient than empty_like + assignment\n",
    "        result[positive_mask] += 0.5\n",
    "        result[~positive_mask] = torch.sigmoid_(result[~positive_mask])  # inplace sigmoid\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def log_g_activation(x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Log version of g activation - improved numerical stability\"\"\"\n",
    "        positive_mask = x >= 0\n",
    "        result = torch.empty_like(x)\n",
    "        \n",
    "        # For positive values: log(x + 0.5)\n",
    "        result[positive_mask] = torch.log(x[positive_mask] + 0.5).to(x.dtype)\n",
    "        \n",
    "        # For negative values: log(sigmoid(x)) = -softplus(-x)\n",
    "        result[~positive_mask] = -F.softplus(-x[~positive_mask]).to(x.dtype)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def parallel_scan(log_gates: torch.Tensor, log_values: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Parallel scan operation - fixed dimension handling\"\"\"\n",
    "        # Cumulative sum of log gates with proper padding\n",
    "        cumsum_gates = F.pad(torch.cumsum(log_gates, dim=1), [0, 0, 1, 0])  # pad dim=1 (seq_len)\n",
    "        \n",
    "        # Log-cumsum-exp operation\n",
    "        adjusted_values = log_values - cumsum_gates\n",
    "        cumsum_values = torch.logcumsumexp(adjusted_values, dim=1)\n",
    "        \n",
    "        # Combine results\n",
    "        log_output = cumsum_gates + cumsum_values\n",
    "        return torch.exp(log_output)\n",
    "    \n",
    "    @staticmethod\n",
    "    def mingru_step(gate: torch.Tensor, hidden: torch.Tensor, prev_state: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Single MinGRU computation step - fixed concatenation\"\"\"\n",
    "        eps = 1e-12\n",
    "        \n",
    "        # Safe log computation with numerical stability\n",
    "        log_prev = torch.log(torch.clamp(prev_state, min=eps))\n",
    "        \n",
    "        # Compute log probabilities with clamping for stability\n",
    "        gate_clamped = torch.clamp(gate, min=-20, max=20)\n",
    "        log_forget = -F.softplus(gate_clamped)\n",
    "        log_update = -F.softplus(-gate_clamped)\n",
    "        \n",
    "        # Compute log candidate\n",
    "        log_candidate = MinGRUFunctions.log_g_activation(hidden)\n",
    "        \n",
    "        # Concatenate along sequence dimension (dim=1)\n",
    "        log_states = torch.cat([log_prev, log_update + log_candidate], dim=1)\n",
    "        \n",
    "        # Apply parallel scan\n",
    "        sequence_output = MinGRUFunctions.parallel_scan(log_forget, log_states)\n",
    "        return sequence_output[:, 1:]  # Remove initial state\n",
    "\n",
    "\n",
    "class MinGRULayer(nn.Module):\n",
    "    \"\"\"Single MinGRU layer with optimized initialization\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, hidden_dim: int, use_bias: bool = True):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.gate_projection = nn.Linear(input_dim, hidden_dim * 2, bias=use_bias)\n",
    "        self.residual_projection = nn.Linear(input_dim, hidden_dim, bias=False) if input_dim != hidden_dim else nn.Identity()\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Optimized weight initialization\"\"\"\n",
    "        # Xavier/Glorot initialization for better gradient flow\n",
    "        nn.init.xavier_uniform_(self.gate_projection.weight)\n",
    "        if self.gate_projection.bias is not None:\n",
    "            # Initialize gate bias to favor forgetting (negative bias)\n",
    "            nn.init.constant_(self.gate_projection.bias[:self.hidden_dim], -1.0)  # forget gate\n",
    "            nn.init.constant_(self.gate_projection.bias[self.hidden_dim:], 0.0)   # input gate\n",
    "        \n",
    "        if not isinstance(self.residual_projection, nn.Identity):\n",
    "            nn.init.xavier_uniform_(self.residual_projection.weight)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, prev_state: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # Project input to gate and hidden\n",
    "        gate_hidden = self.gate_projection(x)\n",
    "        gate, hidden = gate_hidden.chunk(2, dim=-1)\n",
    "        \n",
    "        # Apply MinGRU computation\n",
    "        output = MinGRUFunctions.mingru_step(gate, hidden, prev_state)\n",
    "        \n",
    "        # Residual connection\n",
    "        if not isinstance(self.residual_projection, nn.Identity):\n",
    "            output = output + self.residual_projection(x)\n",
    "        \n",
    "        # Return output and last hidden state\n",
    "        next_state = output[:, -1:, :]\n",
    "        return output, next_state\n",
    "\n",
    "\n",
    "class MinGRU(nn.Module):\n",
    "    \"\"\"Multi-layer MinGRU with state caching\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, hidden_dims: List[int], dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.num_layers = len(hidden_dims)\n",
    "        \n",
    "        # Build layers\n",
    "        layer_dims = [input_dim] + hidden_dims\n",
    "        self.layers = nn.ModuleList([\n",
    "            MinGRULayer(layer_dims[i], layer_dims[i + 1])\n",
    "            for i in range(self.num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Dropout (except for last layer)\n",
    "        self.dropouts = nn.ModuleList([\n",
    "            nn.Dropout(dropout) if i < self.num_layers - 1 else nn.Identity()\n",
    "            for i in range(self.num_layers)\n",
    "        ])\n",
    "        \n",
    "        # State cache for inference optimization\n",
    "        self._cached_states: Optional[List[torch.Tensor]] = None\n",
    "        self._cache_batch_size: int = 0\n",
    "    \n",
    "    def init_states(self, batch_size: int, device: torch.device) -> List[torch.Tensor]:\n",
    "        \"\"\"Initialize hidden states with optimized memory layout\"\"\"\n",
    "        states = [\n",
    "            MinGRUFunctions.g_activation(torch.zeros(batch_size, 1, dim, device=device, dtype=torch.float32))\n",
    "            for dim in self.hidden_dims\n",
    "        ]\n",
    "        \n",
    "        # Cache states for inference\n",
    "        if not self.training:\n",
    "            self._cached_states = [state.clone() for state in states]\n",
    "            self._cache_batch_size = batch_size\n",
    "            \n",
    "        return states\n",
    "    \n",
    "    def get_cached_states(self, batch_size: int, device: torch.device) -> Optional[List[torch.Tensor]]:\n",
    "        \"\"\"Get cached states if available and valid\"\"\"\n",
    "        if (self._cached_states is not None and \n",
    "            self._cache_batch_size == batch_size and \n",
    "            not self.training):\n",
    "            return [state.clone() for state in self._cached_states]\n",
    "        return None\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, states: Optional[List[torch.Tensor]] = None) -> Tuple[torch.Tensor, List[torch.Tensor]]:\n",
    "        if states is None:\n",
    "            # Try to use cached states first\n",
    "            states = self.get_cached_states(x.size(0), x.device)\n",
    "            if states is None:\n",
    "                states = self.init_states(x.size(0), x.device)\n",
    "        \n",
    "        output = x\n",
    "        next_states = []\n",
    "        \n",
    "        for i, (layer, dropout) in enumerate(zip(self.layers, self.dropouts)):\n",
    "            output, next_state = layer(output, states[i])\n",
    "            output = dropout(output)\n",
    "            next_states.append(next_state)\n",
    "        \n",
    "        # Update cache for next inference\n",
    "        if not self.training:\n",
    "            self._cached_states = [state.clone() for state in next_states]\n",
    "        \n",
    "        return output, next_states\n",
    "\n",
    "\n",
    "class SwiGLU(nn.Module):\n",
    "    \"\"\"SwiGLU Feed-Forward Network with mixed precision support\"\"\"\n",
    "    \n",
    "    def __init__(self, dim: int, expansion_factor: float = 2.0, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(dim * expansion_factor * 2/3)\n",
    "        hidden_dim = ((hidden_dim + 7) // 8) * 8  # Round to multiple of 8 for tensor cores\n",
    "        \n",
    "        self.gate_proj = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.up_proj = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.down_proj = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = nn.SiLU()\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize weights for mixed precision training\"\"\"\n",
    "        for module in [self.gate_proj, self.up_proj, self.down_proj]:\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            # Scale down weights for numerical stability in fp16\n",
    "            module.weight.data *= 0.5\n",
    "    \n",
    "    @torch.cuda.amp.autocast()  # Enable automatic mixed precision\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Fused gating operation\n",
    "        gate = self.activation(self.gate_proj(x))\n",
    "        up = self.up_proj(x)\n",
    "        \n",
    "        # Element-wise multiplication in fp16, but accumulate in fp32\n",
    "        gated = gate * up\n",
    "        return self.dropout(self.down_proj(gated))\n",
    "\n",
    "\n",
    "class MinGRUDecoder(nn.Module):\n",
    "    \"\"\"Complete MinGRU-based decoder model with optimizations\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embed_dim: int,\n",
    "        hidden_dims: Union[int, List[int]],\n",
    "        num_layers: Optional[int] = None,\n",
    "        dropout: float = 0.1,\n",
    "        use_conv: bool = True,\n",
    "        conv_kernel: int = 3,\n",
    "        ffn_expansion: float = 1.0,\n",
    "        norm_eps: float = 1e-8,\n",
    "        use_gradient_checkpointing: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Handle hidden dimensions\n",
    "        if isinstance(hidden_dims, int):\n",
    "            if num_layers is None:\n",
    "                raise ValueError(\"num_layers must be specified when hidden_dims is int\")\n",
    "            hidden_dims = [hidden_dims] * num_layers\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.use_gradient_checkpointing = use_gradient_checkpointing\n",
    "        \n",
    "        # Input layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.input_proj = nn.Linear(embed_dim, hidden_dims[0]) if embed_dim != hidden_dims[0] else nn.Identity()\n",
    "        \n",
    "        # Optional convolution\n",
    "        self.conv = CausalConv1D(hidden_dims[0], conv_kernel) if use_conv else None\n",
    "        \n",
    "        # Core MinGRU\n",
    "        self.pre_gru_norm = nn.RMSNorm(hidden_dims[0], eps=norm_eps)\n",
    "        self.mingru = MinGRU(hidden_dims[0], hidden_dims, dropout)\n",
    "        \n",
    "        # Feed-forward network\n",
    "        self.post_gru_norm = nn.RMSNorm(hidden_dims[-1], eps=norm_eps)\n",
    "        self.ffn = SwiGLU(hidden_dims[-1], ffn_expansion, dropout)\n",
    "        \n",
    "        # Output layers\n",
    "        self.final_norm = nn.RMSNorm(hidden_dims[-1], eps=norm_eps)\n",
    "        self.output_proj = nn.Linear(hidden_dims[-1], vocab_size)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize all model weights\"\"\"\n",
    "        # Embedding initialization\n",
    "        nn.init.normal_(self.embedding.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        # Linear layer initialization\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def _forward_block(self, h: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass through MinGRU and FFN blocks\"\"\"\n",
    "        # MinGRU processing\n",
    "        h_norm = self.pre_gru_norm(h)\n",
    "        gru_out, _ = self.mingru(h_norm)\n",
    "        h = h + gru_out  # Residual connection\n",
    "        \n",
    "        # Feed-forward with residual\n",
    "        h_norm = self.post_gru_norm(h)\n",
    "        ffn_out = self.ffn(h_norm)\n",
    "        h = h + ffn_out  # Residual connection\n",
    "        \n",
    "        return h\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Embedding and input projection\n",
    "        h = self.embedding(x)\n",
    "        h = self.input_proj(h)\n",
    "        \n",
    "        # Optional convolution with residual\n",
    "        if self.conv is not None:\n",
    "            h = h + self.conv(h)\n",
    "        \n",
    "        # Main processing with optional gradient checkpointing\n",
    "        if self.use_gradient_checkpointing and self.training:\n",
    "            h = torch.utils.checkpoint.checkpoint(self._forward_block, h, use_reentrant=False)\n",
    "        else:\n",
    "            h = self._forward_block(h)\n",
    "        \n",
    "        # Final output\n",
    "        h = self.final_norm(h)\n",
    "        logits = self.output_proj(h)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "# Example usage with optimizations\n",
    "if __name__ == \"__main__\":\n",
    "    # Enable optimizations\n",
    "    torch.backends.cudnn.benchmark = True  # Optimize for fixed input sizes\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True  # Enable TF32 on Ampere GPUs\n",
    "    \n",
    "    model = MinGRUDecoder(\n",
    "        vocab_size=10000,\n",
    "        embed_dim=512,\n",
    "        hidden_dims=[512, 512],\n",
    "        dropout=0.1,\n",
    "        use_conv=True,\n",
    "        conv_kernel=3,\n",
    "        ffn_expansion=2.0,\n",
    "        use_gradient_checkpointing=True  # Enable memory-efficient training\n",
    "    )\n",
    "    \n",
    "    # Compile model for optimization (PyTorch 2.0+)\n",
    "    model = torch.compile(model, mode=\"reduce-overhead\")\n",
    "    \n",
    "    # Test forward pass\n",
    "    batch_size, seq_len = 4, 128\n",
    "    input_ids = torch.randint(0, 10000, (batch_size, seq_len))\n",
    "    \n",
    "    # Mixed precision training\n",
    "    with torch.amp.autocast('cuda'):\n",
    "        output = model(input_ids)\n",
    "    \n",
    "    print(f\"Input shape: {input_ids.shape}\")\n",
    "    print(f\"Output shape: {output.shape}\")  # Should be (4, 128, 10000)\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # Memory usage optimization example\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        input_ids = input_ids.cuda()\n",
    "        \n",
    "        # Clear cache and measure memory\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        \n",
    "        with torch.amp.autocast('cuda'):\n",
    "            output = model(input_ids)\n",
    "        \n",
    "        peak_memory = torch.cuda.max_memory_allocated() / 1024**3  # GB\n",
    "        print(f\"Peak GPU memory usage: {peak_memory:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "260f2c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_489590/3658400224.py:367: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([4, 128])\n",
      "Output shape: torch.Size([4, 128, 10000])\n",
      "Model parameters: 12,623,632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_489590/3658400224.py:383: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak GPU memory usage: 0.19 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Tuple, Optional, Union\n",
    "\n",
    "# Conditional import for mixed precision\n",
    "try:\n",
    "    from torch.cuda.amp import autocast\n",
    "    HAS_AMP = True\n",
    "except ImportError:\n",
    "    HAS_AMP = False\n",
    "    # Dummy decorator if AMP is not available\n",
    "    def autocast():\n",
    "        def decorator(func):\n",
    "            return func\n",
    "        return decorator\n",
    "\n",
    "\n",
    "class CausalConv1D(nn.Module):\n",
    "    \"\"\"Causal 1D Depthwise Convolution\"\"\"\n",
    "    \n",
    "    def __init__(self, dim: int, kernel_size: int):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.depthwise = nn.Conv1d(dim, dim, kernel_size, groups=dim)\n",
    "        self.pointwise = nn.Conv1d(dim, dim, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (batch, seq_len, dim)\n",
    "        x = x.transpose(1, 2)  # (batch, dim, seq_len)\n",
    "        x = F.pad(x, (self.kernel_size - 1, 0))  # causal padding\n",
    "        x = self.pointwise(self.depthwise(x))\n",
    "        return x.transpose(1, 2)  # (batch, seq_len, dim)\n",
    "\n",
    "\n",
    "class MinGRUFunctions:\n",
    "    \"\"\"MinGRU core mathematical functions\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def g_activation(x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Custom activation function - optimized with inplace ops\"\"\"\n",
    "        positive_mask = x >= 0\n",
    "        result = x.clone()  # More efficient than empty_like + assignment\n",
    "        result[positive_mask] += 0.5\n",
    "        result[~positive_mask] = torch.sigmoid_(result[~positive_mask])  # inplace sigmoid\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def log_g_activation(x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Log version of g activation - improved numerical stability\"\"\"\n",
    "        positive_mask = x >= 0\n",
    "        result = torch.empty_like(x)\n",
    "        \n",
    "        # For positive values: log(x + 0.5)\n",
    "        result[positive_mask] = torch.log(x[positive_mask] + 0.5).to(x.dtype)\n",
    "        \n",
    "        # For negative values: log(sigmoid(x)) = -softplus(-x)\n",
    "        result[~positive_mask] = -F.softplus(-x[~positive_mask]).to(x.dtype)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def parallel_scan(log_gates: torch.Tensor, log_values: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Parallel scan operation - fixed dimension handling\"\"\"\n",
    "        # Cumulative sum of log gates with proper padding\n",
    "        cumsum_gates = F.pad(torch.cumsum(log_gates, dim=1), [0, 0, 1, 0])  # pad dim=1 (seq_len)\n",
    "        \n",
    "        # Log-cumsum-exp operation\n",
    "        adjusted_values = log_values - cumsum_gates\n",
    "        cumsum_values = torch.logcumsumexp(adjusted_values, dim=1)\n",
    "        \n",
    "        # Combine results\n",
    "        log_output = cumsum_gates + cumsum_values\n",
    "        return torch.exp(log_output)\n",
    "    \n",
    "    @staticmethod\n",
    "    def mingru_step(gate: torch.Tensor, hidden: torch.Tensor, prev_state: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Single MinGRU computation step - fixed concatenation\"\"\"\n",
    "        eps = 1e-12\n",
    "        \n",
    "        # Safe log computation with numerical stability\n",
    "        log_prev = torch.log(torch.clamp(prev_state, min=eps))\n",
    "        \n",
    "        # Compute log probabilities with clamping for stability\n",
    "        gate_clamped = torch.clamp(gate, min=-20, max=20)\n",
    "        log_forget = -F.softplus(gate_clamped)\n",
    "        log_update = -F.softplus(-gate_clamped)\n",
    "        \n",
    "        # Compute log candidate\n",
    "        log_candidate = MinGRUFunctions.log_g_activation(hidden)\n",
    "        \n",
    "        # Concatenate along sequence dimension (dim=1)\n",
    "        log_states = torch.cat([log_prev, log_update + log_candidate], dim=1)\n",
    "        \n",
    "        # Apply parallel scan\n",
    "        sequence_output = MinGRUFunctions.parallel_scan(log_forget, log_states)\n",
    "        return sequence_output[:, 1:]  # Remove initial state\n",
    "\n",
    "\n",
    "class MinGRULayer(nn.Module):\n",
    "    \"\"\"Single MinGRU layer with optimized initialization\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, hidden_dim: int, use_bias: bool = True):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.gate_projection = nn.Linear(input_dim, hidden_dim * 2, bias=use_bias)\n",
    "        self.residual_projection = nn.Linear(input_dim, hidden_dim, bias=False) if input_dim != hidden_dim else nn.Identity()\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Optimized weight initialization\"\"\"\n",
    "        # Xavier/Glorot initialization for better gradient flow\n",
    "        nn.init.xavier_uniform_(self.gate_projection.weight)\n",
    "        if self.gate_projection.bias is not None:\n",
    "            # Initialize gate bias to favor forgetting (negative bias)\n",
    "            nn.init.constant_(self.gate_projection.bias[:self.hidden_dim], -1.0)  # forget gate\n",
    "            nn.init.constant_(self.gate_projection.bias[self.hidden_dim:], 0.0)   # input gate\n",
    "        \n",
    "        if not isinstance(self.residual_projection, nn.Identity):\n",
    "            nn.init.xavier_uniform_(self.residual_projection.weight)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, prev_state: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # Project input to gate and hidden\n",
    "        gate_hidden = self.gate_projection(x)\n",
    "        gate, hidden = gate_hidden.chunk(2, dim=-1)\n",
    "        \n",
    "        # Apply MinGRU computation\n",
    "        output = MinGRUFunctions.mingru_step(gate, hidden, prev_state)\n",
    "        \n",
    "        # Residual connection\n",
    "        if not isinstance(self.residual_projection, nn.Identity):\n",
    "            output = output + self.residual_projection(x)\n",
    "        \n",
    "        # Return output and last hidden state\n",
    "        next_state = output[:, -1:, :]\n",
    "        return output, next_state\n",
    "\n",
    "\n",
    "class MinGRU(nn.Module):\n",
    "    \"\"\"Multi-layer MinGRU with state caching\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, hidden_dims: List[int], dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.num_layers = len(hidden_dims)\n",
    "        \n",
    "        # Build layers\n",
    "        layer_dims = [input_dim] + hidden_dims\n",
    "        self.layers = nn.ModuleList([\n",
    "            MinGRULayer(layer_dims[i], layer_dims[i + 1])\n",
    "            for i in range(self.num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Dropout (except for last layer)\n",
    "        self.dropouts = nn.ModuleList([\n",
    "            nn.Dropout(dropout) if i < self.num_layers - 1 else nn.Identity()\n",
    "            for i in range(self.num_layers)\n",
    "        ])\n",
    "        \n",
    "        # State cache for inference optimization\n",
    "        self._cached_states: Optional[List[torch.Tensor]] = None\n",
    "        self._cache_batch_size: int = 0\n",
    "    \n",
    "    def init_states(self, batch_size: int, device: torch.device) -> List[torch.Tensor]:\n",
    "        \"\"\"Initialize hidden states with optimized memory layout\"\"\"\n",
    "        states = [\n",
    "            MinGRUFunctions.g_activation(torch.zeros(batch_size, 1, dim, device=device, dtype=torch.float32))\n",
    "            for dim in self.hidden_dims\n",
    "        ]\n",
    "        \n",
    "        # Cache states for inference\n",
    "        if not self.training:\n",
    "            self._cached_states = [state.clone() for state in states]\n",
    "            self._cache_batch_size = batch_size\n",
    "            \n",
    "        return states\n",
    "    \n",
    "    def get_cached_states(self, batch_size: int, device: torch.device) -> Optional[List[torch.Tensor]]:\n",
    "        \"\"\"Get cached states if available and valid\"\"\"\n",
    "        if (self._cached_states is not None and \n",
    "            self._cache_batch_size == batch_size and \n",
    "            not self.training):\n",
    "            return [state.clone() for state in self._cached_states]\n",
    "        return None\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, states: Optional[List[torch.Tensor]] = None) -> Tuple[torch.Tensor, List[torch.Tensor]]:\n",
    "        if states is None:\n",
    "            # Try to use cached states first\n",
    "            states = self.get_cached_states(x.size(0), x.device)\n",
    "            if states is None:\n",
    "                states = self.init_states(x.size(0), x.device)\n",
    "        \n",
    "        output = x\n",
    "        next_states = []\n",
    "        \n",
    "        for i, (layer, dropout) in enumerate(zip(self.layers, self.dropouts)):\n",
    "            output, next_state = layer(output, states[i])\n",
    "            output = dropout(output)\n",
    "            next_states.append(next_state)\n",
    "        \n",
    "        # Update cache for next inference\n",
    "        if not self.training:\n",
    "            self._cached_states = [state.clone() for state in next_states]\n",
    "        \n",
    "        return output, next_states\n",
    "\n",
    "\n",
    "class SwiGLU(nn.Module):\n",
    "    \"\"\"SwiGLU Feed-Forward Network with mixed precision support\"\"\"\n",
    "    \n",
    "    def __init__(self, dim: int, expansion_factor: float = 2.0, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(dim * expansion_factor * 2/3)\n",
    "        hidden_dim = ((hidden_dim + 7) // 8) * 8  # Round to multiple of 8 for tensor cores\n",
    "        \n",
    "        self.gate_proj = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.up_proj = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.down_proj = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = nn.SiLU()\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize weights for mixed precision training\"\"\"\n",
    "        for module in [self.gate_proj, self.up_proj, self.down_proj]:\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            # Scale down weights for numerical stability in fp16\n",
    "            module.weight.data *= 0.5\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Fused gating operation\n",
    "        gate = self.activation(self.gate_proj(x))\n",
    "        up = self.up_proj(x)\n",
    "        \n",
    "        # Element-wise multiplication \n",
    "        gated = gate * up\n",
    "        return self.dropout(self.down_proj(gated))\n",
    "\n",
    "\n",
    "class MinGRUDecoder(nn.Module):\n",
    "    \"\"\"Complete MinGRU-based decoder model with optimizations\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embed_dim: int,\n",
    "        hidden_dims: Union[int, List[int]],\n",
    "        num_layers: Optional[int] = None,\n",
    "        dropout: float = 0.1,\n",
    "        use_conv: bool = True,\n",
    "        conv_kernel: int = 3,\n",
    "        ffn_expansion: float = 1.0,\n",
    "        norm_eps: float = 1e-8,\n",
    "        use_gradient_checkpointing: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Handle hidden dimensions\n",
    "        if isinstance(hidden_dims, int):\n",
    "            if num_layers is None:\n",
    "                raise ValueError(\"num_layers must be specified when hidden_dims is int\")\n",
    "            hidden_dims = [hidden_dims] * num_layers\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.use_gradient_checkpointing = use_gradient_checkpointing\n",
    "        \n",
    "        # Input layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.input_proj = nn.Linear(embed_dim, hidden_dims[0]) if embed_dim != hidden_dims[0] else nn.Identity()\n",
    "        \n",
    "        # Optional convolution\n",
    "        self.conv = CausalConv1D(hidden_dims[0], conv_kernel) if use_conv else None\n",
    "        \n",
    "        # Core MinGRU\n",
    "        self.pre_gru_norm = nn.RMSNorm(hidden_dims[0], eps=norm_eps)\n",
    "        self.mingru = MinGRU(hidden_dims[0], hidden_dims, dropout)\n",
    "        \n",
    "        # Feed-forward network\n",
    "        self.post_gru_norm = nn.RMSNorm(hidden_dims[-1], eps=norm_eps)\n",
    "        self.ffn = SwiGLU(hidden_dims[-1], ffn_expansion, dropout)\n",
    "        \n",
    "        # Output layers\n",
    "        self.final_norm = nn.RMSNorm(hidden_dims[-1], eps=norm_eps)\n",
    "        self.output_proj = nn.Linear(hidden_dims[-1], vocab_size)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize all model weights\"\"\"\n",
    "        # Embedding initialization\n",
    "        nn.init.normal_(self.embedding.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        # Linear layer initialization\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def _forward_block(self, h: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass through MinGRU and FFN blocks\"\"\"\n",
    "        # MinGRU processing\n",
    "        h_norm = self.pre_gru_norm(h)\n",
    "        gru_out, _ = self.mingru(h_norm)\n",
    "        h = h + gru_out  # Residual connection\n",
    "        \n",
    "        # Feed-forward with residual\n",
    "        h_norm = self.post_gru_norm(h)\n",
    "        ffn_out = self.ffn(h_norm)\n",
    "        h = h + ffn_out  # Residual connection\n",
    "        \n",
    "        return h\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Embedding and input projection\n",
    "        h = self.embedding(x)\n",
    "        h = self.input_proj(h)\n",
    "        \n",
    "        # Optional convolution with residual\n",
    "        if self.conv is not None:\n",
    "            h = h + self.conv(h)\n",
    "        \n",
    "        # Main processing with optional gradient checkpointing\n",
    "        if self.use_gradient_checkpointing and self.training:\n",
    "            h = torch.utils.checkpoint.checkpoint(self._forward_block, h, use_reentrant=False)\n",
    "        else:\n",
    "            h = self._forward_block(h)\n",
    "        \n",
    "        # Final output\n",
    "        h = self.final_norm(h)\n",
    "        logits = self.output_proj(h)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "# Example usage with optimizations\n",
    "if __name__ == \"__main__\":\n",
    "    # Enable optimizations\n",
    "    torch.backends.cudnn.benchmark = True  # Optimize for fixed input sizes\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True  # Enable TF32 on Ampere GPUs\n",
    "    \n",
    "    model = MinGRUDecoder(\n",
    "        vocab_size=10000,\n",
    "        embed_dim=512,\n",
    "        hidden_dims=[512, 512],\n",
    "        dropout=0.1,\n",
    "        use_conv=True,\n",
    "        conv_kernel=3,\n",
    "        ffn_expansion=2.0,\n",
    "        use_gradient_checkpointing=True  # Enable memory-efficient training\n",
    "    )\n",
    "    \n",
    "    # Compile model for optimization (PyTorch 2.0+)\n",
    "    model = torch.compile(model, mode=\"reduce-overhead\")\n",
    "    \n",
    "    # Test forward pass\n",
    "    batch_size, seq_len = 4, 128\n",
    "    input_ids = torch.randint(0, 10000, (batch_size, seq_len))\n",
    "    \n",
    "    # Mixed precision training\n",
    "    with torch.cuda.amp.autocast():\n",
    "        output = model(input_ids)\n",
    "    \n",
    "    print(f\"Input shape: {input_ids.shape}\")\n",
    "    print(f\"Output shape: {output.shape}\")  # Should be (4, 128, 10000)\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # Memory usage optimization example\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        input_ids = input_ids.cuda()\n",
    "        \n",
    "        # Clear cache and measure memory\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(input_ids)\n",
    "        \n",
    "        peak_memory = torch.cuda.max_memory_allocated() / 1024**3  # GB\n",
    "        print(f\"Peak GPU memory usage: {peak_memory:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7edf7e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Attempting to compile model...\n",
      "Model compiled successfully!\n",
      "\n",
      "Input shape: torch.Size([4, 64])\n",
      "\n",
      "Performing warm-up passes...\n",
      "Using AMP with dtype: torch.bfloat16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_inductor/cudagraph_trees.py:2385: UserWarning: Unable to hit fast path of CUDAGraphs because of pending, uninvoked backwards. Consider running with torch.no_grad() or using torch.compiler.cudagraph_mark_step_begin() before each model invocation\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Measuring execution time with AMP (torch.bfloat16) over 50 iterations...\n",
      "Average inference time (AMP, torch.bfloat16 on CUDA): 10.142 ms per iteration\n",
      "Output shape (AMP): torch.Size([4, 64, 10000])\n",
      "\n",
      "Measuring execution time with standard precision (torch.float32) over 50 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_inductor/cudagraph_trees.py:2385: UserWarning: Unable to hit fast path of CUDAGraphs because of pending, uninvoked backwards. Consider running with torch.no_grad() or using torch.compiler.cudagraph_mark_step_begin() before each model invocation\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average inference time (torch.float32 on GPU): 12.526 ms per iteration\n",
      "Final output shape: torch.Size([4, 64, 10000])\n",
      "Model parameters: 5,853,968\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Tuple, Optional, Union\n",
    "import time #      \n",
    "\n",
    "# Conditional import for mixed precision\n",
    "try:\n",
    "    from torch.amp import autocast #  API \n",
    "    HAS_AMP = True\n",
    "except ImportError:\n",
    "    HAS_AMP = False\n",
    "    # Dummy autocast for when torch.amp.autocast is not available\n",
    "    class autocast:\n",
    "        def __init__(self, device_type: str, dtype: Optional[torch.dtype] = None, enabled: bool = True, cache_enabled: Optional[bool] = None):\n",
    "            # These arguments are for API compatibility with the real torch.amp.autocast.\n",
    "            self.device_type = device_type\n",
    "            self.dtype = dtype\n",
    "            self.enabled = enabled\n",
    "            # print(f\"Dummy autocast initialized for device: {self.device_type}, enabled: {self.enabled}, dtype: {self.dtype}\")\n",
    "\n",
    "        def __enter__(self):\n",
    "            # print(f\"Dummy autocast entered for device: {self.device_type}\")\n",
    "            return self\n",
    "\n",
    "        def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "            # print(f\"Dummy autocast exited for device: {self.device_type}\")\n",
    "            pass\n",
    "\n",
    "        def __call__(self, func): #   \n",
    "            import functools\n",
    "            @functools.wraps(func)\n",
    "            def wrapper(*args, **kwargs):\n",
    "                return func(*args, **kwargs)\n",
    "            return wrapper\n",
    "\n",
    "\n",
    "class CausalConv1D(nn.Module):\n",
    "    \"\"\"Causal 1D Depthwise Convolution\"\"\"\n",
    "    \n",
    "    def __init__(self, dim: int, kernel_size: int):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        # Using depthwise separable convolution: depthwise followed by pointwise\n",
    "        self.depthwise = nn.Conv1d(dim, dim, kernel_size, groups=dim)\n",
    "        self.pointwise = nn.Conv1d(dim, dim, kernel_size=1) # Pointwise to mix channels\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (batch, seq_len, dim)\n",
    "        x = x.transpose(1, 2)  # (batch, dim, seq_len) for Conv1d\n",
    "        # Causal padding: Pad only on the left for the time dimension (seq_len)\n",
    "        x = F.pad(x, (self.kernel_size - 1, 0))\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x.transpose(1, 2)  # (batch, seq_len, dim)\n",
    "\n",
    "\n",
    "class MinGRUFunctions:\n",
    "    \"\"\"MinGRU core mathematical functions\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def g_activation(x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Custom activation function - rewritten with torch.where\"\"\"\n",
    "        positive_mask = x >= 0\n",
    "        x_pos = x + 0.5\n",
    "        x_neg = torch.sigmoid(x) # Use non-inplace sigmoid for torch.where\n",
    "        \n",
    "        result = torch.where(positive_mask, x_pos, x_neg)\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def log_g_activation(x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Log version of g activation - improved numerical stability, rewritten with torch.where\"\"\"\n",
    "        positive_mask = x >= 0\n",
    "        log_val_pos = torch.log(x + 0.5) \n",
    "        log_val_neg = -F.softplus(-x)\n",
    "        \n",
    "        result = torch.where(positive_mask, log_val_pos, log_val_neg)\n",
    "        return result.to(x.dtype) \n",
    "    \n",
    "    @staticmethod\n",
    "    def parallel_scan(log_gates: torch.Tensor, log_values: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Parallel scan operation\"\"\"\n",
    "        cumsum_log_gates = torch.cumsum(log_gates, dim=1)\n",
    "        padded_cumsum_log_gates = F.pad(cumsum_log_gates, (0, 0, 1, 0))\n",
    "        adjusted_values = log_values - padded_cumsum_log_gates\n",
    "        cumsum_values = torch.logcumsumexp(adjusted_values, dim=1)\n",
    "        log_output = padded_cumsum_log_gates + cumsum_values\n",
    "        return torch.exp(log_output)\n",
    "    \n",
    "    @staticmethod\n",
    "    def mingru_step(gate: torch.Tensor, hidden: torch.Tensor, prev_state: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Single MinGRU computation step\"\"\"\n",
    "        # Clone prev_state to potentially resolve issues with TensorAlias in torch.compile\n",
    "        # This is a key change to address the TypeError with FakeTensor and TensorAlias\n",
    "        prev_state_for_ops = prev_state.clone()\n",
    "\n",
    "        eps = 1e-12\n",
    "        # Use the cloned prev_state for subsequent operations\n",
    "        log_prev = torch.log(torch.clamp(prev_state_for_ops, min=eps))\n",
    "        \n",
    "        gate_clamped = torch.clamp(gate, min=-20, max=20)\n",
    "        log_forget = -F.softplus(gate_clamped)\n",
    "        log_update = -F.softplus(-gate_clamped)\n",
    "        log_candidate = MinGRUFunctions.log_g_activation(hidden)\n",
    "        \n",
    "        log_states_for_scan = torch.cat([log_prev, log_update + log_candidate], dim=1)\n",
    "        sequence_output = MinGRUFunctions.parallel_scan(log_forget, log_states_for_scan)\n",
    "        \n",
    "        # The returned slice will be used to form the next 'prev_state'.\n",
    "        # Cloning it here ensures that the state passed to the next step is not a view\n",
    "        # that might cause issues with torch.compile.\n",
    "        return sequence_output[:, 1:, :].clone()\n",
    "\n",
    "\n",
    "class MinGRULayer(nn.Module):\n",
    "    \"\"\"Single MinGRU layer with optimized initialization\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, hidden_dim: int, use_bias: bool = True):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.gate_projection = nn.Linear(input_dim, hidden_dim * 2, bias=use_bias)\n",
    "        self.residual_projection = nn.Linear(input_dim, hidden_dim, bias=False) if input_dim != hidden_dim else nn.Identity()\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.gate_projection.weight)\n",
    "        if self.gate_projection.bias is not None:\n",
    "            nn.init.constant_(self.gate_projection.bias[:self.hidden_dim], -1.0)\n",
    "            nn.init.constant_(self.gate_projection.bias[self.hidden_dim:], 0.0) \n",
    "        if not isinstance(self.residual_projection, nn.Identity):\n",
    "            nn.init.xavier_uniform_(self.residual_projection.weight)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, prev_state: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        gate_hidden_proj = self.gate_projection(x)\n",
    "        gate, hidden = gate_hidden_proj.chunk(2, dim=-1)\n",
    "        # The output from mingru_step is already cloned if the return there is .clone()\n",
    "        output = MinGRUFunctions.mingru_step(gate, hidden, prev_state)\n",
    "        residual_input = self.residual_projection(x)\n",
    "        output = output + residual_input \n",
    "        \n",
    "        # The 'output' here is the result of mingru_step (already cloned) + residual.\n",
    "        # The slice for next_state should also be cloned to ensure clean states are passed.\n",
    "        next_state = output[:, -1:, :].clone()\n",
    "        return output, next_state\n",
    "\n",
    "\n",
    "class MinGRU(nn.Module):\n",
    "    \"\"\"Multi-layer MinGRU with state caching\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, hidden_dims: List[int], dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.num_layers = len(hidden_dims)\n",
    "        \n",
    "        current_dim = input_dim\n",
    "        self.layers = nn.ModuleList()\n",
    "        for h_dim in hidden_dims:\n",
    "            self.layers.append(MinGRULayer(current_dim, h_dim))\n",
    "            current_dim = h_dim\n",
    "            \n",
    "        self.dropouts = nn.ModuleList()\n",
    "        for i in range(self.num_layers):\n",
    "            self.dropouts.append(nn.Dropout(dropout) if i < self.num_layers - 1 else nn.Identity())\n",
    "            \n",
    "        self._cached_states: Optional[List[torch.Tensor]] = None\n",
    "        self._cache_batch_size: int = 0\n",
    "    \n",
    "    def init_states(self, batch_size: int, device: torch.device, dtype: torch.dtype = torch.float32) -> List[torch.Tensor]:\n",
    "        states = []\n",
    "        for dim in self.hidden_dims:\n",
    "            zero_state = torch.zeros(batch_size, 1, dim, device=device, dtype=dtype)\n",
    "            # g_activation should return a new tensor, not a view.\n",
    "            states.append(MinGRUFunctions.g_activation(zero_state)) \n",
    "        \n",
    "        if not self.training: # During inference\n",
    "            # Cached states are cloned, ensuring they are fresh tensors.\n",
    "            self._cached_states = [state.clone() for state in states]\n",
    "            self._cache_batch_size = batch_size\n",
    "        return states\n",
    "    \n",
    "    def get_cached_states(self, batch_size: int, device: torch.device) -> Optional[List[torch.Tensor]]:\n",
    "        if (self._cached_states is not None and \n",
    "            self._cache_batch_size == batch_size and \n",
    "            not self.training): # Only use cache during inference\n",
    "            # Return clones of cached states to prevent modification of the cache\n",
    "            # and ensure they are on the correct device.\n",
    "            return [state.to(device, non_blocking=True).clone() for state in self._cached_states]\n",
    "        return None\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, states: Optional[List[torch.Tensor]] = None) -> Tuple[torch.Tensor, List[torch.Tensor]]:\n",
    "        if states is None: # If no initial states are provided\n",
    "            states = self.get_cached_states(x.size(0), x.device) # Try to get from cache first (for inference)\n",
    "            if states is None: # If not in cache or not valid, initialize them\n",
    "                states = self.init_states(x.size(0), x.device, dtype=x.dtype)\n",
    "        \n",
    "        output = x\n",
    "        next_states_list = []\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            layer = self.layers[i]\n",
    "            dropout_layer = self.dropouts[i]\n",
    "            # states[i] is used as prev_state. It should be a clean tensor due to cloning at init/cache/prev_layer.\n",
    "            output, next_s = layer(output, states[i]) # next_s from MinGRULayer is already cloned.\n",
    "            output = dropout_layer(output)\n",
    "            next_states_list.append(next_s) # next_s is already a cloned tensor.\n",
    "        \n",
    "        if not self.training: # During inference, update the cache\n",
    "            # Detach states before caching if they won't be used for gradient computation later.\n",
    "            self._cached_states = [s.detach().clone() for s in next_states_list]\n",
    "            self._cache_batch_size = x.size(0)\n",
    "        return output, next_states_list\n",
    "\n",
    "\n",
    "class SwiGLU(nn.Module):\n",
    "    \"\"\"SwiGLU Feed-Forward Network\"\"\"\n",
    "    \n",
    "    def __init__(self, dim: int, expansion_factor: float = 2.0, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(dim * expansion_factor)\n",
    "        hidden_dim = ((hidden_dim + 7) // 8) * 8 \n",
    "        \n",
    "        self.gate_proj = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.up_proj = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.down_proj = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = nn.SiLU()\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for module in [self.gate_proj, self.up_proj, self.down_proj]:\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        gate_val = self.activation(self.gate_proj(x))\n",
    "        up_val = self.up_proj(x)\n",
    "        gated_val = gate_val * up_val\n",
    "        output = self.down_proj(gated_val)\n",
    "        return self.dropout(output)\n",
    "\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "        return output * self.weight\n",
    "\n",
    "class MinGRUDecoder(nn.Module):\n",
    "    \"\"\"Complete MinGRU-based decoder model with optimizations\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embed_dim: int,\n",
    "        hidden_dims: Union[int, List[int]],\n",
    "        num_layers: Optional[int] = None,\n",
    "        dropout: float = 0.1,\n",
    "        use_conv: bool = True,\n",
    "        conv_kernel: int = 3,\n",
    "        ffn_expansion: float = 2.0, \n",
    "        norm_eps: float = 1e-5, \n",
    "        use_gradient_checkpointing: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        if isinstance(hidden_dims, int):\n",
    "            if num_layers is None:\n",
    "                raise ValueError(\"num_layers must be specified when hidden_dims is an int\")\n",
    "            actual_hidden_dims = [hidden_dims] * num_layers\n",
    "        else:\n",
    "            actual_hidden_dims = hidden_dims\n",
    "            \n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dims_list = actual_hidden_dims\n",
    "        self.use_gradient_checkpointing = use_gradient_checkpointing\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        first_gru_dim = actual_hidden_dims[0]\n",
    "        self.input_proj = nn.Linear(embed_dim, first_gru_dim) if embed_dim != first_gru_dim else nn.Identity()\n",
    "        self.conv = CausalConv1D(first_gru_dim, conv_kernel) if use_conv else None\n",
    "        self.pre_gru_norm = RMSNorm(first_gru_dim, eps=norm_eps)\n",
    "        self.mingru = MinGRU(first_gru_dim, actual_hidden_dims, dropout) # MinGRU will handle its own state cloning internally\n",
    "        \n",
    "        last_gru_dim = actual_hidden_dims[-1]\n",
    "        self.post_gru_norm = RMSNorm(last_gru_dim, eps=norm_eps)\n",
    "        self.ffn = SwiGLU(last_gru_dim, ffn_expansion, dropout)\n",
    "        \n",
    "        self.final_norm = RMSNorm(last_gru_dim, eps=norm_eps)\n",
    "        self.output_proj = nn.Linear(last_gru_dim, vocab_size)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        nn.init.normal_(self.embedding.weight, mean=0.0, std=self.embed_dim ** -0.5)\n",
    "        for name, module in self.named_modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "\n",
    "    # This internal block is what might be checkpointed.\n",
    "    # It takes the main data tensor `h` and the `initial_states` for the MinGRU component.\n",
    "    def _forward_mingru_ffn_block(self, h: torch.Tensor, initial_states_for_mingru: Optional[List[torch.Tensor]]=None) -> Tuple[torch.Tensor, List[torch.Tensor]]:\n",
    "        h_norm_pre_gru = self.pre_gru_norm(h)\n",
    "        # MinGRU's forward method is called here. It manages its states.\n",
    "        # The `initial_states_for_mingru` are passed to the MinGRU instance.\n",
    "        gru_out, next_mingru_states = self.mingru(h_norm_pre_gru, states=initial_states_for_mingru)\n",
    "        h = h + gru_out # Residual connection\n",
    "        \n",
    "        h_norm_post_gru = self.post_gru_norm(h)\n",
    "        ffn_out = self.ffn(h_norm_post_gru)\n",
    "        h = h + ffn_out # Residual connection\n",
    "        \n",
    "        # This block returns the processed tensor `h` and the `next_mingru_states` from the MinGRU module.\n",
    "        return h, next_mingru_states\n",
    "    \n",
    "    def forward(self, input_ids: torch.Tensor, states: Optional[List[torch.Tensor]] = None) -> Tuple[torch.Tensor, List[torch.Tensor]]:\n",
    "        # `states` here are the initial states for the entire MinGRU stack for this forward pass.\n",
    "        h = self.embedding(input_ids)\n",
    "        h = self.input_proj(h)\n",
    "        if self.conv is not None:\n",
    "            conv_out = self.conv(h)\n",
    "            h = h + conv_out\n",
    "        \n",
    "        # `states` are passed to the block that includes the MinGRU module.\n",
    "        if self.use_gradient_checkpointing and self.training:\n",
    "            # The checkpointed function is `_forward_mingru_ffn_block`.\n",
    "            # It receives `h` and `states` (which are initial_states_for_mingru).\n",
    "            h, next_model_states = torch.utils.checkpoint.checkpoint(\n",
    "                self._forward_mingru_ffn_block,\n",
    "                h,                  # main input tensor\n",
    "                states,             # initial states for MinGRU within the block\n",
    "                use_reentrant=False, \n",
    "                preserve_rng_state=True\n",
    "            )\n",
    "        else:\n",
    "            h, next_model_states = self._forward_mingru_ffn_block(h, initial_states_for_mingru=states)\n",
    "        \n",
    "        h = self.final_norm(h)\n",
    "        logits = self.output_proj(h)\n",
    "        # The `next_model_states` are the final states from the MinGRU module after processing.\n",
    "        return logits, next_model_states\n",
    "\n",
    "\n",
    "# Example usage with optimizations\n",
    "if __name__ == \"__main__\":\n",
    "    if torch.backends.cudnn.is_available():\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    if hasattr(torch.backends.cuda, 'matmul') and hasattr(torch.backends.cuda.matmul, 'allow_tf32'):\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model = MinGRUDecoder(\n",
    "        vocab_size=10000,\n",
    "        embed_dim=256,\n",
    "        hidden_dims=[256, 256],\n",
    "        dropout=0.1,\n",
    "        use_conv=True,\n",
    "        conv_kernel=3,\n",
    "        ffn_expansion=2.0,\n",
    "        norm_eps=1e-5,\n",
    "        use_gradient_checkpointing=False \n",
    "    ).to(device)\n",
    "    \n",
    "    compiled_model = model # Default to original model\n",
    "    if hasattr(torch, 'compile'):\n",
    "        print(\"Attempting to compile model...\")\n",
    "        try:\n",
    "            # Try with fullgraph=True for potentially better performance, but might be stricter.\n",
    "            # If \"reduce-overhead\" fails, \"default\" might be more robust.\n",
    "            compiled_model = torch.compile(model, mode=\"reduce-overhead\") \n",
    "            print(\"Model compiled successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Model compilation failed: {e}\")\n",
    "            print(\"Proceeding without compilation.\")\n",
    "            # compiled_model remains the original model\n",
    "    else:\n",
    "        print(\"torch.compile not available. Proceeding without compilation.\")\n",
    "\n",
    "    compiled_model.eval() #       \n",
    "\n",
    "    batch_size, seq_len = 4, 64\n",
    "    input_ids = torch.randint(0, 10000, (batch_size, seq_len), device=device)\n",
    "    # For inference, initial_model_states are typically None to let the model handle its cache or init.\n",
    "    # If you were stepping through inference token by token, you'd pass the states from the previous step.\n",
    "    initial_model_states = None \n",
    "\n",
    "    print(f\"\\nInput shape: {input_ids.shape}\")\n",
    "\n",
    "    # ---   ---\n",
    "    print(\"\\nPerforming warm-up passes...\")\n",
    "    warm_up_iterations = 10 # Increased warm-up\n",
    "    # Determine the autocast dtype based on GPU capability or default to float16\n",
    "    amp_dtype = torch.bfloat16 if (device.type == 'cuda' and torch.cuda.is_bf16_supported()) else torch.float16\n",
    "\n",
    "    if HAS_AMP and device.type == 'cuda':\n",
    "        print(f\"Using AMP with dtype: {amp_dtype}\")\n",
    "        with autocast(device_type=device.type, dtype=amp_dtype, enabled=True):\n",
    "            for _ in range(warm_up_iterations):\n",
    "                _, _ = compiled_model(input_ids, states=initial_model_states)\n",
    "    else: # CPU or CUDA without AMP\n",
    "        for _ in range(warm_up_iterations):\n",
    "            _, _ = compiled_model(input_ids, states=initial_model_states)\n",
    "\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    # ---   ---\n",
    "\n",
    "    num_iterations = 50 #    \n",
    "    \n",
    "    output_logits = None # Define to ensure it's available for print later\n",
    "\n",
    "    # --- AMP     (CUDA ) ---\n",
    "    if HAS_AMP and device.type == 'cuda':\n",
    "        print(f\"\\nMeasuring execution time with AMP ({amp_dtype}) over {num_iterations} iterations...\")\n",
    "        total_time_amp_ms = 0\n",
    "        start_event = torch.cuda.Event(enable_timing=True)\n",
    "        end_event = torch.cuda.Event(enable_timing=True)\n",
    "        \n",
    "        for i in range(num_iterations):\n",
    "            # torch.cuda.empty_cache() # Generally not needed for inference timing unless specific memory issues\n",
    "            start_event.record()\n",
    "            with autocast(device_type=device.type, dtype=amp_dtype, enabled=True):\n",
    "                output_logits, _ = compiled_model(input_ids, states=initial_model_states)\n",
    "            end_event.record()\n",
    "            torch.cuda.synchronize() \n",
    "            iter_time_ms = start_event.elapsed_time(end_event)\n",
    "            if i >= warm_up_iterations // 2 : # Start accumulating after some initial timed iterations\n",
    "                 total_time_amp_ms += iter_time_ms\n",
    "            # if i == 0: print(f\"  First timed iteration (AMP) took: {iter_time_ms:.3f} ms\") # First timed one can be slower\n",
    "        \n",
    "        # Adjust num_iterations for averaging if skipping some initial ones\n",
    "        avg_iterations_amp = num_iterations - (warm_up_iterations // 2)\n",
    "        if avg_iterations_amp <= 0 : avg_iterations_amp = num_iterations # safety\n",
    "        avg_time_amp_ms = total_time_amp_ms / avg_iterations_amp if avg_iterations_amp > 0 else 0\n",
    "        print(f\"Average inference time (AMP, {amp_dtype} on CUDA): {avg_time_amp_ms:.3f} ms per iteration\")\n",
    "        if output_logits is not None: print(f\"Output shape (AMP): {output_logits.shape}\")\n",
    "\n",
    "    # ---   (FP32 GPU  CPU)   ---\n",
    "    # Determine the standard precision dtype from the model\n",
    "    # model_dtype = next(compiled_model.parameters()).dtype # Get dtype from a parameter\n",
    "    # For this model, embedding is a good indicator.\n",
    "    model_dtype = compiled_model.embedding.weight.dtype\n",
    "    print(f\"\\nMeasuring execution time with standard precision ({model_dtype}) over {num_iterations} iterations...\")\n",
    "    total_time_std_ms = 0\n",
    "    \n",
    "    if device.type == 'cuda':\n",
    "        start_event_std = torch.cuda.Event(enable_timing=True)\n",
    "        end_event_std = torch.cuda.Event(enable_timing=True)\n",
    "        for i in range(num_iterations):\n",
    "            start_event_std.record()\n",
    "            output_logits, _ = compiled_model(input_ids, states=initial_model_states)\n",
    "            end_event_std.record()\n",
    "            torch.cuda.synchronize()\n",
    "            iter_time_ms = start_event_std.elapsed_time(end_event_std)\n",
    "            if i >= warm_up_iterations // 2 :\n",
    "                total_time_std_ms += iter_time_ms\n",
    "            # if i == 0: print(f\"  First timed iteration (FP32 GPU) took: {iter_time_ms:.3f} ms\")\n",
    "\n",
    "        avg_iterations_std = num_iterations - (warm_up_iterations // 2)\n",
    "        if avg_iterations_std <= 0 : avg_iterations_std = num_iterations\n",
    "        avg_time_std_ms = total_time_std_ms / avg_iterations_std if avg_iterations_std > 0 else 0\n",
    "        print(f\"Average inference time ({model_dtype} on GPU): {avg_time_std_ms:.3f} ms per iteration\")\n",
    "    else: # CPU\n",
    "        cpu_total_time_sec = 0\n",
    "        for i in range(num_iterations):\n",
    "            start_time_cpu = time.perf_counter()\n",
    "            output_logits, _ = compiled_model(input_ids, states=initial_model_states)\n",
    "            end_time_cpu = time.perf_counter()\n",
    "            iter_time_sec = end_time_cpu - start_time_cpu\n",
    "            if i >= warm_up_iterations // 2:\n",
    "                cpu_total_time_sec += iter_time_sec\n",
    "            # if i == 0: print(f\"  First timed iteration (CPU) took: {iter_time_sec * 1000:.3f} ms\")\n",
    "        \n",
    "        avg_iterations_cpu = num_iterations - (warm_up_iterations // 2)\n",
    "        if avg_iterations_cpu <=0 : avg_iterations_cpu = num_iterations\n",
    "        avg_time_std_ms = (cpu_total_time_sec / avg_iterations_cpu) * 1000 if avg_iterations_cpu > 0 else 0\n",
    "        print(f\"Average inference time (CPU, {model_dtype}): {avg_time_std_ms:.3f} ms per iteration\")\n",
    "\n",
    "    if output_logits is not None: \n",
    "        print(f\"Final output shape: {output_logits.shape}\")\n",
    "        # Ensure the shape is as expected\n",
    "        expected_shape = (batch_size, seq_len, 10000) # Use model.vocab_size\n",
    "        assert output_logits.shape == expected_shape, \\\n",
    "            f\"Output shape mismatch! Expected {expected_shape}, got {output_logits.shape}\"\n",
    "    \n",
    "    print(f\"Model parameters: {sum(p.numel() for p in compiled_model.parameters() if p.requires_grad):,}\")\n",
    "    \n",
    "    # Memory measurement can be done separately if needed, as it might interfere with timing.\n",
    "    # if device.type == 'cuda':\n",
    "    #     torch.cuda.empty_cache()\n",
    "    #     torch.cuda.reset_peak_memory_stats(device)\n",
    "    #     # Perform a single pass for memory measurement\n",
    "    #     with autocast(device_type=device.type, dtype=amp_dtype, enabled=HAS_AMP and device.type == 'cuda'):\n",
    "    #         _, _ = compiled_model(input_ids, states=initial_model_states)\n",
    "    #     torch.cuda.synchronize()\n",
    "    #     peak_memory_bytes = torch.cuda.max_memory_allocated(device)\n",
    "    #     peak_memory_gb = peak_memory_bytes / (1024**3)\n",
    "    #     print(f\"Peak GPU memory usage for one forward pass: {peak_memory_gb:.2f} GB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4bf556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2886ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7503751b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049aa66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20de826b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
