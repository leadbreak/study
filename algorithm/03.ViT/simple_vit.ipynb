{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, dropout_rate, channels=3):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        # 이미지는 패치로 분할되고, 각 패치는 Transformer에 입력될 수 있도록 임베딩되어야 합니다.\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "        patch_dim = channels * patch_size ** 2\n",
    "        self.patch_to_embedding = nn.Linear(patch_dim, dim)\n",
    "\n",
    "        # 클래스 토큰을 추가합니다. 이 토큰은 분류를 위해 사용됩니다.\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "\n",
    "        # 위치 임베딩은 Transformer 모델에 시퀀스의 순서 정보를 제공합니다.\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "\n",
    "        # Transformer 인코더를 정의합니다.\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=dim, nhead=heads, dim_feedforward=mlp_dim, dropout=dropout_rate, activation='gelu'),\n",
    "            num_layers=depth\n",
    "        )\n",
    "\n",
    "        # 분류를 위한 MLP 헤드입니다.\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.Linear(dim, mlp_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(mlp_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "\n",
    "        # 이미지를 패치로 분할하고 임베딩합니다.\n",
    "        x = x.reshape(b, c, h // self.patch_size, self.patch_size, w // self.patch_size, self.patch_size)\n",
    "        x = x.transpose(2, 4).flatten(2)\n",
    "        x = self.patch_to_embedding(x)\n",
    "\n",
    "        # 클래스 토큰과 위치 임베딩을 추가합니다.\n",
    "        cls_tokens = self.cls_token.expand(b, -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.pos_embedding\n",
    "\n",
    "        # Transformer를 통과시킵니다.\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        # 분류를 위해 첫 번째 토큰 (클래스 토큰)만 사용합니다.\n",
    "        x = x[:, 0]\n",
    "\n",
    "        return self.mlp_head(x)\n",
    "\n",
    "# 예시 사용\n",
    "vit = ViT(image_size=256, patch_size=32, num_classes=10, dim=1024, depth=6, heads=8, mlp_dim=2048, dropout_rate=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 1024]) torch.Size([2, 2, 1024])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (197) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/root/study/algorithm/03.ViT/simple_vit.ipynb 셀 2\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bqscar:192.168.10.110/root/study/algorithm/03.ViT/simple_vit.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m# 모델을 통해 테스트 이미지 전달\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bqscar:192.168.10.110/root/study/algorithm/03.ViT/simple_vit.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bqscar:192.168.10.110/root/study/algorithm/03.ViT/simple_vit.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m     output \u001b[39m=\u001b[39m hybrid_vit(test_images)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bqscar:192.168.10.110/root/study/algorithm/03.ViT/simple_vit.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mprint\u001b[39m(output\u001b[39m.\u001b[39mshape)  \u001b[39m# 최종 출력 형상 출력\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/root/study/algorithm/03.ViT/simple_vit.ipynb 셀 2\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bqscar:192.168.10.110/root/study/algorithm/03.ViT/simple_vit.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mprint\u001b[39m(cls_tokens\u001b[39m.\u001b[39mshape, x\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bqscar:192.168.10.110/root/study/algorithm/03.ViT/simple_vit.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((cls_tokens, x), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bqscar:192.168.10.110/root/study/algorithm/03.ViT/simple_vit.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m x \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_embedding\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bqscar:192.168.10.110/root/study/algorithm/03.ViT/simple_vit.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# Transformer를 통과시킵니다.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bqscar:192.168.10.110/root/study/algorithm/03.ViT/simple_vit.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer(x)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (197) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class HybridViT(nn.Module):\n",
    "    def __init__(self, num_classes, dim, depth, heads, mlp_dim, dropout_rate, backbone_model=models.resnet50(pretrained=True)):\n",
    "        super().__init__()\n",
    "\n",
    "        # CNN 기반 백본 모델을 사용합니다.\n",
    "        self.backbone = backbone_model\n",
    "        self.backbone.fc = nn.Identity()  # 마지막 FC 레이어는 사용하지 않습니다.\n",
    "\n",
    "        # 위치 임베딩은 백본 모델의 출력 특징 맵 크기에 맞춰 조정해야 합니다.\n",
    "        num_patches = 196  # 예시: ResNet의 경우 14x14 특징 맵이 출력될 수 있습니다.\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "\n",
    "        # 클래스 토큰 및 Transformer 인코더는 동일합니다.\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=dim, nhead=heads, dim_feedforward=mlp_dim, dropout=dropout_rate, activation='gelu'),\n",
    "            num_layers=depth\n",
    "        )\n",
    "\n",
    "        # 분류를 위한 MLP 헤드는 동일합니다.\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.Linear(dim, mlp_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(mlp_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 백본 모델을 통해 특징 맵을 추출합니다.\n",
    "        x = self.backbone(x)\n",
    "        x = x.view(x.size(0), -1, 2, 1)\n",
    "\n",
    "        # 추출된 특징 맵을 Transformer의 입력 형식에 맞게 변환합니다.\n",
    "        b, _, h, w = x.shape\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "\n",
    "        # 클래스 토큰과 위치 임베딩을 추가합니다.\n",
    "        cls_tokens = self.cls_token.expand(b, -1, -1)\n",
    "        print(cls_tokens.shape, x.shape)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.pos_embedding\n",
    "\n",
    "        # Transformer를 통과시킵니다.\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        # 분류를 위해 첫 번째 토큰 (클래스 토큰)만 사용합니다.\n",
    "        x = x[:, 0]\n",
    "\n",
    "        return self.mlp_head(x)\n",
    "\n",
    "# 예시 사용\n",
    "hybrid_vit = HybridViT(num_classes=10, dim=1024, depth=6, heads=8, mlp_dim=2048, dropout_rate=0.1)\n",
    "test_images = torch.randn(2, 3, 224, 224)\n",
    "\n",
    "# 모델을 통해 테스트 이미지 전달\n",
    "with torch.no_grad():\n",
    "    output = hybrid_vit(test_images)\n",
    "\n",
    "print(output.shape)  # 최종 출력 형상 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone = models.resnet50(pretrained=True)\n",
    "# backbone.avgpool = nn.Identity()\n",
    "# backbone.fc = nn.Identity()\n",
    "backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "후 CNN 특징 맵의 형상: torch.Size([4, 100352])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/root/study/algorithm/03.ViT/simple_vit.ipynb 셀 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bqscar:192.168.10.110/root/study/algorithm/03.ViT/simple_vit.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m후 CNN 특징 맵의 형상:\u001b[39m\u001b[39m\"\u001b[39m, features\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bqscar:192.168.10.110/root/study/algorithm/03.ViT/simple_vit.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# 특징 맵을 Transformer의 입력 형식으로 변환\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bqscar:192.168.10.110/root/study/algorithm/03.ViT/simple_vit.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m b, _, h, w \u001b[39m=\u001b[39m features\u001b[39m.\u001b[39mshape\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bqscar:192.168.10.110/root/study/algorithm/03.ViT/simple_vit.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m features \u001b[39m=\u001b[39m features\u001b[39m.\u001b[39mflatten(\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bqscar:192.168.10.110/root/study/algorithm/03.ViT/simple_vit.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTransformer 입력 형태 변환 후의 형상:\u001b[39m\u001b[39m\"\u001b[39m, features\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
     ]
    }
   ],
   "source": [
    "# 임의의 테스트 데이터 생성\n",
    "batch_size = 4\n",
    "img_height, img_width = 224, 224\n",
    "test_images = torch.randn(batch_size, 3, img_height, img_width)\n",
    "\n",
    "# 모델을 통해 테스트 데이터 전달\n",
    "with torch.no_grad():\n",
    "    # 백본 모델을 통한 특징 추출\n",
    "    features = hybrid_vit.backbone(test_images)\n",
    "    print(\"후 CNN 특징 맵의 형상:\", features.shape)\n",
    "\n",
    "    # 특징 맵을 Transformer의 입력 형식으로 변환\n",
    "    b, _, h, w = features.shape\n",
    "    features = features.flatten(2).transpose(1, 2)\n",
    "    print(\"Transformer 입력 형태 변환 후의 형상:\", features.shape)\n",
    "\n",
    "    # 클래스 토큰과 위치 임베딩 추가\n",
    "    cls_tokens = hybrid_vit.cls_token.expand(b, -1, -1)\n",
    "    x = torch.cat((cls_tokens, features), dim=1)\n",
    "    x += hybrid_vit.pos_embedding\n",
    "    print(\"클래스 토큰 및 위치 임베딩 추가 후의 형상:\", x.shape)\n",
    "\n",
    "    # Transformer 통과\n",
    "    x = hybrid_vit.transformer(x)\n",
    "    print(\"Transformer 통과 후의 형상:\", x.shape)\n",
    "\n",
    "    # 분류를 위해 첫 번째 토큰만 사용\n",
    "    x = x[:, 0]\n",
    "    print(\"클래스 토큰 추출 후의 형상:\", x.shape)\n",
    "\n",
    "    # MLP 헤드를 통과하여 최종 결과 도출\n",
    "    logits = hybrid_vit.mlp_head(x)\n",
    "    print(\"최종 분류 결과의 형상:\", logits.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/root/study/algorithm/03.ViT/simple_vit.ipynb 셀 5\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bqscar:192.168.10.110/root/study/algorithm/03.ViT/simple_vit.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# 모델을 통해 테스트 데이터 전달\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bqscar:192.168.10.110/root/study/algorithm/03.ViT/simple_vit.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bqscar:192.168.10.110/root/study/algorithm/03.ViT/simple_vit.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     output \u001b[39m=\u001b[39m hybrid_vit(test_images)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bqscar:192.168.10.110/root/study/algorithm/03.ViT/simple_vit.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m최종 출력 형상:\u001b[39m\u001b[39m\"\u001b[39m, output\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/root/study/algorithm/03.ViT/simple_vit.ipynb 셀 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bqscar:192.168.10.110/root/study/algorithm/03.ViT/simple_vit.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackbone(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bqscar:192.168.10.110/root/study/algorithm/03.ViT/simple_vit.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# 추출된 특징 맵을 Transformer의 입력 형식에 맞게 변환합니다.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bqscar:192.168.10.110/root/study/algorithm/03.ViT/simple_vit.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m b, _, h, w \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bqscar:192.168.10.110/root/study/algorithm/03.ViT/simple_vit.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mflatten(\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bqscar:192.168.10.110/root/study/algorithm/03.ViT/simple_vit.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# 클래스 토큰과 위치 임베딩을 추가합니다.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
     ]
    }
   ],
   "source": [
    "# 임의의 테스트 데이터 생성 (배치 크기 1, 채널 3, 이미지 크기 224x224)\n",
    "test_images = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# 모델을 통해 테스트 데이터 전달\n",
    "with torch.no_grad():\n",
    "    output = hybrid_vit(test_images)\n",
    "    print(\"최종 출력 형상:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-5.7796e-02, -3.0435e-01,  1.8525e-01,  1.1514e-01,  1.0378e-03,\n",
       "          2.2246e-01, -6.2290e-01,  9.2540e-01,  1.9607e-01,  6.4851e-02,\n",
       "         -8.0616e-01,  4.6046e-01,  2.3427e-01,  6.3772e-01,  3.1046e-01,\n",
       "         -6.4819e-01,  8.5056e-02, -4.9830e-01,  1.0569e-01, -1.4349e-01,\n",
       "          1.8110e-01,  8.3484e-01, -4.8748e-01, -7.3032e-01,  8.3258e-01,\n",
       "         -2.1776e-01, -9.8833e-01, -1.7072e-01, -2.5503e-01, -1.3897e-01,\n",
       "          1.3533e-01, -4.0996e-01, -5.4686e-02, -8.7365e-01, -1.1466e+00,\n",
       "         -4.0644e-01,  6.9038e-01,  3.0300e-01,  7.9072e-02, -4.8798e-01,\n",
       "          9.4769e-01,  3.5820e-01, -6.9957e-02,  4.4079e-01, -1.6465e-02,\n",
       "         -1.8087e-01,  3.2531e-01, -1.0300e+00,  3.4123e-01,  4.0831e-01,\n",
       "         -4.8030e-01,  4.5952e-01,  1.0688e+00,  3.2649e-01,  1.6197e-01,\n",
       "          4.1529e-01,  6.5238e-01, -3.3665e-02, -2.3757e-01, -6.7546e-02,\n",
       "         -7.5127e-01, -6.4708e-01,  2.3200e-01,  1.2811e-01,  4.3578e-01,\n",
       "         -2.8260e-01, -4.0929e-01, -2.7068e-01, -5.7327e-02,  1.6964e-01,\n",
       "          1.7812e-01, -4.8438e-01,  2.4231e-01, -7.5064e-02,  8.4116e-01,\n",
       "          1.8011e-01, -1.1144e+00,  5.0145e-01,  6.9135e-01, -6.8501e-01,\n",
       "          1.1442e+00,  3.2556e-01,  4.5633e-01,  7.2548e-01, -4.1889e-01,\n",
       "         -3.3593e-01, -1.1754e+00,  9.0248e-03,  5.2786e-01,  1.6694e-01,\n",
       "         -4.3446e-01,  3.1233e-01, -2.2072e-01, -1.3151e+00, -4.0997e-01,\n",
       "          1.7186e-01, -5.3632e-01, -4.4361e-01,  8.7030e-01,  3.9446e-01,\n",
       "         -5.5050e-01, -1.0045e+00, -5.5667e-02,  7.1917e-02, -5.8229e-01,\n",
       "          5.3537e-01, -6.6074e-01,  6.9855e-02,  8.0689e-01,  1.0591e-01,\n",
       "         -4.1884e-01, -9.3434e-01, -9.5536e-01,  2.3997e-02,  1.6492e-01,\n",
       "          4.8997e-01, -3.4195e-01, -5.1919e-01, -2.8054e-01,  1.4536e-01,\n",
       "         -5.3210e-01, -1.2004e+00, -2.3814e-01,  3.8688e-01, -1.1858e-01,\n",
       "          1.3443e+00, -3.6016e-01, -5.1640e-02,  2.7140e-01,  5.6521e-01,\n",
       "         -3.0486e-02, -7.9059e-01,  7.3961e-01,  2.7340e-01,  2.5309e-01,\n",
       "          3.2371e-02, -3.9422e-01, -2.5111e-01, -4.1644e-01, -5.0741e-01,\n",
       "          6.2117e-02, -6.2994e-02, -8.7995e-01, -1.2601e-01,  8.2520e-01,\n",
       "         -2.5230e-01,  3.2677e-01,  4.9539e-01, -3.2165e-01, -2.8434e-01,\n",
       "          3.5801e-01, -1.8343e+00, -2.6781e-01, -9.3528e-01, -5.1733e-01,\n",
       "          4.1613e-01,  7.3138e-01, -4.0605e-01,  7.3428e-01, -6.6284e-02,\n",
       "          3.1726e-01,  1.1630e-01,  4.8052e-01,  9.8271e-02,  1.9252e-01,\n",
       "         -3.2477e-01,  1.0254e-01, -7.0712e-01, -6.2520e-01,  8.5091e-01,\n",
       "          1.9179e-01, -1.0015e+00, -1.5698e-01,  1.2816e-01,  1.3217e+00,\n",
       "          4.1555e-01, -9.0526e-02, -5.5547e-02, -3.1142e-01, -5.9820e-02,\n",
       "         -1.0776e-01,  9.7322e-01, -3.2442e-01,  3.5341e-02, -1.3411e-01,\n",
       "         -3.4666e-01, -1.2181e-01, -7.8315e-01,  1.0476e+00,  1.1379e+00,\n",
       "         -4.8817e-01,  3.0131e-01, -1.9348e-01,  4.9172e-01,  3.7552e-01,\n",
       "         -3.3501e-01,  2.2670e-01,  5.0654e-01,  4.4631e-01, -5.6974e-01,\n",
       "          1.5872e-02, -6.2137e-01,  9.4008e-01, -1.5198e+00, -2.8743e-01,\n",
       "          6.4654e-01, -2.5434e-01, -2.7465e-01, -8.7297e-02,  1.2382e+00,\n",
       "         -3.3252e-01, -3.1218e-01, -8.6829e-01,  4.9682e-01,  5.5433e-01,\n",
       "          7.9303e-02,  8.2211e-01, -3.8680e-01, -2.4828e-01,  3.5870e-01,\n",
       "          7.7404e-02,  8.2309e-01,  9.2224e-01,  8.3167e-01, -1.2835e+00,\n",
       "         -4.6981e-01, -1.7322e-01,  1.5455e-01,  6.4682e-01,  8.9669e-01,\n",
       "          1.5534e-01,  8.6830e-02,  8.6442e-01,  7.1756e-01,  2.8135e-01,\n",
       "         -4.4293e-01, -5.7782e-01, -7.6314e-01,  1.0067e+00,  6.0563e-01,\n",
       "         -1.0386e+00,  2.5427e-01, -7.1894e-01,  1.3845e-01,  6.1342e-01,\n",
       "         -7.8996e-02,  2.0235e-01,  1.7840e-01, -8.2134e-01,  4.3775e-01,\n",
       "          1.0998e-01, -2.3236e-01, -2.4520e-01, -5.2951e-01,  1.5481e-01,\n",
       "         -8.9498e-02,  5.3027e-01,  2.0198e-01, -3.5926e-01, -6.3037e-01,\n",
       "         -3.5207e-01, -1.9198e-01,  1.1050e+00,  5.0579e-01,  8.7890e-01,\n",
       "         -8.1723e-01,  3.1481e-01,  6.0220e-01, -9.1016e-01, -2.7496e-02,\n",
       "         -5.8782e-01, -3.2921e-01, -3.3271e-01, -2.0360e-01,  3.3177e-01,\n",
       "          7.0551e-01,  4.5490e-01,  9.2022e-01,  4.8531e-01, -1.1315e-01,\n",
       "          8.1282e-01,  5.7407e-01,  5.9476e-01,  6.3984e-01, -4.0739e-02,\n",
       "          2.6492e-01,  5.1184e-01, -1.9738e-02, -9.8142e-02,  1.5255e+00,\n",
       "          1.2965e-02,  5.6525e-01,  1.0825e+00,  5.6559e-01, -2.9576e-01,\n",
       "         -5.2305e-01, -3.4039e-01, -4.3222e-01, -1.5685e-01, -1.6683e-01,\n",
       "         -8.5521e-01, -2.4305e-01,  4.3467e-01,  7.8506e-01,  2.6691e-01,\n",
       "          5.5193e-01, -3.0560e-01, -2.1908e-02, -5.7218e-01,  9.4767e-02,\n",
       "          4.8839e-01, -3.7637e-02,  2.0262e-01,  2.0532e-01,  1.0329e-01,\n",
       "          1.0900e+00,  4.1043e-01, -5.1575e-01,  5.4854e-02, -3.5246e-01,\n",
       "          2.4140e-01, -2.9162e-01, -2.2832e-01, -6.1218e-03, -3.9726e-01,\n",
       "          1.2281e+00,  1.3669e-01, -2.4072e-01,  1.5865e-02, -2.4918e-01,\n",
       "         -9.2584e-02,  1.2918e-01, -1.8542e-01,  2.3911e-01, -3.6371e-01,\n",
       "         -4.7763e-01,  8.4756e-01, -1.1776e-01,  8.0149e-01, -1.5561e-01,\n",
       "          3.1406e-01, -6.7847e-01,  4.2987e-02, -1.1619e-01,  5.8295e-02,\n",
       "         -6.2793e-01,  2.8971e-01,  3.2480e-01,  9.6428e-01,  2.7625e-01,\n",
       "         -3.7174e-01, -9.9222e-01,  3.1844e-02, -5.7521e-02, -6.2449e-01,\n",
       "         -5.0885e-01, -1.0190e-01,  2.0280e-01, -9.5376e-01, -4.0550e-01,\n",
       "         -8.6700e-01, -5.6179e-02,  2.3484e-01, -1.0063e+00, -3.7252e-01,\n",
       "          5.4390e-01, -4.3389e-01, -2.4898e-02, -9.6534e-01,  7.2823e-02,\n",
       "          8.7183e-01, -2.3766e-01,  3.3629e-02, -6.7375e-01,  4.5115e-01,\n",
       "          7.6932e-01,  7.9928e-01, -1.5904e-01, -4.5991e-03,  2.5396e-01,\n",
       "         -2.9911e-01, -2.4926e-01, -6.8154e-01, -3.8845e-01, -3.2281e-01,\n",
       "          3.5086e-01,  6.3162e-01,  1.1633e-01, -1.0738e+00,  9.6402e-01,\n",
       "         -7.9875e-01,  3.2623e-01, -1.1343e+00, -3.6136e-01,  2.6131e-01,\n",
       "          6.2969e-01, -4.4431e-02, -1.9975e-01, -4.1360e-02, -6.0790e-01,\n",
       "          3.3820e-01, -7.2314e-01,  8.5783e-01, -8.8355e-01,  7.4389e-02,\n",
       "         -1.7453e-02,  5.7043e-01,  8.6322e-01, -1.1520e+00,  6.3736e-01,\n",
       "         -1.1144e-01, -1.0628e+00,  7.1666e-01,  2.8252e-01, -2.6038e-01,\n",
       "         -8.4140e-04, -2.0078e-01,  6.2200e-02, -5.4591e-01, -1.1829e+00,\n",
       "          4.4693e-01,  7.9990e-01, -2.2636e-01, -9.4195e-02, -3.1667e-01,\n",
       "         -4.7173e-01,  3.6566e-02,  4.8074e-01, -1.4555e+00,  4.7994e-01,\n",
       "         -3.2380e-01,  2.5046e-01,  1.6539e-01,  3.4714e-01,  2.4242e-01,\n",
       "         -2.2597e-01, -6.4889e-01, -8.1442e-02,  2.2209e-02,  9.6313e-01,\n",
       "          8.2745e-02, -1.2210e-01, -1.1111e+00, -8.7031e-01,  2.2567e-02,\n",
       "         -2.9879e-01, -6.8832e-01,  5.6707e-01,  5.1697e-01, -3.5421e-02,\n",
       "          1.1641e+00,  2.8188e-01, -2.3397e+00,  2.7515e-01,  7.7647e-01,\n",
       "          2.9800e-01, -5.3258e-01, -3.4143e-01,  1.0869e+00, -3.6614e-01,\n",
       "          8.9655e-01,  1.7401e-01,  3.4252e-01, -6.8298e-01, -5.0774e-01,\n",
       "          4.3994e-01, -6.9482e-01,  2.7292e-01,  1.4951e-01, -6.1739e-02,\n",
       "          7.5451e-01,  1.0532e+00,  7.9448e-01,  1.2292e+00, -6.2868e-02,\n",
       "          1.1014e+00, -1.0009e+00,  2.6907e-02,  1.2459e-01,  6.4694e-01,\n",
       "         -4.6516e-01, -1.4013e+00, -7.8187e-02,  5.6566e-01,  1.3776e-01,\n",
       "          8.0908e-01,  3.4794e-01, -7.2556e-01, -2.0809e-01,  3.0621e-01,\n",
       "         -1.1962e+00, -5.9505e-01,  3.6095e-01,  4.8674e-01, -2.5091e-01,\n",
       "         -1.6237e-01,  1.7649e-01, -5.7379e-03, -6.0181e-02, -4.9711e-01,\n",
       "          1.3681e+00,  6.5402e-01,  3.8325e-01, -1.2730e-01, -1.1732e-01,\n",
       "          1.0321e+00, -7.2565e-02, -3.3321e-01,  1.0627e-01, -5.9475e-01,\n",
       "         -4.6380e-01, -5.6907e-01,  9.5559e-01,  9.9215e-02,  4.5927e-01,\n",
       "         -4.9433e-03, -4.5157e-01, -1.5095e-01, -1.0765e-02, -5.3640e-01,\n",
       "          9.8681e-01, -9.8474e-01, -6.4372e-01,  1.6758e-01, -1.5104e-01,\n",
       "         -8.7243e-02,  2.2151e-01, -5.4569e-01, -5.4161e-02, -5.8583e-01,\n",
       "         -1.2908e-01,  2.5652e-01,  8.3019e-01,  5.5720e-01,  1.0718e+00,\n",
       "          5.2105e-03,  5.9443e-02,  3.5849e-01,  7.6298e-01,  4.6637e-01,\n",
       "          5.7270e-01,  5.2561e-01, -8.2753e-01, -4.1586e-01, -3.1649e-01,\n",
       "         -5.9265e-01,  1.0947e-02,  2.9052e-02,  1.4886e+00, -3.0164e-01,\n",
       "          2.0036e-01,  2.7503e-01, -9.2327e-01, -2.6067e-01,  7.5683e-02,\n",
       "         -1.9395e-01,  2.2838e-01, -1.6223e-01, -2.6995e-01,  3.7766e-01,\n",
       "          7.8250e-01, -8.6444e-01,  6.0203e-01,  7.0179e-01,  8.4775e-01,\n",
       "          7.0232e-01, -2.6465e-01, -6.4764e-01, -1.7129e-01, -2.0005e-01,\n",
       "         -1.4947e-01,  6.5834e-01,  5.4379e-02,  9.7130e-01, -1.6799e-02,\n",
       "         -1.8749e-01, -1.8396e-01, -7.8146e-01, -2.9841e-01,  1.1993e-01,\n",
       "          3.3721e-01,  5.9137e-01,  1.0387e-01, -1.0489e-01,  3.8897e-01,\n",
       "          1.7897e-01, -1.8449e-01,  4.0440e-01,  6.3981e-01, -1.2217e-01,\n",
       "         -5.6578e-01,  2.1519e-01,  4.5096e-01, -7.1892e-01, -4.9757e-01,\n",
       "          5.4919e-01, -7.1816e-01, -1.5614e-01,  1.0403e-01, -3.8865e-02,\n",
       "         -7.6379e-02, -6.4314e-01,  2.0861e-01,  3.4308e-01, -2.4599e-01,\n",
       "         -5.7527e-01, -4.1765e-01,  1.8289e-01, -4.7638e-01, -1.1890e-01,\n",
       "         -2.0496e-01, -6.8657e-01,  1.1661e+00, -8.2202e-01, -6.8930e-01,\n",
       "         -5.4058e-01,  4.5825e-01,  8.2246e-01, -1.0593e-01, -2.5614e-01,\n",
       "          1.8649e-01,  1.5537e-01,  2.1625e-01,  1.3131e+00,  6.9519e-01,\n",
       "         -5.6081e-02,  2.7226e-01, -3.4230e-01, -5.8868e-01,  1.6574e-01,\n",
       "          1.2758e-01,  1.7874e-01,  7.1211e-03, -1.0730e+00,  1.0446e+00,\n",
       "          1.5927e-01, -2.2035e-01, -4.3861e-01,  3.2597e-02, -2.5732e-01,\n",
       "          9.9650e-01, -4.2391e-01,  5.8469e-01,  7.5723e-01, -9.5743e-03,\n",
       "         -6.6640e-02, -3.8763e-02,  2.8281e-01,  4.5718e-01,  7.1988e-01,\n",
       "          2.7046e-01,  1.6878e-01, -7.3486e-01, -1.3925e-01, -5.5635e-01,\n",
       "         -5.4349e-02,  2.6265e-01, -1.5680e-01,  1.6327e-01, -4.0694e-01,\n",
       "         -8.3742e-01,  1.1915e+00,  2.6396e-01, -7.5481e-01, -2.2974e-01,\n",
       "         -2.3189e-01, -8.4983e-01, -5.6669e-01,  8.8767e-01, -2.4702e-01,\n",
       "          9.2983e-02,  5.8319e-01,  8.0363e-02,  3.7544e-01,  8.5501e-02,\n",
       "         -5.8571e-01,  7.4825e-01, -4.1249e-01,  5.4794e-01, -2.2581e-01,\n",
       "          5.7698e-01,  7.3150e-01,  8.2346e-02, -7.1947e-01, -6.0600e-01,\n",
       "         -8.1687e-01, -8.8694e-01, -3.0700e-01, -1.0175e-01, -6.3110e-01,\n",
       "          3.0773e-01,  4.1982e-01,  3.0694e-01,  5.8302e-01, -5.2905e-01,\n",
       "         -2.1314e-01, -1.8658e-02,  7.8373e-01, -5.0123e-01, -4.4934e-02,\n",
       "         -3.8713e-01, -3.2743e-01, -4.2199e-01, -1.5591e-01,  1.9305e-01,\n",
       "         -8.6464e-01,  1.9852e-01, -3.3626e-01, -6.4218e-01, -4.3064e-01,\n",
       "          6.0878e-01, -1.2816e+00,  1.4790e-01,  3.3713e-01, -6.2724e-01,\n",
       "         -8.1478e-01,  2.8780e-02,  3.2540e-01, -3.3006e-02, -5.5184e-01,\n",
       "          1.4559e-01,  4.8336e-01, -3.6338e-01, -9.3598e-01, -7.5406e-01,\n",
       "         -5.1975e-02, -6.9711e-01, -2.3368e-01,  7.7250e-02,  7.7487e-01,\n",
       "          5.5043e-01,  3.7964e-01, -4.7436e-01, -1.3110e-01,  3.3939e-01,\n",
       "         -5.6053e-01, -4.0075e-02,  5.6178e-02, -8.6585e-01, -1.2434e-01,\n",
       "         -3.0942e-01,  6.6363e-01, -7.2948e-01, -1.1745e+00,  2.4829e-01,\n",
       "          4.6473e-01,  2.4233e-01,  4.3183e-01, -6.6085e-01,  6.9461e-01,\n",
       "          4.1943e-01,  3.9693e-01, -1.8590e-01, -2.3057e-01, -2.8918e-01,\n",
       "         -4.3697e-01, -3.9863e-01, -9.0025e-02,  4.0482e-01, -1.4782e-01,\n",
       "          5.5454e-01,  9.4754e-02,  1.1975e+00,  2.3397e-01,  5.0466e-01,\n",
       "          7.4644e-01,  2.0821e-01,  7.3111e-01,  7.3098e-01,  2.2512e-02,\n",
       "         -2.1714e-01,  2.4465e-01,  1.1471e+00, -3.5071e-02, -6.5205e-01,\n",
       "         -2.3812e-01, -2.2367e-01, -5.2762e-01, -2.2357e-01,  5.9844e-01,\n",
       "          8.2527e-02,  5.3225e-02,  2.5688e-01,  6.5900e-01,  3.7800e-01,\n",
       "          1.0625e+00,  6.0824e-01, -6.1711e-01, -6.9324e-01, -4.1501e-01,\n",
       "         -2.2718e-01,  7.1094e-01, -4.8706e-01,  7.6748e-01, -3.7966e-01,\n",
       "          1.4762e-01,  2.0096e-01, -1.0754e+00, -6.1328e-01,  3.0005e-01,\n",
       "         -5.1799e-01,  4.2290e-01,  1.8191e-01, -1.0296e+00, -9.0764e-02,\n",
       "         -4.1017e-01, -5.5488e-01,  7.1723e-01,  1.3706e+00,  9.4081e-02,\n",
       "         -2.6246e-01, -1.4753e+00, -8.3855e-02, -6.0677e-01,  4.8236e-02,\n",
       "         -7.2789e-01, -4.1961e-01,  1.3715e-01,  1.8083e-01, -2.3749e-01,\n",
       "         -4.1459e-01,  6.8162e-01,  3.0217e-02, -9.7106e-02,  6.4162e-01,\n",
       "         -1.8146e-01, -5.3643e-02,  4.2372e-02, -6.1746e-01, -4.5089e-01,\n",
       "         -5.7468e-01, -3.6468e-01, -2.4013e-01, -8.7232e-01, -5.1370e-01,\n",
       "          2.8640e-01,  1.9771e-01,  1.6560e-01,  3.0182e-02,  2.7213e-01,\n",
       "          2.5208e-01, -7.0631e-02,  4.6007e-01, -7.3038e-01, -3.6933e-01,\n",
       "         -5.8860e-01,  1.2312e-02,  2.0061e-01, -2.5818e-01,  5.7867e-01,\n",
       "          4.8595e-02,  7.5221e-02,  5.7773e-01, -2.2422e-01,  4.7834e-01,\n",
       "          4.2518e-01,  1.1745e-01,  5.7717e-01, -3.2595e-01, -1.2332e+00,\n",
       "         -4.4504e-01,  4.8712e-01,  2.9488e-02, -5.1388e-01, -2.0523e-03,\n",
       "         -1.5399e-01, -3.5823e-01, -1.7584e-02,  7.4784e-01,  6.7210e-01,\n",
       "          1.4321e-01, -4.3237e-01, -1.2380e+00, -1.0926e+00, -5.5717e-02,\n",
       "          1.4769e-02, -1.1637e-01,  4.7847e-01, -2.1297e-02,  9.7387e-01,\n",
       "         -1.6191e+00,  6.4455e-01,  7.3872e-01,  1.1576e+00, -2.0938e-01,\n",
       "         -2.1466e-01, -1.0763e-01,  1.5575e-02,  3.1676e-02,  7.3045e-01,\n",
       "          1.4060e+00,  7.7543e-01,  4.7283e-01,  9.8797e-01,  5.5403e-01,\n",
       "          8.1378e-02,  7.6282e-02, -2.7304e-01, -3.9058e-01,  1.6806e-01,\n",
       "          1.5480e-01, -5.7459e-02, -3.9328e-01, -5.7901e-01, -8.6583e-01,\n",
       "          5.2407e-01, -7.7261e-01, -1.7185e-01,  7.7004e-01, -1.0056e+00,\n",
       "          3.3392e-01, -9.3238e-02,  8.0072e-01,  2.6780e-01, -1.4754e+00,\n",
       "          5.2182e-01, -4.8473e-01, -6.0007e-01,  1.4324e-01, -1.6185e-01,\n",
       "          1.1785e-01,  7.0702e-01,  1.1843e-01, -6.5318e-02, -6.5539e-01,\n",
       "          1.1444e-01, -4.3337e-01,  4.8738e-01, -7.2836e-01, -1.0038e+00,\n",
       "         -9.1325e-01,  7.4594e-01,  8.7787e-03,  7.6759e-01, -5.6108e-02,\n",
       "          6.4435e-01, -5.9084e-01, -6.5360e-02, -5.7588e-01, -6.3002e-01,\n",
       "         -9.0029e-01,  3.9379e-01, -5.5052e-01, -5.1461e-01, -8.2421e-01,\n",
       "         -6.0826e-01,  3.2654e-02, -1.6475e-01, -2.2929e-01,  2.0934e-01,\n",
       "         -2.6665e-01,  1.9338e-01, -4.6387e-01, -1.4941e-02, -5.0069e-01,\n",
       "          5.7059e-01,  2.0383e-02,  7.9026e-01, -8.5302e-02,  4.8343e-01,\n",
       "         -2.1816e-01, -6.6126e-01,  1.8726e-01, -6.5825e-01,  8.9699e-01,\n",
       "          8.1115e-02,  1.0280e+00,  9.1128e-01, -9.6169e-02, -6.2902e-02,\n",
       "          1.4370e-01,  1.8924e-01, -5.1610e-01, -1.1784e+00, -6.3458e-01,\n",
       "          8.1380e-01,  5.4657e-01,  3.8290e-01,  9.5236e-01, -2.0555e-01,\n",
       "          1.9441e-01,  2.3080e-01,  6.6374e-01, -3.7548e-01, -2.5032e-01,\n",
       "         -6.5910e-01, -4.2113e-01, -4.4269e-01, -9.8283e-01,  8.9934e-02,\n",
       "          2.2600e-01, -3.1425e-01,  7.4859e-03,  9.0328e-01, -4.1997e-01,\n",
       "          4.3002e-02,  3.0476e-02, -5.9125e-01, -8.7486e-01,  4.6199e-01]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class HybridViT(nn.Module):\n",
    "    def __init__(self, num_classes=1000, image_size=224, patch_size=1, emb_size=768):\n",
    "        super(HybridViT, self).__init__()\n",
    "\n",
    "        # 클래스 변수로 emb_size 저장\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "        # 사전 훈련된 ResNet50 모델을 사용하여 특징 맵을 추출합니다.\n",
    "        self.cnn = models.resnet50(pretrained=True)\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-2])  # 마지막 두 계층 제거\n",
    "\n",
    "        # CNN 마지막 블록의 출력 채널 수를 얻습니다.\n",
    "        if isinstance(self.cnn[-1], nn.modules.container.Sequential):\n",
    "            cnn_out_channels = self.cnn[-1][-1].conv3.out_channels\n",
    "        else:\n",
    "            cnn_out_channels = self.cnn[-1].conv1.out_channels\n",
    "\n",
    "        # 패치 임베딩을 위한 컨볼루션 레이어 설정 (패치 크기 1x1)\n",
    "        self.patch_emb = nn.Conv2d(cnn_out_channels, emb_size, kernel_size=patch_size)\n",
    "\n",
    "        # 분류 토큰 및 위치 임베딩 초기화\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, emb_size))\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "\n",
    "        # Transformer 인코더 레이어\n",
    "        self.transformer = nn.TransformerEncoderLayer(d_model=emb_size, nhead=8)\n",
    "\n",
    "        # 최종 분류를 위한 선형 레이어\n",
    "        self.head = nn.Linear(emb_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # CNN을 통해 특징 맵 추출\n",
    "        x = self.cnn(x)\n",
    "\n",
    "        # 패치 임베딩 프로젝션 적용\n",
    "        x = self.patch_emb(x)\n",
    "        x = x.flatten(2).transpose(1, 2)  # 특징 맵을 펼치고, Transformer 형식으로 변환\n",
    "\n",
    "        # 위치 임베딩의 크기를 설정\n",
    "        if self.pos_embed is None:\n",
    "            self.num_patches = x.shape[1]\n",
    "            self.pos_embed = nn.Parameter(torch.zeros(1, self.num_patches + 1, self.emb_size))\n",
    "\n",
    "        # 분류 토큰 추가 및 위치 임베딩 적용\n",
    "        cls_token = self.cls_token.expand(x.shape[0], -1, -1)\n",
    "        x = torch.cat((cls_token, x), dim=1)\n",
    "        x += self.pos_embed\n",
    "\n",
    "        # Transformer 인코더 적용\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        # 최종적으로 선형 레이어를 통해 분류\n",
    "        x = self.head(x[:, 0])\n",
    "        return x\n",
    "\n",
    "# 모델 인스턴스 생성\n",
    "model = HybridViT()\n",
    "\n",
    "# 더미 이미지 데이터 생성 (예: 배치 크기 1, 채널 3, 크기 224x224)\n",
    "image = torch.randn(1, 3, 224, 224)  \n",
    "\n",
    "# 모델에 이미지를 입력하고 결과 출력\n",
    "output = model(image)\n",
    "output  # 클래스별 확률을 나타내는 출력값을 확인합니다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
