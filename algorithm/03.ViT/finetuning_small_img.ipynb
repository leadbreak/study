{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 98/98 [00:31<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.916131854057312, Val Loss: 1.9400612771511079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 98/98 [00:30<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7580667734146118, Val Loss: 1.8092978358268739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 98/98 [00:31<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.591298222541809, Val Loss: 1.6233053386211396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 98/98 [00:31<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.577829122543335, Val Loss: 1.5546675503253937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 98/98 [00:31<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.574291467666626, Val Loss: 1.542280125617981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 98/98 [00:31<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5153234004974365, Val Loss: 1.4216112852096559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 98/98 [00:31<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.3828635215759277, Val Loss: 1.342096483707428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 98/98 [00:31<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4008663892745972, Val Loss: 1.3377744436264039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 98/98 [00:31<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.269587516784668, Val Loss: 1.2351432919502259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 98/98 [00:31<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.29839026927948, Val Loss: 1.2327030301094055\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms.autoaugment import AutoAugmentPolicy\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "img_size = 32\n",
    "patch_size = 4\n",
    "channels = 3\n",
    "\n",
    "batch_size = 512\n",
    "num_classes = 10\n",
    "num_workers = 64\n",
    "\n",
    "device = 'cuda:2'\n",
    "\n",
    "# CIFAR-10 데이터셋을 위한 전처리\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(img_size),  # 무작위 크기 및 비율로 자르기\n",
    "    transforms.AutoAugment(AutoAugmentPolicy.CIFAR10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# 모델 불러오기 및 수정\n",
    "model = timm.create_model('vit_small_patch16_224', pretrained=True)\n",
    "\n",
    "# 패치 임베딩 수정\n",
    "model.patch_embed = timm.models.vision_transformer.PatchEmbed(\n",
    "    img_size=img_size, patch_size=patch_size, in_chans=channels, embed_dim=model.embed_dim\n",
    ")\n",
    "\n",
    "# 포지셔널 임베딩 조정\n",
    "num_patches = (img_size // patch_size) ** 2\n",
    "model.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, model.embed_dim))\n",
    "\n",
    "# 분류기 수정\n",
    "model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "\n",
    "# 학습 파라미터 설정\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.to(device)\n",
    "# 학습 루프\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(trainloader), total=len(trainloader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    model.train()\n",
    "    for i, data in pbar:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(testloader)\n",
    "    \n",
    "    text = f'\\tLoss: {loss}, Val Loss: {val_loss}'\n",
    "    print(text)\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.562400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.561588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.562400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.547092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.562400\n",
       "1  Precision  0.561588\n",
       "2     Recall  0.562400\n",
       "3   F1 Score  0.547092"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "display(performance_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 98/98 [02:00<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.7248024940490723, Val Loss: 1.7568284094333648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 98/98 [02:01<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.65959894657135, Val Loss: 1.6409284830093385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 98/98 [02:01<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.5587505102157593, Val Loss: 1.5472254753112793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 98/98 [02:01<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4636024236679077, Val Loss: 1.4681180596351624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 98/98 [02:01<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.4648040533065796, Val Loss: 1.4282831370830535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 98/98 [02:01<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.409483551979065, Val Loss: 1.376497322320938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 98/98 [02:01<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.3905757665634155, Val Loss: 1.3468469321727752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 98/98 [02:01<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.3854670524597168, Val Loss: 1.3098032891750335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 98/98 [02:01<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.3407928943634033, Val Loss: 1.2821733832359314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 98/98 [02:01<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.2658334970474243, Val Loss: 1.221460407972336\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import model.vit_better as vit_custom\n",
    "\n",
    "# 모델 불러오기 및 수정\n",
    "model = vit_custom.VisionTransformer(img_size=224, \n",
    "                        patch_size=16, \n",
    "                        num_classes=100, \n",
    "                        dropout=0.1,\n",
    "                        embed_dim=768,\n",
    "                        num_layers=12,\n",
    "                        num_heads=12,\n",
    "                        mlp_ratio=4.,\n",
    "                        estimate_params=True)\n",
    "model.load_state_dict(torch.load('./model/last_sports.pth', map_location=device))\n",
    "model.embed_dim = 768\n",
    "\n",
    "# 패치 임베딩 수정\n",
    "model.patch_embed = vit_custom.PatchEmbedding(img_size=img_size, \n",
    "                                              patch_size=patch_size, \n",
    "                                              in_channels=channels, \n",
    "                                              embed_dim=model.embed_dim)\n",
    "\n",
    "# 포지셔널 임베딩 조정\n",
    "num_patches = (img_size // patch_size) ** 2\n",
    "model.pos_embed = vit_custom.PositionalEmbedding(num_patches, model.embed_dim)\n",
    "\n",
    "# 분류기 수정\n",
    "model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "\n",
    "# 학습 파라미터 설정\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.to(device)\n",
    "# 학습 루프\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(trainloader), total=len(trainloader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    model.train()\n",
    "    for i, data in pbar:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(testloader)\n",
    "    \n",
    "    text = f'\\tLoss: {loss}, Val Loss: {val_loss}'\n",
    "    print(text)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.565400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.562812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.565400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.559064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.565400\n",
       "1  Precision  0.562812\n",
       "2     Recall  0.565400\n",
       "3   F1 Score  0.559064"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# 예측 수행 및 레이블 저장\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 예측과 실제 레이블\n",
    "y_true = all_labels  # 실제 레이블\n",
    "y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "# 전체 데이터셋에 대한 정확도\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 판다스 데이터프레임으로 결과 정리\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "display(performance_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
