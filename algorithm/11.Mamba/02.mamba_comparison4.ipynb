{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94bebad5",
   "metadata": {},
   "source": [
    "```\n",
    "LSTM vs LLaMA vs Mamba\n",
    "- test in practice env\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20ec8bf0",
   "metadata": {
    "id": "20ec8bf0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torchinfo import summary\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3390f4",
   "metadata": {
    "id": "5a3390f4"
   },
   "source": [
    "## Hyperparameters and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0c61f36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1732703737281,
     "user": {
      "displayName": "Hugman Sangkeun Jung",
      "userId": "08689291704194029524"
     },
     "user_tz": -540
    },
    "id": "d0c61f36",
    "outputId": "45d9894c-a14d-4164-9f2d-699025751e72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Modified hyperparameters\n",
    "SEQUENCE_LENGTH = 64\n",
    "\n",
    "EMBEDDING_DIM = 32\n",
    "HIDDEN_DIM = EMBEDDING_DIM*2\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "VALIDATION_SPLIT = 0.1\n",
    "\n",
    "NUM_LAYERS = 4\n",
    "NUM_HEADS = 4\n",
    "FFN_DIM = 480\n",
    "DROPOUT = 0.1\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c9b962",
   "metadata": {
    "id": "89c9b962"
   },
   "source": [
    "## Data Preparation\n",
    "\n",
    "We are using the TinyShakespeare dataset, a small character-level text corpus consisting of a subset of Shakespeare's plays. It's often used for testing sequence models, as it includes a rich set of vocabulary and provides a challenging task for next-character prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "089830e2",
   "metadata": {
    "id": "089830e2"
   },
   "outputs": [],
   "source": [
    "## Utility Functions\n",
    "\n",
    "def load_data(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "def create_char_mappings(text):\n",
    "    chars = sorted(list(set(text)))\n",
    "    char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
    "    idx_to_char = {i: ch for i, ch in enumerate(chars)}\n",
    "    return chars, char_to_idx, idx_to_char"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fc6452",
   "metadata": {
    "id": "30fc6452"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f07670d9",
   "metadata": {
    "id": "f07670d9"
   },
   "outputs": [],
   "source": [
    "class CharDataset(Dataset):\n",
    "    def __init__(self, text, seq_length, char_to_idx):\n",
    "        self.text = text\n",
    "        self.seq_length = seq_length\n",
    "        self.char_to_idx = char_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text) - self.seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = [self.char_to_idx[ch] for ch in self.text[idx:idx+self.seq_length]]\n",
    "        y = [self.char_to_idx[ch] for ch in self.text[idx+1:idx+self.seq_length+1]]\n",
    "        return torch.tensor(x), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9172da13",
   "metadata": {
    "id": "9172da13"
   },
   "outputs": [],
   "source": [
    "def prepare_data(text, seq_length, batch_size, val_split):\n",
    "    chars, char_to_idx, idx_to_char = create_char_mappings(text)\n",
    "\n",
    "    # Split data into train and validation\n",
    "    val_size = int(len(text) * val_split)\n",
    "    train_text, val_text = text[:-val_size], text[-val_size:]\n",
    "\n",
    "    train_dataset = CharDataset(train_text, seq_length, char_to_idx)\n",
    "    val_dataset = CharDataset(val_text, seq_length, char_to_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=12, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=12, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader, chars, char_to_idx, idx_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "nEwKFB_8L6AG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3706,
     "status": "ok",
     "timestamp": 1732704246464,
     "user": {
      "displayName": "Hugman Sangkeun Jung",
      "userId": "08689291704194029524"
     },
     "user_tz": -540
    },
    "id": "nEwKFB_8L6AG",
    "outputId": "e75cdff9-3775-461e-d930-0ced534bf74d"
   },
   "outputs": [],
   "source": [
    "# !wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=19zosLuU0z4MxIMKbGVYEGlg52QyfbTIy' -O input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47d03398",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 668,
     "status": "ok",
     "timestamp": 1732704255324,
     "user": {
      "displayName": "Hugman Sangkeun Jung",
      "userId": "08689291704194029524"
     },
     "user_tz": -540
    },
    "id": "47d03398",
    "outputId": "f247f5b3-88ff-4ecb-e8a3-4b2e42a2820b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 1000\n",
      "Vocabulary size: 46\n",
      "Train dataset size: 836\n",
      "Validation dataset size: 36\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "text = load_data('./input.txt')[:1000]\n",
    "train_loader, val_loader, chars, char_to_idx, idx_to_char = prepare_data(text, SEQUENCE_LENGTH, BATCH_SIZE, VALIDATION_SPLIT)\n",
    "vocab_size = len(chars)\n",
    "\n",
    "print(f\"Total characters: {len(text)}\")\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "print(f\"Train dataset size: {len(train_loader.dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9442b104",
   "metadata": {
    "id": "9442b104"
   },
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1f0a6a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 916,
     "status": "ok",
     "timestamp": 1732704257555,
     "user": {
      "displayName": "Hugman Sangkeun Jung",
      "userId": "08689291704194029524"
     },
     "user_tz": -540
    },
    "id": "f1f0a6a1",
    "outputId": "9ef6eb5a-0015-40ad-f143-236e3d38fb7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 64])\n",
      "Target shape: torch.Size([1, 64])\n"
     ]
    }
   ],
   "source": [
    "# Function to convert index sequence to character sequence\n",
    "def indices_to_text(indices, idx_to_char):\n",
    "    return ''.join([idx_to_char[idx.item()] for idx in indices])\n",
    "\n",
    "# Get a batch of data\n",
    "dataiter = iter(train_loader)\n",
    "batch_x, batch_y = next(dataiter)\n",
    "\n",
    "print(f\"Input shape: {batch_x.shape}\")\n",
    "print(f\"Target shape: {batch_y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5486f73f",
   "metadata": {
    "id": "5486f73f"
   },
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61a52f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_vram_usage(device=\"cuda\"):\n",
    "    allocated = torch.cuda.memory_allocated(device) / (1024**2)  # in MB\n",
    "    reserved = torch.cuda.memory_reserved(device) / (1024**2)    # in MB\n",
    "    max_allocated = torch.cuda.max_memory_allocated(device) / (1024**2)  # in MB\n",
    "    print(f\"Allocated: {allocated:.2f} MB, Reserved: {reserved:.2f} MB, Max Allocated: {max_allocated:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59178a11",
   "metadata": {
    "id": "59178a11"
   },
   "outputs": [],
   "source": [
    "def validate(model, dataloader, criterion, device, epoch, step):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output, _ = model(x)\n",
    "            loss = criterion(output.view(-1, output.size(-1)), y.view(-1))\n",
    "            losses.append((step, epoch, loss.item()))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea5e61f5",
   "metadata": {
    "id": "ea5e61f5"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, dataloader, criterion, optimizer, device, epoch, step):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    vram_usage = []\n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch}\", leave=False)\n",
    "    for batch, (x, y) in enumerate(pbar):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.amp.autocast('cuda'):\n",
    "            output, _ = model(x)\n",
    "            loss = criterion(output.view(-1, output.size(-1)), y.view(-1))\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        step += 1\n",
    "        losses.append((step, epoch, loss.item()))\n",
    "        \n",
    "        # VRAM 사용량을 progress bar의 postfix로 업데이트\n",
    "        allocated = torch.cuda.memory_allocated(device) / (1024**2)\n",
    "        vram_usage.append(allocated)\n",
    "        pbar.set_postfix(loss=f'{loss.item():.4f}', step=step, vram=f'{allocated:.2f} MB')\n",
    "\n",
    "    return losses, step, vram_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbedfd61",
   "metadata": {
    "id": "cbedfd61"
   },
   "source": [
    "## Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e91075e8",
   "metadata": {
    "id": "e91075e8"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs):\n",
    "    all_train_losses = []\n",
    "    all_val_losses = []\n",
    "    all_vram_usages = []\n",
    "    step = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        # Training phase with tqdm updates\n",
    "        epoch_train_losses, step, vram_usage = train(model, train_loader, criterion, optimizer, device, epoch, step)\n",
    "        all_train_losses.extend(epoch_train_losses)\n",
    "        all_vram_usages.append(vram_usage)\n",
    "        \n",
    "        # Validation phase\n",
    "        epoch_val_losses = validate(model, val_loader, criterion, device, epoch, step)\n",
    "        all_val_losses.extend(epoch_val_losses)\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        print(f'Single Batch Time: {epoch_time:.2f}ms',\n",
    "              f'Average Vram Usage: {np.mean(vram_usage):.2f}MB')\n",
    "\n",
    "    train_losses_df = pd.DataFrame(all_train_losses, columns=['step', 'epoch', 'loss_value'])\n",
    "    val_losses_df = pd.DataFrame(all_val_losses, columns=['step', 'epoch', 'loss_value'])\n",
    "    # average_vram_usage = np.mean(all_vram_usages)\n",
    "    return model, train_losses_df, val_losses_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4535c886",
   "metadata": {
    "id": "4535c886"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, char_to_idx, idx_to_char, start_text, device, max_length=500):\n",
    "    model.eval()\n",
    "    current_text = start_text\n",
    "    hidden = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            x = torch.tensor([[char_to_idx[ch] for ch in current_text[-SEQUENCE_LENGTH:]]]).to(device)\n",
    "            output, hidden = model(x, hidden)\n",
    "            probs = torch.softmax(output[0, -1], dim=0)\n",
    "            next_char_idx = torch.multinomial(probs, 1).item()\n",
    "            next_char = idx_to_char[next_char_idx]\n",
    "            current_text += next_char\n",
    "\n",
    "    return current_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aef1cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_comparison_dict = {}\n",
    "\n",
    "def add_loss_to_comparison(model_name, train_losses_df, val_losses_df):\n",
    "    \"\"\"\n",
    "    Adds training and validation losses from a model to the comparison dictionary.\n",
    "    \"\"\"\n",
    "    loss_comparison_dict[model_name] = {\n",
    "        'train': train_losses_df,\n",
    "        'val': val_losses_df\n",
    "    }\n",
    "\n",
    "def print_final_losses(loss_dict):\n",
    "    for model_name, losses in loss_dict.items():\n",
    "        train_df = losses['train']\n",
    "        val_df = losses['val']\n",
    "        final_train = train_df.groupby('epoch')['loss_value'].last().iloc[-1]\n",
    "        final_val = val_df.groupby('epoch')['loss_value'].last().iloc[-1]\n",
    "        print(f\"{model_name}: Final Train Loss: {final_train:.4f}, Final Val Loss: {final_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "973b4a80",
   "metadata": {
    "id": "973b4a80"
   },
   "outputs": [],
   "source": [
    "# Function to plot loss curves\n",
    "def plot_loss(train_losses_df, val_losses_df):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Plot training losses\n",
    "    for epoch in train_losses_df['epoch'].unique():\n",
    "        epoch_train_losses = train_losses_df[train_losses_df['epoch'] == epoch]\n",
    "        plt.plot(epoch_train_losses['step'], epoch_train_losses['loss_value'],\n",
    "                 color='blue', alpha=0.3)\n",
    "\n",
    "    # scatter training loss at the end of each epoch\n",
    "    last_train_losses = train_losses_df.groupby('epoch').last().reset_index()\n",
    "    plt.scatter(last_train_losses['step'], last_train_losses['loss_value'],\n",
    "                color='blue')\n",
    "\n",
    "    # Plot and scatter validation loss at the end of each epoch\n",
    "    last_val_losses = val_losses_df.groupby('epoch').last().reset_index()\n",
    "    plt.plot(last_val_losses['step'], last_val_losses['loss_value'],\n",
    "             color='orange', label='Validation Loss')\n",
    "    plt.scatter(last_val_losses['step'], last_val_losses['loss_value'],\n",
    "                color='orange')\n",
    "\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Function to print final loss values\n",
    "def print_final_losses(train_losses_df, val_losses_df):\n",
    "    print(\"Final Training Loss:\", train_losses_df.groupby('epoch')['loss_value'].last().iloc[-1])\n",
    "    print(\"Final Validation Loss:\", val_losses_df.groupby('epoch')['loss_value'].last().iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5001e203",
   "metadata": {
    "id": "5001e203"
   },
   "outputs": [],
   "source": [
    "# Function to plot loss curves for multiple models stored in loss_comparison_dict\n",
    "def plot_loss_comparisons():\n",
    "    \"\"\"\n",
    "    Plots the training loss curves and average validation loss per epoch for multiple models added to the loss comparison dictionary.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Get the last model in the dictionary (for special final-point highlighting)\n",
    "    last_model_name = list(loss_comparison_dict.keys())[-1]\n",
    "\n",
    "    # Loop through each model in the loss dictionary\n",
    "    for model_name, losses in loss_comparison_dict.items():\n",
    "        train_losses_df = losses['train']\n",
    "        val_losses_df = losses['val']\n",
    "\n",
    "        # Plot training losses for each model\n",
    "        plt.plot(train_losses_df['step'], train_losses_df['loss_value'],\n",
    "                 label=f'{model_name} train', linestyle='-', alpha=0.7)\n",
    "\n",
    "        # Scatter training loss at the end of each epoch\n",
    "        last_train_losses = train_losses_df.groupby('epoch').last().reset_index()\n",
    "        plt.scatter(last_train_losses['step'], last_train_losses['loss_value'], marker='o', s=50)\n",
    "\n",
    "        # Compute average validation loss per epoch (using the last step of each epoch for x-axis)\n",
    "        avg_val_losses = val_losses_df.groupby('epoch').agg({'loss_value': 'mean', 'step': 'last'}).reset_index()\n",
    "        # Scatter the average validation loss for each epoch\n",
    "        plt.scatter(avg_val_losses['step'], avg_val_losses['loss_value'], marker='s', s=50,\n",
    "                    label=f'{model_name} val avg')\n",
    "\n",
    "        # For the last model, highlight the final training loss with a star\n",
    "        if model_name == last_model_name:\n",
    "            final_step = train_losses_df['step'].iloc[-1]\n",
    "            final_loss = train_losses_df['loss_value'].iloc[-1]\n",
    "            plt.scatter(final_step, final_loss, marker='*', s=100, color='red', zorder=5)\n",
    "\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Comparison')\n",
    "    plt.legend()  # Legend shows both training and validation average labels\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16777ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_separate_train_val(loss_dict):\n",
    "    \"\"\"\n",
    "    모델별 Training Loss와 Validation Loss를 각각 별도의 그래프로 그립니다.\n",
    "    단, Validation Loss는 에포크별 평균으로 계산합니다.\n",
    "    \"\"\"\n",
    "    # 1. Training Loss Plot (원본 그대로)\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.subplot(1, 2, 1)  # 1행 2열 중 첫 번째\n",
    "    for model_name, losses in loss_dict.items():\n",
    "        train_df = losses['train']\n",
    "        steps_train = train_df['step'].values\n",
    "        loss_train = train_df['loss_value'].values\n",
    "        plt.plot(steps_train, loss_train, label=f'{model_name} Train')\n",
    "    plt.title('Training Loss Comparison')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # 2. Validation Loss Plot (에포크별 평균 처리)\n",
    "    plt.subplot(1, 2, 2)  # 1행 2열 중 두 번째\n",
    "    for model_name, losses in loss_dict.items():\n",
    "        val_df = losses['val']\n",
    "        # 에포크별 평균 loss와 마지막 step을 계산\n",
    "        val_avg = val_df.groupby('epoch').agg({'loss_value': 'mean', 'step': 'last'}).reset_index()\n",
    "        plt.plot(val_avg['step'], val_avg['loss_value'], label=f'{model_name} Val')\n",
    "    plt.title('Validation Loss (Epoch Avg) Comparison')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3425645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text generation using validation data\n",
    "val_sample, _ = next(iter(val_loader))\n",
    "start_text = ''.join([idx_to_char[idx.item()] for idx in val_sample[0][:SEQUENCE_LENGTH]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64810fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_attention(model, char_to_idx, idx_to_char, start_text, device, max_length=500):\n",
    "    model.eval()\n",
    "    current_text = start_text\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            # Convert the last sequence of characters to indices and feed it to the model\n",
    "            x = torch.tensor([[char_to_idx[ch] for ch in current_text[-SEQUENCE_LENGTH:]]]).to(device)\n",
    "            output = model(x)[0]  # No hidden state needed for attention-based models\n",
    "            probs = torch.softmax(output[0, -1], dim=0)\n",
    "            next_char_idx = torch.multinomial(probs, 1).item()\n",
    "            next_char = idx_to_char[next_char_idx]\n",
    "            current_text += next_char\n",
    "\n",
    "    return current_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f6d867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(model_desc, model, start_text):\n",
    "    \n",
    "    print(summary(model, input_size=(BATCH_SIZE, SEQUENCE_LENGTH), dtypes=[torch.long]))\n",
    "    print()\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = model.to(device)\n",
    "    # Use the same optimizer and criterion\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # Train the model\n",
    "    trained_model, train_losses_df, val_losses_df = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer, device, EPOCHS\n",
    "    )\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1eb8ad",
   "metadata": {
    "id": "aa1eb8ad"
   },
   "source": [
    "## Model 1: GRU Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e017e89b",
   "metadata": {
    "id": "e017e89b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GRUDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, ffn_dim, num_layers, dropout=0.1):\n",
    "        super(GRUDecoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=num_layers,\n",
    "                          dropout=dropout if num_layers > 1 else 0.0, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_dim, ffn_dim)\n",
    "        self.fc2 = nn.Linear(ffn_dim, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        embed = self.embedding(x)\n",
    "        output, hidden = self.gru(embed, hidden)\n",
    "        output = self.dropout(output)\n",
    "        output = self.layer_norm(output)\n",
    "        output = F.gelu(self.fc1(output))\n",
    "        output = self.fc2(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a3581e4",
   "metadata": {
    "id": "9a3581e4"
   },
   "outputs": [],
   "source": [
    "### Model Initialization\n",
    "gru = GRUDecoder(vocab_size, EMBEDDING_DIM, HIDDEN_DIM, FFN_DIM, NUM_LAYERS+2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(gru.parameters(), lr=LEARNING_RATE, fused=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a885bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "GRUDecoder                               [1, 64, 46]               --\n",
      "├─Embedding: 1-1                         [1, 64, 32]               1,472\n",
      "├─GRU: 1-2                               [1, 64, 64]               143,616\n",
      "├─Dropout: 1-3                           [1, 64, 64]               --\n",
      "├─LayerNorm: 1-4                         [1, 64, 64]               128\n",
      "├─Linear: 1-5                            [1, 64, 480]              31,200\n",
      "├─Linear: 1-6                            [1, 64, 46]               22,126\n",
      "==========================================================================================\n",
      "Total params: 198,542\n",
      "Trainable params: 198,542\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 9.25\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.35\n",
      "Params size (MB): 0.79\n",
      "Estimated Total Size (MB): 1.15\n",
      "==========================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Batch Time: 8.52ms Average Vram Usage: 24.37MB\n"
     ]
    }
   ],
   "source": [
    "train_and_test(\"GRU\", gru, start_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "645a951b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function gc.collect(generation=2)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del gru\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "gc.collect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39911f55",
   "metadata": {
    "id": "39911f55"
   },
   "source": [
    "## Model 2: Modern Transformer(LLaMA - 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b43bc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    DIM = EMBEDDING_DIM \n",
    "    FFN_DIM = FFN_DIM\n",
    "    NUM_HEADS = NUM_HEADS \n",
    "    NUM_LAYERS = NUM_LAYERS\n",
    "\n",
    "    NUM_KV_HEADS = NUM_HEADS \n",
    "    VOCAB_SIZE = vocab_size\n",
    "    NORM_EPS = 1e-5 # LLaMA: 1e-5\n",
    "    ROPE_THETA = 10000 # LLaMA: 10000\n",
    "\n",
    "    MAX_BATCH_SIZE = BATCH_SIZE\n",
    "    MAX_SEQ_LEN = SEQUENCE_LENGTH # depending on the DATASET\n",
    "    NUM_KV_HEAD_REP = NUM_HEADS // NUM_KV_HEADS\n",
    "\n",
    "    HEAD_DIM = DIM // NUM_HEADS\n",
    "    DROPOUT = DROPOUT\n",
    "    DEVICE = device\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "    def _norm(self, x: torch.Tensor):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.weight.to(x.device) * self._norm(x.float()).type_as(x)\n",
    "    \n",
    "def precompute_freqs_cis(head_dim: int, seq_len: int, theta: float = 100.0, device: str = \"cuda\"):\n",
    "    if head_dim % 2 != 0:\n",
    "        raise ValueError(\"head_dim must be even for rotary embeddings.\")\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, head_dim, 2).float() / head_dim)).to(device)\n",
    "    t = torch.arange(seq_len, device=device, dtype=torch.float32)\n",
    "    freqs = torch.outer(t, freqs)  # [seq_len, head_dim//2]\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)\n",
    "    return freqs_cis  # [seq_len, head_dim // 2]\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    L = x.shape[1]\n",
    "    return freqs_cis.view(1, L, 1, x.shape[-1] // 2)  # [1, L, 1, head_dim]\n",
    "\n",
    "def apply_rotary_emb(x: torch.Tensor, device: str = \"cuda\"):\n",
    "    # x: [B, L, 2*heads, D] & D is even\n",
    "    _, L, _, D = x.shape\n",
    "    x_complex = torch.view_as_complex(x.float().reshape(*x.shape[:-1], -1, 2)) # [B, L, 2*heads, D//2, 2]\n",
    "    freqs_cis = precompute_freqs_cis(D, L)\n",
    "    freqs = reshape_for_broadcast(freqs_cis, x)\n",
    "    x_rotated = x_complex * freqs\n",
    "    x_out = torch.view_as_real(x_rotated).reshape(x.shape)\n",
    "    return x_out.type_as(x).to(device)\n",
    "\n",
    "def repeat_kv(x: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
    "    B, L, nk, d = x.shape\n",
    "    if n_rep == 1:\n",
    "        return x\n",
    "    return x[:, :, :, None, :].expand(B, L, nk, n_rep, d).reshape(B, L, nk * n_rep, d)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, ffn_dim, dropout):\n",
    "        super().__init__()\n",
    "        hidden_dim = ffn_dim\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x: [B, L, D]\n",
    "        return self.w2(F.silu(self.w1(x)) * self.dropout(self.w3(x)))\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, n_heads, n_kv_heads, n_rep, dim, dropout, batch, seq_len, device):\n",
    "        super().__init__()\n",
    "        self.n_heads_q = n_heads\n",
    "        self.n_kv_heads = n_kv_heads\n",
    "        self.n_rep = n_rep\n",
    "        self.head_dim = dim // n_heads\n",
    "\n",
    "        self.wq = nn.Linear(dim, n_heads * self.head_dim, bias=False)\n",
    "        self.wk = nn.Linear(dim, n_kv_heads * self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(dim, n_kv_heads * self.head_dim, bias=False)\n",
    "        self.wo = nn.Linear(n_heads * self.head_dim, dim, bias=False)\n",
    "        self.attn_dropout = dropout\n",
    "        \n",
    "        self.norm = RMSNorm(self.head_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos, mask, return_attn=False):\n",
    "        B, L, _ = x.shape\n",
    "        src_len = trg_len = L\n",
    "        offset = start_pos\n",
    "        \n",
    "        xq = self.wq(x).view(B, L, self.n_heads_q, self.head_dim)\n",
    "        xk = self.wk(x).view(B, L, self.n_kv_heads, self.head_dim)\n",
    "        xv = self.wv(x).view(B, L, self.n_kv_heads, self.head_dim)\n",
    "        \n",
    "        # Apply rotary embeddings\n",
    "        xq = apply_rotary_emb(xq)\n",
    "        xk = apply_rotary_emb(xk)\n",
    "        \n",
    "        # GQA: Adjust dimensions for attention computation\n",
    "        xq = xq.transpose(1, 2)   # [B, n_heads, L, head_dim]\n",
    "        xk = repeat_kv(xk, self.n_rep).transpose(1, 2) # [B, n_heads, L, head_dim]\n",
    "        xv = repeat_kv(xv, self.n_rep).transpose(1, 2) # [B, n_heads, L, head_dim]\n",
    "\n",
    "        # Compute scaled dot-product attention manually to capture attention weights\n",
    "        scores = torch.matmul(xq, xk.transpose(-2, -1)) / math.sqrt(self.head_dim)  # [B, n_heads, L, L]\n",
    "        scores = torch.nan_to_num(scores)\n",
    "        if mask is None:\n",
    "            mask = torch.triu(\n",
    "                torch.zeros([L, L])\n",
    "                .float()\n",
    "                .fill_(float(\"-inf\"))\n",
    "                .type_as(attn_weights),\n",
    "                1 + offset,\n",
    "            )\n",
    "            \n",
    "        scores += mask\n",
    "        attn_weights = torch.softmax(scores, dim=-1)\n",
    "        attn_weights = F.dropout(attn_weights, self.attn_dropout, training=self.training)\n",
    "        attn_output = torch.matmul(attn_weights, xv)  # [B, n_heads, L, head_dim]\n",
    "        attn_output = self.norm(attn_output)\n",
    "        \n",
    "        # Reshape attention output and project\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(B, L, -1)\n",
    "        output = self.wo(attn_output)  # [B, L, D]\n",
    "        if return_attn:\n",
    "            return output, attn_weights\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, args: 'ModelArgs'):\n",
    "        super().__init__()\n",
    "        self.attention = SelfAttention(\n",
    "            args.NUM_HEADS, \n",
    "            args.NUM_KV_HEADS, \n",
    "            args.NUM_KV_HEAD_REP, \n",
    "            args.DIM, \n",
    "            args.DROPOUT, \n",
    "            args.MAX_BATCH_SIZE, \n",
    "            args.MAX_SEQ_LEN, \n",
    "            args.DEVICE\n",
    "        )\n",
    "        self.ffn = FeedForward(args.DIM, args.FFN_DIM, args.DROPOUT)\n",
    "        self.attention_norm = RMSNorm(args.DIM, args.NORM_EPS)\n",
    "        self.ffn_norm = RMSNorm(args.DIM, args.NORM_EPS)\n",
    "        self.res_dropout = nn.Dropout(args.DROPOUT)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, start_pos, mask, return_attn=False):\n",
    "        if return_attn:\n",
    "            attn_out, attn_map = self.attention(self.attention_norm(x), start_pos, mask, return_attn=True)\n",
    "            h = x + self.res_dropout(attn_out)\n",
    "            h = h + self.res_dropout(self.ffn(self.ffn_norm(h)))\n",
    "            return h, attn_map\n",
    "        else:\n",
    "            h = x + self.res_dropout(self.attention(self.attention_norm(x), start_pos, mask))\n",
    "            h = h + self.res_dropout(self.ffn(self.ffn_norm(h)))\n",
    "            return h\n",
    "\n",
    "class LlamaTransformer(nn.Module):\n",
    "    def __init__(self, args: 'ModelArgs'):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.tok_embeddings = nn.Embedding(args.VOCAB_SIZE, args.DIM)\n",
    "        self.layers = nn.ModuleList([TransformerBlock(args) for _ in range(args.NUM_LAYERS)])\n",
    "        self.norm = RMSNorm(args.DIM, args.NORM_EPS)\n",
    "        self.output = nn.Linear(args.DIM, args.VOCAB_SIZE, bias=False)\n",
    "        self.device = args.DEVICE\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, start_pos=0, return_attn=False):\n",
    "        B, L = x.shape\n",
    "        h = self.tok_embeddings(x)  # [B, L, D]\n",
    "        \n",
    "        mask = None\n",
    "        if L > 1:\n",
    "            mask = torch.triu(\n",
    "                torch.zeros([L, L])\n",
    "                .float()\n",
    "                .fill_(float(\"-inf\"))\n",
    "                .type_as(x),\n",
    "                1 + start_pos,\n",
    "            )\n",
    "        attn_maps = []\n",
    "        for layer in self.layers:\n",
    "            if return_attn:\n",
    "                h, attn_map = layer(h, start_pos, mask, return_attn=True)\n",
    "                attn_maps.append(attn_map)\n",
    "            else:\n",
    "                h = layer(h, start_pos, mask)\n",
    "        logits = self.output(self.norm(h)).float()\n",
    "        if return_attn:\n",
    "            return logits, attn_maps\n",
    "        return logits, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66b4f114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTransformer(\n",
       "  (tok_embeddings): Embedding(46, 32)\n",
       "  (layers): ModuleList(\n",
       "    (0-3): 4 x TransformerBlock(\n",
       "      (attention): SelfAttention(\n",
       "        (wq): Linear(in_features=32, out_features=32, bias=False)\n",
       "        (wk): Linear(in_features=32, out_features=32, bias=False)\n",
       "        (wv): Linear(in_features=32, out_features=32, bias=False)\n",
       "        (wo): Linear(in_features=32, out_features=32, bias=False)\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (w1): Linear(in_features=32, out_features=480, bias=False)\n",
       "        (w2): Linear(in_features=480, out_features=32, bias=False)\n",
       "        (w3): Linear(in_features=32, out_features=480, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (attention_norm): RMSNorm()\n",
       "      (ffn_norm): RMSNorm()\n",
       "      (res_dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       "  (output): Linear(in_features=32, out_features=46, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARAMS = ModelArgs()\n",
    "llama = LlamaTransformer(PARAMS).to(device)\n",
    "llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b361db8b",
   "metadata": {
    "id": "b361db8b",
    "outputId": "33c6269c-5979-4100-b6e7-a89b6b4ed962"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "LlamaTransformer                         [1, 64, 46]               --\n",
      "├─Embedding: 1-1                         [1, 64, 32]               1,472\n",
      "├─ModuleList: 1-2                        --                        --\n",
      "│    └─TransformerBlock: 2-1             [1, 64, 32]               --\n",
      "│    │    └─RMSNorm: 3-1                 [1, 64, 32]               32\n",
      "│    │    └─SelfAttention: 3-2           [1, 64, 32]               4,104\n",
      "│    │    └─Dropout: 3-3                 [1, 64, 32]               --\n",
      "│    │    └─RMSNorm: 3-4                 [1, 64, 32]               32\n",
      "│    │    └─FeedForward: 3-5             [1, 64, 32]               46,080\n",
      "│    │    └─Dropout: 3-6                 [1, 64, 32]               --\n",
      "│    └─TransformerBlock: 2-2             [1, 64, 32]               --\n",
      "│    │    └─RMSNorm: 3-7                 [1, 64, 32]               32\n",
      "│    │    └─SelfAttention: 3-8           [1, 64, 32]               4,104\n",
      "│    │    └─Dropout: 3-9                 [1, 64, 32]               --\n",
      "│    │    └─RMSNorm: 3-10                [1, 64, 32]               32\n",
      "│    │    └─FeedForward: 3-11            [1, 64, 32]               46,080\n",
      "│    │    └─Dropout: 3-12                [1, 64, 32]               --\n",
      "│    └─TransformerBlock: 2-3             [1, 64, 32]               --\n",
      "│    │    └─RMSNorm: 3-13                [1, 64, 32]               32\n",
      "│    │    └─SelfAttention: 3-14          [1, 64, 32]               4,104\n",
      "│    │    └─Dropout: 3-15                [1, 64, 32]               --\n",
      "│    │    └─RMSNorm: 3-16                [1, 64, 32]               32\n",
      "│    │    └─FeedForward: 3-17            [1, 64, 32]               46,080\n",
      "│    │    └─Dropout: 3-18                [1, 64, 32]               --\n",
      "│    └─TransformerBlock: 2-4             [1, 64, 32]               --\n",
      "│    │    └─RMSNorm: 3-19                [1, 64, 32]               32\n",
      "│    │    └─SelfAttention: 3-20          [1, 64, 32]               4,104\n",
      "│    │    └─Dropout: 3-21                [1, 64, 32]               --\n",
      "│    │    └─RMSNorm: 3-22                [1, 64, 32]               32\n",
      "│    │    └─FeedForward: 3-23            [1, 64, 32]               46,080\n",
      "│    │    └─Dropout: 3-24                [1, 64, 32]               --\n",
      "├─RMSNorm: 1-3                           [1, 64, 32]               32\n",
      "├─Linear: 1-4                            [1, 64, 46]               1,472\n",
      "==========================================================================================\n",
      "Total params: 203,968\n",
      "Trainable params: 203,968\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.20\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 2.55\n",
      "Params size (MB): 0.82\n",
      "Estimated Total Size (MB): 3.36\n",
      "==========================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Batch Time: 20.11ms Average Vram Usage: 19.39MB\n"
     ]
    }
   ],
   "source": [
    "train_and_test(\"LLaMA\", llama, start_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8775d573",
   "metadata": {},
   "source": [
    "## Model 3: Mamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6be4f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-07 06:26:31,277] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 06:26:32.802069: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-07 06:26:33.598094: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange, repeat\n",
    "import math\n",
    "from causal_conv1d import causal_conv1d_fn\n",
    "from mamba_ssm.ops.selective_scan_interface import selective_scan_fn\n",
    "\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    \"\"\"RMS 정규화 레이어.\n",
    "\n",
    "    Args:\n",
    "        dim (int): 정규화할 벡터의 차원.\n",
    "        eps (float, optional): 분모에 더할 작은 값 (0으로 나누는 것 방지). 기본값: 1e-6.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        # 학습 가능한 스케일링 파라미터 (gamma)\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"RMS 정규화 계산 수행.\"\"\"\n",
    "        # 계산 안정성을 위해 float32 사용 후 원본 타입 복원\n",
    "        original_dtype = x.dtype\n",
    "        # 입력의 제곱 평균의 제곱근 역수 계산\n",
    "        rms = torch.rsqrt(x.to(torch.float32).pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "        return (x * rms).to(original_dtype)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"RMS 정규화 적용.\"\"\"\n",
    "        # 정규화 후 학습 가능한 가중치 적용\n",
    "        return self.weight * self._norm(x)\n",
    "\n",
    "\n",
    "class SSM(nn.Module):\n",
    "    \"\"\"선택적 스캔 메커니즘 (SSM). 최적화된 selective_scan_fn 커널 사용.\n",
    "       Mamba v1 논문의 파라미터화 및 계산 방식 (non-fused path) 기반.\n",
    "       selective_scan_fn이 기대하는 특정 텐서 레이아웃(B,D,L / B,N,L 등)을 따름.\n",
    "\n",
    "    Args:\n",
    "        d_inner (int): 내부 확장 차원 (D).\n",
    "        state_size (int): SSM 상태 벡터 크기 (N).\n",
    "        dt_rank (str or int, optional): Δ 계산 시 사용될 중간 랭크. \"auto\"시 d_inner / 16. 기본값: \"auto\".\n",
    "        dt_min (float, optional): Δ의 최소값 제한 (softplus 적용 후). 기본값: 0.001.\n",
    "        dt_max (float, optional): Δ의 최대값 제한 (softplus 적용 후). 기본값: 0.1.\n",
    "        dt_init (str, optional): dt_proj 가중치 초기화 방식 (\"random\" or \"constant\"). 기본값: \"random\".\n",
    "        dt_scale (float, optional): dt_proj 가중치 초기화 스케일. 기본값: 1.0.\n",
    "        dt_init_floor (float, optional): dt 초기값 하한선. 기본값: 1e-4.\n",
    "        bias (bool, optional): x_proj 레이어에 bias 사용 여부. 기본값: False.\n",
    "        device (str, optional): 연산 장치. 기본값: 'cuda'.\n",
    "        dtype (torch.dtype, optional): 연산 데이터 타입. 기본값: torch.float32.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_inner: int, state_size: int, dt_rank: str | int =\"auto\", dt_min: float =0.001, dt_max: float =0.1,\n",
    "                 dt_init: str =\"random\", dt_scale: float =1.0, dt_init_floor: float =1e-4, bias: bool =False,\n",
    "                 device: str ='cuda', dtype: torch.dtype =torch.float32):\n",
    "        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "        super().__init__()\n",
    "        self.d_inner = d_inner\n",
    "        self.state_size = state_size\n",
    "        # dt_rank 자동 계산 또는 지정값 사용\n",
    "        self.dt_rank = math.ceil(d_inner / 16) if dt_rank == \"auto\" else dt_rank\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "\n",
    "        # 컨볼루션 출력(x)을 받아 dt_inter, B, C 계산용 프로젝션 (Mamba v1 non-fused 방식)\n",
    "        self.x_proj = nn.Linear(self.d_inner, self.dt_rank + self.state_size * 2, bias=bias, **factory_kwargs)\n",
    "\n",
    "        # dt_inter를 받아 dt 계산용 프로젝션\n",
    "        self.dt_proj = nn.Linear(self.dt_rank, self.d_inner, bias=True, **factory_kwargs)\n",
    "\n",
    "        # --- dt_proj bias 특별 초기화 (Mamba v1 공식 코드 참조) ---\n",
    "        # 초기화 시 softplus(bias) 결과가 [dt_min, dt_max] 범위에 있도록 조정\n",
    "        dt_init_std = self.dt_rank**-0.5 * dt_scale\n",
    "        if dt_init == \"constant\":\n",
    "            nn.init.constant_(self.dt_proj.weight, dt_init_std)\n",
    "        elif dt_init == \"random\":\n",
    "            nn.init.uniform_(self.dt_proj.weight, -dt_init_std, dt_init_std)\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Invalid dt_init: {dt_init}\")\n",
    "\n",
    "        # dt bias 초기값 계산 (softplus의 역함수 활용)\n",
    "        dt = torch.exp(\n",
    "            torch.rand(self.d_inner, **factory_kwargs) * (math.log(dt_max) - math.log(dt_min))\n",
    "            + math.log(dt_min)\n",
    "        ).clamp(min=dt_init_floor)\n",
    "        inv_dt = dt + torch.log(-torch.expm1(-dt)) # softplus(inv_dt) ≈ dt\n",
    "        with torch.no_grad():\n",
    "            self.dt_proj.bias.copy_(inv_dt)\n",
    "        # 다른 초기화 루틴에서 이 bias를 덮어쓰지 않도록 플래그 설정 (선택적)\n",
    "        self.dt_proj.bias._no_reinit = True\n",
    "        # --- dt_proj bias 초기화 종료 ---\n",
    "\n",
    "        # --- SSM 파라미터 A (A_log) ---\n",
    "        # S4D-Real 방식 초기화: A 행렬의 대각 요소가 [1, 2, ..., N]이 되도록 A_log 설정\n",
    "        A = repeat(\n",
    "            torch.arange(1, self.state_size + 1, dtype=torch.float32, device=device),\n",
    "            \"n -> d n\", # 1차원 벡터를 d_inner 번 반복하여 (D, N) 행렬 생성\n",
    "            d=self.d_inner,\n",
    "        ).contiguous()\n",
    "        A_log = torch.log(A) # 로그 스케일에서 파라미터 학습 (float32 유지)\n",
    "        self.A_log = nn.Parameter(A_log)\n",
    "        self.A_log._no_weight_decay = True # 가중치 감쇠 제외\n",
    "\n",
    "        # --- SSM 파라미터 D (피드스루) ---\n",
    "        # 형태: (D)\n",
    "        self.D = nn.Parameter(torch.ones(self.d_inner, device=device)) # float32 유지 권장\n",
    "        self.D._no_weight_decay = True # 가중치 감쇠 제외\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"SSM 순방향 계산. 입력 x는 (B, D, L) 레이아웃을 가정.\"\"\"\n",
    "        B, D, L = x.shape # 입력 레이아웃 확인\n",
    "        if D != self.d_inner:\n",
    "            raise ValueError(f\"입력 차원 D({D})가 SSM 내부 차원({self.d_inner})과 불일치\")\n",
    "\n",
    "        # 1. 입력 x(컨볼루션 출력)로부터 dt, B, C 계산\n",
    "        #    선형 프로젝션을 위해 (B*L, D) 형태로 변환\n",
    "        x_reshaped = rearrange(x, \"b d l -> (b l) d\")\n",
    "        x_proj_out = self.x_proj(x_reshaped) # 결과: (B*L, dt_rank + 2*N)\n",
    "        dt_inter, B, C = torch.split(x_proj_out, [self.dt_rank, self.state_size, self.state_size], dim=-1)\n",
    "\n",
    "        # 2. dt 계산 (softplus 적용 전) -> 형태 (B, D, L)\n",
    "        #    dt_inter: (B*L, dt_rank)\n",
    "        #    Mamba v1 non-fused path 방식 적용\n",
    "        dt = self.dt_proj.weight @ dt_inter.t() # 결과: (D, B*L)\n",
    "        dt = rearrange(dt, \"d (b l) -> b d l\", l=L) # 최종 형태: (B, D, L)\n",
    "        # dt_bias는 selective_scan_fn 내부에서 delta_bias 인자로 전달되어 더해짐\n",
    "\n",
    "        # 3. A 행렬 계산, 형태 (D, N)\n",
    "        A = -torch.exp(self.A_log.float()) # float32에서 exp 계산\n",
    "\n",
    "        # 4. B, C 형태 변경 -> (B, N, L)\n",
    "        #    selective_scan_fn 커널이 요구하는 레이아웃\n",
    "        B = rearrange(B, \"(b l) n -> b n l\", l=L).contiguous()\n",
    "        C = rearrange(C, \"(b l) n -> b n l\", l=L).contiguous()\n",
    "\n",
    "        # 5. D 파라미터 준비, 형태 (D)\n",
    "        D_param = self.D.float().contiguous()\n",
    "\n",
    "        # 6. selective_scan_fn 입력 준비 (메모리 연속성 보장)\n",
    "        input_u = x.contiguous()             # u (SSM 입력): (B, D, L)\n",
    "        input_delta = dt.contiguous()        # delta (dt): (B, D, L)\n",
    "        input_A = A.contiguous()             # A: (D, N)\n",
    "        input_B = B                          # B: (B, N, L)\n",
    "        input_C = C                          # C: (B, N, L)\n",
    "        input_D = D_param                    # D: (D)\n",
    "        input_delta_bias = self.dt_proj.bias.float().contiguous() if self.dt_proj.bias is not None else None\n",
    "\n",
    "        # 7. 최적화된 selective_scan_fn 호출\n",
    "        #    입력 레이아웃 및 파라미터 형태는 Mamba v1 non-fused path 기준\n",
    "        y = selective_scan_fn(\n",
    "            u=input_u,\n",
    "            delta=input_delta,\n",
    "            A=input_A,\n",
    "            B=input_B,\n",
    "            C=input_C,\n",
    "            D=input_D,\n",
    "            z=None, # 게이트 z는 MambaBlock 레벨에서 처리\n",
    "            delta_bias=input_delta_bias, # dt_bias 전달\n",
    "            delta_softplus=True, # 내부에서 delta = softplus(dt + delta_bias) 계산\n",
    "        )\n",
    "\n",
    "        # 8. 결과 반환, 형태 (B, D, L)\n",
    "        #    후속 처리를 위해 이 레이아웃 유지\n",
    "        return y\n",
    "\n",
    "\n",
    "class MambaBlock(nn.Module):\n",
    "    \"\"\"Mamba 핵심 블록. RMSNorm, 입력 프로젝션, 인과적 컨볼루션, SSM, 게이팅, 출력 프로젝션 구성.\n",
    "       내부적으로 (B, D, L) 텐서 레이아웃 사용.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, state_size: int, d_conv: int = 4, expand: int = 2,\n",
    "                 dropout_prob: float = 0.1, device: str = 'cuda', dtype: torch.dtype = torch.float32):\n",
    "        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_inner = int(expand * d_model) # 내부 확장 차원 (D)\n",
    "        self.state_size = state_size\n",
    "        self.d_conv = d_conv\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "\n",
    "        # 입력 정규화 (RMSNorm)\n",
    "        self.norm = RMSNorm(d_model, eps=1e-5)\n",
    "\n",
    "        # 입력 프로젝션 (d_model -> 2 * d_inner)\n",
    "        self.in_proj = nn.Linear(d_model, 2 * self.d_inner, bias=False, **factory_kwargs)\n",
    "\n",
    "        # 인과적 컨볼루션 파라미터 (가중치 형태: D, K)\n",
    "        self.conv1d_weight = nn.Parameter(torch.empty(self.d_inner, d_conv, **factory_kwargs))\n",
    "        self.conv1d_bias = nn.Parameter(torch.empty(self.d_inner, **factory_kwargs))\n",
    "\n",
    "        # SSM 모듈 인스턴스화 (Mamba v1 파라미터 전달 옵션 추가 가능)\n",
    "        self.ssm = SSM(self.d_inner, state_size, device=device, dtype=dtype)\n",
    "                      # dt_rank, dt_min 등 SSM 파라미터 전달 가능\n",
    "\n",
    "        # 출력 프로젝션 (d_inner -> d_model)\n",
    "        self.out_proj = nn.Linear(self.d_inner, d_model, bias=False, **factory_kwargs)\n",
    "\n",
    "        # 잔차 연결 드롭아웃\n",
    "        self.dropout_res = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Mamba 블록 순방향 계산.\"\"\"\n",
    "        B, L, D_model = x.shape # 입력 형태: (B, L, d_model)\n",
    "        residual = x # 잔차 연결용 원본 저장\n",
    "\n",
    "        # 1. 입력 정규화\n",
    "        x_norm = self.norm(x)\n",
    "\n",
    "        # 2. 입력 프로젝션 및 분할 (x_in, z)\n",
    "        xz = self.in_proj(x_norm) # 결과: (B, L, 2*D)\n",
    "        x_in, z = xz.chunk(2, dim=-1) # 각각: (B, L, D)\n",
    "\n",
    "        # 3. 인과적 컨볼루션 브랜치\n",
    "        #    입력 레이아웃 변경: (B, L, D) -> (B, D, L)\n",
    "        x_conv_in = rearrange(x_in, 'b l d -> b d l').contiguous()\n",
    "        #    최적화된 causal_conv1d_fn 호출 (SiLU 활성화 포함)\n",
    "        #    출력 x_conv_out 형태: (B, D, L)\n",
    "        x_conv_out = causal_conv1d_fn(\n",
    "            x=x_conv_in, weight=self.conv1d_weight, bias=self.conv1d_bias, activation='silu'\n",
    "        )\n",
    "\n",
    "        # 4. SSM 브랜치\n",
    "        #    컨볼루션 출력(B, D, L)을 SSM에 직접 전달\n",
    "        #    SSM 출력 y_ssm 형태: (B, D, L)\n",
    "        y_ssm = self.ssm(x_conv_out)\n",
    "\n",
    "        # 5. 게이팅 메커니즘\n",
    "        #    y_ssm을 z와 곱하기 위해 (B, L, D) 형태로 변경\n",
    "        y_ssm_rearranged = rearrange(y_ssm, 'b d l -> b l d')\n",
    "        #    z에 SiLU 활성화 적용 후 요소별 곱셈\n",
    "        y_gated = y_ssm_rearranged * F.silu(z) # 결과: (B, L, D)\n",
    "\n",
    "        # 6. 출력 프로젝션\n",
    "        output = self.out_proj(y_gated) # 결과: (B, L, d_model)\n",
    "\n",
    "        # 7. 잔차 연결 및 드롭아웃\n",
    "        output = residual + self.dropout_res(output) # 최종 결과: (B, L, d_model)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class Mamba(nn.Module):\n",
    "    \"\"\"Mamba 언어 모델 전체 구조.\"\"\"\n",
    "    def __init__(self, d_model: int, n_layers: int, vocab_size: int, state_size: int = 16,\n",
    "                 d_conv: int = 4, expand: int = 2, dropout_prob: float = 0.1,\n",
    "                 device: str = 'cuda', dtype: torch.dtype = torch.float32):\n",
    "        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_layers = n_layers\n",
    "        self.vocab_size = vocab_size\n",
    "        # 저장된 파라미터는 validation 등에 사용될 수 있음\n",
    "        self.state_size = state_size\n",
    "        self.d_conv = d_conv\n",
    "        self.expand = expand\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "\n",
    "        # 토큰 임베딩 레이어\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model, **factory_kwargs)\n",
    "        self.dropout_emb = nn.Dropout(dropout_prob)\n",
    "\n",
    "        # Mamba 블록 스택\n",
    "        self.layers = nn.ModuleList([\n",
    "            MambaBlock(\n",
    "                d_model=d_model, state_size=state_size, d_conv=d_conv,\n",
    "                expand=expand, dropout_prob=dropout_prob, device=device, dtype=dtype\n",
    "            ) for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "        # 최종 정규화 레이어\n",
    "        self.norm_f = RMSNorm(d_model, eps=1e-5)\n",
    "        # 언어 모델링 헤드 (출력 레이어)\n",
    "        self.lm_head = nn.Linear(d_model, vocab_size, bias=False, **factory_kwargs)\n",
    "\n",
    "        # 가중치 공유 (임베딩과 LM 헤드)\n",
    "        self.lm_head.weight = self.embedding.weight\n",
    "\n",
    "        # 모델 가중치 초기화 적용\n",
    "        self.apply(self._init_weights)\n",
    "        print(f\"Mamba 모델 초기화 완료. Device: {device}, Dtype: {dtype}\")\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\"모델의 각 모듈 가중치 초기화.\"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            # dt_proj의 bias는 특별 초기화되므로 건너뜀\n",
    "            if hasattr(module.bias, '_no_reinit') and module.bias._no_reinit:\n",
    "                return\n",
    "            # Linear 레이어 가중치 초기화 (예: GPT-2 스타일)\n",
    "            std = 0.02\n",
    "            # 모델 깊이에 따른 스케일링 (옵션)\n",
    "            if self.n_layers > 0:\n",
    "                 # 입력/출력 프로젝션 등 특정 레이어에만 적용 고려 가능\n",
    "                 if module.weight.shape[0] == self.d_model or module.weight.shape[1] == self.d_model:\n",
    "                     std /= math.sqrt(2.0 * self.n_layers)\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=std)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            # 임베딩 가중치 초기화\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "        elif isinstance(module, MambaBlock):\n",
    "            # MambaBlock 내의 Conv1d 가중치 초기화\n",
    "            if hasattr(module, 'conv1d_weight'):\n",
    "                # Kaiming 초기화 (SiLU 활성화 함수에 적합)\n",
    "                nn.init.kaiming_normal_(module.conv1d_weight, nonlinearity='leaky_relu')\n",
    "            if hasattr(module, 'conv1d_bias'):\n",
    "                nn.init.zeros_(module.conv1d_bias)\n",
    "        # RMSNorm 가중치는 해당 클래스 생성자에서 1로 초기화됨\n",
    "        # SSM 파라미터 (A_log, D)는 해당 클래스 생성자에서 초기화됨\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor) -> tuple[torch.Tensor, None]:\n",
    "        \"\"\"Mamba 모델 순방향 계산.\"\"\"\n",
    "        B, L = input_ids.shape\n",
    "\n",
    "        # 1. 임베딩 및 드롭아웃\n",
    "        # 임베딩 레이어는 LongTensor 입력 필요\n",
    "        x = self.embedding(input_ids.long())\n",
    "        x = self.dropout_emb(x)\n",
    "\n",
    "        # 2. Mamba 블록 순차 적용\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        # 3. 최종 정규화\n",
    "        x = self.norm_f(x)\n",
    "\n",
    "        # 4. LM 헤드를 통해 로짓 계산\n",
    "        logits = self.lm_head(x) # 결과: [B, L, vocab_size]\n",
    "\n",
    "        # Loss 계산은 외부 학습 루프에서 처리 (labels 사용)\n",
    "        # 여기서는 로짓과 None 반환 (일반적인 Hugging Face 모델 스타일)\n",
    "        return logits, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "014a9b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n- pip install causal-conv1d\\n- mamba github clone > setup.py build > setup.py install\\n- sudo apt-get update && sudo apt-get install -y libaio-dev\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "- pip install causal-conv1d\n",
    "- mamba github clone > setup.py build > setup.py install\n",
    "- sudo apt-get update && sudo apt-get install -y libaio-dev\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cf6a7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mamba 모델 초기화 완료. Device: cuda, Dtype: torch.float32\n",
      "test_output.shape = torch.Size([1, 64, 46])\n"
     ]
    }
   ],
   "source": [
    "STATE_SIZE = 8\n",
    "\n",
    "x = torch.randint(0, vocab_size, (BATCH_SIZE, SEQUENCE_LENGTH)).to(device)\n",
    "\n",
    "mamba = Mamba(HIDDEN_DIM, NUM_LAYERS, vocab_size, STATE_SIZE, d_conv=4, expand=3).to(device)\n",
    "\n",
    "test_output, _ = mamba(x)\n",
    "print(f\"test_output.shape = {test_output.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51ce9296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Mamba                                    [1, 64, 46]               --\n",
      "├─Embedding: 1-1                         [1, 64, 64]               2,944\n",
      "├─Dropout: 1-2                           [1, 64, 64]               --\n",
      "├─ModuleList: 1-3                        --                        --\n",
      "│    └─MambaBlock: 2-1                   [1, 64, 64]               960\n",
      "│    │    └─RMSNorm: 3-1                 [1, 64, 64]               64\n",
      "│    │    └─Linear: 3-2                  [1, 64, 384]              24,576\n",
      "│    │    └─SSM: 3-3                     [1, 192, 64]              9,600\n",
      "│    │    └─Linear: 3-4                  [1, 64, 64]               12,288\n",
      "│    │    └─Dropout: 3-5                 [1, 64, 64]               --\n",
      "│    └─MambaBlock: 2-2                   [1, 64, 64]               960\n",
      "│    │    └─RMSNorm: 3-6                 [1, 64, 64]               64\n",
      "│    │    └─Linear: 3-7                  [1, 64, 384]              24,576\n",
      "│    │    └─SSM: 3-8                     [1, 192, 64]              9,600\n",
      "│    │    └─Linear: 3-9                  [1, 64, 64]               12,288\n",
      "│    │    └─Dropout: 3-10                [1, 64, 64]               --\n",
      "│    └─MambaBlock: 2-3                   [1, 64, 64]               960\n",
      "│    │    └─RMSNorm: 3-11                [1, 64, 64]               64\n",
      "│    │    └─Linear: 3-12                 [1, 64, 384]              24,576\n",
      "│    │    └─SSM: 3-13                    [1, 192, 64]              9,600\n",
      "│    │    └─Linear: 3-14                 [1, 64, 64]               12,288\n",
      "│    │    └─Dropout: 3-15                [1, 64, 64]               --\n",
      "│    └─MambaBlock: 2-4                   [1, 64, 64]               960\n",
      "│    │    └─RMSNorm: 3-16                [1, 64, 64]               64\n",
      "│    │    └─Linear: 3-17                 [1, 64, 384]              24,576\n",
      "│    │    └─SSM: 3-18                    [1, 192, 64]              9,600\n",
      "│    │    └─Linear: 3-19                 [1, 64, 64]               12,288\n",
      "│    │    └─Dropout: 3-20                [1, 64, 64]               --\n",
      "├─RMSNorm: 1-4                           [1, 64, 64]               64\n",
      "├─Linear: 1-5                            [1, 64, 46]               2,944\n",
      "==========================================================================================\n",
      "Total params: 195,904\n",
      "Trainable params: 195,904\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 1.53\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.20\n",
      "Params size (MB): 0.70\n",
      "Estimated Total Size (MB): 1.90\n",
      "==========================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/836 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Batch Time: 13.91ms Average Vram Usage: 21.12MB\n"
     ]
    }
   ],
   "source": [
    "train_and_test(\"mamba\", mamba, start_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd60a76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
