{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94bebad5",
   "metadata": {},
   "source": [
    "```\n",
    "LSTM vs Transformer vs LLaMA vs Diff\n",
    "```\n",
    "- 파라미터 수 78만 정도의 작은 모델 & without GQA\n",
    "- 작은 배치 사이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20ec8bf0",
   "metadata": {
    "id": "20ec8bf0"
   },
   "outputs": [],
   "source": [
    "## Importing Libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3390f4",
   "metadata": {
    "id": "5a3390f4"
   },
   "source": [
    "## Hyperparameters and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0c61f36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1732703737281,
     "user": {
      "displayName": "Hugman Sangkeun Jung",
      "userId": "08689291704194029524"
     },
     "user_tz": -540
    },
    "id": "d0c61f36",
    "outputId": "45d9894c-a14d-4164-9f2d-699025751e72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Modified hyperparameters\n",
    "SEQUENCE_LENGTH = 64\n",
    "\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = EMBEDDING_DIM*2\n",
    "\n",
    "BATCH_SIZE = 2048\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "VALIDATION_SPLIT = 0.1\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c9b962",
   "metadata": {
    "id": "89c9b962"
   },
   "source": [
    "## Data Preparation\n",
    "\n",
    "We are using the TinyShakespeare dataset, a small character-level text corpus consisting of a subset of Shakespeare's plays. It's often used for testing sequence models, as it includes a rich set of vocabulary and provides a challenging task for next-character prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "089830e2",
   "metadata": {
    "id": "089830e2"
   },
   "outputs": [],
   "source": [
    "## Utility Functions\n",
    "\n",
    "def load_data(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "def create_char_mappings(text):\n",
    "    chars = sorted(list(set(text)))\n",
    "    char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
    "    idx_to_char = {i: ch for i, ch in enumerate(chars)}\n",
    "    return chars, char_to_idx, idx_to_char"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fc6452",
   "metadata": {
    "id": "30fc6452"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f07670d9",
   "metadata": {
    "id": "f07670d9"
   },
   "outputs": [],
   "source": [
    "class CharDataset(Dataset):\n",
    "    def __init__(self, text, seq_length, char_to_idx):\n",
    "        self.text = text\n",
    "        self.seq_length = seq_length\n",
    "        self.char_to_idx = char_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text) - self.seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = [self.char_to_idx[ch] for ch in self.text[idx:idx+self.seq_length]]\n",
    "        y = [self.char_to_idx[ch] for ch in self.text[idx+1:idx+self.seq_length+1]]\n",
    "        return torch.tensor(x), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9172da13",
   "metadata": {
    "id": "9172da13"
   },
   "outputs": [],
   "source": [
    "def prepare_data(text, seq_length, batch_size, val_split):\n",
    "    chars, char_to_idx, idx_to_char = create_char_mappings(text)\n",
    "\n",
    "    # Split data into train and validation\n",
    "    val_size = int(len(text) * val_split)\n",
    "    train_text, val_text = text[:-val_size], text[-val_size:]\n",
    "\n",
    "    train_dataset = CharDataset(train_text, seq_length, char_to_idx)\n",
    "    val_dataset = CharDataset(val_text, seq_length, char_to_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=12, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=12, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader, chars, char_to_idx, idx_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "nEwKFB_8L6AG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3706,
     "status": "ok",
     "timestamp": 1732704246464,
     "user": {
      "displayName": "Hugman Sangkeun Jung",
      "userId": "08689291704194029524"
     },
     "user_tz": -540
    },
    "id": "nEwKFB_8L6AG",
    "outputId": "e75cdff9-3775-461e-d930-0ced534bf74d"
   },
   "outputs": [],
   "source": [
    "# !wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=19zosLuU0z4MxIMKbGVYEGlg52QyfbTIy' -O input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47d03398",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 668,
     "status": "ok",
     "timestamp": 1732704255324,
     "user": {
      "displayName": "Hugman Sangkeun Jung",
      "userId": "08689291704194029524"
     },
     "user_tz": -540
    },
    "id": "47d03398",
    "outputId": "f247f5b3-88ff-4ecb-e8a3-4b2e42a2820b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 1115394\n",
      "Vocabulary size: 65\n",
      "Train dataset size: 1003791\n",
      "Validation dataset size: 111475\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "text = load_data('./input.txt')\n",
    "train_loader, val_loader, chars, char_to_idx, idx_to_char = prepare_data(text, SEQUENCE_LENGTH, BATCH_SIZE, VALIDATION_SPLIT)\n",
    "vocab_size = len(chars)\n",
    "\n",
    "print(f\"Total characters: {len(text)}\")\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "print(f\"Train dataset size: {len(train_loader.dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9442b104",
   "metadata": {
    "id": "9442b104"
   },
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1f0a6a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 916,
     "status": "ok",
     "timestamp": 1732704257555,
     "user": {
      "displayName": "Hugman Sangkeun Jung",
      "userId": "08689291704194029524"
     },
     "user_tz": -540
    },
    "id": "f1f0a6a1",
    "outputId": "9ef6eb5a-0015-40ad-f143-236e3d38fb7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2048, 64])\n",
      "Target shape: torch.Size([2048, 64])\n",
      "Sample 1: ------------------------------\n",
      "Input sequence : erd:I would there were no age between sixteen andthree-and-twe\n",
      "Target sequence: rd:I would there were no age between sixteen andthree-and-twen\n",
      "\n",
      "Sample 2: ------------------------------\n",
      "Input sequence : smother'd.But, God be thank'd, there's no need of me,And much \n",
      "Target sequence: mother'd.But, God be thank'd, there's no need of me,And much I\n",
      "\n",
      "Sample 3: ------------------------------\n",
      "Input sequence : s hear your firm resolve.BONA:Your grant, or your denial, sha\n",
      "Target sequence:  hear your firm resolve.BONA:Your grant, or your denial, shal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to convert index sequence to character sequence\n",
    "def indices_to_text(indices, idx_to_char):\n",
    "    return ''.join([idx_to_char[idx.item()] for idx in indices])\n",
    "\n",
    "# Get a batch of data\n",
    "dataiter = iter(train_loader)\n",
    "batch_x, batch_y = next(dataiter)\n",
    "\n",
    "print(f\"Input shape: {batch_x.shape}\")\n",
    "print(f\"Target shape: {batch_y.shape}\")\n",
    "\n",
    "# Print a few samples from the batch\n",
    "num_samples = 3\n",
    "for i in range(num_samples):\n",
    "    print(f\"Sample {i+1}: ------------------------------\" )\n",
    "    print(\"Input sequence :\", indices_to_text(batch_x[i], idx_to_char).replace('\\n',''))\n",
    "    print(\"Target sequence:\", indices_to_text(batch_y[i], idx_to_char).replace('\\n',''))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5486f73f",
   "metadata": {
    "id": "5486f73f"
   },
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61a52f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_vram_usage(device=\"cuda\"):\n",
    "    allocated = torch.cuda.memory_allocated(device) / (1024**2)  # in MB\n",
    "    reserved = torch.cuda.memory_reserved(device) / (1024**2)    # in MB\n",
    "    max_allocated = torch.cuda.max_memory_allocated(device) / (1024**2)  # in MB\n",
    "    print(f\"Allocated: {allocated:.2f} MB, Reserved: {reserved:.2f} MB, Max Allocated: {max_allocated:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59178a11",
   "metadata": {
    "id": "59178a11"
   },
   "outputs": [],
   "source": [
    "def validate(model, dataloader, criterion, device, epoch, step):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output, _ = model(x)\n",
    "            loss = criterion(output.view(-1, output.size(-1)), y.view(-1))\n",
    "            losses.append((step, epoch, loss.item()))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea5e61f5",
   "metadata": {
    "id": "ea5e61f5"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, dataloader, criterion, optimizer, device, epoch, step):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    vram_usage = []\n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch}\", leave=False)\n",
    "    for batch, (x, y) in enumerate(pbar):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.amp.autocast('cuda'):\n",
    "            output, _ = model(x)\n",
    "            loss = criterion(output.view(-1, output.size(-1)), y.view(-1))\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        step += 1\n",
    "        losses.append((step, epoch, loss.item()))\n",
    "        \n",
    "        # VRAM 사용량을 progress bar의 postfix로 업데이트\n",
    "        allocated = torch.cuda.memory_allocated(device) / (1024**2)\n",
    "        vram_usage.append(allocated)\n",
    "        pbar.set_postfix(loss=f'{loss.item():.4f}', step=step, vram=f'{allocated:.2f} MB')\n",
    "    return losses, step, vram_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbedfd61",
   "metadata": {
    "id": "cbedfd61"
   },
   "source": [
    "## Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e91075e8",
   "metadata": {
    "id": "e91075e8"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs):\n",
    "    all_train_losses = []\n",
    "    all_val_losses = []\n",
    "    all_vram_usages = []\n",
    "    step = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        # Training phase with tqdm updates\n",
    "        epoch_train_losses, step, vram_usage = train(model, train_loader, criterion, optimizer, device, epoch, step)\n",
    "        all_train_losses.extend(epoch_train_losses)\n",
    "        all_vram_usages.append(vram_usage)\n",
    "        \n",
    "        # Validation phase\n",
    "        epoch_val_losses = validate(model, val_loader, criterion, device, epoch, step)\n",
    "        all_val_losses.extend(epoch_val_losses)\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        print(f'Epoch {epoch}/{epochs}, Train Loss: {epoch_train_losses[-1][2]:.4f}, '\n",
    "              f'Val Loss: {epoch_val_losses[-1][2]:.4f}, Epoch Time: {epoch_time:.2f}s',\n",
    "              f'Average Vram Usage: {np.mean(vram_usage):.2f}MB')\n",
    "\n",
    "    train_losses_df = pd.DataFrame(all_train_losses, columns=['step', 'epoch', 'loss_value'])\n",
    "    val_losses_df = pd.DataFrame(all_val_losses, columns=['step', 'epoch', 'loss_value'])\n",
    "    # average_vram_usage = np.mean(all_vram_usages)\n",
    "    return model, train_losses_df, val_losses_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4535c886",
   "metadata": {
    "id": "4535c886"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, char_to_idx, idx_to_char, start_text, device, max_length=500):\n",
    "    model.eval()\n",
    "    current_text = start_text\n",
    "    hidden = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            x = torch.tensor([[char_to_idx[ch] for ch in current_text[-SEQUENCE_LENGTH:]]]).to(device)\n",
    "            output, hidden = model(x, hidden)\n",
    "            probs = torch.softmax(output[0, -1], dim=0)\n",
    "            next_char_idx = torch.multinomial(probs, 1).item()\n",
    "            next_char = idx_to_char[next_char_idx]\n",
    "            current_text += next_char\n",
    "\n",
    "    return current_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aef1cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_comparison_dict = {}\n",
    "\n",
    "def add_loss_to_comparison(model_name, train_losses_df, val_losses_df):\n",
    "    \"\"\"\n",
    "    Adds training and validation losses from a model to the comparison dictionary.\n",
    "    \"\"\"\n",
    "    loss_comparison_dict[model_name] = {\n",
    "        'train': train_losses_df,\n",
    "        'val': val_losses_df\n",
    "    }\n",
    "\n",
    "def print_final_losses(loss_dict):\n",
    "    for model_name, losses in loss_dict.items():\n",
    "        train_df = losses['train']\n",
    "        val_df = losses['val']\n",
    "        final_train = train_df.groupby('epoch')['loss_value'].last().iloc[-1]\n",
    "        final_val = val_df.groupby('epoch')['loss_value'].last().iloc[-1]\n",
    "        print(f\"{model_name}: Final Train Loss: {final_train:.4f}, Final Val Loss: {final_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "973b4a80",
   "metadata": {
    "id": "973b4a80"
   },
   "outputs": [],
   "source": [
    "# Function to plot loss curves\n",
    "def plot_loss(train_losses_df, val_losses_df):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Plot training losses\n",
    "    for epoch in train_losses_df['epoch'].unique():\n",
    "        epoch_train_losses = train_losses_df[train_losses_df['epoch'] == epoch]\n",
    "        plt.plot(epoch_train_losses['step'], epoch_train_losses['loss_value'],\n",
    "                 color='blue', alpha=0.3)\n",
    "\n",
    "    # scatter training loss at the end of each epoch\n",
    "    last_train_losses = train_losses_df.groupby('epoch').last().reset_index()\n",
    "    plt.scatter(last_train_losses['step'], last_train_losses['loss_value'],\n",
    "                color='blue')\n",
    "\n",
    "    # Plot and scatter validation loss at the end of each epoch\n",
    "    last_val_losses = val_losses_df.groupby('epoch').last().reset_index()\n",
    "    plt.plot(last_val_losses['step'], last_val_losses['loss_value'],\n",
    "             color='orange', label='Validation Loss')\n",
    "    plt.scatter(last_val_losses['step'], last_val_losses['loss_value'],\n",
    "                color='orange')\n",
    "\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Function to print final loss values\n",
    "def print_final_losses(train_losses_df, val_losses_df):\n",
    "    print(\"Final Training Loss:\", train_losses_df.groupby('epoch')['loss_value'].last().iloc[-1])\n",
    "    print(\"Final Validation Loss:\", val_losses_df.groupby('epoch')['loss_value'].last().iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5001e203",
   "metadata": {
    "id": "5001e203"
   },
   "outputs": [],
   "source": [
    "# Function to plot loss curves for multiple models stored in loss_comparison_dict\n",
    "def plot_loss_comparisons():\n",
    "    \"\"\"\n",
    "    Plots the training loss curves and average validation loss per epoch for multiple models added to the loss comparison dictionary.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Get the last model in the dictionary (for special final-point highlighting)\n",
    "    last_model_name = list(loss_comparison_dict.keys())[-1]\n",
    "\n",
    "    # Loop through each model in the loss dictionary\n",
    "    for model_name, losses in loss_comparison_dict.items():\n",
    "        train_losses_df = losses['train']\n",
    "        val_losses_df = losses['val']\n",
    "\n",
    "        # Plot training losses for each model\n",
    "        plt.plot(train_losses_df['step'], train_losses_df['loss_value'],\n",
    "                 label=f'{model_name} train', linestyle='-', alpha=0.7)\n",
    "\n",
    "        # Scatter training loss at the end of each epoch\n",
    "        last_train_losses = train_losses_df.groupby('epoch').last().reset_index()\n",
    "        plt.scatter(last_train_losses['step'], last_train_losses['loss_value'], marker='o', s=50)\n",
    "\n",
    "        # Compute average validation loss per epoch (using the last step of each epoch for x-axis)\n",
    "        avg_val_losses = val_losses_df.groupby('epoch').agg({'loss_value': 'mean', 'step': 'last'}).reset_index()\n",
    "        # Scatter the average validation loss for each epoch\n",
    "        plt.scatter(avg_val_losses['step'], avg_val_losses['loss_value'], marker='s', s=50,\n",
    "                    label=f'{model_name} val avg')\n",
    "\n",
    "        # For the last model, highlight the final training loss with a star\n",
    "        if model_name == last_model_name:\n",
    "            final_step = train_losses_df['step'].iloc[-1]\n",
    "            final_loss = train_losses_df['loss_value'].iloc[-1]\n",
    "            plt.scatter(final_step, final_loss, marker='*', s=100, color='red', zorder=5)\n",
    "\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Comparison')\n",
    "    plt.legend()  # Legend shows both training and validation average labels\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16777ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_separate_train_val(loss_dict):\n",
    "    \"\"\"\n",
    "    모델별 Training Loss와 Validation Loss를 각각 별도의 그래프로 그립니다.\n",
    "    단, Validation Loss는 에포크별 평균으로 계산합니다.\n",
    "    \"\"\"\n",
    "    # 1. Training Loss Plot (원본 그대로)\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.subplot(1, 2, 1)  # 1행 2열 중 첫 번째\n",
    "    for model_name, losses in loss_dict.items():\n",
    "        train_df = losses['train']\n",
    "        steps_train = train_df['step'].values\n",
    "        loss_train = train_df['loss_value'].values\n",
    "        plt.plot(steps_train, loss_train, label=f'{model_name} Train')\n",
    "    plt.title('Training Loss Comparison')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # 2. Validation Loss Plot (에포크별 평균 처리)\n",
    "    plt.subplot(1, 2, 2)  # 1행 2열 중 두 번째\n",
    "    for model_name, losses in loss_dict.items():\n",
    "        val_df = losses['val']\n",
    "        # 에포크별 평균 loss와 마지막 step을 계산\n",
    "        val_avg = val_df.groupby('epoch').agg({'loss_value': 'mean', 'step': 'last'}).reset_index()\n",
    "        plt.plot(val_avg['step'], val_avg['loss_value'], label=f'{model_name} Val')\n",
    "    plt.title('Validation Loss (Epoch Avg) Comparison')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1eb8ad",
   "metadata": {
    "id": "aa1eb8ad"
   },
   "source": [
    "## Model 1: GRU Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e017e89b",
   "metadata": {
    "id": "e017e89b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GRUDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers=2, dropout=0.1):\n",
    "        super(GRUDecoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=num_layers,\n",
    "                          dropout=dropout if num_layers > 1 else 0.0, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        embed = self.embedding(x)\n",
    "        output, hidden = self.gru(embed, hidden)\n",
    "        output = self.dropout(output)\n",
    "        output = self.layer_norm(output)\n",
    "        output = F.gelu(self.fc1(output))\n",
    "        output = self.fc2(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a3581e4",
   "metadata": {
    "id": "9a3581e4"
   },
   "outputs": [],
   "source": [
    "### Model Initialization\n",
    "gru = GRUDecoder(vocab_size, EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(gru.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fe18507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "GRUDecoder                               [2048, 64, 65]            --\n",
       "├─Embedding: 1-1                         [2048, 64, 128]           8,320\n",
       "├─GRU: 1-2                               [2048, 64, 256]           691,200\n",
       "├─Dropout: 1-3                           [2048, 64, 256]           --\n",
       "├─LayerNorm: 1-4                         [2048, 64, 256]           512\n",
       "├─Linear: 1-5                            [2048, 64, 256]           65,792\n",
       "├─Linear: 1-6                            [2048, 64, 65]            16,705\n",
       "==========================================================================================\n",
       "Total params: 782,529\n",
       "Trainable params: 782,529\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 90.78\n",
       "==========================================================================================\n",
       "Input size (MB): 1.05\n",
       "Forward/backward pass size (MB): 1007.68\n",
       "Params size (MB): 3.13\n",
       "Estimated Total Size (MB): 1011.86\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(gru, input_size=(BATCH_SIZE, SEQUENCE_LENGTH), dtypes=[torch.long])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec86dc8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 121082,
     "status": "ok",
     "timestamp": 1732704395031,
     "user": {
      "displayName": "Hugman Sangkeun Jung",
      "userId": "08689291704194029524"
     },
     "user_tz": -540
    },
    "id": "ec86dc8e",
    "outputId": "d3a32ebf-e2ad-4e8b-fb04-f2651e0ac049"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Train Loss: 1.8876, Val Loss: 2.0073, Epoch Time: 13.77s Average Vram Usage: 53.47MB\n"
     ]
    }
   ],
   "source": [
    "## Training Loop\n",
    "trained_model, train_losses_df, val_losses_df = train_model(gru, train_loader, val_loader, criterion, optimizer, device, EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70664998",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1732704395512,
     "user": {
      "displayName": "Hugman Sangkeun Jung",
      "userId": "08689291704194029524"
     },
     "user_tz": -540
    },
    "id": "70664998",
    "outputId": "a970b003-a23c-47b7-900e-5ed705866838"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text (starting with validation data [\n",
      "\n",
      "GREMIO:\n",
      "Good morrow, neighbour Baptista.\n",
      "\n",
      "BAPTISTA:\n",
      "Good morro]):\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "GREMIO:\n",
      "Good morrow, neighbour Baptista.\n",
      "\n",
      "BAPTISTA:\n",
      "Good morrow, deel 'flient\n",
      "And on that\n",
      "My do fander of where greate,\n",
      "Muse in any pood thy in sof we is the hall farther a knuld garines:\n",
      "Thin wither leftles take say mother, what this voy ceard wit, but driou the mid you che,\n",
      "wo have you so though, he daptogh prever are not will the kind sice thee dair, sif, dithim'd yumar, fid Gities\n",
      "And dove furmsif, best sone for the setule matcher, that the couth wonder it your thou lroaths virtterus\n",
      "Cerot's your with a privey preevend of chem.\n",
      "To was beedF:\n",
      "We chercon\n",
      "\n",
      "\n",
      "GREMIO:\n",
      "Good morrow, neighbour Baptista.\n",
      "\n",
      "BAPTISTA:\n",
      "Good morro\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Text generation using validation data\n",
    "val_sample, _ = next(iter(val_loader))\n",
    "start_text = ''.join([idx_to_char[idx.item()] for idx in val_sample[0][:SEQUENCE_LENGTH]])\n",
    "generated_text = generate_text(trained_model, char_to_idx, idx_to_char, start_text, device)\n",
    "answer_text = ''.join([idx_to_char[idx.item()] for idx in val_sample[0]])\n",
    "num = 0\n",
    "while len(answer_text) == len(generated_text):\n",
    "    num += 1\n",
    "    answer_text += ''.join([idx_to_char[idx.item()] for idx in val_sample[num]])[-1]    \n",
    "                      \n",
    "print(f\"Generated text (starting with validation data [{start_text}]):\")\n",
    "print(\"-\"*50)\n",
    "print(generated_text)\n",
    "print(answer_text)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcca4e52",
   "metadata": {
    "id": "fcca4e52"
   },
   "outputs": [],
   "source": [
    "# After training a model (e.g., LSTM without RMSNorm), add its losses\n",
    "add_loss_to_comparison('GRU', train_losses_df, val_losses_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98b72703",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1732704396861,
     "user": {
      "displayName": "Hugman Sangkeun Jung",
      "userId": "08689291704194029524"
     },
     "user_tz": -540
    },
    "id": "98b72703",
    "outputId": "ece1620a-8690-4750-97c1-ada645d59a08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Input:\n",
      "\n",
      "\n",
      "GREMIO:\n",
      "Good morrow, neighbour Baptista.\n",
      "\n",
      "BAPTISTA:\n",
      "Good morro\n",
      "\n",
      "Model Output (logits for next character prediction):\n",
      "torch.Size([1, 64, 65])\n",
      "tensor([ 0.6636, -2.7419, -3.3868, -2.8372, -1.5797, -0.3829, -4.4019, -1.9397,\n",
      "        -3.9474, -1.0281], device='cuda:0')\n",
      "\n",
      "Predicted next character:\n",
      "w\n"
     ]
    }
   ],
   "source": [
    "# Decoder Input/Output Example\n",
    "sample_input, _ = next(iter(val_loader))\n",
    "sample_input = sample_input[0].unsqueeze(0).to(device)  # Add batch dimension\n",
    "\n",
    "trained_model.eval()\n",
    "with torch.no_grad():\n",
    "    output, _ = trained_model(sample_input)\n",
    "\n",
    "print(\"\\nSample Input:\")\n",
    "print(''.join([idx_to_char[idx.item()] for idx in sample_input[0]]))\n",
    "\n",
    "print(\"\\nModel Output (logits for next character prediction):\")\n",
    "print(output.shape)\n",
    "print(output[0, 0, :10])  # Print first 10 logits of the first timestep\n",
    "\n",
    "print(\"\\nPredicted next character:\")\n",
    "predicted_char_idx = torch.argmax(output[0, -1]).item()\n",
    "print(idx_to_char[predicted_char_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f23a4aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_comparisons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "868a5338",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 899,
     "status": "ok",
     "timestamp": 1732704397758,
     "user": {
      "displayName": "Hugman Sangkeun Jung",
      "userId": "08689291704194029524"
     },
     "user_tz": -540
    },
    "id": "868a5338",
    "outputId": "06397d97-49fb-4f85-b2b3-2b27ca481fe0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_separate_train_val(loss_comparison_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2d8a352",
   "metadata": {
    "id": "a2d8a352"
   },
   "outputs": [],
   "source": [
    "def generate_text_attention(model, char_to_idx, idx_to_char, start_text, device, max_length=500):\n",
    "    model.eval()\n",
    "    current_text = start_text\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            # Convert the last sequence of characters to indices and feed it to the model\n",
    "            x = torch.tensor([[char_to_idx[ch] for ch in current_text[-SEQUENCE_LENGTH:]]]).to(device)\n",
    "            output = model(x)[0]  # No hidden state needed for attention-based models\n",
    "            probs = torch.softmax(output[0, -1], dim=0)\n",
    "            next_char_idx = torch.multinomial(probs, 1).item()\n",
    "            next_char = idx_to_char[next_char_idx]\n",
    "            current_text += next_char\n",
    "\n",
    "    return current_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32c936b1",
   "metadata": {
    "id": "32c936b1"
   },
   "outputs": [],
   "source": [
    "def train_and_test(model_desc, model, start_text):\n",
    "    # Initialize the model\n",
    "    model = model.to(device)\n",
    "    # Use the same optimizer and criterion\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # Train the model\n",
    "    trained_model, train_losses_df, val_losses_df = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer, device, EPOCHS\n",
    "    )\n",
    "\n",
    "    # Generate text\n",
    "    generated_text = generate_text_attention(trained_model, char_to_idx, idx_to_char, start_text, device)\n",
    "    print(f\"Generated text [{start_text}]:\")\n",
    "    print(\"-\"*50)\n",
    "    print(generated_text)\n",
    "    print(\"-\"*50)\n",
    "    print(answer_text)\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    add_loss_to_comparison(model_desc, train_losses_df, val_losses_df)\n",
    "\n",
    "    # Plot loss comparisons including this model\n",
    "    plot_loss_comparisons()\n",
    "    \n",
    "    plot_separate_train_val(loss_comparison_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "645a951b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function gc.collect(generation=2)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del gru\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import gc\n",
    "gc.collect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39911f55",
   "metadata": {
    "id": "39911f55"
   },
   "source": [
    "## Model 2: Modern Transformer(LLaMA - 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9dc773d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for Transformer\n",
    "NUM_LAYERS = 4\n",
    "NUM_HEADS = 4\n",
    "FFN_DIM = 480\n",
    "DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc30f0f8",
   "metadata": {
    "id": "fc30f0f8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    DIM = EMBEDDING_DIM \n",
    "    # FFN_DIM = HIDDEN_DIM\n",
    "    FFN_DIM = 320\n",
    "    NUM_HEADS = NUM_HEADS \n",
    "    NUM_LAYERS = NUM_LAYERS\n",
    "\n",
    "    NUM_KV_HEADS = NUM_HEADS \n",
    "    VOCAB_SIZE = vocab_size\n",
    "    NORM_EPS = 1e-5 # LLaMA: 1e-5\n",
    "    ROPE_THETA = 10000 # LLaMA: 10000\n",
    "\n",
    "    MAX_BATCH_SIZE = BATCH_SIZE\n",
    "    MAX_SEQ_LEN = SEQUENCE_LENGTH # depending on the DATASET\n",
    "    NUM_KV_HEAD_REP = NUM_HEADS // NUM_KV_HEADS\n",
    "\n",
    "    HEAD_DIM = DIM // NUM_HEADS\n",
    "    DROPOUT = DROPOUT\n",
    "    DEVICE = device\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "    def _norm(self, x: torch.Tensor):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.weight.to(x.device) * self._norm(x.float()).type_as(x)\n",
    "    \n",
    "def precompute_freqs_cis(head_dim: int, seq_len: int, theta: float = 100.0, device: str = \"cuda\"):\n",
    "    if head_dim % 2 != 0:\n",
    "        raise ValueError(\"head_dim must be even for rotary embeddings.\")\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, head_dim, 2).float() / head_dim)).to(device)\n",
    "    t = torch.arange(seq_len, device=device, dtype=torch.float32)\n",
    "    freqs = torch.outer(t, freqs)  # [seq_len, head_dim//2]\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)\n",
    "    return freqs_cis  # [seq_len, head_dim // 2]\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    L = x.shape[1]\n",
    "    return freqs_cis.view(1, L, 1, x.shape[-1] // 2)  # [1, L, 1, head_dim]\n",
    "\n",
    "def apply_rotary_emb(x: torch.Tensor, device: str = \"cuda\"):\n",
    "    # x: [B, L, 2*heads, D] & D is even\n",
    "    _, L, _, D = x.shape\n",
    "    x_complex = torch.view_as_complex(x.float().reshape(*x.shape[:-1], -1, 2)) # [B, L, 2*heads, D//2, 2]\n",
    "    freqs_cis = precompute_freqs_cis(D, L)\n",
    "    freqs = reshape_for_broadcast(freqs_cis, x)\n",
    "    x_rotated = x_complex * freqs\n",
    "    x_out = torch.view_as_real(x_rotated).reshape(x.shape)\n",
    "    return x_out.type_as(x).to(device)\n",
    "\n",
    "def repeat_kv(x: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
    "    B, L, nk, d = x.shape\n",
    "    if n_rep == 1:\n",
    "        return x\n",
    "    return x[:, :, :, None, :].expand(B, L, nk, n_rep, d).reshape(B, L, nk * n_rep, d)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, ffn_dim, dropout):\n",
    "        super().__init__()\n",
    "        hidden_dim = ffn_dim\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x: [B, L, D]\n",
    "        return self.w2(F.silu(self.w1(x)) * self.dropout(self.w3(x)))\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, n_heads, n_kv_heads, n_rep, dim, dropout, batch, seq_len, device):\n",
    "        super().__init__()\n",
    "        self.n_heads_q = n_heads\n",
    "        self.n_kv_heads = n_kv_heads\n",
    "        self.n_rep = n_rep\n",
    "        self.head_dim = dim // n_heads\n",
    "\n",
    "        self.wq = nn.Linear(dim, n_heads * self.head_dim, bias=False)\n",
    "        self.wk = nn.Linear(dim, n_kv_heads * self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(dim, n_kv_heads * self.head_dim, bias=False)\n",
    "        self.wo = nn.Linear(n_heads * self.head_dim, dim, bias=False)\n",
    "        self.attn_dropout = dropout\n",
    "        \n",
    "        self.norm = RMSNorm(self.head_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos, mask, return_attn=False):\n",
    "        B, L, _ = x.shape\n",
    "        src_len = trg_len = L\n",
    "        offset = start_pos\n",
    "        \n",
    "        xq = self.wq(x).view(B, L, self.n_heads_q, self.head_dim)\n",
    "        xk = self.wk(x).view(B, L, self.n_kv_heads, self.head_dim)\n",
    "        xv = self.wv(x).view(B, L, self.n_kv_heads, self.head_dim)\n",
    "        \n",
    "        # Apply rotary embeddings\n",
    "        xq = apply_rotary_emb(xq)\n",
    "        xk = apply_rotary_emb(xk)\n",
    "        \n",
    "        # GQA: Adjust dimensions for attention computation\n",
    "        xq = xq.transpose(1, 2)   # [B, n_heads, L, head_dim]\n",
    "        xk = repeat_kv(xk, self.n_rep).transpose(1, 2) # [B, n_heads, L, head_dim]\n",
    "        xv = repeat_kv(xv, self.n_rep).transpose(1, 2) # [B, n_heads, L, head_dim]\n",
    "\n",
    "        # Compute scaled dot-product attention manually to capture attention weights\n",
    "        scores = torch.matmul(xq, xk.transpose(-2, -1)) / math.sqrt(self.head_dim)  # [B, n_heads, L, L]\n",
    "        scores = torch.nan_to_num(scores)\n",
    "        if mask is None:\n",
    "            mask = torch.triu(\n",
    "                torch.zeros([L, L])\n",
    "                .float()\n",
    "                .fill_(float(\"-inf\"))\n",
    "                .type_as(attn_weights),\n",
    "                1 + offset,\n",
    "            )\n",
    "            \n",
    "        scores += mask\n",
    "        attn_weights = torch.softmax(scores, dim=-1)\n",
    "        attn_weights = F.dropout(attn_weights, self.attn_dropout, training=self.training)\n",
    "        attn_output = torch.matmul(attn_weights, xv)  # [B, n_heads, L, head_dim]\n",
    "        attn_output = self.norm(attn_output)\n",
    "        \n",
    "        # Reshape attention output and project\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(B, L, -1)\n",
    "        output = self.wo(attn_output)  # [B, L, D]\n",
    "        if return_attn:\n",
    "            return output, attn_weights\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, args: 'ModelArgs'):\n",
    "        super().__init__()\n",
    "        self.attention = SelfAttention(\n",
    "            args.NUM_HEADS, \n",
    "            args.NUM_KV_HEADS, \n",
    "            args.NUM_KV_HEAD_REP, \n",
    "            args.DIM, \n",
    "            args.DROPOUT, \n",
    "            args.MAX_BATCH_SIZE, \n",
    "            args.MAX_SEQ_LEN, \n",
    "            args.DEVICE\n",
    "        )\n",
    "        self.ffn = FeedForward(args.DIM, args.FFN_DIM, args.DROPOUT)\n",
    "        self.attention_norm = RMSNorm(args.DIM, args.NORM_EPS)\n",
    "        self.ffn_norm = RMSNorm(args.DIM, args.NORM_EPS)\n",
    "        self.res_dropout = nn.Dropout(args.DROPOUT)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, start_pos, mask, return_attn=False):\n",
    "        if return_attn:\n",
    "            attn_out, attn_map = self.attention(self.attention_norm(x), start_pos, mask, return_attn=True)\n",
    "            h = x + self.res_dropout(attn_out)\n",
    "            h = h + self.res_dropout(self.ffn(self.ffn_norm(h)))\n",
    "            return h, attn_map\n",
    "        else:\n",
    "            h = x + self.res_dropout(self.attention(self.attention_norm(x), start_pos, mask))\n",
    "            h = h + self.res_dropout(self.ffn(self.ffn_norm(h)))\n",
    "            return h\n",
    "\n",
    "class LlamaTransformer(nn.Module):\n",
    "    def __init__(self, args: 'ModelArgs'):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.tok_embeddings = nn.Embedding(args.VOCAB_SIZE, args.DIM)\n",
    "        self.layers = nn.ModuleList([TransformerBlock(args) for _ in range(args.NUM_LAYERS)])\n",
    "        self.norm = RMSNorm(args.DIM, args.NORM_EPS)\n",
    "        self.output = nn.Linear(args.DIM, args.VOCAB_SIZE, bias=False)\n",
    "        self.device = args.DEVICE\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, start_pos=0, return_attn=False):\n",
    "        B, L = x.shape\n",
    "        h = self.tok_embeddings(x)  # [B, L, D]\n",
    "        \n",
    "        mask = None\n",
    "        if L > 1:\n",
    "            mask = torch.triu(\n",
    "                torch.zeros([L, L])\n",
    "                .float()\n",
    "                .fill_(float(\"-inf\"))\n",
    "                .type_as(x),\n",
    "                1 + start_pos,\n",
    "            )\n",
    "        attn_maps = []\n",
    "        for layer in self.layers:\n",
    "            if return_attn:\n",
    "                h, attn_map = layer(h, start_pos, mask, return_attn=True)\n",
    "                attn_maps.append(attn_map)\n",
    "            else:\n",
    "                h = layer(h, start_pos, mask)\n",
    "        logits = self.output(self.norm(h)).float()\n",
    "        if return_attn:\n",
    "            return logits, attn_maps\n",
    "        return logits, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66b4f114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTransformer(\n",
       "  (tok_embeddings): Embedding(65, 128)\n",
       "  (layers): ModuleList(\n",
       "    (0-3): 4 x TransformerBlock(\n",
       "      (attention): SelfAttention(\n",
       "        (wq): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (wk): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (wv): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (wo): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (w1): Linear(in_features=128, out_features=320, bias=False)\n",
       "        (w2): Linear(in_features=320, out_features=128, bias=False)\n",
       "        (w3): Linear(in_features=128, out_features=320, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (attention_norm): RMSNorm()\n",
       "      (ffn_norm): RMSNorm()\n",
       "      (res_dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       "  (output): Linear(in_features=128, out_features=65, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARAMS = ModelArgs()\n",
    "llama = LlamaTransformer(PARAMS).to(device)\n",
    "llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "087c3927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LlamaTransformer                         [2048, 64, 65]            --\n",
       "├─Embedding: 1-1                         [2048, 64, 128]           8,320\n",
       "├─ModuleList: 1-2                        --                        --\n",
       "│    └─TransformerBlock: 2-1             [2048, 64, 128]           --\n",
       "│    │    └─RMSNorm: 3-1                 [2048, 64, 128]           128\n",
       "│    │    └─SelfAttention: 3-2           [2048, 64, 128]           65,568\n",
       "│    │    └─Dropout: 3-3                 [2048, 64, 128]           --\n",
       "│    │    └─RMSNorm: 3-4                 [2048, 64, 128]           128\n",
       "│    │    └─FeedForward: 3-5             [2048, 64, 128]           122,880\n",
       "│    │    └─Dropout: 3-6                 [2048, 64, 128]           --\n",
       "│    └─TransformerBlock: 2-2             [2048, 64, 128]           --\n",
       "│    │    └─RMSNorm: 3-7                 [2048, 64, 128]           128\n",
       "│    │    └─SelfAttention: 3-8           [2048, 64, 128]           65,568\n",
       "│    │    └─Dropout: 3-9                 [2048, 64, 128]           --\n",
       "│    │    └─RMSNorm: 3-10                [2048, 64, 128]           128\n",
       "│    │    └─FeedForward: 3-11            [2048, 64, 128]           122,880\n",
       "│    │    └─Dropout: 3-12                [2048, 64, 128]           --\n",
       "│    └─TransformerBlock: 2-3             [2048, 64, 128]           --\n",
       "│    │    └─RMSNorm: 3-13                [2048, 64, 128]           128\n",
       "│    │    └─SelfAttention: 3-14          [2048, 64, 128]           65,568\n",
       "│    │    └─Dropout: 3-15                [2048, 64, 128]           --\n",
       "│    │    └─RMSNorm: 3-16                [2048, 64, 128]           128\n",
       "│    │    └─FeedForward: 3-17            [2048, 64, 128]           122,880\n",
       "│    │    └─Dropout: 3-18                [2048, 64, 128]           --\n",
       "│    └─TransformerBlock: 2-4             [2048, 64, 128]           --\n",
       "│    │    └─RMSNorm: 3-19                [2048, 64, 128]           128\n",
       "│    │    └─SelfAttention: 3-20          [2048, 64, 128]           65,568\n",
       "│    │    └─Dropout: 3-21                [2048, 64, 128]           --\n",
       "│    │    └─RMSNorm: 3-22                [2048, 64, 128]           128\n",
       "│    │    └─FeedForward: 3-23            [2048, 64, 128]           122,880\n",
       "│    │    └─Dropout: 3-24                [2048, 64, 128]           --\n",
       "├─RMSNorm: 1-3                           [2048, 64, 128]           128\n",
       "├─Linear: 1-4                            [2048, 64, 65]            8,320\n",
       "==========================================================================================\n",
       "Total params: 771,584\n",
       "Trainable params: 771,584\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.58\n",
       "==========================================================================================\n",
       "Input size (MB): 1.05\n",
       "Forward/backward pass size (MB): 7315.91\n",
       "Params size (MB): 3.09\n",
       "Estimated Total Size (MB): 7320.05\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(llama.to(device), input_size=(BATCH_SIZE, SEQUENCE_LENGTH), dtypes=[torch.long])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b361db8b",
   "metadata": {
    "id": "b361db8b",
    "outputId": "33c6269c-5979-4100-b6e7-a89b6b4ed962"
   },
   "outputs": [],
   "source": [
    "# train_and_test(\"LLaMA\", llama, start_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66d8c9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function gc.collect(generation=2)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del llama\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8775d573",
   "metadata": {},
   "source": [
    "## Model 3: Mamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd160c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aea173f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration flags and hyperparameters\n",
    "USE_MAMBA = 1\n",
    "DIFFERENT_H_STATES_RECURRENT_UPDATE_MECHANISM = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6946406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-defined hyperparameters\n",
    "d_model = 8\n",
    "n_layers = 6\n",
    "state_size = 128  # Example state size\n",
    "seq_len = SEQUENCE_LENGTH  # Example sequence length\n",
    "batch_size = BATCH_SIZE  # Example batch size\n",
    "current_batch_size = batch_size\n",
    "different_batch_size = False\n",
    "h_new = None\n",
    "temp_buffer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ead95121",
   "metadata": {},
   "outputs": [],
   "source": [
    "class S6(nn.Module):\n",
    "    def __init__(self, seq_len, d_model, state_size, device):\n",
    "        super(S6, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(d_model, d_model, device=device)\n",
    "        self.fc2 = nn.Linear(d_model, state_size, device=device)\n",
    "        self.fc3 = nn.Linear(d_model, state_size, device=device)\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "        self.d_model = d_model\n",
    "        self.state_size = state_size\n",
    "\n",
    "        #self.A = nn.Parameter(torch.ones(d_model, state_size, device=device))\n",
    "        self.A = nn.Parameter(F.normalize(torch.ones(d_model, state_size, device=device), p=2, dim=-1))\n",
    "        nn.init.xavier_uniform_(self.A)\n",
    "\n",
    "        self.B = torch.zeros(batch_size, self.seq_len, self.state_size, device=device)\n",
    "        self.C = torch.zeros(batch_size, self.seq_len, self.state_size, device=device)\n",
    "\n",
    "        self.delta = torch.zeros(batch_size, self.seq_len, self.d_model, device=device)\n",
    "        self.dA = torch.zeros(batch_size, self.seq_len, self.d_model, self.state_size, device=device)\n",
    "        self.dB = torch.zeros(batch_size, self.seq_len, self.d_model, self.state_size, device=device)\n",
    "\n",
    "        # h should have dimensions [batch_size, seq_len, d_model, state_size]\n",
    "        self.h = torch.zeros(batch_size, self.seq_len, self.d_model, self.state_size, device=device)\n",
    "        self.y = torch.zeros(batch_size, self.seq_len, self.d_model, device=device)\n",
    "\n",
    "\n",
    "    def discretization(self):\n",
    "        # discretization function is defined based on the MAMBA paper's description using ZOH on page 28\n",
    "        # in Section C : Mechanics on Selective SSMs\n",
    "        # See also \"Zero-order hold discretization\" maths proof inside https://studywolf.wordpress.com/tag/zero-order-hold/\n",
    "        \"\"\"\n",
    "        Here is an explanation of the mathematical rationale for the formulation of Δt used in Mamba:\n",
    "        The key idea is that Δt controls the discretization rate of the continuous SSM dynamics. By making Δt input-dependent, it introduces selectivity into the discrete transition matrices.\n",
    "        Specifically, in Mamba they parameterize Δt as:\n",
    "        Δt = τΔ(Parameter + sΔ(xt))\n",
    "        Where:\n",
    "        - Parameter is a learned scalar parameter that controls the baseline discretization rate\n",
    "        - sΔ(xt) is a projection that makes Δt input-dependent by computing a value based on xt\n",
    "        - τΔ(x) = softplus(x) transforms the result to be positive through the softplus nonlinearity\n",
    "        The rationale for this formulation is:\n",
    "        - Parameter provides a reasonable default discretization rate\n",
    "        - sΔ(xt) injects input-dependence through the projection\n",
    "        - softplus ensures Δt is positive as required to be a valid timestep\n",
    "        - The projection sΔ allows the model to learn to modulate Δt based on the input xt\n",
    "        - This modulation creates selectivity in how rapidly or slowly the states update\n",
    "        So in summary, the learned input-dependent projection allows Δt, and thus the discrete dynamics, to become selective. The softplus and scalar parameter provide useful inductive biases on top of this flexibility.\n",
    "        The end result is discrete transition matrices that are selective on the input, enabling powerful sequence modeling capabilities.\n",
    "        Credit: Claude2 AI chatbot\n",
    "        \"\"\"\n",
    "\n",
    "        # inverse() only supports square matrix\n",
    "        #dB = torch.matmul(torch.inverse(A * delta), torch.matmul(dA - torch.eye(A.shape[0]), B))\n",
    "        self.dB = torch.einsum(\"bld,bln->bldn\", self.delta, self.B)\n",
    "\n",
    "        # https://github.com/state-spaces/mamba/blob/0131c1e94a46fc9f70bcfc9d57962963bb2f0b9e/mamba_ssm/modules/mamba_simple.py#L240\n",
    "        #dA = torch.matrix_exp(A * delta)  # matrix_exp() only supports square matrix\n",
    "        self.dA = torch.exp(torch.einsum(\"bld,dn->bldn\", self.delta, self.A))\n",
    "        #print(f\"self.dA.shape = {self.dA.shape}\")\n",
    "        #print(f\"self.dA.requires_grad = {self.dA.requires_grad}\")\n",
    "\n",
    "        return self.dA, self.dB\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Refer to Algorithm 2 in the MAMBA paper\n",
    "        self.B = self.fc2(x)\n",
    "        self.C = self.fc3(x)\n",
    "        self.delta = F.softplus(self.fc1(x))\n",
    "\n",
    "        # Uses ZOH as in MAMBA, Hungry Hippo still uses bilinear transform for discretization\n",
    "        self.discretization()\n",
    "\n",
    "        if DIFFERENT_H_STATES_RECURRENT_UPDATE_MECHANISM:  # this will trigger in-place runtime error if without using `h_new`\n",
    "          \n",
    "            global current_batch_size\n",
    "            current_batch_size = x.shape[0]\n",
    "\n",
    "            if self.h.shape[0] != current_batch_size:\n",
    "                #print(\"Adjusting h_new for the different batch size of input data `x`\")\n",
    "                different_batch_size = True\n",
    "\n",
    "                # Resize self.h to match the current batch size\n",
    "                h_new =  torch.einsum('bldn,bldn->bldn', self.dA, self.h[:current_batch_size, ...]) + rearrange(x, \"b l d -> b l d 1\") * self.dB\n",
    "\n",
    "            else:\n",
    "                different_batch_size = False\n",
    "                h_new =  torch.einsum('bldn,bldn->bldn', self.dA, self.h) + rearrange(x, \"b l d -> b l d 1\") * self.dB\n",
    "\n",
    "            # y needs to have a shape of [batch_size, seq_len, d_model]\n",
    "            self.y = torch.einsum('bln,bldn->bld', self.C, h_new)\n",
    "\n",
    "            # Update self.h with the detached state of h_new\n",
    "            # Only do this if retaining gradients for self.h is not necessary for backprop\n",
    "            # Otherwise, store h_new in a temporary list and update self.h after the loop\n",
    "            global temp_buffer\n",
    "            temp_buffer = h_new.detach().clone() if not self.h.requires_grad else h_new.clone()\n",
    "  \n",
    "            return self.y\n",
    "\n",
    "        else:  # this will not trigger in-place runtime error\n",
    "            # h should have dimensions [batch_size, seq_len, d_model, state_size]\n",
    "            h = torch.zeros(x.size(0), self.seq_len, self.d_model, self.state_size, device=x.device)\n",
    "            y = torch.zeros_like(x)\n",
    "\n",
    "            h =  torch.einsum('bldn,bldn->bldn', self.dA, h) + rearrange(x, \"b l d -> b l d 1\") * self.dB\n",
    "\n",
    "            # y needs to have a shape of [batch_size, seq_len, d_model]\n",
    "            y = torch.einsum('bln,bldn->bld', self.C, h)\n",
    "\n",
    "            return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d7b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MambaBlock(nn.Module):\n",
    "    def __init__(self, seq_len, d_model, state_size, device):\n",
    "        super(MambaBlock, self).__init__()\n",
    "\n",
    "        self.inp_proj = nn.Linear(d_model, 2*d_model, device=device)\n",
    "        self.out_proj = nn.Linear(2*d_model, d_model, device=device)\n",
    "\n",
    "        # For residual skip connection\n",
    "        self.D = nn.Linear(d_model, 2*d_model, device=device)\n",
    "\n",
    "        # Set _no_weight_decay attribute on bias\n",
    "        self.out_proj.bias._no_weight_decay = True\n",
    "\n",
    "        # Initialize bias to a small constant value\n",
    "        nn.init.constant_(self.out_proj.bias, 1.0)\n",
    "\n",
    "        self.S6 = S6(seq_len, 2*d_model, state_size, device)\n",
    "\n",
    "        # Add 1D convolution with kernel size 3\n",
    "        self.conv = nn.Conv1d(seq_len, seq_len, kernel_size=3, padding=1, device=device)\n",
    "\n",
    "        # Add linear layer for conv output\n",
    "        self.conv_linear = nn.Linear(2*d_model, 2*d_model, device=device)\n",
    "\n",
    "        # rmsnorm\n",
    "        self.norm = RMSNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x_proj.shape = torch.Size([batch_size, seq_len, 2*d_model])\n",
    "        x_conv.shape = torch.Size([batch_size, seq_len, 2*d_model])\n",
    "        x_conv_act.shape = torch.Size([batch_size, seq_len, 2*d_model])\n",
    "        \"\"\"\n",
    "        # Refer to Figure 3 in the MAMBA paper\n",
    "        x = self.norm(x)\n",
    "\n",
    "        x_proj = self.inp_proj(x)\n",
    "        #print(f\"x_proj.shape = {x_proj.shape}\")\n",
    "\n",
    "        # Add 1D convolution with kernel size 3\n",
    "        x_conv = self.conv(x_proj)\n",
    "        #print(f\"x_conv.shape = {x_conv.shape}\")\n",
    "\n",
    "        x_conv_act = F.silu(x_conv)\n",
    "        #print(f\"x_conv_act.shape = {x_conv_act.shape}\")\n",
    "\n",
    "        # Add linear layer for conv output\n",
    "        x_conv_out = self.conv_linear(x_conv_act)\n",
    "        #print(f\"x_conv_out.shape = {x_conv_out.shape}\")\n",
    "\n",
    "        x_ssm = self.S6(x_conv_out)\n",
    "        x_act = F.silu(x_ssm)  # Swish activation can be implemented as x * sigmoid(x)\n",
    "        #print(f\"x_act.shape = {x_act.shape}\")\n",
    "\n",
    "        # residual skip connection with nonlinearity introduced by multiplication\n",
    "        x_residual = F.silu(self.D(x))\n",
    "        #print(f\"x_residual.shape = {x_residual.shape}\")\n",
    "        x_combined = x_act * x_residual\n",
    "        #print(f\"x_combined.shape = {x_combined.shape}\")\n",
    "\n",
    "        x_out = self.out_proj(x_combined)\n",
    "        #print(f\"x_out.shape = {x_out.shape}\")\n",
    "\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6be4f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mamba(nn.Module):\n",
    "    def __init__(self, seq_len, d_model, state_size, n_layers, device):\n",
    "        super(Mamba, self).__init__()\n",
    "        self.layers = nn.ModuleList([MambaBlock(seq_len, d_model, state_size, device) for _ in range(n_layers)])\n",
    "        # self.mamba_block1 = MambaBlock(seq_len, d_model, state_size, device)\n",
    "        # self.mamba_block2 = MambaBlock(seq_len, d_model, state_size, device)\n",
    "        # self.mamba_block3 = MambaBlock(seq_len, d_model, state_size, device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            print(x.shape)\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7cf6a7c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacity of 79.15 GiB of which 997.69 MiB is free. Process 3644092 has 78.17 GiB memory in use. Of the allocated memory 77.57 GiB is allocated by PyTorch, and 93.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(batch_size, seq_len, d_model, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Create the Mamba model\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m mamba \u001b[38;5;241m=\u001b[39m \u001b[43mMamba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m      5\u001b[0m test_output \u001b[38;5;241m=\u001b[39m mamba(x)\n",
      "Cell \u001b[0;32mIn[43], line 4\u001b[0m, in \u001b[0;36mMamba.__init__\u001b[0;34m(self, seq_len, d_model, state_size, n_layers, device)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, seq_len, d_model, state_size, n_layers, device):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28msuper\u001b[39m(Mamba, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([MambaBlock(seq_len, d_model, state_size, device) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_layers)])\n",
      "Cell \u001b[0;32mIn[43], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, seq_len, d_model, state_size, n_layers, device):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28msuper\u001b[39m(Mamba, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\u001b[43mMambaBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_layers)])\n",
      "Cell \u001b[0;32mIn[40], line 17\u001b[0m, in \u001b[0;36mMambaBlock.__init__\u001b[0;34m(self, seq_len, d_model, state_size, device)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Initialize bias to a small constant value\u001b[39;00m\n\u001b[1;32m     15\u001b[0m nn\u001b[38;5;241m.\u001b[39minit\u001b[38;5;241m.\u001b[39mconstant_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_proj\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mS6 \u001b[38;5;241m=\u001b[39m \u001b[43mS6\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Add 1D convolution with kernel size 3\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv1d(seq_len, seq_len, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "Cell \u001b[0;32mIn[39], line 25\u001b[0m, in \u001b[0;36mS6.__init__\u001b[0;34m(self, seq_len, d_model, state_size, device)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdB \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_size, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# h should have dimensions [batch_size, seq_len, d_model, state_size]\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacity of 79.15 GiB of which 997.69 MiB is free. Process 3644092 has 78.17 GiB memory in use. Of the allocated memory 77.57 GiB is allocated by PyTorch, and 93.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "x = torch.rand(batch_size, seq_len, d_model, device=device)\n",
    "# Create the Mamba model\n",
    "mamba = Mamba(seq_len, d_model, state_size, n_layers, device)\n",
    "# Forward pass\n",
    "test_output = mamba(x)\n",
    "print(f\"test_output.shape = {test_output.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e31528f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 64, 8])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchinfo/torchinfo.py:295\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 295\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1844\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1790\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1788\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1790\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "Cell \u001b[0;32mIn[43], line 12\u001b[0m, in \u001b[0;36mMamba.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1844\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1790\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1788\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1790\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "Cell \u001b[0;32mIn[40], line 35\u001b[0m, in \u001b[0;36mMambaBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Refer to Figure 3 in the MAMBA paper\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m x_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minp_proj(x)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1844\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1790\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1788\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1790\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "Cell \u001b[0;32mIn[31], line 36\u001b[0m, in \u001b[0;36mRMSNorm.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (8) at non-singleton dimension 2",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmamba\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchinfo/torchinfo.py:223\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m validate_user_params(\n\u001b[1;32m    217\u001b[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[1;32m    218\u001b[0m )\n\u001b[1;32m    220\u001b[0m x, correct_input_size \u001b[38;5;241m=\u001b[39m process_input(\n\u001b[1;32m    221\u001b[0m     input_data, input_size, batch_dim, device, dtypes\n\u001b[1;32m    222\u001b[0m )\n\u001b[0;32m--> 223\u001b[0m summary_list \u001b[38;5;241m=\u001b[39m \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_forward_pass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m formatting \u001b[38;5;241m=\u001b[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[1;32m    227\u001b[0m results \u001b[38;5;241m=\u001b[39m ModelStatistics(\n\u001b[1;32m    228\u001b[0m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[1;32m    229\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchinfo/torchinfo.py:304\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    303\u001b[0m     executed_layers \u001b[38;5;241m=\u001b[39m [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mexecuted]\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecuted_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []"
     ]
    }
   ],
   "source": [
    "summary(mamba.to(device), input_size=(batch_size, seq_len, d_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ce9296",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape=torch.Size([2048, 64]), self.norm=RMSNorm()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (8) must match the size of tensor b (64) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_and_test\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmamba\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmamba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[28], line 9\u001b[0m, in \u001b[0;36mtrain_and_test\u001b[0;34m(model_desc, model, start_text)\u001b[0m\n\u001b[1;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLEARNING_RATE)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m trained_model, train_losses_df, val_losses_df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Generate text\u001b[39;00m\n\u001b[1;32m     14\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m generate_text_attention(trained_model, char_to_idx, idx_to_char, start_text, device)\n",
      "Cell \u001b[0;32mIn[12], line 10\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, device, epochs)\u001b[0m\n\u001b[1;32m      8\u001b[0m epoch_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Training phase with tqdm updates\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m epoch_train_losses, step, vram_usage \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m all_train_losses\u001b[38;5;241m.\u001b[39mextend(epoch_train_losses)\n\u001b[1;32m     12\u001b[0m all_vram_usages\u001b[38;5;241m.\u001b[39mappend(vram_usage)\n",
      "Cell \u001b[0;32mIn[11], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, criterion, optimizer, device, epoch, step)\u001b[0m\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 14\u001b[0m     output, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), y\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     17\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[47], line 11\u001b[0m, in \u001b[0;36mMamba.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 11\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[46], line 36\u001b[0m, in \u001b[0;36mMambaBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Refer to Figure 3 in the MAMBA paper\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m x_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minp_proj(x)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#print(f\"x_proj.shape = {x_proj.shape}\")\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Add 1D convolution with kernel size 3\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[31], line 36\u001b[0m, in \u001b[0;36mRMSNorm.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (8) must match the size of tensor b (64) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "train_and_test(\"mamba\", mamba, start_text)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
