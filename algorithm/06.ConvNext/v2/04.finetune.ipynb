{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/lib/python3.10/site-packages/MinkowskiEngine-0.5.4-py3.10-linux-x86_64.egg/MinkowskiEngine/__init__.py:36: UserWarning: The environment variable `OMP_NUM_THREADS` not set. MinkowskiEngine will automatically set `OMP_NUM_THREADS=16`. If you want to set `OMP_NUM_THREADS` manually, please export it on the command line before running a python script. e.g. `export OMP_NUM_THREADS=12; python your_program.py`. It is recommended to set it below 24.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from timm.data import Mixup\n",
    "from timm.utils import ModelEmaV3\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "import transformers\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from collections import OrderedDict\n",
    "from model.convnextv2 import load_convNext\n",
    "import math\n",
    "import warnings\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "class CosineWarmupScheduler(_LRScheduler):\n",
    "    def __init__(self, optimizer, num_warmup_steps, num_training_steps, num_cycles=0.5, min_lr=1e-6, last_epoch=-1, verbose=False):\n",
    "        self.num_warmup_steps = num_warmup_steps\n",
    "        self.num_training_steps = num_training_steps\n",
    "        self.num_cycles = num_cycles\n",
    "        self.min_lr = min_lr\n",
    "        self.base_lrs = [group['lr'] for group in optimizer.param_groups]\n",
    "        super().__init__(optimizer, last_epoch, verbose)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if not self._get_lr_called_within_step:\n",
    "            warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
    "                          \"please use `get_last_lr()`.\", UserWarning)\n",
    "        \n",
    "        lrs = []\n",
    "        for base_lr in self.base_lrs:\n",
    "            if self.last_epoch < self.num_warmup_steps:\n",
    "                # Linear warmup\n",
    "                lr = (base_lr - self.min_lr) * self.last_epoch / max(1, self.num_warmup_steps) + self.min_lr\n",
    "            else:\n",
    "                # Cosine annealing\n",
    "                progress = (self.last_epoch - self.num_warmup_steps) / max(1, self.num_training_steps - self.num_warmup_steps)\n",
    "                lr = self.min_lr + (base_lr - self.min_lr) * 0.5 * (1 + math.cos(math.pi * self.num_cycles * 2.0 * progress))\n",
    "            lrs.append(lr)\n",
    "        return lrs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_model = convnextv2_fcmae_tiny()\n",
    "model = load_convNext()\n",
    "\n",
    "pretrain_path = '../../model/convnext/fcmae.pt'\n",
    "checkpoint_model = torch.load(pretrain_path, map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_checkpoint_keys(ckpt):\n",
    "    new_ckpt = OrderedDict()\n",
    "    for k, v in ckpt.items():\n",
    "        if k.startswith('encoder'):\n",
    "            k = '.'.join(k.split('.')[1:]) # remove encoder in the name\n",
    "        if k.endswith('kernel'):\n",
    "            k = '.'.join(k.split('.')[:-1]) # remove kernel in the name\n",
    "            new_k = k + '.weight'\n",
    "            if len(v.shape) == 3: # resahpe standard convolution\n",
    "                kv, in_dim, out_dim = v.shape\n",
    "                ks = int(math.sqrt(kv))\n",
    "                new_ckpt[new_k] = v.permute(2, 1, 0).\\\n",
    "                    reshape(out_dim, in_dim, ks, ks).transpose(3, 2)\n",
    "            elif len(v.shape) == 2: # reshape depthwise convolution\n",
    "                kv, dim = v.shape\n",
    "                ks = int(math.sqrt(kv))\n",
    "                new_ckpt[new_k] = v.permute(1, 0).\\\n",
    "                    reshape(dim, 1, ks, ks).transpose(3, 2)\n",
    "            continue\n",
    "        elif 'ln' in k or 'linear' in k:\n",
    "            k = k.split('.')\n",
    "            k.pop(-2) # remove ln and linear in the name\n",
    "            new_k = '.'.join(k)\n",
    "        else:\n",
    "            new_k = k\n",
    "        new_ckpt[new_k] = v\n",
    "\n",
    "    # reshape grn affine parameters and biases\n",
    "    for k, v in new_ckpt.items():\n",
    "        if k.endswith('bias') and len(v.shape) != 1:\n",
    "            new_ckpt[k] = v.reshape(-1)\n",
    "        elif 'grn' in k:\n",
    "            new_ckpt[k] = v.unsqueeze(0).unsqueeze(1)\n",
    "    return new_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_state_dict(model, state_dict, prefix='', ignore_missing=\"relative_position_index\"):\n",
    "    missing_keys = []\n",
    "    unexpected_keys = []\n",
    "    error_msgs = []\n",
    "    # copy state_dict so _load_from_state_dict can modify it\n",
    "    metadata = getattr(state_dict, '_metadata', None)\n",
    "    state_dict = state_dict.copy()\n",
    "    if metadata is not None:\n",
    "        state_dict._metadata = metadata\n",
    "\n",
    "    def load(module, prefix=''):\n",
    "        local_metadata = {} if metadata is None else metadata.get(\n",
    "            prefix[:-1], {})\n",
    "        module._load_from_state_dict(\n",
    "            state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)\n",
    "        for name, child in module._modules.items():\n",
    "            if child is not None:\n",
    "                load(child, prefix + name + '.')\n",
    "\n",
    "    load(model, prefix=prefix)\n",
    "\n",
    "    warn_missing_keys = []\n",
    "    ignore_missing_keys = []\n",
    "    for key in missing_keys:\n",
    "        keep_flag = True\n",
    "        for ignore_key in ignore_missing.split('|'):\n",
    "            if ignore_key in key:\n",
    "                keep_flag = False\n",
    "                break\n",
    "        if keep_flag:\n",
    "            warn_missing_keys.append(key)\n",
    "        else:\n",
    "            ignore_missing_keys.append(key)\n",
    "\n",
    "    missing_keys = warn_missing_keys\n",
    "\n",
    "    if len(missing_keys) > 0:\n",
    "        print(\"Weights of {} not initialized from pretrained model: {}\".format(\n",
    "            model.__class__.__name__, missing_keys))\n",
    "    if len(unexpected_keys) > 0:\n",
    "        print(\"Weights from pretrained model not used in {}: {}\".format(\n",
    "            model.__class__.__name__, unexpected_keys))\n",
    "    if len(ignore_missing_keys) > 0:\n",
    "        print(\"Ignored weights of {} not initialized from pretrained model: {}\".format(\n",
    "            model.__class__.__name__, ignore_missing_keys))\n",
    "    if len(error_msgs) > 0:\n",
    "        print('\\n'.join(error_msgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing key mask_token from pretrained checkpoint\n",
      "Removing key proj.weight from pretrained checkpoint\n",
      "Removing key proj.bias from pretrained checkpoint\n",
      "Removing key decoder.0.dwconv.weight from pretrained checkpoint\n",
      "Removing key decoder.0.dwconv.bias from pretrained checkpoint\n",
      "Removing key decoder.0.layernorm.weight from pretrained checkpoint\n",
      "Removing key decoder.0.layernorm.bias from pretrained checkpoint\n",
      "Removing key decoder.0.pwconv1.weight from pretrained checkpoint\n",
      "Removing key decoder.0.pwconv1.bias from pretrained checkpoint\n",
      "Removing key decoder.0.grn.gamma from pretrained checkpoint\n",
      "Removing key decoder.0.grn.beta from pretrained checkpoint\n",
      "Removing key decoder.0.pwconv2.weight from pretrained checkpoint\n",
      "Removing key decoder.0.pwconv2.bias from pretrained checkpoint\n",
      "Removing key pred.weight from pretrained checkpoint\n",
      "Removing key pred.bias from pretrained checkpoint\n",
      "Weights of ConvNeXtV2 not initialized from pretrained model: ['stem.stem_ln.weight', 'stem.stem_ln.bias', 'downsample_layers.0.stem_ln.weight', 'downsample_layers.0.stem_ln.bias', 'layernorm.weight', 'layernorm.bias', 'fc.weight', 'fc.bias']\n",
      "Weights from pretrained model not used in ConvNeXtV2: ['stem.weight', 'stem.bias', 'downsample_layers.0.weight', 'downsample_layers.0.bias']\n"
     ]
    }
   ],
   "source": [
    "state_dict = model.state_dict()\n",
    "for k in ['head.weight', 'head.bias']:\n",
    "    if k in checkpoint_model and checkpoint_model[k].shape != state_dict[k].shape:\n",
    "        print(f\"Removing key {k} from pretrained checkpoint\")\n",
    "        del checkpoint_model[k]\n",
    "\n",
    "\n",
    "# remove decoder weights\n",
    "checkpoint_model_keys = list(checkpoint_model.keys())\n",
    "for k in checkpoint_model_keys:\n",
    "    if 'decoder' in k or 'mask_token'in k or \\\n",
    "        'proj' in k or 'pred' in k:\n",
    "        print(f\"Removing key {k} from pretrained checkpoint\")\n",
    "        del checkpoint_model[k]\n",
    "\n",
    "checkpoint_model = remap_checkpoint_keys(checkpoint_model)\n",
    "load_state_dict(model, checkpoint_model, prefix='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "\n",
      "Total Parameters: 27,943,396\n",
      "Trainable Parameters: 27,943,396\n",
      "\n",
      "================================================================================\n",
      "Using EMA with decay = 0.9998\n"
     ]
    }
   ],
   "source": [
    "# 총 파라미터 수 계산\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "# 학습 가능한 파라미터 수 계산\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print('='*80)\n",
    "print(f\"\\nTotal Parameters: {total_params:,}\")\n",
    "print(f\"Trainable Parameters: {trainable_params:,}\\n\")\n",
    "print('='*80)\n",
    "\n",
    "# model_summary = summary(model.cuda(), (3, 224, 224))\n",
    "\n",
    "# Transforms 정의하기\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.TrivialAugmentWide(interpolation=F.InterpolationMode.BICUBIC),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.6,1), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "data_dir = '../../data/sports'\n",
    "batch_size = 256\n",
    "\n",
    "train_path = data_dir+'/train'\n",
    "valid_path = data_dir+'/valid'\n",
    "test_path = data_dir+'/test'\n",
    "\n",
    "# dataset load\n",
    "train_data = ImageFolder(train_path, transform=train_transform)\n",
    "valid_data = ImageFolder(valid_path, transform=test_transform)\n",
    "test_data = ImageFolder(test_path, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = 'cuda:4'\n",
    "max_norm = 3.0 \n",
    "\n",
    "model.to(device)\n",
    "\n",
    "model_ema = None\n",
    "ema_active = True\n",
    "if ema_active:\n",
    "    ema_decay = 0.9998\n",
    "    model_ema = ModelEmaV3(\n",
    "        model,\n",
    "        decay=ema_decay,\n",
    "    )\n",
    "    print(f\"Using EMA with decay = {ema_decay}\")\n",
    "\n",
    "model_path = ''\n",
    "\n",
    "mixup = True\n",
    "if mixup :\n",
    "    mixup_fn = Mixup(mixup_alpha=.8, \n",
    "                    cutmix_alpha=1., \n",
    "                    prob=1., \n",
    "                    switch_prob=0.5, \n",
    "                    mode='batch',\n",
    "                    label_smoothing=.1,\n",
    "                    num_classes=100)\n",
    "    \n",
    "    criterion = SoftTargetCrossEntropy()\n",
    "else :\n",
    "    criterion = LabelSmoothingCrossEntropy(.1)\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: fc.bias's lr=0.0008\n",
      "1: fc.weight's lr=0.0008\n",
      "2: layernorm.bias's lr=0.00072\n",
      "3: layernorm.weight's lr=0.00072\n",
      "4: stages.3.2.pwconv2.bias's lr=0.000648\n",
      "5: stages.3.2.pwconv2.weight's lr=0.000648\n",
      "6: stages.3.2.grn.beta's lr=0.000648\n",
      "7: stages.3.2.grn.gamma's lr=0.000648\n",
      "8: stages.3.2.pwconv1.bias's lr=0.000648\n",
      "9: stages.3.2.pwconv1.weight's lr=0.000648\n",
      "10: stages.3.2.layernorm.bias's lr=0.000648\n",
      "11: stages.3.2.layernorm.weight's lr=0.000648\n",
      "12: stages.3.2.dwconv.bias's lr=0.000648\n",
      "13: stages.3.2.dwconv.weight's lr=0.000648\n",
      "14: stages.3.1.pwconv2.bias's lr=0.000648\n",
      "15: stages.3.1.pwconv2.weight's lr=0.000648\n",
      "16: stages.3.1.grn.beta's lr=0.000648\n",
      "17: stages.3.1.grn.gamma's lr=0.000648\n",
      "18: stages.3.1.pwconv1.bias's lr=0.000648\n",
      "19: stages.3.1.pwconv1.weight's lr=0.000648\n",
      "20: stages.3.1.layernorm.bias's lr=0.000648\n",
      "21: stages.3.1.layernorm.weight's lr=0.000648\n",
      "22: stages.3.1.dwconv.bias's lr=0.000648\n",
      "23: stages.3.1.dwconv.weight's lr=0.000648\n",
      "24: stages.3.0.pwconv2.bias's lr=0.000648\n",
      "25: stages.3.0.pwconv2.weight's lr=0.000648\n",
      "26: stages.3.0.grn.beta's lr=0.000648\n",
      "27: stages.3.0.grn.gamma's lr=0.000648\n",
      "28: stages.3.0.pwconv1.bias's lr=0.000648\n",
      "29: stages.3.0.pwconv1.weight's lr=0.000648\n",
      "30: stages.3.0.layernorm.bias's lr=0.000648\n",
      "31: stages.3.0.layernorm.weight's lr=0.000648\n",
      "32: stages.3.0.dwconv.bias's lr=0.000648\n",
      "33: stages.3.0.dwconv.weight's lr=0.000648\n",
      "34: stages.2.8.pwconv2.bias's lr=0.000648\n",
      "35: stages.2.8.pwconv2.weight's lr=0.000648\n",
      "36: stages.2.8.grn.beta's lr=0.000648\n",
      "37: stages.2.8.grn.gamma's lr=0.000648\n",
      "38: stages.2.8.pwconv1.bias's lr=0.000648\n",
      "39: stages.2.8.pwconv1.weight's lr=0.000648\n",
      "40: stages.2.8.layernorm.bias's lr=0.000648\n",
      "41: stages.2.8.layernorm.weight's lr=0.000648\n",
      "42: stages.2.8.dwconv.bias's lr=0.000648\n",
      "43: stages.2.8.dwconv.weight's lr=0.000648\n",
      "44: stages.2.7.pwconv2.bias's lr=0.000648\n",
      "45: stages.2.7.pwconv2.weight's lr=0.000648\n",
      "46: stages.2.7.grn.beta's lr=0.000648\n",
      "47: stages.2.7.grn.gamma's lr=0.000648\n",
      "48: stages.2.7.pwconv1.bias's lr=0.000648\n",
      "49: stages.2.7.pwconv1.weight's lr=0.000648\n",
      "50: stages.2.7.layernorm.bias's lr=0.000648\n",
      "51: stages.2.7.layernorm.weight's lr=0.000648\n",
      "52: stages.2.7.dwconv.bias's lr=0.000648\n",
      "53: stages.2.7.dwconv.weight's lr=0.000648\n",
      "54: stages.2.6.pwconv2.bias's lr=0.000648\n",
      "55: stages.2.6.pwconv2.weight's lr=0.000648\n",
      "56: stages.2.6.grn.beta's lr=0.000648\n",
      "57: stages.2.6.grn.gamma's lr=0.000648\n",
      "58: stages.2.6.pwconv1.bias's lr=0.000648\n",
      "59: stages.2.6.pwconv1.weight's lr=0.000648\n",
      "60: stages.2.6.layernorm.bias's lr=0.000648\n",
      "61: stages.2.6.layernorm.weight's lr=0.000648\n",
      "62: stages.2.6.dwconv.bias's lr=0.000648\n",
      "63: stages.2.6.dwconv.weight's lr=0.000648\n",
      "64: stages.2.5.pwconv2.bias's lr=0.000648\n",
      "65: stages.2.5.pwconv2.weight's lr=0.000648\n",
      "66: stages.2.5.grn.beta's lr=0.000648\n",
      "67: stages.2.5.grn.gamma's lr=0.000648\n",
      "68: stages.2.5.pwconv1.bias's lr=0.000648\n",
      "69: stages.2.5.pwconv1.weight's lr=0.000648\n",
      "70: stages.2.5.layernorm.bias's lr=0.000648\n",
      "71: stages.2.5.layernorm.weight's lr=0.000648\n",
      "72: stages.2.5.dwconv.bias's lr=0.000648\n",
      "73: stages.2.5.dwconv.weight's lr=0.000648\n",
      "74: stages.2.4.pwconv2.bias's lr=0.000648\n",
      "75: stages.2.4.pwconv2.weight's lr=0.000648\n",
      "76: stages.2.4.grn.beta's lr=0.000648\n",
      "77: stages.2.4.grn.gamma's lr=0.000648\n",
      "78: stages.2.4.pwconv1.bias's lr=0.000648\n",
      "79: stages.2.4.pwconv1.weight's lr=0.000648\n",
      "80: stages.2.4.layernorm.bias's lr=0.000648\n",
      "81: stages.2.4.layernorm.weight's lr=0.000648\n",
      "82: stages.2.4.dwconv.bias's lr=0.000648\n",
      "83: stages.2.4.dwconv.weight's lr=0.000648\n",
      "84: stages.2.3.pwconv2.bias's lr=0.000648\n",
      "85: stages.2.3.pwconv2.weight's lr=0.000648\n",
      "86: stages.2.3.grn.beta's lr=0.000648\n",
      "87: stages.2.3.grn.gamma's lr=0.000648\n",
      "88: stages.2.3.pwconv1.bias's lr=0.000648\n",
      "89: stages.2.3.pwconv1.weight's lr=0.000648\n",
      "90: stages.2.3.layernorm.bias's lr=0.000648\n",
      "91: stages.2.3.layernorm.weight's lr=0.000648\n",
      "92: stages.2.3.dwconv.bias's lr=0.000648\n",
      "93: stages.2.3.dwconv.weight's lr=0.000648\n",
      "94: stages.2.2.pwconv2.bias's lr=0.000648\n",
      "95: stages.2.2.pwconv2.weight's lr=0.000648\n",
      "96: stages.2.2.grn.beta's lr=0.000648\n",
      "97: stages.2.2.grn.gamma's lr=0.000648\n",
      "98: stages.2.2.pwconv1.bias's lr=0.000648\n",
      "99: stages.2.2.pwconv1.weight's lr=0.000648\n",
      "100: stages.2.2.layernorm.bias's lr=0.000648\n",
      "101: stages.2.2.layernorm.weight's lr=0.000648\n",
      "102: stages.2.2.dwconv.bias's lr=0.000648\n",
      "103: stages.2.2.dwconv.weight's lr=0.000648\n",
      "104: stages.2.1.pwconv2.bias's lr=0.000648\n",
      "105: stages.2.1.pwconv2.weight's lr=0.000648\n",
      "106: stages.2.1.grn.beta's lr=0.000648\n",
      "107: stages.2.1.grn.gamma's lr=0.000648\n",
      "108: stages.2.1.pwconv1.bias's lr=0.000648\n",
      "109: stages.2.1.pwconv1.weight's lr=0.000648\n",
      "110: stages.2.1.layernorm.bias's lr=0.000648\n",
      "111: stages.2.1.layernorm.weight's lr=0.000648\n",
      "112: stages.2.1.dwconv.bias's lr=0.000648\n",
      "113: stages.2.1.dwconv.weight's lr=0.000648\n",
      "114: stages.2.0.pwconv2.bias's lr=0.000648\n",
      "115: stages.2.0.pwconv2.weight's lr=0.000648\n",
      "116: stages.2.0.grn.beta's lr=0.000648\n",
      "117: stages.2.0.grn.gamma's lr=0.000648\n",
      "118: stages.2.0.pwconv1.bias's lr=0.000648\n",
      "119: stages.2.0.pwconv1.weight's lr=0.000648\n",
      "120: stages.2.0.layernorm.bias's lr=0.000648\n",
      "121: stages.2.0.layernorm.weight's lr=0.000648\n",
      "122: stages.2.0.dwconv.bias's lr=0.000648\n",
      "123: stages.2.0.dwconv.weight's lr=0.000648\n",
      "124: stages.1.2.pwconv2.bias's lr=0.000648\n",
      "125: stages.1.2.pwconv2.weight's lr=0.000648\n",
      "126: stages.1.2.grn.beta's lr=0.000648\n",
      "127: stages.1.2.grn.gamma's lr=0.000648\n",
      "128: stages.1.2.pwconv1.bias's lr=0.000648\n",
      "129: stages.1.2.pwconv1.weight's lr=0.000648\n",
      "130: stages.1.2.layernorm.bias's lr=0.000648\n",
      "131: stages.1.2.layernorm.weight's lr=0.000648\n",
      "132: stages.1.2.dwconv.bias's lr=0.000648\n",
      "133: stages.1.2.dwconv.weight's lr=0.000648\n",
      "134: stages.1.1.pwconv2.bias's lr=0.000648\n",
      "135: stages.1.1.pwconv2.weight's lr=0.000648\n",
      "136: stages.1.1.grn.beta's lr=0.000648\n",
      "137: stages.1.1.grn.gamma's lr=0.000648\n",
      "138: stages.1.1.pwconv1.bias's lr=0.000648\n",
      "139: stages.1.1.pwconv1.weight's lr=0.000648\n",
      "140: stages.1.1.layernorm.bias's lr=0.000648\n",
      "141: stages.1.1.layernorm.weight's lr=0.000648\n",
      "142: stages.1.1.dwconv.bias's lr=0.000648\n",
      "143: stages.1.1.dwconv.weight's lr=0.000648\n",
      "144: stages.1.0.pwconv2.bias's lr=0.000648\n",
      "145: stages.1.0.pwconv2.weight's lr=0.000648\n",
      "146: stages.1.0.grn.beta's lr=0.000648\n",
      "147: stages.1.0.grn.gamma's lr=0.000648\n",
      "148: stages.1.0.pwconv1.bias's lr=0.000648\n",
      "149: stages.1.0.pwconv1.weight's lr=0.000648\n",
      "150: stages.1.0.layernorm.bias's lr=0.000648\n",
      "151: stages.1.0.layernorm.weight's lr=0.000648\n",
      "152: stages.1.0.dwconv.bias's lr=0.000648\n",
      "153: stages.1.0.dwconv.weight's lr=0.000648\n",
      "154: stages.0.2.pwconv2.bias's lr=0.000648\n",
      "155: stages.0.2.pwconv2.weight's lr=0.000648\n",
      "156: stages.0.2.grn.beta's lr=0.000648\n",
      "157: stages.0.2.grn.gamma's lr=0.000648\n",
      "158: stages.0.2.pwconv1.bias's lr=0.000648\n",
      "159: stages.0.2.pwconv1.weight's lr=0.000648\n",
      "160: stages.0.2.layernorm.bias's lr=0.000648\n",
      "161: stages.0.2.layernorm.weight's lr=0.000648\n",
      "162: stages.0.2.dwconv.bias's lr=0.000648\n",
      "163: stages.0.2.dwconv.weight's lr=0.000648\n",
      "164: stages.0.1.pwconv2.bias's lr=0.000648\n",
      "165: stages.0.1.pwconv2.weight's lr=0.000648\n",
      "166: stages.0.1.grn.beta's lr=0.000648\n",
      "167: stages.0.1.grn.gamma's lr=0.000648\n",
      "168: stages.0.1.pwconv1.bias's lr=0.000648\n",
      "169: stages.0.1.pwconv1.weight's lr=0.000648\n",
      "170: stages.0.1.layernorm.bias's lr=0.000648\n",
      "171: stages.0.1.layernorm.weight's lr=0.000648\n",
      "172: stages.0.1.dwconv.bias's lr=0.000648\n",
      "173: stages.0.1.dwconv.weight's lr=0.000648\n",
      "174: stages.0.0.pwconv2.bias's lr=0.000648\n",
      "175: stages.0.0.pwconv2.weight's lr=0.000648\n",
      "176: stages.0.0.grn.beta's lr=0.000648\n",
      "177: stages.0.0.grn.gamma's lr=0.000648\n",
      "178: stages.0.0.pwconv1.bias's lr=0.000648\n",
      "179: stages.0.0.pwconv1.weight's lr=0.000648\n",
      "180: stages.0.0.layernorm.bias's lr=0.000648\n",
      "181: stages.0.0.layernorm.weight's lr=0.000648\n",
      "182: stages.0.0.dwconv.bias's lr=0.000648\n",
      "183: stages.0.0.dwconv.weight's lr=0.000648\n",
      "184: downsample_layers.3.ds_conv3.bias's lr=0.0005832000000000001\n",
      "185: downsample_layers.3.ds_conv3.weight's lr=0.0005832000000000001\n",
      "186: downsample_layers.3.ds_ln2.bias's lr=0.0005832000000000001\n",
      "187: downsample_layers.3.ds_ln2.weight's lr=0.0005832000000000001\n",
      "188: downsample_layers.2.ds_conv2.bias's lr=0.0005832000000000001\n",
      "189: downsample_layers.2.ds_conv2.weight's lr=0.0005832000000000001\n",
      "190: downsample_layers.2.ds_ln1.bias's lr=0.0005832000000000001\n",
      "191: downsample_layers.2.ds_ln1.weight's lr=0.0005832000000000001\n",
      "192: downsample_layers.1.ds_conv1.bias's lr=0.0005832000000000001\n",
      "193: downsample_layers.1.ds_conv1.weight's lr=0.0005832000000000001\n",
      "194: downsample_layers.1.ds_ln0.bias's lr=0.0005832000000000001\n",
      "195: downsample_layers.1.ds_ln0.weight's lr=0.0005832000000000001\n",
      "196: stem.stem_ln.bias's lr=0.0005248800000000001\n",
      "197: stem.stem_ln.weight's lr=0.0005248800000000001\n",
      "198: stem.stem_conv.bias's lr=0.0005248800000000001\n",
      "199: stem.stem_conv.weight's lr=0.0005248800000000001\n"
     ]
    }
   ],
   "source": [
    "layer_names = []\n",
    "for i, (name, params) in enumerate(model.named_parameters()):\n",
    "    layer_names.append(name)\n",
    "    \n",
    "layer_names.reverse()\n",
    "\n",
    "lr      = 8e-4  \n",
    "lr_mult = 0.9  \n",
    "weight_decay = 0.05 \n",
    "\n",
    "param_groups = []\n",
    "prev_group_name = layer_names[0].split('.')[0]\n",
    "\n",
    "for idx, name in enumerate(layer_names):\n",
    "    \n",
    "    cur_group_name = name.split('.')[0]\n",
    "    \n",
    "    if cur_group_name != prev_group_name:\n",
    "        lr *= lr_mult\n",
    "    prev_group_name = cur_group_name\n",
    "    \n",
    "    print(f\"{idx}: {name}'s lr={lr}\")\n",
    "    \n",
    "    param_groups += [{'params': [ p for n, p in model.named_parameters() if n == name and p.requires_grad],\n",
    "                      'lr' : lr,\n",
    "                      'weight_decay': weight_decay}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "Epoch 1: 100%|██████████| 53/53 [01:40<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.7468, Val_Loss: 4.6995, Total Mean Loss: 4.7232, LR: 1.6098e-05, Duration: 101.37 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 53/53 [01:38<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.6487, Val_Loss: 4.6234, Total Mean Loss: 4.6360, LR: 3.2096000000000006e-05, Duration: 99.94 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.6034, Val_Loss: 4.6151, Total Mean Loss: 4.6093, LR: 4.809400000000001e-05, Duration: 100.48 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.6015, Val_Loss: 4.6175, Total Mean Loss: 4.6095, LR: 6.409200000000001e-05, Duration: 100.47 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.6035, Val_Loss: 4.6189, Total Mean Loss: 4.6112, LR: 8.009000000000001e-05, Duration: 100.31 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 53/53 [01:38<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.6051, Val_Loss: 4.6212, Total Mean Loss: 4.6132, LR: 9.608800000000002e-05, Duration: 100.13 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.6051, Val_Loss: 4.6230, Total Mean Loss: 4.6141, LR: 0.00011208600000000002, Duration: 100.38 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8:  11%|█▏        | 6/53 [00:11<01:28,  1.89s/it]"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "\n",
    "optimizer = optim.AdamW(param_groups)\n",
    "warmup_steps = int(len(train_loader)*(epochs)*0.1)\n",
    "train_steps = len(train_loader)*(epochs)\n",
    "scheduler = CosineWarmupScheduler(optimizer, \n",
    "                                num_warmup_steps=warmup_steps, \n",
    "                                num_training_steps=train_steps,\n",
    "                                num_cycles=0.5,\n",
    "                                min_lr=1e-7)\n",
    "# scheduler = transformers.get_cosine_schedule_with_warmup(optimizer, \n",
    "#                                                         num_warmup_steps=warmup_steps, \n",
    "#                                                         num_training_steps=train_steps,\n",
    "#                                                         num_cycles=0.5)\n",
    "\n",
    "training_time = 0\n",
    "losses = []\n",
    "val_losses = []\n",
    "lrs = []\n",
    "best_loss = float('inf')\n",
    "model_save = False\n",
    "\n",
    "for i in range(epochs // 100):\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1 + i*100}\")\n",
    "        \n",
    "        for _, data in pbar:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            inputs, labels = mixup_fn(inputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "                \n",
    "            loss.backward()\n",
    "            # 그라디언트 클리핑 적용\n",
    "            clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # EMA 모델 업데이트, 필요한 경우\n",
    "            if model_ema is not None:\n",
    "                model_ema.update(model)\n",
    "                \n",
    "            scheduler.step()\n",
    "                \n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "            lrs.append(lr)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        losses.append(epoch_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for data in valid_loader:\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "        val_loss /= len(valid_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # 모델 저장 조건 수정\n",
    "        total_loss = val_loss + epoch_loss\n",
    "        if total_loss < best_loss:\n",
    "            best_loss = total_loss\n",
    "            # torch.save(model.state_dict(), model_path)\n",
    "            model_save = True\n",
    "            save_text = ' - model saved!'\n",
    "        else:\n",
    "            save_text = ''\n",
    "\n",
    "        epoch_duration = time.time() - start_time\n",
    "        training_time += epoch_duration\n",
    "        \n",
    "        text = f'\\tLoss: {epoch_loss:.4f}, Val_Loss: {val_loss:.4f}, Total Mean Loss: {total_loss/2:.4f}, LR: {lr}, Duration: {epoch_duration:.2f} sec{save_text}'\n",
    "        print(text)\n",
    "\n",
    "    # 예측 수행 및 레이블 저장\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # 혼동 행렬 생성\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # 예측과 실제 레이블\n",
    "    y_true = all_labels  # 실제 레이블\n",
    "    y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "    # 전체 데이터셋에 대한 정확도\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "    # 판다스 데이터프레임으로 결과 정리\n",
    "    performance_metrics = pd.DataFrame({\n",
    "        'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "        'Value': [accuracy, precision, recall, f1_score]\n",
    "    })\n",
    "\n",
    "    # 데이터프레임 출력\n",
    "    print(f\"\\n[{i*100+100} epoch result]\\n\", performance_metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
