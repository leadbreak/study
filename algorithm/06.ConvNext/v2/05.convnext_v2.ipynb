{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 00 - Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from timm.data import Mixup\n",
    "from timm.utils import ModelEmaV3\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "import transformers\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from torchsummary import summary\n",
    "\n",
    "from convnext_v1 import load_convNext_v1\n",
    "from convnext_v2 import load_convNext\n",
    "import math\n",
    "import warnings\n",
    "from torch.optim.lr_scheduler import _LRScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineWarmupScheduler(_LRScheduler):\n",
    "    def __init__(self, optimizer, num_warmup_steps, num_training_steps, num_cycles=0.5, min_lr=1e-6, last_epoch=-1, verbose=False):\n",
    "        self.num_warmup_steps = num_warmup_steps\n",
    "        self.num_training_steps = num_training_steps\n",
    "        self.num_cycles = num_cycles\n",
    "        self.min_lr = min_lr\n",
    "        self.base_lrs = [group['lr'] for group in optimizer.param_groups]\n",
    "        super().__init__(optimizer, last_epoch, verbose)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if not self._get_lr_called_within_step:\n",
    "            warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
    "                          \"please use `get_last_lr()`.\", UserWarning)\n",
    "        \n",
    "        lrs = []\n",
    "        for base_lr in self.base_lrs:\n",
    "            if self.last_epoch < self.num_warmup_steps:\n",
    "                # Linear warmup\n",
    "                lr = (base_lr - self.min_lr) * self.last_epoch / max(1, self.num_warmup_steps) + self.min_lr\n",
    "            else:\n",
    "                # Cosine annealing\n",
    "                progress = (self.last_epoch - self.num_warmup_steps) / max(1, self.num_training_steps - self.num_warmup_steps)\n",
    "                lr = self.min_lr + (base_lr - self.min_lr) * 0.5 * (1 + math.cos(math.pi * self.num_cycles * 2.0 * progress))\n",
    "            lrs.append(lr)\n",
    "        return lrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 01 - Test ConvNeXt V1(sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v1 = load_convNext_v1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "\n",
      "Total Parameters: 27,897,028\n",
      "Trainable Parameters: 27,897,028\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 총 파라미터 수 계산\n",
    "total_params = sum(p.numel() for p in model_v1.parameters())\n",
    "\n",
    "# 학습 가능한 파라미터 수 계산\n",
    "trainable_params = sum(p.numel() for p in model_v1.parameters() if p.requires_grad)\n",
    "\n",
    "print('='*80)\n",
    "print(f\"\\nTotal Parameters: {total_params:,}\")\n",
    "print(f\"Trainable Parameters: {trainable_params:,}\\n\")\n",
    "print('='*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using EMA with decay = 0.9998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "# Transforms 정의하기\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.6,1), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=1., scale=(0.02, 0.33)),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "data_dir = '../../data/sports'\n",
    "batch_size = 512\n",
    "\n",
    "train_path = data_dir+'/train'\n",
    "valid_path = data_dir+'/valid'\n",
    "test_path = data_dir+'/test'\n",
    "\n",
    "# dataset load\n",
    "train_data = ImageFolder(train_path, transform=train_transform)\n",
    "valid_data = ImageFolder(valid_path, transform=test_transform)\n",
    "test_data = ImageFolder(test_path, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = 'cuda:3'\n",
    "max_norm = 3.0 \n",
    "\n",
    "model_v1.to(device)\n",
    "\n",
    "model_ema = None\n",
    "ema_active = True\n",
    "if ema_active:\n",
    "    ema_decay = 0.9998\n",
    "    model_ema = ModelEmaV3(\n",
    "        model_v1,\n",
    "        decay=ema_decay,\n",
    "    )\n",
    "    print(f\"Using EMA with decay = {ema_decay}\")\n",
    "\n",
    "model_path = ''\n",
    "\n",
    "mixup = True\n",
    "if mixup :\n",
    "    mixup_fn = Mixup(mixup_alpha=.8, \n",
    "                    cutmix_alpha=1., \n",
    "                    prob=1., \n",
    "                    switch_prob=0.5, \n",
    "                    mode='batch',\n",
    "                    label_smoothing=.1,\n",
    "                    num_classes=100)\n",
    "    \n",
    "    criterion = SoftTargetCrossEntropy()\n",
    "else :\n",
    "    criterion = LabelSmoothingCrossEntropy(.1)\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "optimizer = optim.AdamW(model_v1.parameters(), lr=4e-3, weight_decay=0.05)\n",
    "warmup_steps = int(len(train_loader)*(epochs)*0.1)\n",
    "train_steps = len(train_loader)*(epochs)\n",
    "scheduler = CosineWarmupScheduler(optimizer, \n",
    "                                num_warmup_steps=warmup_steps, \n",
    "                                num_training_steps=train_steps,\n",
    "                                num_cycles=0.5,\n",
    "                                min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 27/27 [00:56<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.4774, Val_Loss: 4.0328, Total Mean Loss: 4.2551, LR: 0.00040008999999999997, Duration: 57.10 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 27/27 [00:55<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.3636, Val_Loss: 3.9938, Total Mean Loss: 4.1787, LR: 0.0008000799999999999, Duration: 56.24 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 27/27 [00:55<00:00,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.3047, Val_Loss: 3.7656, Total Mean Loss: 4.0352, LR: 0.0012000700000000001, Duration: 56.54 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 27/27 [00:55<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.2676, Val_Loss: 3.7741, Total Mean Loss: 4.0209, LR: 0.00160006, Duration: 56.30 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.1701, Val_Loss: 3.5921, Total Mean Loss: 3.8811, LR: 0.0020000499999999997, Duration: 56.13 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.1979, Val_Loss: 3.5395, Total Mean Loss: 3.8687, LR: 0.00240004, Duration: 56.20 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.1892, Val_Loss: 3.5515, Total Mean Loss: 3.8703, LR: 0.00280003, Duration: 56.03 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.0846, Val_Loss: 3.3567, Total Mean Loss: 3.7207, LR: 0.0032000199999999996, Duration: 56.08 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 27/27 [00:55<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.0832, Val_Loss: 3.2658, Total Mean Loss: 3.6745, LR: 0.00360001, Duration: 56.34 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.9733, Val_Loss: 3.2181, Total Mean Loss: 3.5957, LR: 0.004, Duration: 56.18 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.9585, Val_Loss: 3.1206, Total Mean Loss: 3.5395, LR: 0.003998781684496841, Duration: 56.13 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.9332, Val_Loss: 2.9625, Total Mean Loss: 3.4478, LR: 0.003995128222317136, Duration: 56.06 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 27/27 [00:54<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.9000, Val_Loss: 2.9625, Total Mean Loss: 3.4313, LR: 0.003989044064641779, Duration: 55.92 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.8427, Val_Loss: 2.8141, Total Mean Loss: 3.3284, LR: 0.0039805366240797035, Duration: 56.11 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 27/27 [00:54<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7609, Val_Loss: 2.6553, Total Mean Loss: 3.2081, LR: 0.003969616265636766, Duration: 55.97 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 27/27 [00:54<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.8194, Val_Loss: 2.6457, Total Mean Loss: 3.2325, LR: 0.003956296294087574, Duration: 55.85 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 27/27 [00:54<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6426, Val_Loss: 2.5182, Total Mean Loss: 3.0804, LR: 0.003940592937765679, Duration: 55.96 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6091, Val_Loss: 2.3043, Total Mean Loss: 2.9567, LR: 0.003922525328791841, Duration: 56.04 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 27/27 [00:54<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7503, Val_Loss: 2.3364, Total Mean Loss: 3.0433, LR: 0.0039021154797644923, Duration: 55.73 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 27/27 [00:54<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5655, Val_Loss: 2.2997, Total Mean Loss: 2.9326, LR: 0.0038793882569407774, Duration: 55.96 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 27/27 [00:54<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5359, Val_Loss: 2.1852, Total Mean Loss: 2.8605, LR: 0.0038543713499408464, Duration: 55.90 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5495, Val_Loss: 2.2021, Total Mean Loss: 2.8758, LR: 0.003827095238012319, Duration: 56.02 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 27/27 [00:54<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4314, Val_Loss: 1.8701, Total Mean Loss: 2.6508, LR: 0.003797593152896019, Duration: 55.81 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 27/27 [00:54<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5395, Val_Loss: 2.0334, Total Mean Loss: 2.7864, LR: 0.0037659010383382105, Duration: 55.96 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 27/27 [00:54<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.3701, Val_Loss: 1.9876, Total Mean Loss: 2.6788, LR: 0.003732057506298688, Duration: 55.82 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 27/27 [00:54<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.3378, Val_Loss: 1.7445, Total Mean Loss: 2.5411, LR: 0.0036961037899080436, Duration: 55.90 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 27/27 [00:54<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2249, Val_Loss: 1.6983, Total Mean Loss: 2.4616, LR: 0.0036580836932314552, Duration: 55.84 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 27/27 [00:55<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.3712, Val_Loss: 1.7954, Total Mean Loss: 2.5833, LR: 0.003618043537900176, Duration: 56.32 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 27/27 [00:54<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2627, Val_Loss: 1.6444, Total Mean Loss: 2.4536, LR: 0.003576032106675763, Duration: 55.88 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 27/27 [00:54<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2453, Val_Loss: 1.6847, Total Mean Loss: 2.4650, LR: 0.0035321005840157995, Duration: 55.90 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 27/27 [00:54<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0739, Val_Loss: 1.4796, Total Mean Loss: 2.2767, LR: 0.0034863024937135142, Duration: 55.85 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2991, Val_Loss: 1.4953, Total Mean Loss: 2.3972, LR: 0.003438693633687285, Duration: 56.03 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 27/27 [00:54<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0333, Val_Loss: 1.4960, Total Mean Loss: 2.2647, LR: 0.0033893320079994714, Duration: 55.97 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1110, Val_Loss: 1.4444, Total Mean Loss: 2.2777, LR: 0.003338277756187398, Duration: 56.15 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1195, Val_Loss: 1.5030, Total Mean Loss: 2.3113, LR: 0.003285593079992594, Duration: 56.06 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1100, Val_Loss: 1.3832, Total Mean Loss: 2.2466, LR: 0.00323134216757755, Duration: 56.12 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0795, Val_Loss: 1.4472, Total Mean Loss: 2.2634, LR: 0.0031755911153223313, Duration: 56.11 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9890, Val_Loss: 1.2568, Total Mean Loss: 2.1229, LR: 0.0031184078472963196, Duration: 56.06 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 27/27 [00:54<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1263, Val_Loss: 1.3073, Total Mean Loss: 2.2168, LR: 0.003059862032503198, Duration: 55.97 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0529, Val_Loss: 1.2554, Total Mean Loss: 2.1542, LR: 0.0030000249999999995, Duration: 56.05 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7628, Val_Loss: 1.1780, Total Mean Loss: 1.9704, LR: 0.002938969651993642, Duration: 56.07 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 27/27 [00:54<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8932, Val_Loss: 1.1685, Total Mean Loss: 2.0308, LR: 0.002876770375020815, Duration: 55.86 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8992, Val_Loss: 1.2290, Total Mean Loss: 2.0641, LR: 0.0028135029493194467, Duration: 56.12 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 27/27 [00:55<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9412, Val_Loss: 1.2404, Total Mean Loss: 2.0908, LR: 0.0027492444565021534, Duration: 56.27 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 27/27 [00:54<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9296, Val_Loss: 1.1521, Total Mean Loss: 2.0409, LR: 0.0026840731856441714, Duration: 55.90 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6970, Val_Loss: 1.0895, Total Mean Loss: 1.8932, LR: 0.0026180685379001757, Duration: 56.01 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 27/27 [00:54<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5881, Val_Loss: 0.9863, Total Mean Loss: 1.7872, LR: 0.002551310929766207, Duration: 55.95 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 27/27 [00:54<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9589, Val_Loss: 1.0798, Total Mean Loss: 2.0193, LR: 0.002483881695104555, Duration: 55.89 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 27/27 [00:54<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7937, Val_Loss: 1.0734, Total Mean Loss: 1.9336, LR: 0.0024158629860509774, Duration: 55.96 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8662, Val_Loss: 1.0298, Total Mean Loss: 1.9480, LR: 0.0023473376729249776, Duration: 56.12 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 27/27 [00:54<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6298, Val_Loss: 1.0176, Total Mean Loss: 1.8237, LR: 0.0022783892432650826, Duration: 55.98 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2934, Val_Loss: 0.9682, Total Mean Loss: 1.6308, LR: 0.0022091017001121434, Duration: 56.07 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 27/27 [00:54<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7997, Val_Loss: 1.0152, Total Mean Loss: 1.9075, LR: 0.002139559459664563, Duration: 55.89 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5031, Val_Loss: 0.9415, Total Mean Loss: 1.7223, LR: 0.0020698472484301667, Duration: 56.06 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 27/27 [00:54<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3984, Val_Loss: 0.9141, Total Mean Loss: 1.6562, LR: 0.0020000499999999997, Duration: 55.90 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 27/27 [00:54<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5740, Val_Loss: 0.8883, Total Mean Loss: 1.7312, LR: 0.0019302527515698336, Duration: 55.99 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 27/27 [00:54<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6690, Val_Loss: 0.9551, Total Mean Loss: 1.8120, LR: 0.0018605405403354365, Duration: 55.98 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6134, Val_Loss: 0.9461, Total Mean Loss: 1.7797, LR: 0.0017909982998878568, Duration: 56.05 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5852, Val_Loss: 0.9271, Total Mean Loss: 1.7561, LR: 0.0017217107567349176, Duration: 56.02 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|██████████| 27/27 [00:55<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5558, Val_Loss: 0.8173, Total Mean Loss: 1.6865, LR: 0.0016527623270750228, Duration: 56.21 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|██████████| 27/27 [00:54<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5551, Val_Loss: 0.8222, Total Mean Loss: 1.6887, LR: 0.0015842370139490226, Duration: 55.97 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|██████████| 27/27 [00:54<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5135, Val_Loss: 0.8065, Total Mean Loss: 1.6600, LR: 0.0015162183048954448, Duration: 55.95 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4218, Val_Loss: 0.8387, Total Mean Loss: 1.6302, LR: 0.0014487890702337925, Duration: 56.10 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3691, Val_Loss: 0.8183, Total Mean Loss: 1.5937, LR: 0.001382031462099824, Duration: 56.03 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4415, Val_Loss: 0.8186, Total Mean Loss: 1.6301, LR: 0.001316026814355829, Duration: 56.01 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4425, Val_Loss: 0.8346, Total Mean Loss: 1.6386, LR: 0.0012508555434978467, Duration: 56.06 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3497, Val_Loss: 0.7826, Total Mean Loss: 1.5661, LR: 0.0011865970506805537, Duration: 56.03 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 100%|██████████| 27/27 [00:54<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3265, Val_Loss: 0.7799, Total Mean Loss: 1.5532, LR: 0.0011233296249791845, Duration: 55.93 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5047, Val_Loss: 0.8032, Total Mean Loss: 1.6540, LR: 0.0010611303480063583, Duration: 56.02 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70: 100%|██████████| 27/27 [00:55<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0608, Val_Loss: 0.7569, Total Mean Loss: 1.4088, LR: 0.0010000750000000004, Duration: 56.27 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2896, Val_Loss: 0.7690, Total Mean Loss: 1.5293, LR: 0.000940237967496802, Duration: 56.04 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72: 100%|██████████| 27/27 [00:54<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3211, Val_Loss: 0.7482, Total Mean Loss: 1.5347, LR: 0.0008816921527036801, Duration: 55.96 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73: 100%|██████████| 27/27 [00:54<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3094, Val_Loss: 0.7497, Total Mean Loss: 1.5295, LR: 0.0008245088846776685, Duration: 55.97 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74: 100%|██████████| 27/27 [00:54<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3828, Val_Loss: 0.7911, Total Mean Loss: 1.5869, LR: 0.0007687578324224496, Duration: 55.95 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3892, Val_Loss: 0.7802, Total Mean Loss: 1.5847, LR: 0.0007145069200074055, Duration: 56.00 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76: 100%|██████████| 27/27 [00:55<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3461, Val_Loss: 0.7231, Total Mean Loss: 1.5346, LR: 0.000661822243812602, Duration: 56.24 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1545, Val_Loss: 0.7566, Total Mean Loss: 1.4556, LR: 0.0006107679920005282, Duration: 56.03 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78: 100%|██████████| 27/27 [00:55<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2703, Val_Loss: 0.7705, Total Mean Loss: 1.5204, LR: 0.0005614063663127149, Duration: 56.34 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3561, Val_Loss: 0.7499, Total Mean Loss: 1.5530, LR: 0.000513797506286485, Duration: 56.12 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2656, Val_Loss: 0.7683, Total Mean Loss: 1.5169, LR: 0.00046799941598420013, Duration: 56.14 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2729, Val_Loss: 0.7432, Total Mean Loss: 1.5081, LR: 0.0004240678933242365, Duration: 56.04 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2517, Val_Loss: 0.7783, Total Mean Loss: 1.5150, LR: 0.00038205646209982404, Duration: 56.18 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2930, Val_Loss: 0.7482, Total Mean Loss: 1.5206, LR: 0.0003420163067685445, Duration: 56.11 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1917, Val_Loss: 0.7575, Total Mean Loss: 1.4746, LR: 0.0003039962100919559, Duration: 56.06 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2999, Val_Loss: 0.7637, Total Mean Loss: 1.5318, LR: 0.0002680424937013118, Duration: 56.07 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1889, Val_Loss: 0.7282, Total Mean Loss: 1.4586, LR: 0.00023419896166178896, Duration: 56.07 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1473, Val_Loss: 0.7745, Total Mean Loss: 1.4609, LR: 0.0002025068471039813, Duration: 56.04 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1531, Val_Loss: 0.8005, Total Mean Loss: 1.4768, LR: 0.00017300476198768016, Duration: 56.04 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2986, Val_Loss: 0.7652, Total Mean Loss: 1.5319, LR: 0.00014572865005915372, Duration: 56.19 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3740, Val_Loss: 0.7677, Total Mean Loss: 1.5708, LR: 0.00012071174305922266, Duration: 56.13 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2788, Val_Loss: 0.7759, Total Mean Loss: 1.5273, LR: 9.79845202355077e-05, Duration: 56.12 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92: 100%|██████████| 27/27 [00:55<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1289, Val_Loss: 0.7813, Total Mean Loss: 1.4551, LR: 7.757467120815912e-05, Duration: 56.22 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0349, Val_Loss: 0.7657, Total Mean Loss: 1.4003, LR: 5.950706223432085e-05, Duration: 56.15 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94: 100%|██████████| 27/27 [00:54<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0171, Val_Loss: 0.7645, Total Mean Loss: 1.3908, LR: 4.3803705912425316e-05, Duration: 55.99 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0323, Val_Loss: 0.7693, Total Mean Loss: 1.4008, LR: 3.0483734363234566e-05, Duration: 56.10 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96: 100%|██████████| 27/27 [00:54<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2488, Val_Loss: 0.7582, Total Mean Loss: 1.5035, LR: 1.9563375920296352e-05, Duration: 55.99 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.8898, Val_Loss: 0.7615, Total Mean Loss: 1.3256, LR: 1.1055935358221834e-05, Duration: 56.10 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1196, Val_Loss: 0.7607, Total Mean Loss: 1.4401, LR: 4.971777682864596e-06, Duration: 56.02 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0866, Val_Loss: 0.7598, Total Mean Loss: 1.4232, LR: 1.3183155031594304e-06, Duration: 56.12 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100: 100%|██████████| 27/27 [00:55<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1089, Val_Loss: 0.7597, Total Mean Loss: 1.4343, LR: 1e-07, Duration: 56.03 sec\n",
      "\n",
      "[100 epoch result]\n",
      "       Metric     Value\n",
      "0   Accuracy  0.876000\n",
      "1  Precision  0.896143\n",
      "2     Recall  0.876000\n",
      "3   F1 Score  0.872440\n"
     ]
    }
   ],
   "source": [
    "training_time = 0\n",
    "losses = []\n",
    "val_losses = []\n",
    "lrs = []\n",
    "best_loss = float('inf')\n",
    "\n",
    "# GradScaler 초기화\n",
    "scaler = GradScaler()\n",
    "\n",
    "for i in range(epochs // 100):\n",
    "    for epoch in range(100):\n",
    "        model_v1.train()\n",
    "        start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1 + i*100}\")\n",
    "        \n",
    "        for _, data in pbar:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            inputs, labels = mixup_fn(inputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # AutoCast 적용\n",
    "            with autocast():\n",
    "                outputs = model_v1(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "            # 스케일링된 그라디언트 계산\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # 그라디언트 클리핑 전에 스케일링 제거\n",
    "            scaler.unscale_(optimizer)\n",
    "            clip_grad_norm_(model_v1.parameters(), max_norm=max_norm)\n",
    "\n",
    "            # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            # EMA 모델 업데이트\n",
    "            if model_ema is not None:\n",
    "                model_ema.update(model_v1)\n",
    "                \n",
    "            scheduler.step()\n",
    "                \n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "            lrs.append(lr)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        losses.append(epoch_loss)        \n",
    "\n",
    "        model_v1.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for data in valid_loader:\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = model_v1(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "        val_loss /= len(valid_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # 모델 저장\n",
    "        total_loss = val_loss + epoch_loss\n",
    "        if total_loss < best_loss:\n",
    "            best_loss = total_loss\n",
    "            model_save = False\n",
    "            if model_save:\n",
    "                torch.save(model_v1.state_dict(), model_path)\n",
    "\n",
    "        epoch_duration = time.time() - start_time\n",
    "        training_time += epoch_duration\n",
    "        \n",
    "        text = f'\\tLoss: {epoch_loss:.4f}, Val_Loss: {val_loss:.4f}, Total Mean Loss: {total_loss/2:.4f}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "        \n",
    "        if model_save:\n",
    "            text += f' - model saved!'\n",
    "            model_save = False\n",
    "\n",
    "        print(text)\n",
    "\n",
    "    # 예측 수행 및 레이블 저장\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model_v1(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # 혼동 행렬 생성\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # 예측과 실제 레이블\n",
    "    y_true = all_labels  # 실제 레이블\n",
    "    y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "    # 전체 데이터셋에 대한 정확도\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "    # 판다스 데이터프레임으로 결과 정리\n",
    "    performance_metrics = pd.DataFrame({\n",
    "        'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "        'Value': [accuracy, precision, recall, f1_score]\n",
    "    })\n",
    "\n",
    "    # 데이터프레임 출력\n",
    "    print(f\"\\n[{i*100+100} epoch result]\\n\", performance_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v1.cpu()\n",
    "del model_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 02 - Test ConvNeXt V2(sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "\n",
      "Total Parameters: 27,943,396\n",
      "Trainable Parameters: 27,943,396\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "model_v2 = load_convNext()\n",
    "\n",
    "# 총 파라미터 수 계산\n",
    "total_params = sum(p.numel() for p in model_v2.parameters())\n",
    "\n",
    "# 학습 가능한 파라미터 수 계산\n",
    "trainable_params = sum(p.numel() for p in model_v2.parameters() if p.requires_grad)\n",
    "\n",
    "print('='*80)\n",
    "print(f\"\\nTotal Parameters: {total_params:,}\")\n",
    "print(f\"Trainable Parameters: {trainable_params:,}\\n\")\n",
    "print('='*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using EMA with decay = 0.9998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "model_v2.to(device)\n",
    "\n",
    "model_ema = None\n",
    "ema_active = True\n",
    "if ema_active:\n",
    "    ema_decay = 0.9998\n",
    "    model_ema = ModelEmaV3(\n",
    "        model_v2,\n",
    "        decay=ema_decay,\n",
    "    )\n",
    "    print(f\"Using EMA with decay = {ema_decay}\")\n",
    "\n",
    "model_path = ''\n",
    "\n",
    "mixup = True\n",
    "if mixup :\n",
    "    mixup_fn = Mixup(mixup_alpha=.8, \n",
    "                    cutmix_alpha=1., \n",
    "                    prob=1., \n",
    "                    switch_prob=0.5, \n",
    "                    mode='batch',\n",
    "                    label_smoothing=.1,\n",
    "                    num_classes=100)\n",
    "    \n",
    "    criterion = SoftTargetCrossEntropy()\n",
    "else :\n",
    "    criterion = LabelSmoothingCrossEntropy(.1)\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "optimizer = optim.AdamW(model_v2.parameters(), lr=4e-3, weight_decay=0.05)\n",
    "warmup_steps = int(len(train_loader)*(epochs)*0.1)\n",
    "train_steps = len(train_loader)*(epochs)\n",
    "scheduler = CosineWarmupScheduler(optimizer, \n",
    "                                num_warmup_steps=warmup_steps, \n",
    "                                num_training_steps=train_steps,\n",
    "                                num_cycles=0.5,\n",
    "                                min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.4953, Val_Loss: 3.9957, Total Mean Loss: 4.2455, LR: 0.00040008999999999997, Duration: 67.57 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.3383, Val_Loss: 3.8066, Total Mean Loss: 4.0724, LR: 0.0008000799999999999, Duration: 67.57 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 27/27 [01:06<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.2863, Val_Loss: 3.7261, Total Mean Loss: 4.0062, LR: 0.0012000700000000001, Duration: 67.70 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 27/27 [01:06<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.2008, Val_Loss: 3.6685, Total Mean Loss: 3.9346, LR: 0.00160006, Duration: 67.98 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 27/27 [01:06<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.2399, Val_Loss: 3.5638, Total Mean Loss: 3.9018, LR: 0.0020000499999999997, Duration: 67.65 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 27/27 [01:06<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.1107, Val_Loss: 3.3985, Total Mean Loss: 3.7546, LR: 0.00240004, Duration: 67.89 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 27/27 [01:06<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.0405, Val_Loss: 3.2016, Total Mean Loss: 3.6211, LR: 0.00280003, Duration: 67.75 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 27/27 [01:06<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.0470, Val_Loss: 3.0241, Total Mean Loss: 3.5355, LR: 0.0032000199999999996, Duration: 67.74 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 27/27 [01:07<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.0337, Val_Loss: 3.0783, Total Mean Loss: 3.5560, LR: 0.00360001, Duration: 68.12 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 27/27 [01:06<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.9008, Val_Loss: 2.8049, Total Mean Loss: 3.3528, LR: 0.004, Duration: 67.85 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 27/27 [01:06<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7319, Val_Loss: 2.6172, Total Mean Loss: 3.1745, LR: 0.003998781684496841, Duration: 67.93 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7359, Val_Loss: 2.5972, Total Mean Loss: 3.1665, LR: 0.003995128222317136, Duration: 67.60 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7365, Val_Loss: 2.3938, Total Mean Loss: 3.0652, LR: 0.003989044064641779, Duration: 67.60 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5635, Val_Loss: 2.3816, Total Mean Loss: 2.9726, LR: 0.0039805366240797035, Duration: 67.60 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7393, Val_Loss: 2.2984, Total Mean Loss: 3.0189, LR: 0.003969616265636766, Duration: 67.59 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5639, Val_Loss: 2.1167, Total Mean Loss: 2.8403, LR: 0.003956296294087574, Duration: 67.48 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6771, Val_Loss: 2.0762, Total Mean Loss: 2.8767, LR: 0.003940592937765679, Duration: 67.58 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4355, Val_Loss: 2.0092, Total Mean Loss: 2.7224, LR: 0.003922525328791841, Duration: 67.61 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4700, Val_Loss: 2.1298, Total Mean Loss: 2.7999, LR: 0.0039021154797644923, Duration: 67.51 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5844, Val_Loss: 2.1278, Total Mean Loss: 2.8561, LR: 0.0038793882569407774, Duration: 67.55 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4391, Val_Loss: 1.9167, Total Mean Loss: 2.6779, LR: 0.0038543713499408464, Duration: 67.53 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.3674, Val_Loss: 1.7117, Total Mean Loss: 2.5396, LR: 0.003827095238012319, Duration: 67.48 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1984, Val_Loss: 1.6721, Total Mean Loss: 2.4352, LR: 0.003797593152896019, Duration: 67.56 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.3351, Val_Loss: 1.7236, Total Mean Loss: 2.5294, LR: 0.0037659010383382105, Duration: 67.45 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 27/27 [01:06<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2980, Val_Loss: 1.5397, Total Mean Loss: 2.4188, LR: 0.003732057506298688, Duration: 67.72 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 27/27 [01:06<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2775, Val_Loss: 1.6634, Total Mean Loss: 2.4704, LR: 0.0036961037899080436, Duration: 67.67 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1404, Val_Loss: 1.6914, Total Mean Loss: 2.4159, LR: 0.0036580836932314552, Duration: 67.52 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2671, Val_Loss: 1.5354, Total Mean Loss: 2.4012, LR: 0.003618043537900176, Duration: 67.54 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9860, Val_Loss: 1.4390, Total Mean Loss: 2.2125, LR: 0.003576032106675763, Duration: 67.41 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1470, Val_Loss: 1.3110, Total Mean Loss: 2.2290, LR: 0.0035321005840157995, Duration: 67.41 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8700, Val_Loss: 1.2069, Total Mean Loss: 2.0385, LR: 0.0034863024937135142, Duration: 67.52 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0219, Val_Loss: 1.3896, Total Mean Loss: 2.2057, LR: 0.003438693633687285, Duration: 67.56 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0175, Val_Loss: 1.3374, Total Mean Loss: 2.1774, LR: 0.0033893320079994714, Duration: 67.50 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8511, Val_Loss: 1.1852, Total Mean Loss: 2.0182, LR: 0.003338277756187398, Duration: 67.57 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0255, Val_Loss: 1.2675, Total Mean Loss: 2.1465, LR: 0.003285593079992594, Duration: 67.41 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9926, Val_Loss: 1.1701, Total Mean Loss: 2.0814, LR: 0.00323134216757755, Duration: 67.49 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8710, Val_Loss: 1.1276, Total Mean Loss: 1.9993, LR: 0.0031755911153223313, Duration: 67.41 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8884, Val_Loss: 1.0406, Total Mean Loss: 1.9645, LR: 0.0031184078472963196, Duration: 67.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 27/27 [01:06<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6145, Val_Loss: 1.1127, Total Mean Loss: 1.8636, LR: 0.003059862032503198, Duration: 67.70 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9169, Val_Loss: 1.0917, Total Mean Loss: 2.0043, LR: 0.0030000249999999995, Duration: 67.52 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9894, Val_Loss: 1.0460, Total Mean Loss: 2.0177, LR: 0.002938969651993642, Duration: 67.55 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7877, Val_Loss: 1.0938, Total Mean Loss: 1.9408, LR: 0.002876770375020815, Duration: 67.37 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5092, Val_Loss: 0.9956, Total Mean Loss: 1.7524, LR: 0.0028135029493194467, Duration: 67.48 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6443, Val_Loss: 1.0065, Total Mean Loss: 1.8254, LR: 0.0027492444565021534, Duration: 67.49 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 27/27 [01:06<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4927, Val_Loss: 0.9553, Total Mean Loss: 1.7240, LR: 0.0026840731856441714, Duration: 67.69 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 27/27 [01:07<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5427, Val_Loss: 0.9239, Total Mean Loss: 1.7333, LR: 0.0026180685379001757, Duration: 68.13 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 27/27 [01:06<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6331, Val_Loss: 0.9464, Total Mean Loss: 1.7898, LR: 0.002551310929766207, Duration: 67.36 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6876, Val_Loss: 0.8948, Total Mean Loss: 1.7912, LR: 0.002483881695104555, Duration: 67.42 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6114, Val_Loss: 0.9237, Total Mean Loss: 1.7676, LR: 0.0024158629860509774, Duration: 67.55 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 27/27 [01:06<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6508, Val_Loss: 0.9648, Total Mean Loss: 1.8078, LR: 0.0023473376729249776, Duration: 67.33 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5695, Val_Loss: 0.9561, Total Mean Loss: 1.7628, LR: 0.0022783892432650826, Duration: 67.48 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4391, Val_Loss: 0.8177, Total Mean Loss: 1.6284, LR: 0.0022091017001121434, Duration: 67.44 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4974, Val_Loss: 0.8427, Total Mean Loss: 1.6701, LR: 0.002139559459664563, Duration: 67.52 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4575, Val_Loss: 0.7762, Total Mean Loss: 1.6168, LR: 0.0020698472484301667, Duration: 67.46 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5227, Val_Loss: 0.8147, Total Mean Loss: 1.6687, LR: 0.0020000499999999997, Duration: 67.56 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 27/27 [01:06<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4267, Val_Loss: 0.8300, Total Mean Loss: 1.6284, LR: 0.0019302527515698336, Duration: 67.35 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4398, Val_Loss: 0.7255, Total Mean Loss: 1.5827, LR: 0.0018605405403354365, Duration: 67.56 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2488, Val_Loss: 0.8539, Total Mean Loss: 1.5514, LR: 0.0017909982998878568, Duration: 67.61 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1985, Val_Loss: 0.7956, Total Mean Loss: 1.4970, LR: 0.0017217107567349176, Duration: 67.54 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3759, Val_Loss: 0.8497, Total Mean Loss: 1.6128, LR: 0.0016527623270750228, Duration: 67.58 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|██████████| 27/27 [01:06<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2043, Val_Loss: 0.8578, Total Mean Loss: 1.5311, LR: 0.0015842370139490226, Duration: 67.73 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3755, Val_Loss: 0.8482, Total Mean Loss: 1.6119, LR: 0.0015162183048954448, Duration: 67.44 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1355, Val_Loss: 0.8108, Total Mean Loss: 1.4731, LR: 0.0014487890702337925, Duration: 67.54 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1350, Val_Loss: 0.7789, Total Mean Loss: 1.4570, LR: 0.001382031462099824, Duration: 67.42 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1932, Val_Loss: 0.8184, Total Mean Loss: 1.5058, LR: 0.001316026814355829, Duration: 67.60 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1584, Val_Loss: 0.7591, Total Mean Loss: 1.4588, LR: 0.0012508555434978467, Duration: 67.54 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 100%|██████████| 27/27 [01:06<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2821, Val_Loss: 0.8223, Total Mean Loss: 1.5522, LR: 0.0011865970506805537, Duration: 67.65 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2484, Val_Loss: 0.8220, Total Mean Loss: 1.5352, LR: 0.0011233296249791845, Duration: 67.50 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1439, Val_Loss: 0.7533, Total Mean Loss: 1.4486, LR: 0.0010611303480063583, Duration: 67.41 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2082, Val_Loss: 0.7790, Total Mean Loss: 1.4936, LR: 0.0010000750000000004, Duration: 67.47 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2692, Val_Loss: 0.7999, Total Mean Loss: 1.5346, LR: 0.000940237967496802, Duration: 67.54 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0755, Val_Loss: 0.7652, Total Mean Loss: 1.4203, LR: 0.0008816921527036801, Duration: 67.51 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1475, Val_Loss: 0.7764, Total Mean Loss: 1.4620, LR: 0.0008245088846776685, Duration: 67.45 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1947, Val_Loss: 0.7709, Total Mean Loss: 1.4828, LR: 0.0007687578324224496, Duration: 67.51 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1150, Val_Loss: 0.7763, Total Mean Loss: 1.4456, LR: 0.0007145069200074055, Duration: 67.46 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2568, Val_Loss: 0.7770, Total Mean Loss: 1.5169, LR: 0.000661822243812602, Duration: 67.61 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0956, Val_Loss: 0.8004, Total Mean Loss: 1.4480, LR: 0.0006107679920005282, Duration: 67.49 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2704, Val_Loss: 0.8184, Total Mean Loss: 1.5444, LR: 0.0005614063663127149, Duration: 67.54 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1208, Val_Loss: 0.7864, Total Mean Loss: 1.4536, LR: 0.000513797506286485, Duration: 67.39 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2827, Val_Loss: 0.7837, Total Mean Loss: 1.5332, LR: 0.00046799941598420013, Duration: 67.39 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9240, Val_Loss: 0.7633, Total Mean Loss: 1.3437, LR: 0.0004240678933242365, Duration: 67.58 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1949, Val_Loss: 0.7407, Total Mean Loss: 1.4678, LR: 0.00038205646209982404, Duration: 67.43 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9439, Val_Loss: 0.7818, Total Mean Loss: 1.3629, LR: 0.0003420163067685445, Duration: 67.42 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0535, Val_Loss: 0.7407, Total Mean Loss: 1.3971, LR: 0.0003039962100919559, Duration: 67.52 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0102, Val_Loss: 0.7809, Total Mean Loss: 1.3955, LR: 0.0002680424937013118, Duration: 67.37 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3759, Val_Loss: 0.7563, Total Mean Loss: 1.5661, LR: 0.00023419896166178896, Duration: 67.55 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87: 100%|██████████| 27/27 [01:06<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2072, Val_Loss: 0.7671, Total Mean Loss: 1.4871, LR: 0.0002025068471039813, Duration: 67.28 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88: 100%|██████████| 27/27 [01:06<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0811, Val_Loss: 0.8004, Total Mean Loss: 1.4408, LR: 0.00017300476198768016, Duration: 67.27 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0743, Val_Loss: 0.7554, Total Mean Loss: 1.4149, LR: 0.00014572865005915372, Duration: 67.54 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0216, Val_Loss: 0.7178, Total Mean Loss: 1.3697, LR: 0.00012071174305922266, Duration: 67.37 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9036, Val_Loss: 0.7793, Total Mean Loss: 1.3415, LR: 9.79845202355077e-05, Duration: 67.45 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1194, Val_Loss: 0.7585, Total Mean Loss: 1.4390, LR: 7.757467120815912e-05, Duration: 67.51 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93: 100%|██████████| 27/27 [01:06<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1681, Val_Loss: 0.7490, Total Mean Loss: 1.4586, LR: 5.950706223432085e-05, Duration: 67.35 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0356, Val_Loss: 0.7410, Total Mean Loss: 1.3883, LR: 4.3803705912425316e-05, Duration: 67.52 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95: 100%|██████████| 27/27 [01:06<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 1.9751, Val_Loss: 0.7690, Total Mean Loss: 1.3720, LR: 3.0483734363234566e-05, Duration: 67.76 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96: 100%|██████████| 27/27 [01:06<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0435, Val_Loss: 0.7558, Total Mean Loss: 1.3996, LR: 1.9563375920296352e-05, Duration: 67.69 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0720, Val_Loss: 0.7562, Total Mean Loss: 1.4141, LR: 1.1055935358221834e-05, Duration: 67.62 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98: 100%|██████████| 27/27 [01:06<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1632, Val_Loss: 0.7543, Total Mean Loss: 1.4588, LR: 4.971777682864596e-06, Duration: 67.64 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1685, Val_Loss: 0.7549, Total Mean Loss: 1.4617, LR: 1.3183155031594304e-06, Duration: 67.57 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.0983, Val_Loss: 0.7549, Total Mean Loss: 1.4266, LR: 1e-07, Duration: 67.38 sec\n",
      "\n",
      "[100 epoch result]\n",
      "       Metric     Value\n",
      "0   Accuracy  0.894000\n",
      "1  Precision  0.912238\n",
      "2     Recall  0.894000\n",
      "3   F1 Score  0.891306\n"
     ]
    }
   ],
   "source": [
    "training_time = 0\n",
    "losses = []\n",
    "val_losses = []\n",
    "lrs = []\n",
    "best_loss = float('inf')\n",
    "\n",
    "# GradScaler 초기화\n",
    "scaler = GradScaler()\n",
    "\n",
    "for i in range(epochs // 100):\n",
    "    for epoch in range(100):\n",
    "        model_v2.train()\n",
    "        start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1 + i*100}\")\n",
    "        \n",
    "        for _, data in pbar:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            inputs, labels = mixup_fn(inputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # AutoCast 적용\n",
    "            with autocast():\n",
    "                outputs = model_v2(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "            # 스케일링된 그라디언트 계산\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # 그라디언트 클리핑 전에 스케일링 제거\n",
    "            scaler.unscale_(optimizer)\n",
    "            clip_grad_norm_(model_v2.parameters(), max_norm=max_norm)\n",
    "\n",
    "            # 옵티마이저 스텝 및 스케일러 업데이트\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            # EMA 모델 업데이트\n",
    "            if model_ema is not None:\n",
    "                model_ema.update(model_v2)\n",
    "                \n",
    "            scheduler.step()\n",
    "                \n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "            lrs.append(lr)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        losses.append(epoch_loss)        \n",
    "\n",
    "        model_v2.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for data in valid_loader:\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = model_v2(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "        val_loss /= len(valid_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # 모델 저장\n",
    "        total_loss = val_loss + epoch_loss\n",
    "        if total_loss < best_loss:\n",
    "            best_loss = total_loss\n",
    "            model_save = False\n",
    "            if model_save:\n",
    "                torch.save(model_v2.state_dict(), model_path)\n",
    "\n",
    "        epoch_duration = time.time() - start_time\n",
    "        training_time += epoch_duration\n",
    "        \n",
    "        text = f'\\tLoss: {epoch_loss:.4f}, Val_Loss: {val_loss:.4f}, Total Mean Loss: {total_loss/2:.4f}, LR: {lr}, Duration: {epoch_duration:.2f} sec'\n",
    "        \n",
    "        if model_save:\n",
    "            text += f' - model saved!'\n",
    "            model_save = False\n",
    "\n",
    "        print(text)\n",
    "\n",
    "    # 예측 수행 및 레이블 저장\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model_v2(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # 혼동 행렬 생성\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # 예측과 실제 레이블\n",
    "    y_true = all_labels  # 실제 레이블\n",
    "    y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "    # 전체 데이터셋에 대한 정확도\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "    # 판다스 데이터프레임으로 결과 정리\n",
    "    performance_metrics = pd.DataFrame({\n",
    "        'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "        'Value': [accuracy, precision, recall, f1_score]\n",
    "    })\n",
    "\n",
    "    # 데이터프레임 출력\n",
    "    print(f\"\\n[{i*100+100} epoch result]\\n\", performance_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 03 - Test ConvNeXt V2 with FCMAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00.MASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "원본 데이터\n",
      "tensor([[[[ 1.,  2.,  3.,  4.],\n",
      "          [ 5.,  6.,  7.,  8.],\n",
      "          [ 9., 10., 11., 12.],\n",
      "          [13., 14., 15., 16.]]]])\n",
      "\n",
      "마스크\n",
      "tensor([[[[0, 0, 1, 1],\n",
      "          [0, 0, 1, 1],\n",
      "          [0, 0, 1, 1],\n",
      "          [0, 0, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 0, 0],\n",
      "          [1, 1, 0, 0],\n",
      "          [1, 1, 0, 0],\n",
      "          [1, 1, 0, 0]]]])\n",
      "\n",
      "마스크 된 데이터\n",
      "tensor([[[[ 1.,  2.,  0.,  0.],\n",
      "          [ 5.,  6.,  0.,  0.],\n",
      "          [ 9., 10.,  0.,  0.],\n",
      "          [13., 14.,  0.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  0.,  3.,  4.],\n",
      "          [ 0.,  0.,  7.,  8.],\n",
      "          [ 0.,  0., 11., 12.],\n",
      "          [ 0.,  0., 15., 16.]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define the upsample_mask and a simple example\n",
    "def upsample_mask(mask, scale):\n",
    "    assert len(mask.shape) == 2\n",
    "    p = int(mask.shape[1] ** .5)\n",
    "    return mask.reshape(-1, p, p).repeat_interleave(scale, axis=1).repeat_interleave(scale, axis=2)\n",
    "\n",
    "# 예시 마스크와 데이터\n",
    "mask = torch.tensor([[0, 1, 0, 1],\n",
    "                     [1, 0, 1, 0]])\n",
    "x = torch.arange(1., 17.).reshape(1, 1, 4, 4)  # 4x4 데이터, 채널과 배치 차원 포함\n",
    "\n",
    "# 마스크 업샘플링\n",
    "upsampled_mask = upsample_mask(mask, 2)  # 스케일을 2로 설정\n",
    "upsampled_mask = upsampled_mask.unsqueeze(1)  # 채널 차원 추가, 올바른 변수 이름 사용\n",
    "\n",
    "# 데이터에 마스크 적용\n",
    "x_orig = x.clone()  # 원본 데이터 복사\n",
    "x_masked = x * (1. - upsampled_mask.type_as(x))  # 마스크 적용, 타입 일치 시키기\n",
    "\n",
    "print(f\"\\n원본 데이터\\n{x_orig}\")\n",
    "print(f\"\\n마스크\\n{upsampled_mask}\")\n",
    "print(f\"\\n마스크 된 데이터\\n{x_masked}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01.TRAIN FCMAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/MinkowskiEngine-0.5.4-py3.10-linux-x86_64.egg/MinkowskiEngine/__init__.py:36: UserWarning: The environment variable `OMP_NUM_THREADS` not set. MinkowskiEngine will automatically set `OMP_NUM_THREADS=16`. If you want to set `OMP_NUM_THREADS` manually, please export it on the command line before running a python script. e.g. `export OMP_NUM_THREADS=12; python your_program.py`. It is recommended to set it below 24.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from model.fcmae import convnextv2_fcmae_tiny\n",
    "\n",
    "model = convnextv2_fcmae_tiny()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "# Transforms 정의하기\n",
    "train_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224, scale=(0.2, 1.0), interpolation=3),  # 3 is bicubic\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "data_dir = '../../data/sports/'\n",
    "batch_size = 800\n",
    "train_path = data_dir\n",
    "\n",
    "# dataset load\n",
    "train_data = ImageFolder(train_path, transform=train_transform)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "len(train_loader)\n",
    "device = 'cuda:0'\n",
    "model.to(device)\n",
    "\n",
    "model_path = '../../model/convnext/fcmae.pt'\n",
    "\n",
    "epochs = 500\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1.5e-4, weight_decay=0.05, betas=(0.9, 0.95))\n",
    "\n",
    "warmup_steps = int(len(train_loader)*(epochs)*0.1)\n",
    "train_steps = len(train_loader)*(epochs)\n",
    "scheduler = CosineWarmupScheduler(optimizer, \n",
    "                                num_warmup_steps=50, \n",
    "                                num_training_steps=500,\n",
    "                                num_cycles=0.5,\n",
    "                                min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_time = 0\n",
    "losses = []\n",
    "val_losses = []\n",
    "lrs = []\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for _, data in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        samples= data[0].to(device)\n",
    "        loss, _, _ = model(samples, mask_ratio=0.6)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        lrs.append(lr)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)        \n",
    "    \n",
    "    # 모델 저장 로직 조정\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        if epoch > (epochs // 2) :\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            model_saved_text = ' - model saved!'\n",
    "        else :\n",
    "            model_saved_text = ' - model save pass'\n",
    "    else:\n",
    "        model_saved_text = ''\n",
    "    \n",
    "    epoch_duration = time.time() - start_time\n",
    "    training_time += epoch_duration\n",
    "    \n",
    "    text = f'\\tLoss: {epoch_loss:,.4f}, LR: {lr}, Duration: {epoch_duration:.2f} sec{model_saved_text}'\n",
    "    print(text)\n",
    "\n",
    "    # 에폭마다 스케줄러 업데이트\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.SUP after FCMAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model & pretrained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.convnextv2 import load_convNext\n",
    "\n",
    "model = load_convNext(droppath=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['downsample_layers.0.stem_conv.weight', 'downsample_layers.0.stem_conv.bias', 'downsample_layers.0.stem_ln.weight', 'downsample_layers.0.stem_ln.bias', 'downsample_layers.1.ds_ln.weight', 'downsample_layers.1.ds_ln.bias', 'downsample_layers.1.ds_conv.weight', 'downsample_layers.1.ds_conv.bias', 'downsample_layers.2.ds_ln.weight', 'downsample_layers.2.ds_ln.bias', 'downsample_layers.2.ds_conv.weight', 'downsample_layers.2.ds_conv.bias', 'downsample_layers.3.ds_ln.weight', 'downsample_layers.3.ds_ln.bias', 'downsample_layers.3.ds_conv.weight', 'downsample_layers.3.ds_conv.bias', 'stages.0.0.dwconv.weight', 'stages.0.0.dwconv.bias', 'stages.0.0.layernorm.weight', 'stages.0.0.layernorm.bias', 'stages.0.0.pwconv1.weight', 'stages.0.0.pwconv1.bias', 'stages.0.0.grn.gamma', 'stages.0.0.grn.beta', 'stages.0.0.pwconv2.weight', 'stages.0.0.pwconv2.bias', 'stages.0.1.dwconv.weight', 'stages.0.1.dwconv.bias', 'stages.0.1.layernorm.weight', 'stages.0.1.layernorm.bias', 'stages.0.1.pwconv1.weight', 'stages.0.1.pwconv1.bias', 'stages.0.1.grn.gamma', 'stages.0.1.grn.beta', 'stages.0.1.pwconv2.weight', 'stages.0.1.pwconv2.bias', 'stages.0.2.dwconv.weight', 'stages.0.2.dwconv.bias', 'stages.0.2.layernorm.weight', 'stages.0.2.layernorm.bias', 'stages.0.2.pwconv1.weight', 'stages.0.2.pwconv1.bias', 'stages.0.2.grn.gamma', 'stages.0.2.grn.beta', 'stages.0.2.pwconv2.weight', 'stages.0.2.pwconv2.bias', 'stages.1.0.dwconv.weight', 'stages.1.0.dwconv.bias', 'stages.1.0.layernorm.weight', 'stages.1.0.layernorm.bias', 'stages.1.0.pwconv1.weight', 'stages.1.0.pwconv1.bias', 'stages.1.0.grn.gamma', 'stages.1.0.grn.beta', 'stages.1.0.pwconv2.weight', 'stages.1.0.pwconv2.bias', 'stages.1.1.dwconv.weight', 'stages.1.1.dwconv.bias', 'stages.1.1.layernorm.weight', 'stages.1.1.layernorm.bias', 'stages.1.1.pwconv1.weight', 'stages.1.1.pwconv1.bias', 'stages.1.1.grn.gamma', 'stages.1.1.grn.beta', 'stages.1.1.pwconv2.weight', 'stages.1.1.pwconv2.bias', 'stages.1.2.dwconv.weight', 'stages.1.2.dwconv.bias', 'stages.1.2.layernorm.weight', 'stages.1.2.layernorm.bias', 'stages.1.2.pwconv1.weight', 'stages.1.2.pwconv1.bias', 'stages.1.2.grn.gamma', 'stages.1.2.grn.beta', 'stages.1.2.pwconv2.weight', 'stages.1.2.pwconv2.bias', 'stages.2.0.dwconv.weight', 'stages.2.0.dwconv.bias', 'stages.2.0.layernorm.weight', 'stages.2.0.layernorm.bias', 'stages.2.0.pwconv1.weight', 'stages.2.0.pwconv1.bias', 'stages.2.0.grn.gamma', 'stages.2.0.grn.beta', 'stages.2.0.pwconv2.weight', 'stages.2.0.pwconv2.bias', 'stages.2.1.dwconv.weight', 'stages.2.1.dwconv.bias', 'stages.2.1.layernorm.weight', 'stages.2.1.layernorm.bias', 'stages.2.1.pwconv1.weight', 'stages.2.1.pwconv1.bias', 'stages.2.1.grn.gamma', 'stages.2.1.grn.beta', 'stages.2.1.pwconv2.weight', 'stages.2.1.pwconv2.bias', 'stages.2.2.dwconv.weight', 'stages.2.2.dwconv.bias', 'stages.2.2.layernorm.weight', 'stages.2.2.layernorm.bias', 'stages.2.2.pwconv1.weight', 'stages.2.2.pwconv1.bias', 'stages.2.2.grn.gamma', 'stages.2.2.grn.beta', 'stages.2.2.pwconv2.weight', 'stages.2.2.pwconv2.bias', 'stages.2.3.dwconv.weight', 'stages.2.3.dwconv.bias', 'stages.2.3.layernorm.weight', 'stages.2.3.layernorm.bias', 'stages.2.3.pwconv1.weight', 'stages.2.3.pwconv1.bias', 'stages.2.3.grn.gamma', 'stages.2.3.grn.beta', 'stages.2.3.pwconv2.weight', 'stages.2.3.pwconv2.bias', 'stages.2.4.dwconv.weight', 'stages.2.4.dwconv.bias', 'stages.2.4.layernorm.weight', 'stages.2.4.layernorm.bias', 'stages.2.4.pwconv1.weight', 'stages.2.4.pwconv1.bias', 'stages.2.4.grn.gamma', 'stages.2.4.grn.beta', 'stages.2.4.pwconv2.weight', 'stages.2.4.pwconv2.bias', 'stages.2.5.dwconv.weight', 'stages.2.5.dwconv.bias', 'stages.2.5.layernorm.weight', 'stages.2.5.layernorm.bias', 'stages.2.5.pwconv1.weight', 'stages.2.5.pwconv1.bias', 'stages.2.5.grn.gamma', 'stages.2.5.grn.beta', 'stages.2.5.pwconv2.weight', 'stages.2.5.pwconv2.bias', 'stages.2.6.dwconv.weight', 'stages.2.6.dwconv.bias', 'stages.2.6.layernorm.weight', 'stages.2.6.layernorm.bias', 'stages.2.6.pwconv1.weight', 'stages.2.6.pwconv1.bias', 'stages.2.6.grn.gamma', 'stages.2.6.grn.beta', 'stages.2.6.pwconv2.weight', 'stages.2.6.pwconv2.bias', 'stages.2.7.dwconv.weight', 'stages.2.7.dwconv.bias', 'stages.2.7.layernorm.weight', 'stages.2.7.layernorm.bias', 'stages.2.7.pwconv1.weight', 'stages.2.7.pwconv1.bias', 'stages.2.7.grn.gamma', 'stages.2.7.grn.beta', 'stages.2.7.pwconv2.weight', 'stages.2.7.pwconv2.bias', 'stages.2.8.dwconv.weight', 'stages.2.8.dwconv.bias', 'stages.2.8.layernorm.weight', 'stages.2.8.layernorm.bias', 'stages.2.8.pwconv1.weight', 'stages.2.8.pwconv1.bias', 'stages.2.8.grn.gamma', 'stages.2.8.grn.beta', 'stages.2.8.pwconv2.weight', 'stages.2.8.pwconv2.bias', 'stages.3.0.dwconv.weight', 'stages.3.0.dwconv.bias', 'stages.3.0.layernorm.weight', 'stages.3.0.layernorm.bias', 'stages.3.0.pwconv1.weight', 'stages.3.0.pwconv1.bias', 'stages.3.0.grn.gamma', 'stages.3.0.grn.beta', 'stages.3.0.pwconv2.weight', 'stages.3.0.pwconv2.bias', 'stages.3.1.dwconv.weight', 'stages.3.1.dwconv.bias', 'stages.3.1.layernorm.weight', 'stages.3.1.layernorm.bias', 'stages.3.1.pwconv1.weight', 'stages.3.1.pwconv1.bias', 'stages.3.1.grn.gamma', 'stages.3.1.grn.beta', 'stages.3.1.pwconv2.weight', 'stages.3.1.pwconv2.bias', 'stages.3.2.dwconv.weight', 'stages.3.2.dwconv.bias', 'stages.3.2.layernorm.weight', 'stages.3.2.layernorm.bias', 'stages.3.2.pwconv1.weight', 'stages.3.2.pwconv1.bias', 'stages.3.2.grn.gamma', 'stages.3.2.grn.beta', 'stages.3.2.pwconv2.weight', 'stages.3.2.pwconv2.bias', 'layernorm.weight', 'layernorm.bias', 'fc.weight', 'fc.bias'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0706,  0.0843,  0.1174, -0.0564],\n",
       "         [-0.0312,  0.0365, -0.0785,  0.1419],\n",
       "         [ 0.1391, -0.0071,  0.0951,  0.0685],\n",
       "         [ 0.1208,  0.1312, -0.0996, -0.0800]],\n",
       "\n",
       "        [[-0.0195, -0.0032,  0.1358,  0.0999],\n",
       "         [-0.0467, -0.0245,  0.1219,  0.0473],\n",
       "         [-0.0452, -0.1008, -0.0227,  0.0074],\n",
       "         [-0.1250, -0.0701,  0.0236, -0.1186]],\n",
       "\n",
       "        [[ 0.0773, -0.0125, -0.0491,  0.0931],\n",
       "         [ 0.0114,  0.0861, -0.0023, -0.1396],\n",
       "         [-0.1040, -0.0269, -0.0973, -0.0261],\n",
       "         [-0.0505,  0.0579,  0.0791,  0.0156]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['downsample_layers.0.stem_conv.weight'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0734, -0.0590,  0.0357,  0.1099,  0.1364,  0.0044, -0.0072],\n",
       "         [ 0.1428,  0.0287,  0.0041, -0.1135,  0.0391,  0.0359, -0.0417],\n",
       "         [-0.1169,  0.1240,  0.0015, -0.0630,  0.0014,  0.1363, -0.0307],\n",
       "         [ 0.0050,  0.0252,  0.0829, -0.0207, -0.0538,  0.0051,  0.1162],\n",
       "         [-0.1228, -0.0476,  0.0530, -0.0216, -0.1081,  0.0138, -0.0492],\n",
       "         [ 0.0289,  0.1040,  0.0111,  0.1309, -0.0321,  0.0836,  0.0027],\n",
       "         [ 0.1196,  0.0018,  0.0150, -0.0379,  0.1347, -0.0381, -0.0342]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['stages.0.0.dwconv.weight'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remap Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def remap_checkpoint_keys(ckpt):\n",
    "    new_ckpt = OrderedDict()\n",
    "    for k, v in ckpt.items():\n",
    "        if k.startswith('encoder'):\n",
    "            k = '.'.join(k.split('.')[1:]) # remove encoder in the name\n",
    "        if k.endswith('kernel'):\n",
    "            k = '.'.join(k.split('.')[:-1]) # remove kernel in the name\n",
    "            new_k = k + '.weight'\n",
    "            if len(v.shape) == 3: # resahpe standard convolution\n",
    "                kv, in_dim, out_dim = v.shape\n",
    "                ks = int(math.sqrt(kv))\n",
    "                new_ckpt[new_k] = v.permute(2, 1, 0).\\\n",
    "                    reshape(out_dim, in_dim, ks, ks).transpose(3, 2)\n",
    "            elif len(v.shape) == 2: # reshape depthwise convolution\n",
    "                kv, dim = v.shape\n",
    "                ks = int(math.sqrt(kv))\n",
    "                new_ckpt[new_k] = v.permute(1, 0).\\\n",
    "                    reshape(dim, 1, ks, ks).transpose(3, 2)\n",
    "            continue\n",
    "        elif 'ln' in k or 'linear' in k:\n",
    "            k = k.split('.')\n",
    "            k.pop(-2) # remove ln and linear in the name\n",
    "            new_k = '.'.join(k)\n",
    "        else:\n",
    "            new_k = k\n",
    "        new_ckpt[new_k] = v\n",
    "\n",
    "    # reshape grn affine parameters and biases\n",
    "    for k, v in new_ckpt.items():\n",
    "        if k.endswith('bias') and len(v.shape) != 1:\n",
    "            new_ckpt[k] = v.reshape(-1)\n",
    "        elif 'grn' in k:\n",
    "            new_ckpt[k] = v.unsqueeze(0).unsqueeze(1)\n",
    "    return new_ckpt\n",
    "\n",
    "def load_state_dict(model, state_dict, prefix='', ignore_missing=\"relative_position_index\"):\n",
    "    missing_keys = []\n",
    "    unexpected_keys = []\n",
    "    error_msgs = []\n",
    "    # copy state_dict so _load_from_state_dict can modify it\n",
    "    metadata = getattr(state_dict, '_metadata', None)\n",
    "    state_dict = state_dict.copy()\n",
    "    if metadata is not None:\n",
    "        state_dict._metadata = metadata\n",
    "\n",
    "    def load(module, prefix=''):\n",
    "        local_metadata = {} if metadata is None else metadata.get(\n",
    "            prefix[:-1], {})\n",
    "        module._load_from_state_dict(\n",
    "            state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)\n",
    "        for name, child in module._modules.items():\n",
    "            if child is not None:\n",
    "                load(child, prefix + name + '.')\n",
    "\n",
    "    load(model, prefix=prefix)\n",
    "\n",
    "    warn_missing_keys = []\n",
    "    ignore_missing_keys = []\n",
    "    for key in missing_keys:\n",
    "        keep_flag = True\n",
    "        for ignore_key in ignore_missing.split('|'):\n",
    "            if ignore_key in key:\n",
    "                keep_flag = False\n",
    "                break\n",
    "        if keep_flag:\n",
    "            warn_missing_keys.append(key)\n",
    "        else:\n",
    "            ignore_missing_keys.append(key)\n",
    "\n",
    "    missing_keys = warn_missing_keys\n",
    "\n",
    "    if len(missing_keys) > 0:\n",
    "        print(\"Weights of {} not initialized from pretrained model: {}\".format(\n",
    "            model.__class__.__name__, missing_keys))\n",
    "    if len(unexpected_keys) > 0:\n",
    "        print(\"Weights from pretrained model not used in {}: {}\".format(\n",
    "            model.__class__.__name__, unexpected_keys))\n",
    "    if len(ignore_missing_keys) > 0:\n",
    "        print(\"Ignored weights of {} not initialized from pretrained model: {}\".format(\n",
    "            model.__class__.__name__, ignore_missing_keys))\n",
    "    if len(error_msgs) > 0:\n",
    "        print('\\n'.join(error_msgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing key mask_token from decoder of pretrained checkpoint\n",
      "Removing key proj.weight from decoder of pretrained checkpoint\n",
      "Removing key proj.bias from decoder of pretrained checkpoint\n",
      "Removing key decoder.0.dwconv.weight from decoder of pretrained checkpoint\n",
      "Removing key decoder.0.dwconv.bias from decoder of pretrained checkpoint\n",
      "Removing key decoder.0.layernorm.weight from decoder of pretrained checkpoint\n",
      "Removing key decoder.0.layernorm.bias from decoder of pretrained checkpoint\n",
      "Removing key decoder.0.pwconv1.weight from decoder of pretrained checkpoint\n",
      "Removing key decoder.0.pwconv1.bias from decoder of pretrained checkpoint\n",
      "Removing key decoder.0.grn.gamma from decoder of pretrained checkpoint\n",
      "Removing key decoder.0.grn.beta from decoder of pretrained checkpoint\n",
      "Removing key decoder.0.pwconv2.weight from decoder of pretrained checkpoint\n",
      "Removing key decoder.0.pwconv2.bias from decoder of pretrained checkpoint\n",
      "Removing key pred.weight from decoder of pretrained checkpoint\n",
      "Removing key pred.bias from decoder of pretrained checkpoint\n",
      "Weights of ConvNeXtV2 not initialized from pretrained model: ['downsample_layers.0.stem_ln.weight', 'downsample_layers.0.stem_ln.bias', 'layernorm.weight', 'layernorm.bias', 'fc.weight', 'fc.bias']\n",
      "Weights from pretrained model not used in ConvNeXtV2: ['downsample_layers.0.weight', 'downsample_layers.0.bias']\n"
     ]
    }
   ],
   "source": [
    "pretrain_path = '../../model/convnext/fcmae.pt'\n",
    "checkpoint_model = torch.load(pretrain_path, map_location='cpu')\n",
    "\n",
    "state_dict = model.state_dict()\n",
    "for k in ['head.weight', 'head.bias']:\n",
    "    if k in checkpoint_model and checkpoint_model[k].shape != state_dict[k].shape:\n",
    "        print(f\"Removing key {k} from head of pretrained checkpoint\")\n",
    "        del checkpoint_model[k]\n",
    "\n",
    "# remove decoder weights\n",
    "checkpoint_model_keys = list(checkpoint_model.keys())\n",
    "for k in checkpoint_model_keys:\n",
    "    if 'decoder' in k or 'mask_token'in k or \\\n",
    "        'proj' in k or 'pred' in k:\n",
    "        print(f\"Removing key {k} from decoder of pretrained checkpoint\")\n",
    "        del checkpoint_model[k]\n",
    "\n",
    "checkpoint_model = remap_checkpoint_keys(checkpoint_model)\n",
    "load_state_dict(model, checkpoint_model, prefix='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually initialize fc layer\n",
    "nn.init.trunc_normal_(model.fc.weight, std=2e-5)\n",
    "torch.nn.init.constant_(model.fc.bias, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8802,  0.2752, -0.4035, -1.2205],\n",
       "         [ 0.7427,  0.1955, -0.2904,  0.3602],\n",
       "         [-0.7897, -0.2285, -1.3589,  0.5611],\n",
       "         [-0.7793,  0.5858,  0.4699,  0.0270]],\n",
       "\n",
       "        [[-1.0506,  0.1854,  0.8416,  0.4679],\n",
       "         [ 0.6952,  0.1837, -1.1599,  0.5895],\n",
       "         [ 0.5511,  0.8517,  0.6042,  0.2877],\n",
       "         [-1.5525,  0.0553,  0.6789, -0.2969]],\n",
       "\n",
       "        [[-1.2694, -0.5104,  0.2598, -0.7962],\n",
       "         [ 0.9042,  1.3319,  0.4094,  0.1948],\n",
       "         [ 1.4617, -0.9857,  0.1321, -0.6043],\n",
       "         [-0.3689,  0.2868,  0.9690, -1.3783]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['downsample_layers.0.stem_conv.weight'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['downsample_layers.0.stem_ln.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4445,  1.0452, -0.7260, -0.3631,  0.0227,  0.6246, -0.2825],\n",
       "         [ 1.1328,  0.7457, -0.8378,  0.3528,  0.0799, -0.3967, -0.0432],\n",
       "         [-0.5897,  0.2521, -0.9658,  1.6085, -1.9021, -0.6323,  1.1863],\n",
       "         [-0.0322,  0.1994,  0.4114,  0.0282, -1.5300, -0.1251,  1.0526],\n",
       "         [-0.6060,  0.5384, -0.7747,  0.6380, -1.0716, -0.2204,  1.0994],\n",
       "         [-0.7747, -0.6877, -0.0903, -1.7114, -0.9821, -1.4432,  0.6607],\n",
       "         [-0.1051,  0.6697,  1.3252,  1.1271, -1.1911, -0.8717,  0.0198]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['stages.0.0.dwconv.weight'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "\n",
      "Total Parameters: 27,943,396\n",
      "Trainable Parameters: 27,943,396\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 총 파라미터 수 계산\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "# 학습 가능한 파라미터 수 계산\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print('='*80)\n",
    "print(f\"\\nTotal Parameters: {total_params:,}\")\n",
    "print(f\"Trainable Parameters: {trainable_params:,}\\n\")\n",
    "print('='*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms 정의하기\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.TrivialAugmentWide(interpolation=F.InterpolationMode.BICUBIC),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.6,1), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "data_dir = '../../data/sports'\n",
    "batch_size = 320\n",
    "\n",
    "train_path = data_dir+'/train'\n",
    "valid_path = data_dir+'/valid'\n",
    "test_path = data_dir+'/test'\n",
    "\n",
    "# dataset load\n",
    "train_data = ImageFolder(train_path, transform=train_transform)\n",
    "valid_data = ImageFolder(valid_path, transform=test_transform)\n",
    "test_data = ImageFolder(test_path, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using EMA with decay = 0.999\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:4'\n",
    "max_norm = 3.0 \n",
    "\n",
    "model.to(device)\n",
    "\n",
    "model_ema = None\n",
    "ema_active = True\n",
    "if ema_active:\n",
    "    ema_decay = 0.999\n",
    "    model_ema = ModelEmaV3(\n",
    "        model,\n",
    "        decay=ema_decay,\n",
    "    )\n",
    "    print(f\"Using EMA with decay = {ema_decay}\")\n",
    "\n",
    "model_path = ''\n",
    "\n",
    "mixup = True\n",
    "if mixup :\n",
    "    mixup_fn = Mixup(mixup_alpha=.8, \n",
    "                    cutmix_alpha=1., \n",
    "                    prob=1., \n",
    "                    switch_prob=0.5, \n",
    "                    mode='batch',\n",
    "                    label_smoothing=.1,\n",
    "                    num_classes=100)\n",
    "    \n",
    "    criterion = SoftTargetCrossEntropy()\n",
    "else :\n",
    "    criterion = LabelSmoothingCrossEntropy(.1)\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CASE 01: Without LayerWise Learning Rate Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=8e-3, weight_decay=0.05)\n",
    "warmup_steps = int(len(train_loader)*(epochs)*0.1)\n",
    "train_steps = len(train_loader)*(epochs)\n",
    "scheduler = CosineWarmupScheduler(optimizer, \n",
    "                                num_warmup_steps=warmup_steps, \n",
    "                                num_training_steps=train_steps,\n",
    "                                num_cycles=0.5,\n",
    "                                min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 43/43 [01:41<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.5174, Val_Loss: 3.9555, Total Mean Loss: 4.2364, LR: 0.0008000899999999999, Duration: 103.26 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.3576, Val_Loss: 3.7653, Total Mean Loss: 4.0615, LR: 0.00160008, Duration: 100.78 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.2708, Val_Loss: 3.6170, Total Mean Loss: 3.9439, LR: 0.00240007, Duration: 101.10 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.2401, Val_Loss: 3.4767, Total Mean Loss: 3.8584, LR: 0.00320006, Duration: 100.80 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 43/43 [01:41<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.1595, Val_Loss: 3.4136, Total Mean Loss: 3.7866, LR: 0.004000050000000001, Duration: 102.41 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 43/43 [01:40<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.1002, Val_Loss: 3.1582, Total Mean Loss: 3.6292, LR: 0.00480004, Duration: 102.22 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 43/43 [01:41<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.0583, Val_Loss: 3.2720, Total Mean Loss: 3.6651, LR: 0.005600030000000001, Duration: 102.64 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 43/43 [01:41<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.0330, Val_Loss: 2.9468, Total Mean Loss: 3.4899, LR: 0.00640002, Duration: 103.30 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 43/43 [01:40<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.0363, Val_Loss: 3.0413, Total Mean Loss: 3.5388, LR: 0.0072000100000000015, Duration: 102.32 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 43/43 [01:41<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.9551, Val_Loss: 2.8868, Total Mean Loss: 3.4209, LR: 0.008, Duration: 103.23 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 43/43 [01:42<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.9574, Val_Loss: 2.7514, Total Mean Loss: 3.3544, LR: 0.007997563338535033, Duration: 104.34 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 43/43 [01:41<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.8570, Val_Loss: 2.7344, Total Mean Loss: 3.2957, LR: 0.007990256322836784, Duration: 102.60 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 43/43 [01:41<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.8681, Val_Loss: 2.5248, Total Mean Loss: 3.1965, LR: 0.007978087855378325, Duration: 102.72 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 43/43 [01:42<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7876, Val_Loss: 2.5320, Total Mean Loss: 3.1598, LR: 0.007961072761562845, Duration: 103.62 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 43/43 [01:41<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7998, Val_Loss: 2.4282, Total Mean Loss: 3.1140, LR: 0.007939231771661183, Duration: 102.80 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.8225, Val_Loss: 2.4126, Total Mean Loss: 3.1176, LR: 0.007912591495555185, Duration: 101.95 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6847, Val_Loss: 2.4743, Total Mean Loss: 3.0795, LR: 0.007881184390317672, Duration: 101.29 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7576, Val_Loss: 2.1219, Total Mean Loss: 2.9398, LR: 0.007845048720668478, Duration: 101.73 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 43/43 [01:41<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6963, Val_Loss: 2.1244, Total Mean Loss: 2.9104, LR: 0.007804228512354801, Duration: 102.30 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 43/43 [01:42<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6600, Val_Loss: 1.9895, Total Mean Loss: 2.8247, LR: 0.007758773498512596, Duration: 103.69 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7373, Val_Loss: 2.2895, Total Mean Loss: 3.0134, LR: 0.0077087390590744225, Duration: 101.65 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6895, Val_Loss: 1.9331, Total Mean Loss: 2.8113, LR: 0.007654186153297522, Duration: 100.99 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5832, Val_Loss: 2.0351, Total Mean Loss: 2.8091, LR: 0.007595181245494354, Duration: 101.03 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6645, Val_Loss: 1.9636, Total Mean Loss: 2.8141, LR: 0.007531796224056066, Duration: 100.65 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6152, Val_Loss: 1.8906, Total Mean Loss: 2.7529, LR: 0.007464108313867567, Duration: 100.54 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5144, Val_Loss: 1.8880, Total Mean Loss: 2.7012, LR: 0.007392199982220897, Duration: 100.78 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4348, Val_Loss: 1.7945, Total Mean Loss: 2.6147, LR: 0.00731615883834154, Duration: 100.65 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4844, Val_Loss: 1.7314, Total Mean Loss: 2.6079, LR: 0.007236077526650072, Duration: 100.41 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4791, Val_Loss: 1.6426, Total Mean Loss: 2.5609, LR: 0.007152053613889208, Duration: 101.06 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4843, Val_Loss: 1.7159, Total Mean Loss: 2.6001, LR: 0.007064189470253756, Duration: 101.05 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.3647, Val_Loss: 1.6714, Total Mean Loss: 2.5181, LR: 0.006972592144668304, Duration: 100.75 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4009, Val_Loss: 1.8616, Total Mean Loss: 2.6312, LR: 0.0068773732343645885, Duration: 101.09 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.3194, Val_Loss: 1.4487, Total Mean Loss: 2.3840, LR: 0.006778648748917467, Duration: 101.45 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.3243, Val_Loss: 1.6330, Total Mean Loss: 2.4787, LR: 0.006676538968905116, Duration: 100.81 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.3318, Val_Loss: 1.5348, Total Mean Loss: 2.4333, LR: 0.006571168299365673, Duration: 100.98 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.3523, Val_Loss: 1.5313, Total Mean Loss: 2.4418, LR: 0.006462665118228867, Duration: 100.55 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2279, Val_Loss: 1.4897, Total Mean Loss: 2.3588, LR: 0.006351161619907278, Duration: 100.72 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1622, Val_Loss: 1.4437, Total Mean Loss: 2.3030, LR: 0.006236793654237814, Duration: 100.55 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1753, Val_Loss: 1.4818, Total Mean Loss: 2.3285, LR: 0.006119700560969609, Duration: 100.68 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.3085, Val_Loss: 1.5160, Total Mean Loss: 2.4123, LR: 0.006000025000000001, Duration: 100.76 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0782, Val_Loss: 1.3151, Total Mean Loss: 2.1966, LR: 0.005877912777565424, Duration: 100.49 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2108, Val_Loss: 1.2391, Total Mean Loss: 2.2250, LR: 0.005753512668598971, Duration: 100.61 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2387, Val_Loss: 1.2823, Total Mean Loss: 2.2605, LR: 0.005626976235471049, Duration: 100.50 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0919, Val_Loss: 1.1246, Total Mean Loss: 2.1083, LR: 0.005498457643333979, Duration: 100.60 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0948, Val_Loss: 1.2930, Total Mean Loss: 2.1939, LR: 0.00536811347229551, Duration: 100.50 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8692, Val_Loss: 1.0588, Total Mean Loss: 1.9640, LR: 0.005236102526650072, Duration: 100.50 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0887, Val_Loss: 1.1858, Total Mean Loss: 2.1373, LR: 0.005102585641400206, Duration: 100.76 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0582, Val_Loss: 1.2281, Total Mean Loss: 2.1432, LR: 0.004967725486303891, Duration: 100.58 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9549, Val_Loss: 1.0682, Total Mean Loss: 2.0116, LR: 0.004831686367686497, Duration: 100.42 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0342, Val_Loss: 1.0445, Total Mean Loss: 2.0393, LR: 0.004694634028258839, Duration: 100.55 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0304, Val_Loss: 1.0406, Total Mean Loss: 2.0355, LR: 0.004556735445185214, Duration: 100.52 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9169, Val_Loss: 1.0159, Total Mean Loss: 1.9664, LR: 0.004418158626647451, Duration: 100.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9099, Val_Loss: 1.0923, Total Mean Loss: 2.0011, LR: 0.004279072407152814, Duration: 100.70 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0031, Val_Loss: 1.1015, Total Mean Loss: 2.0523, LR: 0.00413964624183517, Duration: 100.65 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8709, Val_Loss: 0.9729, Total Mean Loss: 1.9219, LR: 0.004000050000000001, Duration: 100.43 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9064, Val_Loss: 1.0415, Total Mean Loss: 1.9739, LR: 0.0038604537581648324, Duration: 100.46 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7644, Val_Loss: 0.8916, Total Mean Loss: 1.8280, LR: 0.0037210275928471863, Duration: 100.76 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8485, Val_Loss: 0.9641, Total Mean Loss: 1.9063, LR: 0.00358194137335255, Duration: 101.19 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7439, Val_Loss: 0.9852, Total Mean Loss: 1.8645, LR: 0.0034433645548147874, Duration: 100.61 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7590, Val_Loss: 0.9629, Total Mean Loss: 1.8609, LR: 0.0033054659717411624, Duration: 101.03 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8289, Val_Loss: 0.9579, Total Mean Loss: 1.8934, LR: 0.003168413632313504, Duration: 100.51 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7437, Val_Loss: 0.9465, Total Mean Loss: 1.8451, LR: 0.00303237451369611, Duration: 100.54 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7463, Val_Loss: 0.9544, Total Mean Loss: 1.8504, LR: 0.0028975143585997947, Duration: 100.98 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6703, Val_Loss: 0.8787, Total Mean Loss: 1.7745, LR: 0.0027639974733499294, Duration: 100.84 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7541, Val_Loss: 0.9497, Total Mean Loss: 1.8519, LR: 0.002631986527704492, Duration: 100.80 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5575, Val_Loss: 0.9062, Total Mean Loss: 1.7318, LR: 0.0025016423566660228, Duration: 100.77 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7459, Val_Loss: 0.8786, Total Mean Loss: 1.8123, LR: 0.0023731237645289536, Duration: 101.30 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5037, Val_Loss: 0.8012, Total Mean Loss: 1.6524, LR: 0.0022465873314010294, Duration: 100.65 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 100%|██████████| 43/43 [01:39<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6009, Val_Loss: 0.8504, Total Mean Loss: 1.7257, LR: 0.002122187222434577, Duration: 100.35 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4472, Val_Loss: 0.8363, Total Mean Loss: 1.6417, LR: 0.002000075000000001, Duration: 100.80 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6066, Val_Loss: 0.8907, Total Mean Loss: 1.7486, LR: 0.0018803994390303928, Duration: 100.91 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4942, Val_Loss: 0.8203, Total Mean Loss: 1.6573, LR: 0.001763306345762187, Duration: 100.64 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2896, Val_Loss: 0.7736, Total Mean Loss: 1.5316, LR: 0.0016489383800927227, Duration: 100.80 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4167, Val_Loss: 0.8223, Total Mean Loss: 1.6195, LR: 0.0015374348817711334, Duration: 101.16 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5211, Val_Loss: 0.8380, Total Mean Loss: 1.6795, LR: 0.001428931700634327, Duration: 100.65 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76: 100%|██████████| 43/43 [01:39<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3990, Val_Loss: 0.8152, Total Mean Loss: 1.6071, LR: 0.0013235610310948864, Duration: 100.41 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77: 100%|██████████| 43/43 [01:38<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3730, Val_Loss: 0.7899, Total Mean Loss: 1.5815, LR: 0.0012214512510825336, Duration: 100.04 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.2933, Val_Loss: 0.7832, Total Mean Loss: 1.5383, LR: 0.0011227267656354132, Duration: 101.12 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5673, Val_Loss: 0.8515, Total Mean Loss: 1.7094, LR: 0.0010275078553316965, Duration: 100.49 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4341, Val_Loss: 0.8315, Total Mean Loss: 1.6328, LR: 0.0009359105297462444, Duration: 100.54 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5285, Val_Loss: 0.7779, Total Mean Loss: 1.6532, LR: 0.0008480463861107927, Duration: 100.93 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4238, Val_Loss: 0.7848, Total Mean Loss: 1.6043, LR: 0.0007640224733499294, Duration: 100.46 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.1293, Val_Loss: 0.7640, Total Mean Loss: 1.4467, LR: 0.0006839411616584612, Duration: 100.81 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3635, Val_Loss: 0.7825, Total Mean Loss: 1.5730, LR: 0.000607900017779104, Duration: 100.58 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5074, Val_Loss: 0.7821, Total Mean Loss: 1.6447, LR: 0.0005359916861324344, Duration: 100.76 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4612, Val_Loss: 0.7745, Total Mean Loss: 1.6179, LR: 0.000468303775943935, Duration: 100.97 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3710, Val_Loss: 0.7603, Total Mean Loss: 1.5657, LR: 0.0004049187545056477, Duration: 100.60 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88: 100%|██████████| 43/43 [01:39<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3455, Val_Loss: 0.7427, Total Mean Loss: 1.5441, LR: 0.00034591384670247825, Duration: 100.33 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 43/43 [01:38<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4511, Val_Loss: 0.7847, Total Mean Loss: 1.6179, LR: 0.0002913609409255791, Duration: 99.96 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3802, Val_Loss: 0.7559, Total Mean Loss: 1.5681, LR: 0.00024132650148740606, Duration: 100.47 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3893, Val_Loss: 0.7604, Total Mean Loss: 1.5748, LR: 0.00019587148764520066, Duration: 100.73 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3822, Val_Loss: 0.7569, Total Mean Loss: 1.5695, LR: 0.00015505127933152136, Duration: 101.02 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4014, Val_Loss: 0.7536, Total Mean Loss: 1.5775, LR: 0.00011891560968232792, Duration: 100.62 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94: 100%|██████████| 43/43 [01:39<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3272, Val_Loss: 0.7621, Total Mean Loss: 1.5446, LR: 8.750850444481394e-05, Duration: 100.33 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95: 100%|██████████| 43/43 [01:39<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3300, Val_Loss: 0.7494, Total Mean Loss: 1.5397, LR: 6.0868228338818537e-05, Duration: 100.37 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3357, Val_Loss: 0.7471, Total Mean Loss: 1.5414, LR: 3.902723843715564e-05, Duration: 100.57 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4103, Val_Loss: 0.7500, Total Mean Loss: 1.5802, LR: 2.2012144621675257e-05, Duration: 100.54 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.3573, Val_Loss: 0.7515, Total Mean Loss: 1.5544, LR: 9.843677163216202e-06, Duration: 100.81 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4389, Val_Loss: 0.7519, Total Mean Loss: 1.5954, LR: 2.5366614649679064e-06, Duration: 100.53 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100: 100%|██████████| 43/43 [01:38<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4062, Val_Loss: 0.7520, Total Mean Loss: 1.5791, LR: 1e-07, Duration: 100.26 sec\n",
      "\n",
      "[100 epoch result]\n",
      "       Metric     Value\n",
      "0   Accuracy  0.898000\n",
      "1  Precision  0.913381\n",
      "2     Recall  0.898000\n",
      "3   F1 Score  0.893048\n"
     ]
    }
   ],
   "source": [
    "training_time = 0\n",
    "losses = []\n",
    "val_losses = []\n",
    "lrs = []\n",
    "best_loss = float('inf')\n",
    "model_save = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "for i in range(epochs // 100):\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1 + i*100}\")\n",
    "        \n",
    "        for _, data in pbar:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            inputs, labels = mixup_fn(inputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "                \n",
    "            loss.backward()\n",
    "            # 그라디언트 클리핑 적용\n",
    "            clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # EMA 모델 업데이트, 필요한 경우\n",
    "            if model_ema is not None:\n",
    "                model_ema.update(model)\n",
    "                \n",
    "            scheduler.step()\n",
    "                \n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "            lrs.append(lr)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        losses.append(epoch_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for data in valid_loader:\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "        val_loss /= len(valid_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # 모델 저장 조건 수정\n",
    "        total_loss = val_loss + epoch_loss\n",
    "        if total_loss < best_loss:\n",
    "            best_loss = total_loss\n",
    "            # torch.save(model.state_dict(), model_path)\n",
    "            model_save = True\n",
    "            save_text = ' - model saved!'\n",
    "        else:\n",
    "            save_text = ''\n",
    "\n",
    "        epoch_duration = time.time() - start_time\n",
    "        training_time += epoch_duration\n",
    "        \n",
    "        text = f'\\tLoss: {epoch_loss:.4f}, Val_Loss: {val_loss:.4f}, Total Mean Loss: {total_loss/2:.4f}, LR: {lr}, Duration: {epoch_duration:.2f} sec{save_text}'\n",
    "        print(text)\n",
    "\n",
    "    # 예측 수행 및 레이블 저장\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # 혼동 행렬 생성\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # 예측과 실제 레이블\n",
    "    y_true = all_labels  # 실제 레이블\n",
    "    y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "    # 전체 데이터셋에 대한 정확도\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "    # 판다스 데이터프레임으로 결과 정리\n",
    "    performance_metrics = pd.DataFrame({\n",
    "        'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "        'Value': [accuracy, precision, recall, f1_score]\n",
    "    })\n",
    "\n",
    "    # 데이터프레임 출력\n",
    "    print(f\"\\n[{i*100+100} epoch result]\\n\", performance_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CASE 02: Big Grouped LLRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLRD_ConvNeXt(depths=[3,3,9,3]):\n",
    "    stage = 0\n",
    "    layer_names = []\n",
    "    for depth in depths:\n",
    "        if stage == 0:\n",
    "            layer_names.append(f'downsampling_layers.{stage}.stem_conv.weight')\n",
    "            layer_names.append(f'downsampling_layers.{stage}.stem_conv.bias')\n",
    "            layer_names.append(f'downsampling_layers.{stage}.stem_ln.weight')\n",
    "            layer_names.append(f'downsampling_layers.{stage}.stem_ln.bias')\n",
    "        else :\n",
    "            layer_names.append(f'downsampling_layers.{stage}.ds_ln.weight')\n",
    "            layer_names.append(f'downsampling_layers.{stage}.ds_ln.bias')\n",
    "            layer_names.append(f'downsampling_layers.{stage}.ds_conv.weight')\n",
    "            layer_names.append(f'downsampling_layers.{stage}.ds_conv.bias')\n",
    "        \n",
    "        for i in range(depth):\n",
    "            layer_names.append(f'stages.{stage}.{i}.dwconv.weight')\n",
    "            layer_names.append(f'stages.{stage}.{i}.dwconv.bias')\n",
    "            layer_names.append(f'stages.{stage}.{i}.layernorm.weight')\n",
    "            layer_names.append(f'stages.{stage}.{i}.layernorm.bias')\n",
    "            layer_names.append(f'stages.{stage}.{i}.pwconv1.weight')\n",
    "            layer_names.append(f'stages.{stage}.{i}.pwconv1.bias')\n",
    "            layer_names.append(f'stages.{stage}.{i}.grn.gamma')\n",
    "            layer_names.append(f'stages.{stage}.{i}.grn.beta')            \n",
    "            layer_names.append(f'stages.{stage}.{i}.pwconv2.weight')\n",
    "            layer_names.append(f'stages.{stage}.{i}.pwconv2.bias')\n",
    "        stage += 1\n",
    "    \n",
    "    layer_names.append('layernorm.weight')\n",
    "    layer_names.append('layernorm.bias')\n",
    "    layer_names.append('fc.weight')\n",
    "    layer_names.append('fc.bias')\n",
    "    return layer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: fc.bias | lr=0.008\n",
      "1: fc.weight | lr=0.008, weight decay=0.05\n",
      "2: layernorm.bias | lr=0.008\n",
      "3: layernorm.weight | lr=0.008\n",
      "4: stages.3.2.pwconv2.bias | lr=0.008\n",
      "5: stages.3.2.pwconv2.weight | lr=0.007200000000000001, weight decay=0.05\n",
      "6: stages.3.2.grn.beta | lr=0.008\n",
      "7: stages.3.2.grn.gamma | lr=0.008\n",
      "8: stages.3.2.pwconv1.bias | lr=0.008\n",
      "9: stages.3.2.pwconv1.weight | lr=0.007200000000000001, weight decay=0.05\n",
      "10: stages.3.2.layernorm.bias | lr=0.008\n",
      "11: stages.3.2.layernorm.weight | lr=0.008\n",
      "12: stages.3.2.dwconv.bias | lr=0.008\n",
      "13: stages.3.2.dwconv.weight | lr=0.007200000000000001, weight decay=0.05\n",
      "14: stages.3.1.pwconv2.bias | lr=0.008\n",
      "15: stages.3.1.pwconv2.weight | lr=0.007200000000000001, weight decay=0.05\n",
      "16: stages.3.1.grn.beta | lr=0.008\n",
      "17: stages.3.1.grn.gamma | lr=0.008\n",
      "18: stages.3.1.pwconv1.bias | lr=0.008\n",
      "19: stages.3.1.pwconv1.weight | lr=0.007200000000000001, weight decay=0.05\n",
      "20: stages.3.1.layernorm.bias | lr=0.008\n",
      "21: stages.3.1.layernorm.weight | lr=0.008\n",
      "22: stages.3.1.dwconv.bias | lr=0.008\n",
      "23: stages.3.1.dwconv.weight | lr=0.007200000000000001, weight decay=0.05\n",
      "24: stages.3.0.pwconv2.bias | lr=0.008\n",
      "25: stages.3.0.pwconv2.weight | lr=0.007200000000000001, weight decay=0.05\n",
      "26: stages.3.0.grn.beta | lr=0.008\n",
      "27: stages.3.0.grn.gamma | lr=0.008\n",
      "28: stages.3.0.pwconv1.bias | lr=0.008\n",
      "29: stages.3.0.pwconv1.weight | lr=0.007200000000000001, weight decay=0.05\n",
      "30: stages.3.0.layernorm.bias | lr=0.008\n",
      "31: stages.3.0.layernorm.weight | lr=0.008\n",
      "32: stages.3.0.dwconv.bias | lr=0.008\n",
      "33: stages.3.0.dwconv.weight | lr=0.007200000000000001, weight decay=0.05\n",
      "34: downsampling_layers.3.ds_conv.bias | lr=0.008\n",
      "35: downsampling_layers.3.ds_conv.weight | lr=0.0064800000000000005, weight decay=0.05\n",
      "36: downsampling_layers.3.ds_ln.bias | lr=0.008\n",
      "37: downsampling_layers.3.ds_ln.weight | lr=0.008\n",
      "38: stages.2.8.pwconv2.bias | lr=0.008\n",
      "39: stages.2.8.pwconv2.weight | lr=0.005832, weight decay=0.05\n",
      "40: stages.2.8.grn.beta | lr=0.008\n",
      "41: stages.2.8.grn.gamma | lr=0.008\n",
      "42: stages.2.8.pwconv1.bias | lr=0.008\n",
      "43: stages.2.8.pwconv1.weight | lr=0.005832, weight decay=0.05\n",
      "44: stages.2.8.layernorm.bias | lr=0.008\n",
      "45: stages.2.8.layernorm.weight | lr=0.008\n",
      "46: stages.2.8.dwconv.bias | lr=0.008\n",
      "47: stages.2.8.dwconv.weight | lr=0.005832, weight decay=0.05\n",
      "48: stages.2.7.pwconv2.bias | lr=0.008\n",
      "49: stages.2.7.pwconv2.weight | lr=0.005832, weight decay=0.05\n",
      "50: stages.2.7.grn.beta | lr=0.008\n",
      "51: stages.2.7.grn.gamma | lr=0.008\n",
      "52: stages.2.7.pwconv1.bias | lr=0.008\n",
      "53: stages.2.7.pwconv1.weight | lr=0.005832, weight decay=0.05\n",
      "54: stages.2.7.layernorm.bias | lr=0.008\n",
      "55: stages.2.7.layernorm.weight | lr=0.008\n",
      "56: stages.2.7.dwconv.bias | lr=0.008\n",
      "57: stages.2.7.dwconv.weight | lr=0.005832, weight decay=0.05\n",
      "58: stages.2.6.pwconv2.bias | lr=0.008\n",
      "59: stages.2.6.pwconv2.weight | lr=0.005832, weight decay=0.05\n",
      "60: stages.2.6.grn.beta | lr=0.008\n",
      "61: stages.2.6.grn.gamma | lr=0.008\n",
      "62: stages.2.6.pwconv1.bias | lr=0.008\n",
      "63: stages.2.6.pwconv1.weight | lr=0.005832, weight decay=0.05\n",
      "64: stages.2.6.layernorm.bias | lr=0.008\n",
      "65: stages.2.6.layernorm.weight | lr=0.008\n",
      "66: stages.2.6.dwconv.bias | lr=0.008\n",
      "67: stages.2.6.dwconv.weight | lr=0.005832, weight decay=0.05\n",
      "68: stages.2.5.pwconv2.bias | lr=0.008\n",
      "69: stages.2.5.pwconv2.weight | lr=0.005832, weight decay=0.05\n",
      "70: stages.2.5.grn.beta | lr=0.008\n",
      "71: stages.2.5.grn.gamma | lr=0.008\n",
      "72: stages.2.5.pwconv1.bias | lr=0.008\n",
      "73: stages.2.5.pwconv1.weight | lr=0.005832, weight decay=0.05\n",
      "74: stages.2.5.layernorm.bias | lr=0.008\n",
      "75: stages.2.5.layernorm.weight | lr=0.008\n",
      "76: stages.2.5.dwconv.bias | lr=0.008\n",
      "77: stages.2.5.dwconv.weight | lr=0.005832, weight decay=0.05\n",
      "78: stages.2.4.pwconv2.bias | lr=0.008\n",
      "79: stages.2.4.pwconv2.weight | lr=0.005832, weight decay=0.05\n",
      "80: stages.2.4.grn.beta | lr=0.008\n",
      "81: stages.2.4.grn.gamma | lr=0.008\n",
      "82: stages.2.4.pwconv1.bias | lr=0.008\n",
      "83: stages.2.4.pwconv1.weight | lr=0.005832, weight decay=0.05\n",
      "84: stages.2.4.layernorm.bias | lr=0.008\n",
      "85: stages.2.4.layernorm.weight | lr=0.008\n",
      "86: stages.2.4.dwconv.bias | lr=0.008\n",
      "87: stages.2.4.dwconv.weight | lr=0.005832, weight decay=0.05\n",
      "88: stages.2.3.pwconv2.bias | lr=0.008\n",
      "89: stages.2.3.pwconv2.weight | lr=0.005832, weight decay=0.05\n",
      "90: stages.2.3.grn.beta | lr=0.008\n",
      "91: stages.2.3.grn.gamma | lr=0.008\n",
      "92: stages.2.3.pwconv1.bias | lr=0.008\n",
      "93: stages.2.3.pwconv1.weight | lr=0.005832, weight decay=0.05\n",
      "94: stages.2.3.layernorm.bias | lr=0.008\n",
      "95: stages.2.3.layernorm.weight | lr=0.008\n",
      "96: stages.2.3.dwconv.bias | lr=0.008\n",
      "97: stages.2.3.dwconv.weight | lr=0.005832, weight decay=0.05\n",
      "98: stages.2.2.pwconv2.bias | lr=0.008\n",
      "99: stages.2.2.pwconv2.weight | lr=0.005832, weight decay=0.05\n",
      "100: stages.2.2.grn.beta | lr=0.008\n",
      "101: stages.2.2.grn.gamma | lr=0.008\n",
      "102: stages.2.2.pwconv1.bias | lr=0.008\n",
      "103: stages.2.2.pwconv1.weight | lr=0.005832, weight decay=0.05\n",
      "104: stages.2.2.layernorm.bias | lr=0.008\n",
      "105: stages.2.2.layernorm.weight | lr=0.008\n",
      "106: stages.2.2.dwconv.bias | lr=0.008\n",
      "107: stages.2.2.dwconv.weight | lr=0.005832, weight decay=0.05\n",
      "108: stages.2.1.pwconv2.bias | lr=0.008\n",
      "109: stages.2.1.pwconv2.weight | lr=0.005832, weight decay=0.05\n",
      "110: stages.2.1.grn.beta | lr=0.008\n",
      "111: stages.2.1.grn.gamma | lr=0.008\n",
      "112: stages.2.1.pwconv1.bias | lr=0.008\n",
      "113: stages.2.1.pwconv1.weight | lr=0.005832, weight decay=0.05\n",
      "114: stages.2.1.layernorm.bias | lr=0.008\n",
      "115: stages.2.1.layernorm.weight | lr=0.008\n",
      "116: stages.2.1.dwconv.bias | lr=0.008\n",
      "117: stages.2.1.dwconv.weight | lr=0.005832, weight decay=0.05\n",
      "118: stages.2.0.pwconv2.bias | lr=0.008\n",
      "119: stages.2.0.pwconv2.weight | lr=0.005832, weight decay=0.05\n",
      "120: stages.2.0.grn.beta | lr=0.008\n",
      "121: stages.2.0.grn.gamma | lr=0.008\n",
      "122: stages.2.0.pwconv1.bias | lr=0.008\n",
      "123: stages.2.0.pwconv1.weight | lr=0.005832, weight decay=0.05\n",
      "124: stages.2.0.layernorm.bias | lr=0.008\n",
      "125: stages.2.0.layernorm.weight | lr=0.008\n",
      "126: stages.2.0.dwconv.bias | lr=0.008\n",
      "127: stages.2.0.dwconv.weight | lr=0.005832, weight decay=0.05\n",
      "128: downsampling_layers.2.ds_conv.bias | lr=0.008\n",
      "129: downsampling_layers.2.ds_conv.weight | lr=0.0052488000000000005, weight decay=0.05\n",
      "130: downsampling_layers.2.ds_ln.bias | lr=0.008\n",
      "131: downsampling_layers.2.ds_ln.weight | lr=0.008\n",
      "132: stages.1.2.pwconv2.bias | lr=0.008\n",
      "133: stages.1.2.pwconv2.weight | lr=0.00472392, weight decay=0.05\n",
      "134: stages.1.2.grn.beta | lr=0.008\n",
      "135: stages.1.2.grn.gamma | lr=0.008\n",
      "136: stages.1.2.pwconv1.bias | lr=0.008\n",
      "137: stages.1.2.pwconv1.weight | lr=0.00472392, weight decay=0.05\n",
      "138: stages.1.2.layernorm.bias | lr=0.008\n",
      "139: stages.1.2.layernorm.weight | lr=0.008\n",
      "140: stages.1.2.dwconv.bias | lr=0.008\n",
      "141: stages.1.2.dwconv.weight | lr=0.00472392, weight decay=0.05\n",
      "142: stages.1.1.pwconv2.bias | lr=0.008\n",
      "143: stages.1.1.pwconv2.weight | lr=0.00472392, weight decay=0.05\n",
      "144: stages.1.1.grn.beta | lr=0.008\n",
      "145: stages.1.1.grn.gamma | lr=0.008\n",
      "146: stages.1.1.pwconv1.bias | lr=0.008\n",
      "147: stages.1.1.pwconv1.weight | lr=0.00472392, weight decay=0.05\n",
      "148: stages.1.1.layernorm.bias | lr=0.008\n",
      "149: stages.1.1.layernorm.weight | lr=0.008\n",
      "150: stages.1.1.dwconv.bias | lr=0.008\n",
      "151: stages.1.1.dwconv.weight | lr=0.00472392, weight decay=0.05\n",
      "152: stages.1.0.pwconv2.bias | lr=0.008\n",
      "153: stages.1.0.pwconv2.weight | lr=0.00472392, weight decay=0.05\n",
      "154: stages.1.0.grn.beta | lr=0.008\n",
      "155: stages.1.0.grn.gamma | lr=0.008\n",
      "156: stages.1.0.pwconv1.bias | lr=0.008\n",
      "157: stages.1.0.pwconv1.weight | lr=0.00472392, weight decay=0.05\n",
      "158: stages.1.0.layernorm.bias | lr=0.008\n",
      "159: stages.1.0.layernorm.weight | lr=0.008\n",
      "160: stages.1.0.dwconv.bias | lr=0.008\n",
      "161: stages.1.0.dwconv.weight | lr=0.00472392, weight decay=0.05\n",
      "162: downsampling_layers.1.ds_conv.bias | lr=0.008\n",
      "163: downsampling_layers.1.ds_conv.weight | lr=0.004251528, weight decay=0.05\n",
      "164: downsampling_layers.1.ds_ln.bias | lr=0.008\n",
      "165: downsampling_layers.1.ds_ln.weight | lr=0.008\n",
      "166: stages.0.2.pwconv2.bias | lr=0.008\n",
      "167: stages.0.2.pwconv2.weight | lr=0.0038263752, weight decay=0.05\n",
      "168: stages.0.2.grn.beta | lr=0.008\n",
      "169: stages.0.2.grn.gamma | lr=0.008\n",
      "170: stages.0.2.pwconv1.bias | lr=0.008\n",
      "171: stages.0.2.pwconv1.weight | lr=0.0038263752, weight decay=0.05\n",
      "172: stages.0.2.layernorm.bias | lr=0.008\n",
      "173: stages.0.2.layernorm.weight | lr=0.008\n",
      "174: stages.0.2.dwconv.bias | lr=0.008\n",
      "175: stages.0.2.dwconv.weight | lr=0.0038263752, weight decay=0.05\n",
      "176: stages.0.1.pwconv2.bias | lr=0.008\n",
      "177: stages.0.1.pwconv2.weight | lr=0.0038263752, weight decay=0.05\n",
      "178: stages.0.1.grn.beta | lr=0.008\n",
      "179: stages.0.1.grn.gamma | lr=0.008\n",
      "180: stages.0.1.pwconv1.bias | lr=0.008\n",
      "181: stages.0.1.pwconv1.weight | lr=0.0038263752, weight decay=0.05\n",
      "182: stages.0.1.layernorm.bias | lr=0.008\n",
      "183: stages.0.1.layernorm.weight | lr=0.008\n",
      "184: stages.0.1.dwconv.bias | lr=0.008\n",
      "185: stages.0.1.dwconv.weight | lr=0.0038263752, weight decay=0.05\n",
      "186: stages.0.0.pwconv2.bias | lr=0.008\n",
      "187: stages.0.0.pwconv2.weight | lr=0.0038263752, weight decay=0.05\n",
      "188: stages.0.0.grn.beta | lr=0.008\n",
      "189: stages.0.0.grn.gamma | lr=0.008\n",
      "190: stages.0.0.pwconv1.bias | lr=0.008\n",
      "191: stages.0.0.pwconv1.weight | lr=0.0038263752, weight decay=0.05\n",
      "192: stages.0.0.layernorm.bias | lr=0.008\n",
      "193: stages.0.0.layernorm.weight | lr=0.008\n",
      "194: stages.0.0.dwconv.bias | lr=0.008\n",
      "195: stages.0.0.dwconv.weight | lr=0.0038263752, weight decay=0.05\n",
      "196: downsampling_layers.0.stem_ln.bias | lr=0.008\n",
      "197: downsampling_layers.0.stem_ln.weight | lr=0.008\n",
      "198: downsampling_layers.0.stem_conv.bias | lr=0.008\n",
      "199: downsampling_layers.0.stem_conv.weight | lr=0.0038263752, weight decay=0.05\n"
     ]
    }
   ],
   "source": [
    "# LLRD\n",
    "layer_names = LLRD_ConvNeXt()\n",
    "    \n",
    "layer_names.reverse()\n",
    "\n",
    "lr0     = 8e-3  \n",
    "lr_mult = 0.9  \n",
    "weight_decay = 0.05 \n",
    "\n",
    "param_groups = []\n",
    "prev_group_name = layer_names[0].split('.')[0]\n",
    "\n",
    "lr = lr0\n",
    "for idx, name in enumerate(layer_names):\n",
    "    \n",
    "    cur_group_name = name.split('.')[0] if 'stage' not in name else name.split('.')[3]\n",
    "    \n",
    "    if cur_group_name != prev_group_name:\n",
    "        if (\"ln\" in name) | (\"layernorm\" in name) | ('grn' in name):\n",
    "            pass\n",
    "        else:\n",
    "            lr *= lr_mult\n",
    "    prev_group_name = cur_group_name\n",
    "    \n",
    "    if \"bias\" in name :\n",
    "        print(f\"{idx}: {name} | lr={lr0}\")\n",
    "        param_groups += [{'params': [ p for n, p in model.named_parameters() if n == name and p.requires_grad],\n",
    "                        'lr' : lr0}]\n",
    "    elif (\"ln\" in name) | (\"layernorm\" in name) | ('grn' in name):\n",
    "        param_groups += [{'params': [ p for n, p in model.named_parameters() if n == name and p.requires_grad],\n",
    "                        'lr' : lr0}]   \n",
    "        print(f\"{idx}: {name} | lr={lr0}\")\n",
    "    else :                    \n",
    "        param_groups += [{'params': [ p for n, p in model.named_parameters() if n == name and p.requires_grad],\n",
    "                        'lr' : lr,\n",
    "                        'weight_decay': weight_decay}]\n",
    "        print(f\"{idx}: {name} | lr={lr}, weight decay={weight_decay}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "optimizer = optim.AdamW(param_groups)\n",
    "warmup_steps = int(len(train_loader)*(epochs)*0.1)\n",
    "train_steps = len(train_loader)*(epochs)\n",
    "scheduler = CosineWarmupScheduler(optimizer, \n",
    "                                num_warmup_steps=warmup_steps, \n",
    "                                num_training_steps=train_steps,\n",
    "                                num_cycles=0.5,\n",
    "                                min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 43/43 [01:42<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.5180, Val_Loss: 3.9312, Total Mean Loss: 4.2246, LR: 0.0008000899999999999, Duration: 103.83 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.2863, Val_Loss: 3.6729, Total Mean Loss: 3.9796, LR: 0.00160008, Duration: 101.44 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 43/43 [01:41<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.2434, Val_Loss: 3.4453, Total Mean Loss: 3.8443, LR: 0.00240007, Duration: 102.48 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 43/43 [01:41<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.2196, Val_Loss: 3.3965, Total Mean Loss: 3.8080, LR: 0.00320006, Duration: 102.80 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.1591, Val_Loss: 3.4823, Total Mean Loss: 3.8207, LR: 0.004000050000000001, Duration: 102.07 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 43/43 [01:41<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.0840, Val_Loss: 3.2178, Total Mean Loss: 3.6509, LR: 0.00480004, Duration: 102.32 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.0583, Val_Loss: 3.1269, Total Mean Loss: 3.5926, LR: 0.005600030000000001, Duration: 101.99 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.9968, Val_Loss: 2.8364, Total Mean Loss: 3.4166, LR: 0.00640002, Duration: 101.50 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 43/43 [01:40<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.0051, Val_Loss: 2.9058, Total Mean Loss: 3.4555, LR: 0.0072000100000000015, Duration: 102.23 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 43/43 [01:41<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.0353, Val_Loss: 2.9450, Total Mean Loss: 3.4901, LR: 0.008, Duration: 102.89 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 43/43 [01:41<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.9091, Val_Loss: 2.6014, Total Mean Loss: 3.2553, LR: 0.007997563338535033, Duration: 102.90 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 43/43 [01:41<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.9051, Val_Loss: 2.5303, Total Mean Loss: 3.2177, LR: 0.007990256322836784, Duration: 102.86 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.8067, Val_Loss: 2.4842, Total Mean Loss: 3.1455, LR: 0.007978087855378325, Duration: 101.82 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7991, Val_Loss: 2.3731, Total Mean Loss: 3.0861, LR: 0.007961072761562845, Duration: 101.15 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7490, Val_Loss: 2.3557, Total Mean Loss: 3.0523, LR: 0.007939231771661183, Duration: 102.09 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7787, Val_Loss: 2.2882, Total Mean Loss: 3.0335, LR: 0.007912591495555185, Duration: 101.32 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6883, Val_Loss: 2.1393, Total Mean Loss: 2.9138, LR: 0.007881184390317672, Duration: 101.67 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 43/43 [01:41<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7241, Val_Loss: 2.1959, Total Mean Loss: 2.9600, LR: 0.007845048720668478, Duration: 102.38 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 43/43 [01:41<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6336, Val_Loss: 2.0578, Total Mean Loss: 2.8457, LR: 0.007804228512354801, Duration: 102.92 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6683, Val_Loss: 1.9487, Total Mean Loss: 2.8085, LR: 0.007758773498512596, Duration: 101.56 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6138, Val_Loss: 2.0420, Total Mean Loss: 2.8279, LR: 0.0077087390590744225, Duration: 101.77 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7099, Val_Loss: 2.0678, Total Mean Loss: 2.8889, LR: 0.007654186153297522, Duration: 101.87 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 43/43 [01:40<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5834, Val_Loss: 1.9258, Total Mean Loss: 2.7546, LR: 0.007595181245494354, Duration: 102.18 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 43/43 [01:40<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5902, Val_Loss: 1.9959, Total Mean Loss: 2.7930, LR: 0.007531796224056066, Duration: 102.27 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 43/43 [01:41<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4485, Val_Loss: 1.8237, Total Mean Loss: 2.6361, LR: 0.007464108313867567, Duration: 102.41 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6031, Val_Loss: 1.9028, Total Mean Loss: 2.7530, LR: 0.007392199982220897, Duration: 102.12 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4650, Val_Loss: 1.7997, Total Mean Loss: 2.6324, LR: 0.00731615883834154, Duration: 101.52 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4223, Val_Loss: 1.7926, Total Mean Loss: 2.6074, LR: 0.007236077526650072, Duration: 102.05 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.3020, Val_Loss: 1.6063, Total Mean Loss: 2.4541, LR: 0.007152053613889208, Duration: 102.06 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4899, Val_Loss: 1.6809, Total Mean Loss: 2.5854, LR: 0.007064189470253756, Duration: 101.49 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4294, Val_Loss: 1.6892, Total Mean Loss: 2.5593, LR: 0.006972592144668304, Duration: 101.18 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2263, Val_Loss: 1.5112, Total Mean Loss: 2.3688, LR: 0.0068773732343645885, Duration: 101.23 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2895, Val_Loss: 1.5868, Total Mean Loss: 2.4381, LR: 0.006778648748917467, Duration: 101.73 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2662, Val_Loss: 1.5269, Total Mean Loss: 2.3965, LR: 0.006676538968905116, Duration: 101.43 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.3019, Val_Loss: 1.5468, Total Mean Loss: 2.4243, LR: 0.006571168299365673, Duration: 101.39 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1560, Val_Loss: 1.4216, Total Mean Loss: 2.2888, LR: 0.006462665118228867, Duration: 101.34 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2292, Val_Loss: 1.2856, Total Mean Loss: 2.2574, LR: 0.006351161619907278, Duration: 101.75 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2592, Val_Loss: 1.4643, Total Mean Loss: 2.3617, LR: 0.006236793654237814, Duration: 101.71 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1493, Val_Loss: 1.4180, Total Mean Loss: 2.2836, LR: 0.006119700560969609, Duration: 101.42 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1676, Val_Loss: 1.2761, Total Mean Loss: 2.2219, LR: 0.006000025000000001, Duration: 101.89 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0931, Val_Loss: 1.3337, Total Mean Loss: 2.2134, LR: 0.005877912777565424, Duration: 101.80 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0823, Val_Loss: 1.3262, Total Mean Loss: 2.2043, LR: 0.005753512668598971, Duration: 102.04 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2443, Val_Loss: 1.3608, Total Mean Loss: 2.3026, LR: 0.005626976235471049, Duration: 101.54 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0265, Val_Loss: 1.3098, Total Mean Loss: 2.1681, LR: 0.005498457643333979, Duration: 101.76 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9171, Val_Loss: 1.2229, Total Mean Loss: 2.0700, LR: 0.00536811347229551, Duration: 101.24 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1220, Val_Loss: 1.2170, Total Mean Loss: 2.1695, LR: 0.005236102526650072, Duration: 101.51 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9869, Val_Loss: 1.3762, Total Mean Loss: 2.1815, LR: 0.005102585641400206, Duration: 101.07 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 43/43 [01:39<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9436, Val_Loss: 1.1937, Total Mean Loss: 2.0686, LR: 0.004967725486303891, Duration: 101.28 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9288, Val_Loss: 1.2099, Total Mean Loss: 2.0693, LR: 0.004831686367686497, Duration: 101.33 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9507, Val_Loss: 1.1212, Total Mean Loss: 2.0360, LR: 0.004694634028258839, Duration: 100.86 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9776, Val_Loss: 1.2638, Total Mean Loss: 2.1207, LR: 0.004556735445185214, Duration: 101.52 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8757, Val_Loss: 1.1443, Total Mean Loss: 2.0100, LR: 0.004418158626647451, Duration: 101.32 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0538, Val_Loss: 1.2393, Total Mean Loss: 2.1465, LR: 0.004279072407152814, Duration: 101.66 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8893, Val_Loss: 1.1340, Total Mean Loss: 2.0117, LR: 0.00413964624183517, Duration: 100.98 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 43/43 [01:39<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9374, Val_Loss: 1.1313, Total Mean Loss: 2.0343, LR: 0.004000050000000001, Duration: 101.28 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7037, Val_Loss: 1.0179, Total Mean Loss: 1.8608, LR: 0.0038604537581648324, Duration: 101.51 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0565, Val_Loss: 1.1101, Total Mean Loss: 2.0833, LR: 0.0037210275928471863, Duration: 100.95 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7363, Val_Loss: 1.0155, Total Mean Loss: 1.8759, LR: 0.00358194137335255, Duration: 101.44 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8171, Val_Loss: 1.1080, Total Mean Loss: 1.9626, LR: 0.0034433645548147874, Duration: 101.63 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0577, Val_Loss: 1.1116, Total Mean Loss: 2.0847, LR: 0.0033054659717411624, Duration: 101.17 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7438, Val_Loss: 1.0150, Total Mean Loss: 1.8794, LR: 0.003168413632313504, Duration: 100.93 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7507, Val_Loss: 1.1259, Total Mean Loss: 1.9383, LR: 0.00303237451369611, Duration: 101.02 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8709, Val_Loss: 1.0953, Total Mean Loss: 1.9831, LR: 0.0028975143585997947, Duration: 101.29 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7289, Val_Loss: 1.0432, Total Mean Loss: 1.8861, LR: 0.0027639974733499294, Duration: 101.22 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8669, Val_Loss: 1.1093, Total Mean Loss: 1.9881, LR: 0.002631986527704492, Duration: 100.96 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9030, Val_Loss: 1.0627, Total Mean Loss: 1.9829, LR: 0.0025016423566660228, Duration: 101.07 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8046, Val_Loss: 1.0254, Total Mean Loss: 1.9150, LR: 0.0023731237645289536, Duration: 100.81 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8493, Val_Loss: 1.0674, Total Mean Loss: 1.9583, LR: 0.0022465873314010294, Duration: 101.32 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8641, Val_Loss: 1.1029, Total Mean Loss: 1.9835, LR: 0.002122187222434577, Duration: 100.71 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7768, Val_Loss: 1.0816, Total Mean Loss: 1.9292, LR: 0.002000075000000001, Duration: 100.79 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7133, Val_Loss: 0.9989, Total Mean Loss: 1.8561, LR: 0.0018803994390303928, Duration: 100.82 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72: 100%|██████████| 43/43 [01:39<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8305, Val_Loss: 1.0266, Total Mean Loss: 1.9286, LR: 0.001763306345762187, Duration: 101.27 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7543, Val_Loss: 1.0482, Total Mean Loss: 1.9013, LR: 0.0016489383800927227, Duration: 100.79 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7251, Val_Loss: 0.9862, Total Mean Loss: 1.8556, LR: 0.0015374348817711334, Duration: 100.69 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7442, Val_Loss: 1.0308, Total Mean Loss: 1.8875, LR: 0.001428931700634327, Duration: 100.93 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5932, Val_Loss: 1.0323, Total Mean Loss: 1.8127, LR: 0.0013235610310948864, Duration: 101.45 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6646, Val_Loss: 1.0073, Total Mean Loss: 1.8360, LR: 0.0012214512510825336, Duration: 101.04 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6945, Val_Loss: 1.0292, Total Mean Loss: 1.8619, LR: 0.0011227267656354132, Duration: 101.65 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79: 100%|██████████| 43/43 [01:40<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6632, Val_Loss: 0.9990, Total Mean Loss: 1.8311, LR: 0.0010275078553316965, Duration: 102.21 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4726, Val_Loss: 1.0122, Total Mean Loss: 1.7424, LR: 0.0009359105297462444, Duration: 101.61 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5337, Val_Loss: 1.0280, Total Mean Loss: 1.7809, LR: 0.0008480463861107927, Duration: 101.37 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5877, Val_Loss: 0.9956, Total Mean Loss: 1.7917, LR: 0.0007640224733499294, Duration: 101.32 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7055, Val_Loss: 1.0279, Total Mean Loss: 1.8667, LR: 0.0006839411616584612, Duration: 101.52 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7083, Val_Loss: 1.0136, Total Mean Loss: 1.8610, LR: 0.000607900017779104, Duration: 101.17 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85: 100%|██████████| 43/43 [01:39<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5911, Val_Loss: 1.0010, Total Mean Loss: 1.7961, LR: 0.0005359916861324344, Duration: 101.26 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5469, Val_Loss: 0.9872, Total Mean Loss: 1.7670, LR: 0.000468303775943935, Duration: 101.75 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87: 100%|██████████| 43/43 [01:40<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7433, Val_Loss: 1.0136, Total Mean Loss: 1.8784, LR: 0.0004049187545056477, Duration: 102.19 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5460, Val_Loss: 1.0011, Total Mean Loss: 1.7735, LR: 0.00034591384670247825, Duration: 101.08 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5303, Val_Loss: 0.9884, Total Mean Loss: 1.7594, LR: 0.0002913609409255791, Duration: 101.79 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4586, Val_Loss: 0.9728, Total Mean Loss: 1.7157, LR: 0.00024132650148740606, Duration: 101.78 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91: 100%|██████████| 43/43 [01:40<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5575, Val_Loss: 0.9640, Total Mean Loss: 1.7608, LR: 0.00019587148764520066, Duration: 102.27 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92: 100%|██████████| 43/43 [01:40<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6067, Val_Loss: 0.9753, Total Mean Loss: 1.7910, LR: 0.00015505127933152136, Duration: 102.16 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4709, Val_Loss: 0.9677, Total Mean Loss: 1.7193, LR: 0.00011891560968232792, Duration: 101.25 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5218, Val_Loss: 0.9832, Total Mean Loss: 1.7525, LR: 8.750850444481394e-05, Duration: 101.47 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5693, Val_Loss: 0.9713, Total Mean Loss: 1.7703, LR: 6.0868228338818537e-05, Duration: 101.67 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4227, Val_Loss: 0.9721, Total Mean Loss: 1.6974, LR: 3.902723843715564e-05, Duration: 101.59 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5857, Val_Loss: 0.9726, Total Mean Loss: 1.7791, LR: 2.2012144621675257e-05, Duration: 101.69 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6866, Val_Loss: 0.9718, Total Mean Loss: 1.8292, LR: 9.843677163216202e-06, Duration: 101.70 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6309, Val_Loss: 0.9722, Total Mean Loss: 1.8015, LR: 2.5366614649679064e-06, Duration: 101.63 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5531, Val_Loss: 0.9721, Total Mean Loss: 1.7626, LR: 1e-07, Duration: 101.00 sec\n",
      "\n",
      "[100 epoch result]\n",
      "       Metric     Value\n",
      "0   Accuracy  0.858000\n",
      "1  Precision  0.877226\n",
      "2     Recall  0.858000\n",
      "3   F1 Score  0.852452\n"
     ]
    }
   ],
   "source": [
    "training_time = 0\n",
    "losses = []\n",
    "val_losses = []\n",
    "lrs = []\n",
    "best_loss = float('inf')\n",
    "model_save = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "for i in range(epochs // 100):\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1 + i*100}\")\n",
    "        \n",
    "        for _, data in pbar:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            inputs, labels = mixup_fn(inputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "                \n",
    "            loss.backward()\n",
    "            # 그라디언트 클리핑 적용\n",
    "            clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # EMA 모델 업데이트, 필요한 경우\n",
    "            if model_ema is not None:\n",
    "                model_ema.update(model)\n",
    "                \n",
    "            scheduler.step()\n",
    "                \n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "            lrs.append(lr)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        losses.append(epoch_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for data in valid_loader:\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "        val_loss /= len(valid_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # 모델 저장 조건 수정\n",
    "        total_loss = val_loss + epoch_loss\n",
    "        if total_loss < best_loss:\n",
    "            best_loss = total_loss\n",
    "            # torch.save(model.state_dict(), model_path)\n",
    "            model_save = True\n",
    "            save_text = ' - model saved!'\n",
    "        else:\n",
    "            save_text = ''\n",
    "\n",
    "        epoch_duration = time.time() - start_time\n",
    "        training_time += epoch_duration\n",
    "        \n",
    "        text = f'\\tLoss: {epoch_loss:.4f}, Val_Loss: {val_loss:.4f}, Total Mean Loss: {total_loss/2:.4f}, LR: {lr}, Duration: {epoch_duration:.2f} sec{save_text}'\n",
    "        print(text)\n",
    "\n",
    "    # 예측 수행 및 레이블 저장\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # 혼동 행렬 생성\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # 예측과 실제 레이블\n",
    "    y_true = all_labels  # 실제 레이블\n",
    "    y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "    # 전체 데이터셋에 대한 정확도\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "    # 판다스 데이터프레임으로 결과 정리\n",
    "    performance_metrics = pd.DataFrame({\n",
    "        'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "        'Value': [accuracy, precision, recall, f1_score]\n",
    "    })\n",
    "\n",
    "    # 데이터프레임 출력\n",
    "    print(f\"\\n[{i*100+100} epoch result]\\n\", performance_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CASE 3 : Layer LLRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: fc.bias | lr=0.008\n",
      "1: fc.weight | lr=0.008, weight decay=0.05\n",
      "2: layernorm.bias | lr=0.008\n",
      "3: layernorm.weight | lr=0.008\n",
      "4: stages.3.2.pwconv2.bias | lr=0.008\n",
      "5: stages.3.2.pwconv2.weight | lr=0.007200000000000001, weight decay=0.05\n",
      "6: stages.3.2.grn.beta | lr=0.008\n",
      "7: stages.3.2.grn.gamma | lr=0.008\n",
      "8: stages.3.2.pwconv1.bias | lr=0.008\n",
      "9: stages.3.2.pwconv1.weight | lr=0.0064800000000000005, weight decay=0.05\n",
      "10: stages.3.2.layernorm.bias | lr=0.008\n",
      "11: stages.3.2.layernorm.weight | lr=0.008\n",
      "12: stages.3.2.dwconv.bias | lr=0.008\n",
      "13: stages.3.2.dwconv.weight | lr=0.005832, weight decay=0.05\n",
      "14: stages.3.1.pwconv2.bias | lr=0.008\n",
      "15: stages.3.1.pwconv2.weight | lr=0.0052488000000000005, weight decay=0.05\n",
      "16: stages.3.1.grn.beta | lr=0.008\n",
      "17: stages.3.1.grn.gamma | lr=0.008\n",
      "18: stages.3.1.pwconv1.bias | lr=0.008\n",
      "19: stages.3.1.pwconv1.weight | lr=0.00472392, weight decay=0.05\n",
      "20: stages.3.1.layernorm.bias | lr=0.008\n",
      "21: stages.3.1.layernorm.weight | lr=0.008\n",
      "22: stages.3.1.dwconv.bias | lr=0.008\n",
      "23: stages.3.1.dwconv.weight | lr=0.004251528, weight decay=0.05\n",
      "24: stages.3.0.pwconv2.bias | lr=0.008\n",
      "25: stages.3.0.pwconv2.weight | lr=0.0038263752, weight decay=0.05\n",
      "26: stages.3.0.grn.beta | lr=0.008\n",
      "27: stages.3.0.grn.gamma | lr=0.008\n",
      "28: stages.3.0.pwconv1.bias | lr=0.008\n",
      "29: stages.3.0.pwconv1.weight | lr=0.00344373768, weight decay=0.05\n",
      "30: stages.3.0.layernorm.bias | lr=0.008\n",
      "31: stages.3.0.layernorm.weight | lr=0.008\n",
      "32: stages.3.0.dwconv.bias | lr=0.008\n",
      "33: stages.3.0.dwconv.weight | lr=0.003099363912, weight decay=0.05\n",
      "34: downsampling_layers.3.ds_conv.bias | lr=0.008\n",
      "35: downsampling_layers.3.ds_conv.weight | lr=0.0027894275208, weight decay=0.05\n",
      "36: downsampling_layers.3.ds_ln.bias | lr=0.008\n",
      "37: downsampling_layers.3.ds_ln.weight | lr=0.008\n",
      "38: stages.2.8.pwconv2.bias | lr=0.008\n",
      "39: stages.2.8.pwconv2.weight | lr=0.0025104847687200003, weight decay=0.05\n",
      "40: stages.2.8.grn.beta | lr=0.008\n",
      "41: stages.2.8.grn.gamma | lr=0.008\n",
      "42: stages.2.8.pwconv1.bias | lr=0.008\n",
      "43: stages.2.8.pwconv1.weight | lr=0.0022594362918480003, weight decay=0.05\n",
      "44: stages.2.8.layernorm.bias | lr=0.008\n",
      "45: stages.2.8.layernorm.weight | lr=0.008\n",
      "46: stages.2.8.dwconv.bias | lr=0.008\n",
      "47: stages.2.8.dwconv.weight | lr=0.0020334926626632004, weight decay=0.05\n",
      "48: stages.2.7.pwconv2.bias | lr=0.008\n",
      "49: stages.2.7.pwconv2.weight | lr=0.0018301433963968804, weight decay=0.05\n",
      "50: stages.2.7.grn.beta | lr=0.008\n",
      "51: stages.2.7.grn.gamma | lr=0.008\n",
      "52: stages.2.7.pwconv1.bias | lr=0.008\n",
      "53: stages.2.7.pwconv1.weight | lr=0.0016471290567571925, weight decay=0.05\n",
      "54: stages.2.7.layernorm.bias | lr=0.008\n",
      "55: stages.2.7.layernorm.weight | lr=0.008\n",
      "56: stages.2.7.dwconv.bias | lr=0.008\n",
      "57: stages.2.7.dwconv.weight | lr=0.0014824161510814734, weight decay=0.05\n",
      "58: stages.2.6.pwconv2.bias | lr=0.008\n",
      "59: stages.2.6.pwconv2.weight | lr=0.001334174535973326, weight decay=0.05\n",
      "60: stages.2.6.grn.beta | lr=0.008\n",
      "61: stages.2.6.grn.gamma | lr=0.008\n",
      "62: stages.2.6.pwconv1.bias | lr=0.008\n",
      "63: stages.2.6.pwconv1.weight | lr=0.0012007570823759936, weight decay=0.05\n",
      "64: stages.2.6.layernorm.bias | lr=0.008\n",
      "65: stages.2.6.layernorm.weight | lr=0.008\n",
      "66: stages.2.6.dwconv.bias | lr=0.008\n",
      "67: stages.2.6.dwconv.weight | lr=0.0010806813741383943, weight decay=0.05\n",
      "68: stages.2.5.pwconv2.bias | lr=0.008\n",
      "69: stages.2.5.pwconv2.weight | lr=0.0009726132367245549, weight decay=0.05\n",
      "70: stages.2.5.grn.beta | lr=0.008\n",
      "71: stages.2.5.grn.gamma | lr=0.008\n",
      "72: stages.2.5.pwconv1.bias | lr=0.008\n",
      "73: stages.2.5.pwconv1.weight | lr=0.0008753519130520994, weight decay=0.05\n",
      "74: stages.2.5.layernorm.bias | lr=0.008\n",
      "75: stages.2.5.layernorm.weight | lr=0.008\n",
      "76: stages.2.5.dwconv.bias | lr=0.008\n",
      "77: stages.2.5.dwconv.weight | lr=0.0007878167217468895, weight decay=0.05\n",
      "78: stages.2.4.pwconv2.bias | lr=0.008\n",
      "79: stages.2.4.pwconv2.weight | lr=0.0007090350495722005, weight decay=0.05\n",
      "80: stages.2.4.grn.beta | lr=0.008\n",
      "81: stages.2.4.grn.gamma | lr=0.008\n",
      "82: stages.2.4.pwconv1.bias | lr=0.008\n",
      "83: stages.2.4.pwconv1.weight | lr=0.0006381315446149805, weight decay=0.05\n",
      "84: stages.2.4.layernorm.bias | lr=0.008\n",
      "85: stages.2.4.layernorm.weight | lr=0.008\n",
      "86: stages.2.4.dwconv.bias | lr=0.008\n",
      "87: stages.2.4.dwconv.weight | lr=0.0005743183901534824, weight decay=0.05\n",
      "88: stages.2.3.pwconv2.bias | lr=0.008\n",
      "89: stages.2.3.pwconv2.weight | lr=0.0005168865511381342, weight decay=0.05\n",
      "90: stages.2.3.grn.beta | lr=0.008\n",
      "91: stages.2.3.grn.gamma | lr=0.008\n",
      "92: stages.2.3.pwconv1.bias | lr=0.008\n",
      "93: stages.2.3.pwconv1.weight | lr=0.0004651978960243208, weight decay=0.05\n",
      "94: stages.2.3.layernorm.bias | lr=0.008\n",
      "95: stages.2.3.layernorm.weight | lr=0.008\n",
      "96: stages.2.3.dwconv.bias | lr=0.008\n",
      "97: stages.2.3.dwconv.weight | lr=0.00041867810642188874, weight decay=0.05\n",
      "98: stages.2.2.pwconv2.bias | lr=0.008\n",
      "99: stages.2.2.pwconv2.weight | lr=0.0003768102957796999, weight decay=0.05\n",
      "100: stages.2.2.grn.beta | lr=0.008\n",
      "101: stages.2.2.grn.gamma | lr=0.008\n",
      "102: stages.2.2.pwconv1.bias | lr=0.008\n",
      "103: stages.2.2.pwconv1.weight | lr=0.0003391292662017299, weight decay=0.05\n",
      "104: stages.2.2.layernorm.bias | lr=0.008\n",
      "105: stages.2.2.layernorm.weight | lr=0.008\n",
      "106: stages.2.2.dwconv.bias | lr=0.008\n",
      "107: stages.2.2.dwconv.weight | lr=0.0003052163395815569, weight decay=0.05\n",
      "108: stages.2.1.pwconv2.bias | lr=0.008\n",
      "109: stages.2.1.pwconv2.weight | lr=0.0002746947056234012, weight decay=0.05\n",
      "110: stages.2.1.grn.beta | lr=0.008\n",
      "111: stages.2.1.grn.gamma | lr=0.008\n",
      "112: stages.2.1.pwconv1.bias | lr=0.008\n",
      "113: stages.2.1.pwconv1.weight | lr=0.0002472252350610611, weight decay=0.05\n",
      "114: stages.2.1.layernorm.bias | lr=0.008\n",
      "115: stages.2.1.layernorm.weight | lr=0.008\n",
      "116: stages.2.1.dwconv.bias | lr=0.008\n",
      "117: stages.2.1.dwconv.weight | lr=0.000222502711554955, weight decay=0.05\n",
      "118: stages.2.0.pwconv2.bias | lr=0.008\n",
      "119: stages.2.0.pwconv2.weight | lr=0.00020025244039945951, weight decay=0.05\n",
      "120: stages.2.0.grn.beta | lr=0.008\n",
      "121: stages.2.0.grn.gamma | lr=0.008\n",
      "122: stages.2.0.pwconv1.bias | lr=0.008\n",
      "123: stages.2.0.pwconv1.weight | lr=0.00018022719635951356, weight decay=0.05\n",
      "124: stages.2.0.layernorm.bias | lr=0.008\n",
      "125: stages.2.0.layernorm.weight | lr=0.008\n",
      "126: stages.2.0.dwconv.bias | lr=0.008\n",
      "127: stages.2.0.dwconv.weight | lr=0.0001622044767235622, weight decay=0.05\n",
      "128: downsampling_layers.2.ds_conv.bias | lr=0.008\n",
      "129: downsampling_layers.2.ds_conv.weight | lr=0.00014598402905120598, weight decay=0.05\n",
      "130: downsampling_layers.2.ds_ln.bias | lr=0.008\n",
      "131: downsampling_layers.2.ds_ln.weight | lr=0.008\n",
      "132: stages.1.2.pwconv2.bias | lr=0.008\n",
      "133: stages.1.2.pwconv2.weight | lr=0.0001313856261460854, weight decay=0.05\n",
      "134: stages.1.2.grn.beta | lr=0.008\n",
      "135: stages.1.2.grn.gamma | lr=0.008\n",
      "136: stages.1.2.pwconv1.bias | lr=0.008\n",
      "137: stages.1.2.pwconv1.weight | lr=0.00011824706353147685, weight decay=0.05\n",
      "138: stages.1.2.layernorm.bias | lr=0.008\n",
      "139: stages.1.2.layernorm.weight | lr=0.008\n",
      "140: stages.1.2.dwconv.bias | lr=0.008\n",
      "141: stages.1.2.dwconv.weight | lr=0.00010642235717832917, weight decay=0.05\n",
      "142: stages.1.1.pwconv2.bias | lr=0.008\n",
      "143: stages.1.1.pwconv2.weight | lr=9.578012146049625e-05, weight decay=0.05\n",
      "144: stages.1.1.grn.beta | lr=0.008\n",
      "145: stages.1.1.grn.gamma | lr=0.008\n",
      "146: stages.1.1.pwconv1.bias | lr=0.008\n",
      "147: stages.1.1.pwconv1.weight | lr=8.620210931444663e-05, weight decay=0.05\n",
      "148: stages.1.1.layernorm.bias | lr=0.008\n",
      "149: stages.1.1.layernorm.weight | lr=0.008\n",
      "150: stages.1.1.dwconv.bias | lr=0.008\n",
      "151: stages.1.1.dwconv.weight | lr=7.758189838300197e-05, weight decay=0.05\n",
      "152: stages.1.0.pwconv2.bias | lr=0.008\n",
      "153: stages.1.0.pwconv2.weight | lr=6.982370854470178e-05, weight decay=0.05\n",
      "154: stages.1.0.grn.beta | lr=0.008\n",
      "155: stages.1.0.grn.gamma | lr=0.008\n",
      "156: stages.1.0.pwconv1.bias | lr=0.008\n",
      "157: stages.1.0.pwconv1.weight | lr=6.28413376902316e-05, weight decay=0.05\n",
      "158: stages.1.0.layernorm.bias | lr=0.008\n",
      "159: stages.1.0.layernorm.weight | lr=0.008\n",
      "160: stages.1.0.dwconv.bias | lr=0.008\n",
      "161: stages.1.0.dwconv.weight | lr=5.6557203921208445e-05, weight decay=0.05\n",
      "162: downsampling_layers.1.ds_conv.bias | lr=0.008\n",
      "163: downsampling_layers.1.ds_conv.weight | lr=5.0901483529087605e-05, weight decay=0.05\n",
      "164: downsampling_layers.1.ds_ln.bias | lr=0.008\n",
      "165: downsampling_layers.1.ds_ln.weight | lr=0.008\n",
      "166: stages.0.2.pwconv2.bias | lr=0.008\n",
      "167: stages.0.2.pwconv2.weight | lr=4.5811335176178844e-05, weight decay=0.05\n",
      "168: stages.0.2.grn.beta | lr=0.008\n",
      "169: stages.0.2.grn.gamma | lr=0.008\n",
      "170: stages.0.2.pwconv1.bias | lr=0.008\n",
      "171: stages.0.2.pwconv1.weight | lr=4.123020165856096e-05, weight decay=0.05\n",
      "172: stages.0.2.layernorm.bias | lr=0.008\n",
      "173: stages.0.2.layernorm.weight | lr=0.008\n",
      "174: stages.0.2.dwconv.bias | lr=0.008\n",
      "175: stages.0.2.dwconv.weight | lr=3.7107181492704867e-05, weight decay=0.05\n",
      "176: stages.0.1.pwconv2.bias | lr=0.008\n",
      "177: stages.0.1.pwconv2.weight | lr=3.3396463343434384e-05, weight decay=0.05\n",
      "178: stages.0.1.grn.beta | lr=0.008\n",
      "179: stages.0.1.grn.gamma | lr=0.008\n",
      "180: stages.0.1.pwconv1.bias | lr=0.008\n",
      "181: stages.0.1.pwconv1.weight | lr=3.0056817009090947e-05, weight decay=0.05\n",
      "182: stages.0.1.layernorm.bias | lr=0.008\n",
      "183: stages.0.1.layernorm.weight | lr=0.008\n",
      "184: stages.0.1.dwconv.bias | lr=0.008\n",
      "185: stages.0.1.dwconv.weight | lr=2.7051135308181854e-05, weight decay=0.05\n",
      "186: stages.0.0.pwconv2.bias | lr=0.008\n",
      "187: stages.0.0.pwconv2.weight | lr=2.434602177736367e-05, weight decay=0.05\n",
      "188: stages.0.0.grn.beta | lr=0.008\n",
      "189: stages.0.0.grn.gamma | lr=0.008\n",
      "190: stages.0.0.pwconv1.bias | lr=0.008\n",
      "191: stages.0.0.pwconv1.weight | lr=2.1911419599627302e-05, weight decay=0.05\n",
      "192: stages.0.0.layernorm.bias | lr=0.008\n",
      "193: stages.0.0.layernorm.weight | lr=0.008\n",
      "194: stages.0.0.dwconv.bias | lr=0.008\n",
      "195: stages.0.0.dwconv.weight | lr=1.9720277639664573e-05, weight decay=0.05\n",
      "196: downsampling_layers.0.stem_ln.bias | lr=0.008\n",
      "197: downsampling_layers.0.stem_ln.weight | lr=0.008\n",
      "198: downsampling_layers.0.stem_conv.bias | lr=0.008\n",
      "199: downsampling_layers.0.stem_conv.weight | lr=1.9720277639664573e-05, weight decay=0.05\n"
     ]
    }
   ],
   "source": [
    "# LLRD\n",
    "layer_names = LLRD_ConvNeXt()\n",
    "    \n",
    "layer_names.reverse()\n",
    "\n",
    "lr0     = 8e-3  \n",
    "lr_mult = 0.9  \n",
    "weight_decay = 0.05 \n",
    "\n",
    "param_groups = []\n",
    "prev_group_name = layer_names[0].split('.')[0]\n",
    "\n",
    "lr = lr0\n",
    "for idx, name in enumerate(layer_names):\n",
    "    \n",
    "    cur_group_name = name.split('.')[0] if 'stage' not in name else name.split('.')[3]\n",
    "    \n",
    "    if cur_group_name != prev_group_name:\n",
    "        if (\"ln\" in name) | (\"layernorm\" in name) | ('grn' in name):\n",
    "            pass\n",
    "        else:\n",
    "            lr *= lr_mult\n",
    "    prev_group_name = cur_group_name\n",
    "    \n",
    "    if \"bias\" in name :\n",
    "        print(f\"{idx}: {name} | lr={lr0}\")\n",
    "        param_groups += [{'params': [ p for n, p in model.named_parameters() if n == name and p.requires_grad],\n",
    "                        'lr' : lr0}]\n",
    "    elif (\"ln\" in name) | (\"layernorm\" in name) | ('grn' in name):\n",
    "        param_groups += [{'params': [ p for n, p in model.named_parameters() if n == name and p.requires_grad],\n",
    "                        'lr' : lr0}]   \n",
    "        print(f\"{idx}: {name} | lr={lr0}\")\n",
    "    else :                    \n",
    "        param_groups += [{'params': [ p for n, p in model.named_parameters() if n == name and p.requires_grad],\n",
    "                        'lr' : lr,\n",
    "                        'weight_decay': weight_decay}]\n",
    "        print(f\"{idx}: {name} | lr={lr}, weight decay={weight_decay}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "optimizer = optim.AdamW(param_groups)\n",
    "warmup_steps = int(len(train_loader)*(epochs)*0.1)\n",
    "train_steps = len(train_loader)*(epochs)\n",
    "scheduler = CosineWarmupScheduler(optimizer, \n",
    "                                num_warmup_steps=warmup_steps, \n",
    "                                num_training_steps=train_steps,\n",
    "                                num_cycles=0.5,\n",
    "                                min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 43/43 [01:42<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.5438, Val_Loss: 4.0799, Total Mean Loss: 4.3118, LR: 0.0008000899999999999, Duration: 103.99 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 43/43 [01:42<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.3563, Val_Loss: 3.5882, Total Mean Loss: 3.9722, LR: 0.00160008, Duration: 104.07 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  33%|███▎      | 14/43 [00:33<01:09,  2.41s/it]"
     ]
    }
   ],
   "source": [
    "training_time = 0\n",
    "losses = []\n",
    "val_losses = []\n",
    "lrs = []\n",
    "best_loss = float('inf')\n",
    "model_save = False\n",
    "\n",
    "for i in range(epochs // 100):\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1 + i*100}\")\n",
    "        \n",
    "        for _, data in pbar:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            inputs, labels = mixup_fn(inputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "                \n",
    "            loss.backward()\n",
    "            # 그라디언트 클리핑 적용\n",
    "            clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # EMA 모델 업데이트, 필요한 경우\n",
    "            if model_ema is not None:\n",
    "                model_ema.update(model)\n",
    "                \n",
    "            scheduler.step()\n",
    "                \n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "            lrs.append(lr)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        losses.append(epoch_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for data in valid_loader:\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "        val_loss /= len(valid_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # 모델 저장 조건 수정\n",
    "        total_loss = val_loss + epoch_loss\n",
    "        if total_loss < best_loss:\n",
    "            best_loss = total_loss\n",
    "            # torch.save(model.state_dict(), model_path)\n",
    "            model_save = True\n",
    "            save_text = ' - model saved!'\n",
    "        else:\n",
    "            save_text = ''\n",
    "\n",
    "        epoch_duration = time.time() - start_time\n",
    "        training_time += epoch_duration\n",
    "        \n",
    "        text = f'\\tLoss: {epoch_loss:.4f}, Val_Loss: {val_loss:.4f}, Total Mean Loss: {total_loss/2:.4f}, LR: {lr}, Duration: {epoch_duration:.2f} sec{save_text}'\n",
    "        print(text)\n",
    "\n",
    "    # 예측 수행 및 레이블 저장\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # 혼동 행렬 생성\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # 예측과 실제 레이블\n",
    "    y_true = all_labels  # 실제 레이블\n",
    "    y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "    # 전체 데이터셋에 대한 정확도\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "    # 판다스 데이터프레임으로 결과 정리\n",
    "    performance_metrics = pd.DataFrame({\n",
    "        'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "        'Value': [accuracy, precision, recall, f1_score]\n",
    "    })\n",
    "\n",
    "    # 데이터프레임 출력\n",
    "    print(f\"\\n[{i*100+100} epoch result]\\n\", performance_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 43/43 [01:41<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.5439, Val_Loss: 4.0509, Total Mean Loss: 4.2974, LR: 0.0008000899999999999, Duration: 102.92 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 43/43 [01:41<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.3294, Val_Loss: 3.5472, Total Mean Loss: 3.9383, LR: 0.00160008, Duration: 102.44 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.2834, Val_Loss: 3.5339, Total Mean Loss: 3.9086, LR: 0.00240007, Duration: 100.74 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.2321, Val_Loss: 3.4487, Total Mean Loss: 3.8404, LR: 0.00320006, Duration: 100.86 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.1701, Val_Loss: 3.3304, Total Mean Loss: 3.7502, LR: 0.004000050000000001, Duration: 100.54 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.1254, Val_Loss: 3.2773, Total Mean Loss: 3.7013, LR: 0.00480004, Duration: 100.50 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.1032, Val_Loss: 3.1169, Total Mean Loss: 3.6100, LR: 0.005600030000000001, Duration: 100.55 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.0418, Val_Loss: 3.0981, Total Mean Loss: 3.5699, LR: 0.00640002, Duration: 100.70 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.9627, Val_Loss: 2.9042, Total Mean Loss: 3.4334, LR: 0.0072000100000000015, Duration: 100.70 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.0032, Val_Loss: 2.8879, Total Mean Loss: 3.4455, LR: 0.008, Duration: 100.50 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 43/43 [01:38<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.9659, Val_Loss: 2.8123, Total Mean Loss: 3.3891, LR: 0.007997563338535033, Duration: 100.15 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.9466, Val_Loss: 2.6422, Total Mean Loss: 3.2944, LR: 0.007990256322836784, Duration: 100.60 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 43/43 [01:39<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.9360, Val_Loss: 2.5884, Total Mean Loss: 3.2622, LR: 0.007978087855378325, Duration: 100.37 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.8568, Val_Loss: 2.5014, Total Mean Loss: 3.1791, LR: 0.007961072761562845, Duration: 100.54 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.8742, Val_Loss: 2.4791, Total Mean Loss: 3.1766, LR: 0.007939231771661183, Duration: 100.63 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 43/43 [01:38<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.8121, Val_Loss: 2.4378, Total Mean Loss: 3.1249, LR: 0.007912591495555185, Duration: 100.28 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7935, Val_Loss: 2.3504, Total Mean Loss: 3.0720, LR: 0.007881184390317672, Duration: 100.52 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7920, Val_Loss: 2.3335, Total Mean Loss: 3.0627, LR: 0.007845048720668478, Duration: 100.52 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6700, Val_Loss: 2.2259, Total Mean Loss: 2.9479, LR: 0.007804228512354801, Duration: 100.43 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7042, Val_Loss: 2.2884, Total Mean Loss: 2.9963, LR: 0.007758773498512596, Duration: 100.49 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 43/43 [01:38<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6644, Val_Loss: 2.1908, Total Mean Loss: 2.9276, LR: 0.0077087390590744225, Duration: 100.23 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 43/43 [01:39<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6292, Val_Loss: 2.1408, Total Mean Loss: 2.8850, LR: 0.007654186153297522, Duration: 100.40 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7409, Val_Loss: 2.1110, Total Mean Loss: 2.9260, LR: 0.007595181245494354, Duration: 100.54 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6410, Val_Loss: 2.2603, Total Mean Loss: 2.9507, LR: 0.007531796224056066, Duration: 100.76 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5527, Val_Loss: 1.9628, Total Mean Loss: 2.7578, LR: 0.007464108313867567, Duration: 100.63 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5798, Val_Loss: 1.9464, Total Mean Loss: 2.7631, LR: 0.007392199982220897, Duration: 100.89 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6128, Val_Loss: 1.8800, Total Mean Loss: 2.7464, LR: 0.00731615883834154, Duration: 100.75 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5899, Val_Loss: 1.9268, Total Mean Loss: 2.7584, LR: 0.007236077526650072, Duration: 100.62 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 43/43 [01:38<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4485, Val_Loss: 1.9016, Total Mean Loss: 2.6751, LR: 0.007152053613889208, Duration: 100.19 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5275, Val_Loss: 1.8578, Total Mean Loss: 2.6926, LR: 0.007064189470253756, Duration: 100.73 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6676, Val_Loss: 1.9018, Total Mean Loss: 2.7847, LR: 0.006972592144668304, Duration: 100.47 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 43/43 [01:39<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5159, Val_Loss: 1.6738, Total Mean Loss: 2.5948, LR: 0.0068773732343645885, Duration: 100.30 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5324, Val_Loss: 1.8111, Total Mean Loss: 2.6718, LR: 0.006778648748917467, Duration: 100.49 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5706, Val_Loss: 1.7862, Total Mean Loss: 2.6784, LR: 0.006676538968905116, Duration: 100.59 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4843, Val_Loss: 1.6578, Total Mean Loss: 2.5711, LR: 0.006571168299365673, Duration: 100.45 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.3912, Val_Loss: 1.5638, Total Mean Loss: 2.4775, LR: 0.006462665118228867, Duration: 100.48 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.3838, Val_Loss: 1.6775, Total Mean Loss: 2.5307, LR: 0.006351161619907278, Duration: 100.57 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5325, Val_Loss: 1.6631, Total Mean Loss: 2.5978, LR: 0.006236793654237814, Duration: 100.44 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.3121, Val_Loss: 1.6552, Total Mean Loss: 2.4836, LR: 0.006119700560969609, Duration: 100.46 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 43/43 [01:39<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4129, Val_Loss: 1.5627, Total Mean Loss: 2.4878, LR: 0.006000025000000001, Duration: 100.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2372, Val_Loss: 1.5768, Total Mean Loss: 2.4070, LR: 0.005877912777565424, Duration: 100.73 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2302, Val_Loss: 1.5773, Total Mean Loss: 2.4037, LR: 0.005753512668598971, Duration: 100.60 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4302, Val_Loss: 1.6255, Total Mean Loss: 2.5278, LR: 0.005626976235471049, Duration: 100.72 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.3796, Val_Loss: 1.5220, Total Mean Loss: 2.4508, LR: 0.005498457643333979, Duration: 100.54 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 43/43 [01:38<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2536, Val_Loss: 1.4852, Total Mean Loss: 2.3694, LR: 0.00536811347229551, Duration: 100.26 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2855, Val_Loss: 1.5251, Total Mean Loss: 2.4053, LR: 0.005236102526650072, Duration: 100.53 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2832, Val_Loss: 1.5162, Total Mean Loss: 2.3997, LR: 0.005102585641400206, Duration: 100.43 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2943, Val_Loss: 1.4627, Total Mean Loss: 2.3785, LR: 0.004967725486303891, Duration: 100.68 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2995, Val_Loss: 1.4473, Total Mean Loss: 2.3734, LR: 0.004831686367686497, Duration: 101.08 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.3219, Val_Loss: 1.3763, Total Mean Loss: 2.3491, LR: 0.004694634028258839, Duration: 100.59 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 43/43 [01:39<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1320, Val_Loss: 1.4075, Total Mean Loss: 2.2698, LR: 0.004556735445185214, Duration: 100.40 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2746, Val_Loss: 1.4412, Total Mean Loss: 2.3579, LR: 0.004418158626647451, Duration: 100.86 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2004, Val_Loss: 1.3892, Total Mean Loss: 2.2948, LR: 0.004279072407152814, Duration: 100.67 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 43/43 [01:38<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1925, Val_Loss: 1.3843, Total Mean Loss: 2.2884, LR: 0.00413964624183517, Duration: 100.27 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1447, Val_Loss: 1.3326, Total Mean Loss: 2.2386, LR: 0.004000050000000001, Duration: 100.46 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1338, Val_Loss: 1.4050, Total Mean Loss: 2.2694, LR: 0.0038604537581648324, Duration: 100.72 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1990, Val_Loss: 1.3835, Total Mean Loss: 2.2912, LR: 0.0037210275928471863, Duration: 100.73 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1572, Val_Loss: 1.3433, Total Mean Loss: 2.2503, LR: 0.00358194137335255, Duration: 100.51 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1754, Val_Loss: 1.3191, Total Mean Loss: 2.2473, LR: 0.0034433645548147874, Duration: 100.64 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9605, Val_Loss: 1.2526, Total Mean Loss: 2.1065, LR: 0.0033054659717411624, Duration: 101.97 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1017, Val_Loss: 1.3486, Total Mean Loss: 2.2251, LR: 0.003168413632313504, Duration: 101.92 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0155, Val_Loss: 1.3594, Total Mean Loss: 2.1875, LR: 0.00303237451369611, Duration: 100.74 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|██████████| 43/43 [01:39<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1382, Val_Loss: 1.3734, Total Mean Loss: 2.2558, LR: 0.0028975143585997947, Duration: 100.38 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1314, Val_Loss: 1.2887, Total Mean Loss: 2.2100, LR: 0.0027639974733499294, Duration: 100.61 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|██████████| 43/43 [01:38<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0142, Val_Loss: 1.1900, Total Mean Loss: 2.1021, LR: 0.002631986527704492, Duration: 100.23 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66: 100%|██████████| 43/43 [01:38<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0806, Val_Loss: 1.2947, Total Mean Loss: 2.1877, LR: 0.0025016423566660228, Duration: 100.25 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0932, Val_Loss: 1.3342, Total Mean Loss: 2.2137, LR: 0.0023731237645289536, Duration: 100.70 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0969, Val_Loss: 1.2463, Total Mean Loss: 2.1716, LR: 0.0022465873314010294, Duration: 100.70 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0450, Val_Loss: 1.2923, Total Mean Loss: 2.1687, LR: 0.002122187222434577, Duration: 100.47 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0943, Val_Loss: 1.2782, Total Mean Loss: 2.1862, LR: 0.002000075000000001, Duration: 100.55 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0408, Val_Loss: 1.2648, Total Mean Loss: 2.1528, LR: 0.0018803994390303928, Duration: 101.20 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0290, Val_Loss: 1.2236, Total Mean Loss: 2.1263, LR: 0.001763306345762187, Duration: 100.60 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0486, Val_Loss: 1.2341, Total Mean Loss: 2.1414, LR: 0.0016489383800927227, Duration: 100.56 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9271, Val_Loss: 1.1678, Total Mean Loss: 2.0474, LR: 0.0015374348817711334, Duration: 100.88 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0844, Val_Loss: 1.1964, Total Mean Loss: 2.1404, LR: 0.001428931700634327, Duration: 100.64 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0100, Val_Loss: 1.2416, Total Mean Loss: 2.1258, LR: 0.0013235610310948864, Duration: 100.60 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8591, Val_Loss: 1.1633, Total Mean Loss: 2.0112, LR: 0.0012214512510825336, Duration: 100.82 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8560, Val_Loss: 1.1747, Total Mean Loss: 2.0153, LR: 0.0011227267656354132, Duration: 100.66 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8389, Val_Loss: 1.1418, Total Mean Loss: 1.9903, LR: 0.0010275078553316965, Duration: 100.92 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0686, Val_Loss: 1.2144, Total Mean Loss: 2.1415, LR: 0.0009359105297462444, Duration: 100.72 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9352, Val_Loss: 1.1566, Total Mean Loss: 2.0459, LR: 0.0008480463861107927, Duration: 101.08 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8527, Val_Loss: 1.1463, Total Mean Loss: 1.9995, LR: 0.0007640224733499294, Duration: 100.57 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8976, Val_Loss: 1.1636, Total Mean Loss: 2.0306, LR: 0.0006839411616584612, Duration: 100.56 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8936, Val_Loss: 1.1700, Total Mean Loss: 2.0318, LR: 0.000607900017779104, Duration: 100.70 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0081, Val_Loss: 1.1936, Total Mean Loss: 2.1009, LR: 0.0005359916861324344, Duration: 100.71 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7602, Val_Loss: 1.1640, Total Mean Loss: 1.9621, LR: 0.000468303775943935, Duration: 100.42 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87: 100%|██████████| 43/43 [01:42<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7813, Val_Loss: 1.1519, Total Mean Loss: 1.9666, LR: 0.0004049187545056477, Duration: 103.66 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9038, Val_Loss: 1.1713, Total Mean Loss: 2.0376, LR: 0.00034591384670247825, Duration: 100.56 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0139, Val_Loss: 1.1652, Total Mean Loss: 2.0896, LR: 0.0002913609409255791, Duration: 101.11 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9268, Val_Loss: 1.1752, Total Mean Loss: 2.0510, LR: 0.00024132650148740606, Duration: 101.75 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9417, Val_Loss: 1.1704, Total Mean Loss: 2.0560, LR: 0.00019587148764520066, Duration: 101.03 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8609, Val_Loss: 1.1657, Total Mean Loss: 2.0133, LR: 0.00015505127933152136, Duration: 101.13 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9111, Val_Loss: 1.1582, Total Mean Loss: 2.0346, LR: 0.00011891560968232792, Duration: 100.41 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94: 100%|██████████| 43/43 [01:40<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0383, Val_Loss: 1.1606, Total Mean Loss: 2.0994, LR: 8.750850444481394e-05, Duration: 101.49 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9857, Val_Loss: 1.1684, Total Mean Loss: 2.0771, LR: 6.0868228338818537e-05, Duration: 101.15 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96: 100%|██████████| 43/43 [01:42<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9267, Val_Loss: 1.1653, Total Mean Loss: 2.0460, LR: 3.902723843715564e-05, Duration: 103.47 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97: 100%|██████████| 43/43 [01:41<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9583, Val_Loss: 1.1643, Total Mean Loss: 2.0613, LR: 2.2012144621675257e-05, Duration: 102.74 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98: 100%|██████████| 43/43 [01:40<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9929, Val_Loss: 1.1624, Total Mean Loss: 2.0776, LR: 9.843677163216202e-06, Duration: 101.97 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 43/43 [01:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9072, Val_Loss: 1.1625, Total Mean Loss: 2.0349, LR: 2.5366614649679064e-06, Duration: 100.77 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100: 100%|██████████| 43/43 [01:39<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8787, Val_Loss: 1.1627, Total Mean Loss: 2.0207, LR: 1e-07, Duration: 100.85 sec\n",
      "\n",
      "[100 epoch result]\n",
      "       Metric     Value\n",
      "0   Accuracy  0.780000\n",
      "1  Precision  0.799696\n",
      "2     Recall  0.780000\n",
      "3   F1 Score  0.771682\n"
     ]
    }
   ],
   "source": [
    "training_time = 0\n",
    "losses = []\n",
    "val_losses = []\n",
    "lrs = []\n",
    "best_loss = float('inf')\n",
    "model_save = False\n",
    "\n",
    "for i in range(epochs // 100):\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1 + i*100}\")\n",
    "        \n",
    "        for _, data in pbar:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            inputs, labels = mixup_fn(inputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "                \n",
    "            loss.backward()\n",
    "            # 그라디언트 클리핑 적용\n",
    "            clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # EMA 모델 업데이트, 필요한 경우\n",
    "            if model_ema is not None:\n",
    "                model_ema.update(model)\n",
    "                \n",
    "            scheduler.step()\n",
    "                \n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "            lrs.append(lr)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        losses.append(epoch_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for data in valid_loader:\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "        val_loss /= len(valid_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # 모델 저장 조건 수정\n",
    "        total_loss = val_loss + epoch_loss\n",
    "        if total_loss < best_loss:\n",
    "            best_loss = total_loss\n",
    "            # torch.save(model.state_dict(), model_path)\n",
    "            model_save = True\n",
    "            save_text = ' - model saved!'\n",
    "        else:\n",
    "            save_text = ''\n",
    "\n",
    "        epoch_duration = time.time() - start_time\n",
    "        training_time += epoch_duration\n",
    "        \n",
    "        text = f'\\tLoss: {epoch_loss:.4f}, Val_Loss: {val_loss:.4f}, Total Mean Loss: {total_loss/2:.4f}, LR: {lr}, Duration: {epoch_duration:.2f} sec{save_text}'\n",
    "        print(text)\n",
    "\n",
    "    # 예측 수행 및 레이블 저장\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # 혼동 행렬 생성\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # 예측과 실제 레이블\n",
    "    y_true = all_labels  # 실제 레이블\n",
    "    y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "    # 전체 데이터셋에 대한 정확도\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "    # 판다스 데이터프레임으로 결과 정리\n",
    "    performance_metrics = pd.DataFrame({\n",
    "        'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "        'Value': [accuracy, precision, recall, f1_score]\n",
    "    })\n",
    "\n",
    "    # 데이터프레임 출력\n",
    "    print(f\"\\n[{i*100+100} epoch result]\\n\", performance_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 53/53 [01:41<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.5950, Val_Loss: 4.1453, Total Mean Loss: 4.3702, LR: 0.00080009, Duration: 103.15 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 53/53 [01:39<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.4743, Val_Loss: 4.0018, Total Mean Loss: 4.2381, LR: 0.0016000800000000003, Duration: 100.79 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 53/53 [01:40<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.4219, Val_Loss: 3.7958, Total Mean Loss: 4.1088, LR: 0.00240007, Duration: 101.36 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 53/53 [01:39<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.3900, Val_Loss: 3.7397, Total Mean Loss: 4.0649, LR: 0.0032000600000000002, Duration: 100.97 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 53/53 [01:39<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.3341, Val_Loss: 3.6376, Total Mean Loss: 3.9859, LR: 0.004000050000000001, Duration: 100.68 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.2782, Val_Loss: 3.5548, Total Mean Loss: 3.9165, LR: 0.00480004, Duration: 100.57 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.2267, Val_Loss: 3.5453, Total Mean Loss: 3.8860, LR: 0.005600030000000001, Duration: 100.35 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.1982, Val_Loss: 3.4035, Total Mean Loss: 3.8008, LR: 0.006400020000000001, Duration: 100.46 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.1818, Val_Loss: 3.3875, Total Mean Loss: 3.7846, LR: 0.007200010000000001, Duration: 100.41 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 53/53 [01:38<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.1136, Val_Loss: 3.3307, Total Mean Loss: 3.7221, LR: 0.008, Duration: 100.29 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.1009, Val_Loss: 3.2129, Total Mean Loss: 3.6569, LR: 0.007997563338535033, Duration: 100.33 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.1097, Val_Loss: 3.1263, Total Mean Loss: 3.6180, LR: 0.007990256322836784, Duration: 100.57 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.0599, Val_Loss: 3.1223, Total Mean Loss: 3.5911, LR: 0.007978087855378325, Duration: 100.44 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 4.0101, Val_Loss: 2.9449, Total Mean Loss: 3.4775, LR: 0.007961072761562845, Duration: 100.31 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.9389, Val_Loss: 2.8412, Total Mean Loss: 3.3900, LR: 0.007939231771661183, Duration: 100.35 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 53/53 [01:38<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.9606, Val_Loss: 2.7031, Total Mean Loss: 3.3318, LR: 0.007912591495555185, Duration: 100.07 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.9554, Val_Loss: 2.6873, Total Mean Loss: 3.3214, LR: 0.007881184390317672, Duration: 100.29 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.8809, Val_Loss: 2.6832, Total Mean Loss: 3.2821, LR: 0.007845048720668478, Duration: 100.26 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.8607, Val_Loss: 2.6046, Total Mean Loss: 3.2326, LR: 0.007804228512354801, Duration: 100.28 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 53/53 [01:39<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.9065, Val_Loss: 2.6144, Total Mean Loss: 3.2604, LR: 0.007758773498512596, Duration: 100.74 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 53/53 [01:39<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.8473, Val_Loss: 2.4817, Total Mean Loss: 3.1645, LR: 0.0077087390590744225, Duration: 101.22 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7878, Val_Loss: 2.4968, Total Mean Loss: 3.1423, LR: 0.007654186153297522, Duration: 100.28 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 53/53 [01:39<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.8438, Val_Loss: 2.4143, Total Mean Loss: 3.1290, LR: 0.007595181245494354, Duration: 100.72 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 53/53 [01:38<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7342, Val_Loss: 2.1994, Total Mean Loss: 2.9668, LR: 0.007531796224056066, Duration: 100.29 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7472, Val_Loss: 2.0719, Total Mean Loss: 2.9096, LR: 0.007464108313867567, Duration: 100.27 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 53/53 [01:38<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6859, Val_Loss: 2.3841, Total Mean Loss: 3.0350, LR: 0.007392199982220897, Duration: 100.18 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 53/53 [01:38<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7741, Val_Loss: 2.3366, Total Mean Loss: 3.0553, LR: 0.00731615883834154, Duration: 100.17 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 53/53 [01:38<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5131, Val_Loss: 1.9265, Total Mean Loss: 2.7198, LR: 0.007236077526650072, Duration: 100.15 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 53/53 [01:38<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.6372, Val_Loss: 2.2424, Total Mean Loss: 2.9398, LR: 0.007152053613889208, Duration: 100.14 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.7462, Val_Loss: 2.1536, Total Mean Loss: 2.9499, LR: 0.007064189470253756, Duration: 100.26 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4918, Val_Loss: 1.6969, Total Mean Loss: 2.5943, LR: 0.006972592144668304, Duration: 100.28 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 53/53 [01:38<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5671, Val_Loss: 1.8910, Total Mean Loss: 2.7291, LR: 0.0068773732343645885, Duration: 100.24 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5183, Val_Loss: 1.7305, Total Mean Loss: 2.6244, LR: 0.006778648748917467, Duration: 100.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4650, Val_Loss: 1.8143, Total Mean Loss: 2.6396, LR: 0.006676538968905116, Duration: 100.35 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.5158, Val_Loss: 1.9125, Total Mean Loss: 2.7142, LR: 0.006571168299365673, Duration: 100.57 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 53/53 [01:39<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4353, Val_Loss: 1.7001, Total Mean Loss: 2.5677, LR: 0.006462665118228867, Duration: 100.66 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4231, Val_Loss: 1.6558, Total Mean Loss: 2.5395, LR: 0.006351161619907278, Duration: 100.42 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.4246, Val_Loss: 1.6772, Total Mean Loss: 2.5509, LR: 0.006236793654237814, Duration: 100.34 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 53/53 [01:38<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.3955, Val_Loss: 1.6819, Total Mean Loss: 2.5387, LR: 0.006119700560969609, Duration: 100.21 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 53/53 [01:38<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.3652, Val_Loss: 1.4796, Total Mean Loss: 2.4224, LR: 0.006000025000000001, Duration: 100.18 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.3364, Val_Loss: 1.4906, Total Mean Loss: 2.4135, LR: 0.005877912777565424, Duration: 100.48 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.3491, Val_Loss: 1.5221, Total Mean Loss: 2.4356, LR: 0.005753512668598971, Duration: 100.56 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2630, Val_Loss: 1.3132, Total Mean Loss: 2.2881, LR: 0.005626976235471049, Duration: 100.36 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2669, Val_Loss: 1.4940, Total Mean Loss: 2.3805, LR: 0.005498457643333979, Duration: 100.54 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2238, Val_Loss: 1.2956, Total Mean Loss: 2.2597, LR: 0.00536811347229551, Duration: 100.38 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2199, Val_Loss: 1.3076, Total Mean Loss: 2.2638, LR: 0.005236102526650072, Duration: 100.38 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0790, Val_Loss: 1.3395, Total Mean Loss: 2.2093, LR: 0.005102585641400206, Duration: 100.55 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.2223, Val_Loss: 1.4247, Total Mean Loss: 2.3235, LR: 0.004967725486303891, Duration: 100.48 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0647, Val_Loss: 1.2575, Total Mean Loss: 2.1611, LR: 0.004831686367686497, Duration: 100.35 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 53/53 [01:39<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1002, Val_Loss: 1.2536, Total Mean Loss: 2.1769, LR: 0.004694634028258839, Duration: 100.68 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1481, Val_Loss: 1.1780, Total Mean Loss: 2.1631, LR: 0.004556735445185214, Duration: 100.47 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9954, Val_Loss: 1.2351, Total Mean Loss: 2.1153, LR: 0.004418158626647451, Duration: 100.29 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9960, Val_Loss: 1.2575, Total Mean Loss: 2.1268, LR: 0.004279072407152814, Duration: 100.52 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.1454, Val_Loss: 1.2170, Total Mean Loss: 2.1812, LR: 0.00413964624183517, Duration: 100.39 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0753, Val_Loss: 1.1802, Total Mean Loss: 2.1278, LR: 0.004000050000000001, Duration: 100.43 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9854, Val_Loss: 1.1241, Total Mean Loss: 2.0548, LR: 0.0038604537581648324, Duration: 100.51 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0592, Val_Loss: 1.2451, Total Mean Loss: 2.1521, LR: 0.0037210275928471863, Duration: 100.32 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8498, Val_Loss: 1.0461, Total Mean Loss: 1.9479, LR: 0.00358194137335255, Duration: 100.52 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 53/53 [01:39<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0221, Val_Loss: 1.1233, Total Mean Loss: 2.0727, LR: 0.0034433645548147874, Duration: 100.73 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|██████████| 53/53 [01:39<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 3.0172, Val_Loss: 1.0411, Total Mean Loss: 2.0291, LR: 0.0033054659717411624, Duration: 100.79 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7804, Val_Loss: 1.0907, Total Mean Loss: 1.9356, LR: 0.003168413632313504, Duration: 100.34 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|██████████| 53/53 [01:38<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.9019, Val_Loss: 1.1806, Total Mean Loss: 2.0412, LR: 0.00303237451369611, Duration: 100.27 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7794, Val_Loss: 0.9896, Total Mean Loss: 1.8845, LR: 0.0028975143585997947, Duration: 100.63 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|██████████| 53/53 [01:39<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8134, Val_Loss: 1.0241, Total Mean Loss: 1.9187, LR: 0.0027639974733499294, Duration: 100.72 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7360, Val_Loss: 0.9448, Total Mean Loss: 1.8404, LR: 0.002631986527704492, Duration: 100.32 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.8561, Val_Loss: 1.0950, Total Mean Loss: 1.9755, LR: 0.0025016423566660228, Duration: 100.30 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5907, Val_Loss: 0.9677, Total Mean Loss: 1.7792, LR: 0.0023731237645289536, Duration: 100.32 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6671, Val_Loss: 0.9903, Total Mean Loss: 1.8287, LR: 0.0022465873314010294, Duration: 100.53 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 100%|██████████| 53/53 [01:38<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6060, Val_Loss: 0.9529, Total Mean Loss: 1.7795, LR: 0.002122187222434577, Duration: 100.21 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70: 100%|██████████| 53/53 [01:38<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6892, Val_Loss: 1.0041, Total Mean Loss: 1.8466, LR: 0.002000075000000001, Duration: 100.25 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71: 100%|██████████| 53/53 [01:41<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6691, Val_Loss: 0.9944, Total Mean Loss: 1.8318, LR: 0.0018803994390303928, Duration: 102.34 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72: 100%|██████████| 53/53 [01:39<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5781, Val_Loss: 0.9373, Total Mean Loss: 1.7577, LR: 0.001763306345762187, Duration: 100.83 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73: 100%|██████████| 53/53 [01:39<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7129, Val_Loss: 0.9540, Total Mean Loss: 1.8334, LR: 0.0016489383800927227, Duration: 100.65 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6384, Val_Loss: 0.9378, Total Mean Loss: 1.7881, LR: 0.0015374348817711334, Duration: 100.51 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75: 100%|██████████| 53/53 [01:39<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4799, Val_Loss: 0.9027, Total Mean Loss: 1.6913, LR: 0.001428931700634327, Duration: 100.69 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5822, Val_Loss: 0.8696, Total Mean Loss: 1.7259, LR: 0.0013235610310948864, Duration: 100.49 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5972, Val_Loss: 0.9180, Total Mean Loss: 1.7576, LR: 0.0012214512510825336, Duration: 100.58 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6590, Val_Loss: 0.9583, Total Mean Loss: 1.8086, LR: 0.0011227267656354132, Duration: 100.57 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5161, Val_Loss: 0.9193, Total Mean Loss: 1.7177, LR: 0.0010275078553316965, Duration: 100.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6772, Val_Loss: 0.9182, Total Mean Loss: 1.7977, LR: 0.0009359105297462444, Duration: 100.55 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81: 100%|██████████| 53/53 [01:38<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4884, Val_Loss: 0.8812, Total Mean Loss: 1.6848, LR: 0.0008480463861107927, Duration: 100.15 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5202, Val_Loss: 0.8777, Total Mean Loss: 1.6989, LR: 0.0007640224733499294, Duration: 100.48 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.7413, Val_Loss: 0.9471, Total Mean Loss: 1.8442, LR: 0.0006839411616584612, Duration: 100.54 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5241, Val_Loss: 0.8664, Total Mean Loss: 1.6953, LR: 0.000607900017779104, Duration: 100.56 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5300, Val_Loss: 0.8870, Total Mean Loss: 1.7085, LR: 0.0005359916861324344, Duration: 100.55 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4429, Val_Loss: 0.8650, Total Mean Loss: 1.6540, LR: 0.000468303775943935, Duration: 100.62 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87: 100%|██████████| 53/53 [01:39<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6560, Val_Loss: 0.8964, Total Mean Loss: 1.7762, LR: 0.0004049187545056477, Duration: 100.85 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5887, Val_Loss: 0.8557, Total Mean Loss: 1.7222, LR: 0.00034591384670247825, Duration: 100.54 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 53/53 [01:39<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4711, Val_Loss: 0.8516, Total Mean Loss: 1.6613, LR: 0.0002913609409255791, Duration: 100.97 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90: 100%|██████████| 53/53 [01:40<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5234, Val_Loss: 0.8694, Total Mean Loss: 1.6964, LR: 0.00024132650148740606, Duration: 101.34 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91: 100%|██████████| 53/53 [01:39<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5279, Val_Loss: 0.8560, Total Mean Loss: 1.6920, LR: 0.00019587148764520066, Duration: 100.64 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92: 100%|██████████| 53/53 [01:40<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5953, Val_Loss: 0.8657, Total Mean Loss: 1.7305, LR: 0.00015505127933152136, Duration: 101.71 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93: 100%|██████████| 53/53 [01:41<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.6174, Val_Loss: 0.8608, Total Mean Loss: 1.7391, LR: 0.00011891560968232792, Duration: 102.95 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94: 100%|██████████| 53/53 [01:41<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4460, Val_Loss: 0.8459, Total Mean Loss: 1.6459, LR: 8.750850444481394e-05, Duration: 102.68 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95: 100%|██████████| 53/53 [01:41<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5132, Val_Loss: 0.8560, Total Mean Loss: 1.6846, LR: 6.0868228338818537e-05, Duration: 102.48 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96: 100%|██████████| 53/53 [01:41<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4481, Val_Loss: 0.8532, Total Mean Loss: 1.6506, LR: 3.902723843715564e-05, Duration: 102.59 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97: 100%|██████████| 53/53 [01:41<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.4170, Val_Loss: 0.8491, Total Mean Loss: 1.6330, LR: 2.2012144621675257e-05, Duration: 102.89 sec - model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98: 100%|██████████| 53/53 [01:41<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5952, Val_Loss: 0.8477, Total Mean Loss: 1.7215, LR: 9.843677163216202e-06, Duration: 103.13 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 53/53 [01:40<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5665, Val_Loss: 0.8481, Total Mean Loss: 1.7073, LR: 2.5366614649679064e-06, Duration: 102.18 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100: 100%|██████████| 53/53 [01:40<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 2.5940, Val_Loss: 0.8485, Total Mean Loss: 1.7212, LR: 1e-07, Duration: 101.85 sec\n",
      "\n",
      "[100 epoch result]\n",
      "       Metric     Value\n",
      "0   Accuracy  0.858000\n",
      "1  Precision  0.885246\n",
      "2     Recall  0.858000\n",
      "3   F1 Score  0.852777\n"
     ]
    }
   ],
   "source": [
    "training_time = 0\n",
    "losses = []\n",
    "val_losses = []\n",
    "lrs = []\n",
    "best_loss = float('inf')\n",
    "model_save = False\n",
    "\n",
    "for i in range(epochs // 100):\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1 + i*100}\")\n",
    "        \n",
    "        for _, data in pbar:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            inputs, labels = mixup_fn(inputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "                \n",
    "            loss.backward()\n",
    "            # 그라디언트 클리핑 적용\n",
    "            clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # EMA 모델 업데이트, 필요한 경우\n",
    "            if model_ema is not None:\n",
    "                model_ema.update(model)\n",
    "                \n",
    "            scheduler.step()\n",
    "                \n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "            lrs.append(lr)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        losses.append(epoch_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for data in valid_loader:\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "        val_loss /= len(valid_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # 모델 저장 조건 수정\n",
    "        total_loss = val_loss + epoch_loss\n",
    "        if total_loss < best_loss:\n",
    "            best_loss = total_loss\n",
    "            # torch.save(model.state_dict(), model_path)\n",
    "            model_save = True\n",
    "            save_text = ' - model saved!'\n",
    "        else:\n",
    "            save_text = ''\n",
    "\n",
    "        epoch_duration = time.time() - start_time\n",
    "        training_time += epoch_duration\n",
    "        \n",
    "        text = f'\\tLoss: {epoch_loss:.4f}, Val_Loss: {val_loss:.4f}, Total Mean Loss: {total_loss/2:.4f}, LR: {lr}, Duration: {epoch_duration:.2f} sec{save_text}'\n",
    "        print(text)\n",
    "\n",
    "    # 예측 수행 및 레이블 저장\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # 혼동 행렬 생성\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # 예측과 실제 레이블\n",
    "    y_true = all_labels  # 실제 레이블\n",
    "    y_pred = all_preds  # 모델에 의해 예측된 레이블\n",
    "\n",
    "    # 전체 데이터셋에 대한 정확도\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # 평균 정밀도, 리콜, F1-Score ('weighted')\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "    # 판다스 데이터프레임으로 결과 정리\n",
    "    performance_metrics = pd.DataFrame({\n",
    "        'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "        'Value': [accuracy, precision, recall, f1_score]\n",
    "    })\n",
    "\n",
    "    # 데이터프레임 출력\n",
    "    print(f\"\\n[{i*100+100} epoch result]\\n\", performance_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
