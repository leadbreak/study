{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_theta_pos_frequencies(head_dim:int, seq_len:int, device:str, theta:float=10000.0):\n",
    "    assert head_dim % 2 == 0, \"Dimension (divided with head) must be divisible by 2\"\n",
    "    \n",
    "    theta_numerator = torch.arange(0, head_dim, 2).float()\n",
    "    theta = 1.0 / (theta ** (theta_numerator / head_dim)).to(device)\n",
    "    m = torch.arange(seq_len, device=device)\n",
    "    freqs = torch.outer(m, theta).float() # (seq_len) outer product* (head_dim / 2) -> (seq_len, head_dim/2)\n",
    "    \n",
    "    # torch.polar = abs⋅cos(angle)+abs⋅sin(angle)⋅j\n",
    "    freqs_complex = torch.polar(torch.ones_like(freqs), freqs)\n",
    "    return freqs_complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rotary_embeddings(x: torch.Tensor, freqs_complex:torch.Tensor, device:str):\n",
    "    # (B, seq_len, num_heads, head_dim) -> (B, seq_len, num_heads, head_dim/2)\n",
    "    x_complex = torch.view_as_complex(x.float().reshape(*x.shape[:-1], -1, 2))\n",
    "    # (seq_len, head_dim/2) -> (1, seq_len, 1, head_dim/2)\n",
    "    freqs_complex = freqs_complex.unsqueeze(0).unsqueeze(2)\n",
    "    # (B, seq_len, num_heads, head_dim/2) * (1, seq_len, 1, head_dim/2) = (B, seq_len, num_heads, head_dim/2)\n",
    "    x_rotated = x_complex * freqs_complex\n",
    "    # (B, seq_len, num_heads, head_dim/2) -> (B, seq_len, num_heads, head_dim/2, 2)\n",
    "    x_out = torch.view_as_real(x_rotated)\n",
    "    # (B, seq_len, num_heads, head_dim/2, 2) -> (B, seq_len, num_heads, head)\n",
    "    x_out = x_out.reshape(*x.shape)\n",
    "    return x_out.type_as(x).to(device)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-8):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "        \n",
    "    def _reciprocal_rms(self, x: torch.Tensor):\n",
    "        '''\n",
    "        rms(x) = sqrt(mean(x^2))\n",
    "        reciprocal_rms(x) = x / rms(x)\n",
    "        '''\n",
    "        \n",
    "        # (B, seq_len, dim) * (B,. seq_len, 1) -> (B, seq_len, dim)\n",
    "        return x * torch.rsqrt(x.pow(2).mean(dim=self.dim, keepdim=True) + self.eps)\n",
    "    \n",
    "    def forward(self, x:torch.Tensor):        \n",
    "        # (dim) * (B, seq_len, dim) -> (B, seq_len, dim)\n",
    "        return self.weight * self._reciprocal_rms(x).type_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelArgs:\n",
    "    dim: int = 768      # llama: 4096, gpt: 768\n",
    "    n_layers: int = 4   # llama: 32, gpt: 12\n",
    "    n_heads: int = 4    # llama: 16, gpt: 12\n",
    "    n_kv_heads: Optional[int] = None\n",
    "    vocal_size: int = -1\n",
    "    multiple_of: int = 4 # llama: 256, gpt: 64\n",
    "    ffn_dim_multiplier: Optional[float] = None\n",
    "    norm_eps: float = 1e-6\n",
    "    \n",
    "    # needed for KV cache\n",
    "    max_batch_size: int = 32\n",
    "    max_seq_len: int = 1024   # llama: 2048, gpt: 1024\n",
    "    \n",
    "    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_kv(x: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
    "    '''\n",
    "    x: (B, seq_len, dim) -> (B, seq_len, n_rep, dim)\n",
    "    '''\n",
    "    \n",
    "    batch_size, seq_len, n_kv_heads, head_dim = x.shape\n",
    "    if n_rep == 1:\n",
    "        return x\n",
    "    else:\n",
    "        return (\n",
    "            x[:, :, :, None, :]\n",
    "            .expand(batch_size, seq_len, n_kv_heads, n_rep, head_dim)\n",
    "            .reshape(batch_size, seq_len, n_kv_heads * n_rep, head_dim)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        super().__init__()\n",
    "        \n",
    "        # calculate n_heads of Grouped Attention with KV cache\n",
    "        self.n_kv_heads = args.n_heads if args.n_kv_heads is None else args.n_kv_heads\n",
    "        self.n_heads_q = args.n_heads\n",
    "        self.n_rep = self.n_heads_q // self.n_kv_heads\n",
    "        self.head_dim = args.dim // self.n_heads_q      \n",
    "        \n",
    "        self.wq = nn.Linear(args.dim, self.n_heads_q * self.head_dim, bias=False)       \n",
    "        self.wk = nn.Linear(args.dim, self.n_kv_heads * self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(args.dim, self.n_kv_heads * self.head_dim, bias=False)\n",
    "        self.wo = nn.Linear(args.dim, args.dim, bias=False) \n",
    "        \n",
    "        self.cache_k = torch.zeros((args.max_batch_size, args.max_seq_len, self.n_kv_heads, self.head_dim), device=args.device)\n",
    "        self.cache_v = torch.zeros((args.max_batch_size, args.max_seq_len, self.n_kv_heads, self.head_dim), device=args.device)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_complex: torch.Tensor):\n",
    "        batch_size, seq_len, _ = x.size() # (B, seq_len, dim)\n",
    "        \n",
    "        xq = self.wq(x) # (B, seq_len, dim) -> (B, seq_len, n_heads_q * head_dim)\n",
    "        xk = self.wk(x) # (B, seq_len, dim) -> (B, seq_len, n_heads_kv * head_dim)\n",
    "        xv = self.wv(x) # (B, seq_len, dim) -> (B, seq_len, n_heads_kv * head_dim)\n",
    "        \n",
    "        xq = xq.view(batch_size, seq_len, self.n_heads_q, self.head_dim) # (B, seq_len, n_heads_q * head_dim) -> (B, seq_len, n_heads_q, head_dim)\n",
    "        xk = xk.view(batch_size, seq_len, self.n_kv_heads, self.head_dim) # (B, seq_len, n_heads_kv * head_dim) -> (B, seq_len, n_heads_kv, head_dim) \n",
    "        xv = xv.view(batch_size, seq_len, self.n_kv_heads, self.head_dim) # (B, seq_len, n_heads_kv * head_dim) -> (B, seq_len, n_heads_kv, head_dim)\n",
    "        \n",
    "        # position encoding for query, key\n",
    "        xq = apply_rotary_embeddings(xq, freqs_complex, x.device)\n",
    "        xk = apply_rotary_embeddings(xk, freqs_complex, x.device)\n",
    "        \n",
    "        # Replace the 4entry in the cache with the new values\n",
    "        self.cache_k[:batch_size, start_pos:start_pos+seq_len] = xk\n",
    "        self.cache_v[:batch_size, start_pos:start_pos+seq_len] = xv\n",
    "        \n",
    "        # (B, seq_len_kv, n_heads_kv, head_dim) \n",
    "        keys = self.cache_k[:batch_size, :start_pos+seq_len]\n",
    "        values = self.cache_v[:batch_size, :start_pos+seq_len]\n",
    "        \n",
    "        # repeat the heads of K and V to match the number of heads of Q\n",
    "        keys = repeat_kv(keys, self.n_rep)\n",
    "        values = repeat_kv(values, self.n_rep)\n",
    "        \n",
    "        # (B, seq_len, n_heads_q, head_dim) -> (B, n_heads_q, seq_len, head_dim)\n",
    "        xq = xq.transpose(1, 2)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        \n",
    "        # (B, n_heads_q, seq_len, head_dim) * (B, n_heads_q, head_dim, seq_len_kv) -> (B, n_heads_q, seq_len, seq_len_kv)\n",
    "        scores = torch.matmul(xq, keys.transpose(2, 3) / torch.sqrt(self.head_dim))\n",
    "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "        \n",
    "        # (B, n_heads_q, seq_len, seq_len_kv) * (B, n_heads_q, seq_len_kv, head_dim) -> (B, n_heads_q, seq_len, head_dim)\n",
    "        out = torch.matmul(scores, values)\n",
    "        \n",
    "        # (B, n_heads_q, seq_len, head_dim) -> (B, seq_len, n_heads_q, head_dim) -> (B, seq_len, dim)\n",
    "        out = (out.transpose(1, 2).continguous().view(batch_size, seq_len, self.n_heads_q * self.head_dim))\n",
    "        # (B, seq_len, dim) -> (B, seq_len, dim)\n",
    "        out = self.wo(out) \n",
    "        return out "
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        args: ModelArgs\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        hidden_dim = 4 * args.dim\n",
    "        hidden_dim = int(2 * hidden_dim / 3)\n",
    "        if args.ffn_dim_multiplier is not None:\n",
    "            hidden_dim = int(args.ffn_dim_multiplier * hidden_dim)\n",
    "        # Round the hidden_dim to the nearest multiple of the multiple_of parameter\n",
    "        hidden_dim = args.multiple_of * ((hidden_dim + args.multiple_of - 1) // args.multiple_of)\n",
    "\n",
    "        self.w1 = nn.Linear(args.dim, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(hidden_dim, args.dim, bias=False)\n",
    "        self.w3 = nn.Linear(args.dim, hidden_dim, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # (B, Seq_Len, Dim) --> (B, Seq_Len, Hidden_Dim)\n",
    "        swish = F.silu(self.w1(x))\n",
    "        # (B, Seq_Len, Dim) --> (B, Seq_Len, Hidden_Dim)\n",
    "        x_V = self.w3(x)\n",
    "        # (B, Seq_Len, Hidden_Dim) * (B, Seq_Len, Hidden_Dim) --> (B, Seq_Len, Hidden_Dim)\n",
    "        x = swish * x_V\n",
    "        # (B, Seq_Len, Hidden_Dim) --> (B, Seq_Len, Dim)\n",
    "        x = self.w2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.n_heads = args.n_heads\n",
    "        self.dim = args.dim\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        \n",
    "        self.attention = SelfAttention(args)\n",
    "        self.feed_forward = FeedForward(args)\n",
    "        \n",
    "        # PreNorm\n",
    "        self.attention_norm = RMSNorm(self.dim, eps=args.norm_eps)\n",
    "        self.ffn_norm = RMSNorm(self.dim, eps=args.norm_eps)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_complex: torch.Tensor):        \n",
    "        # attention\n",
    "        ## (B, seq_len, dim) + (B, seq_len, dim) -> (B, seq_len, dim)\n",
    "        y = self.attention_norm(x + self.attention(x, start_pos, freqs_complex))\n",
    "        \n",
    "        # feed forward\n",
    "        ## (B, seq_len, dim) -> (B, seq_len, dim)\n",
    "        y = self.ffn_norm(y + self.feed_forward(y))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        super().__init__()\n",
    "\n",
    "        assert args.vocab_size != -1, \"Vocab size must be set\"\n",
    "\n",
    "        self.args = args\n",
    "        self.vocab_size = args.vocab_size\n",
    "        self.n_layers = args.n_layers\n",
    "        self.tok_embeddings = nn.Embedding(self.vocab_size, args.dim)\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        for layer_id in range(args.n_layers):\n",
    "            self.layers.append(EncoderBlock(args))\n",
    "\n",
    "        self.norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "        self.output = nn.Linear(args.dim, self.vocab_size, bias=False)\n",
    "\n",
    "        self.freqs_complex = precompute_theta_pos_frequencies(self.args.dim // self.args.n_heads, self.args.max_seq_len * 2, device=self.args.device)\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, start_pos: int):\n",
    "        # (B, Seq_Len)\n",
    "        print('scout:', tokens.shape)\n",
    "        batch_size, seq_len = tokens.shape\n",
    "        # assert seq_len == 1, \"Only one token at a time can be processed\"\n",
    "\n",
    "        # (B, Seq_Len) -> (B, Seq_Len, Dim)\n",
    "        h = self.tok_embeddings(tokens)\n",
    "\n",
    "        # Retrieve the pairs (m, theta) corresponding to the positions [start_pos, start_pos + seq_len]\n",
    "        freqs_complex = self.freqs_complex[start_pos:start_pos + seq_len]\n",
    "        \n",
    "        # Consecutively apply all the encoder layers\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, start_pos, freqs_complex)\n",
    "        h = self.norm(h)\n",
    "        output = self.output(h).float()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelArgs(dim=768, n_layers=4, n_heads=4, n_kv_heads=None, vocal_size=-1, multiple_of=4, ffn_dim_multiplier=None, norm_eps=1e-06, max_batch_size=32, max_seq_len=1024, device='cpu')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = ModelArgs()\n",
    "args.vocab_size = 1024\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.cuda.FloatTensor) if args.device == 'cuda' else torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (tok_embeddings): Embedding(1024, 768)\n",
       "  (layers): ModuleList(\n",
       "    (0-3): 4 x EncoderBlock(\n",
       "      (attention): SelfAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (w1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "        (w2): Linear(in_features=2048, out_features=768, bias=False)\n",
       "        (w3): Linear(in_features=768, out_features=2048, bias=False)\n",
       "      )\n",
       "      (attention_norm): RMSNorm()\n",
       "      (ffn_norm): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       "  (output): Linear(in_features=768, out_features=1024, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Transformer(args)\n",
    "x_dummy = torch.rand((args.max_batch_size, args.max_seq_len))\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7816, 0.3278, 0.9132,  ..., 0.2087, 0.0720, 0.6012],\n",
       "        [0.7436, 0.4683, 0.2770,  ..., 0.8653, 0.2248, 0.2945],\n",
       "        [0.7328, 0.7063, 0.3597,  ..., 0.2407, 0.6196, 0.4967],\n",
       "        ...,\n",
       "        [0.5713, 0.9808, 0.3165,  ..., 0.7311, 0.0645, 0.3199],\n",
       "        [0.2580, 0.3368, 0.1721,  ..., 0.0085, 0.3915, 0.9030],\n",
       "        [0.8165, 0.7742, 0.4873,  ..., 0.3979, 0.8503, 0.9920]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = ModelArgs()\n",
    "\n",
    "x_dummy = torch.rand((args.max_batch_size, args.max_seq_len), device=args.device)\n",
    "\n",
    "x_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scout: torch.Size([32, 1024])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dummy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1023\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[10], line 29\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, tokens, start_pos)\u001b[0m\n\u001b[1;32m     25\u001b[0m batch_size, seq_len \u001b[38;5;241m=\u001b[39m tokens\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# assert seq_len == 1, \"Only one token at a time can be processed\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# (B, Seq_Len) -> (B, Seq_Len, Dim)\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtok_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Retrieve the pairs (m, theta) corresponding to the positions [start_pos, start_pos + seq_len]\u001b[39;00m\n\u001b[1;32m     32\u001b[0m freqs_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreqs_complex[start_pos:start_pos \u001b[38;5;241m+\u001b[39m seq_len]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "model(x_dummy, 1023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INFERENCE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import torch\n",
    "import time\n",
    "from pathlib import Path\n",
    "import json\n",
    "from sentencepiece import SentencePieceProcessor\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLaMA:\n",
    "    def __init__(self, model:Transformer, tokenizer:SentencePieceProcessor, model_args:ModelArgs):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model_args = model_args\n",
    "        \n",
    "    @staticmethod\n",
    "    def build(checkpoints_dir: str, tokenizer_path: str, load_model: bool, max_seq_len: int, max_batch_size: int, device: str):\n",
    "        prev_time = time.time()\n",
    "        if load_model:\n",
    "            checkpoints = sorted(Path(checkpoints_dir).glob('*.pth'))\n",
    "            assert len(checkpoints) > 0, \"No checkpoints found\"\n",
    "            chk_path = checkpoints[0]\n",
    "            print(f\"Loading model from {chk_path}\")\n",
    "            checkpoint = torch.load(chk_path, map_location='cpu')\n",
    "            print(f\"Loaded checkpoint in {time.time() - prev_time:.2f}s\")\n",
    "            prev_time = time.time()\n",
    "        with open(Path(checkpoints_dir) / \"params.json\", \"r\") as f:\n",
    "            params = ModelArgs(**json.load(f))\n",
    "        model_args: ModelArgs = ModelArgs(\n",
    "            max_batch_size=max_batch_size,\n",
    "            max_seq_len=max_seq_len,\n",
    "            device=device,\n",
    "            **vars(params)\n",
    "        )\n",
    "        \n",
    "        tokenizer = SentencePieceProcessor()\n",
    "        tokenizer.Load(tokenizer_path)\n",
    "        model_args.vocal_size = tokenizer.vocab_size()\n",
    "        \n",
    "        if device == 'cuda':\n",
    "            torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "        else:\n",
    "            torch.set_default_tensor_type(torch.FloatTensor)\n",
    "            \n",
    "        model = Transformer(model_args).to(device)\n",
    "        \n",
    "        if load_model:\n",
    "            model.load_state_dict(checkpoint['model'])\n",
    "            print(f\"Loaded model in {time.time() - prev_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ModelArgs()\n",
    "args.vocab_size = 1024\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Modern_Transformer(args)\n",
    "x_dummy = torch.rand((args.max_batch_size, args.max_seq_len))\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dummy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(x_dummy, 1023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
